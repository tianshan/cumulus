<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<!--NewPage-->
<HTML>
<HEAD>
<!-- Generated by javadoc (build 1.6.0_18) on Sun May 03 20:19:34 CST 2015 -->
<TITLE>
DataNode (Hadoop-Hdfs 0.22.1-SNAPSHOT API)
</TITLE>

<META NAME="date" CONTENT="2015-05-03">

<LINK REL ="stylesheet" TYPE="text/css" HREF="../../../../../../stylesheet.css" TITLE="Style">

<SCRIPT type="text/javascript">
function windowTitle()
{
    if (location.href.indexOf('is-external=true') == -1) {
        parent.document.title="DataNode (Hadoop-Hdfs 0.22.1-SNAPSHOT API)";
    }
}
</SCRIPT>
<NOSCRIPT>
</NOSCRIPT>

</HEAD>

<BODY BGCOLOR="white" onload="windowTitle();">
<HR>


<!-- ========= START OF TOP NAVBAR ======= -->
<A NAME="navbar_top"><!-- --></A>
<A HREF="#skip-navbar_top" title="跳过导航链接"></A>
<TABLE BORDER="0" WIDTH="100%" CELLPADDING="1" CELLSPACING="0" SUMMARY="">
<TR>
<TD COLSPAN=2 BGCOLOR="#EEEEFF" CLASS="NavBarCell1">
<A NAME="navbar_top_firstrow"><!-- --></A>
<TABLE BORDER="0" CELLPADDING="0" CELLSPACING="3" SUMMARY="">
  <TR ALIGN="center" VALIGN="top">
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="../../../../../../overview-summary.html"><FONT CLASS="NavBarFont1"><B>概述</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="package-summary.html"><FONT CLASS="NavBarFont1"><B>软件包</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#FFFFFF" CLASS="NavBarCell1Rev"> &nbsp;<FONT CLASS="NavBarFont1Rev"><B>类</B></FONT>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="class-use/DataNode.html"><FONT CLASS="NavBarFont1"><B>使用</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="package-tree.html"><FONT CLASS="NavBarFont1"><B>树</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="../../../../../../deprecated-list.html"><FONT CLASS="NavBarFont1"><B>已过时</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="../../../../../../index-all.html"><FONT CLASS="NavBarFont1"><B>索引</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="../../../../../../help-doc.html"><FONT CLASS="NavBarFont1"><B>帮助</B></FONT></A>&nbsp;</TD>
  </TR>
</TABLE>
</TD>
<TD ALIGN="right" VALIGN="top" ROWSPAN=3><EM>
</EM>
</TD>
</TR>

<TR>
<TD BGCOLOR="white" CLASS="NavBarCell2"><FONT SIZE="-2">
&nbsp;上一个类&nbsp;
&nbsp;<A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/DataNode.RCRecoveryThreadTarget.html" title="org.apache.hadoop.hdfs.server.datanode 中的类"><B>下一个类</B></A></FONT></TD>
<TD BGCOLOR="white" CLASS="NavBarCell2"><FONT SIZE="-2">
  <A HREF="../../../../../../index.html?org/apache/hadoop/hdfs/server/datanode/DataNode.html" target="_top"><B>框架</B></A>  &nbsp;
&nbsp;<A HREF="DataNode.html" target="_top"><B>无框架</B></A>  &nbsp;
&nbsp;<SCRIPT type="text/javascript">
  <!--
  if(window==top) {
    document.writeln('<A HREF="../../../../../../allclasses-noframe.html"><B>所有类</B></A>');
  }
  //-->
</SCRIPT>
<NOSCRIPT>
  <A HREF="../../../../../../allclasses-noframe.html"><B>所有类</B></A>
</NOSCRIPT>


</FONT></TD>
</TR>
<TR>
<TD VALIGN="top" CLASS="NavBarCell3"><FONT SIZE="-2">
  摘要：&nbsp;<A HREF="#nested_class_summary">嵌套</A>&nbsp;|&nbsp;<A HREF="#field_summary">字段</A>&nbsp;|&nbsp;构造方法&nbsp;|&nbsp;<A HREF="#method_summary">方法</A></FONT></TD>
<TD VALIGN="top" CLASS="NavBarCell3"><FONT SIZE="-2">
详细信息：&nbsp;<A HREF="#field_detail">字段</A>&nbsp;|&nbsp;构造方法&nbsp;|&nbsp;<A HREF="#method_detail">方法</A></FONT></TD>
</TR>
</TABLE>
<A NAME="skip-navbar_top"></A>
<!-- ========= END OF TOP NAVBAR ========= -->

<HR>
<!-- ======== START OF CLASS DATA ======== -->
<H2>
<FONT SIZE="-1">
org.apache.hadoop.hdfs.server.datanode</FONT>
<BR>
类 DataNode</H2>
<PRE>
java.lang.Object
  <IMG SRC="../../../../../../resources/inherit.gif" ALT="继承者 ">org.apache.hadoop.conf.Configured
      <IMG SRC="../../../../../../resources/inherit.gif" ALT="继承者 "><B>org.apache.hadoop.hdfs.server.datanode.DataNode</B>
</PRE>
<DL>
<DT><B>所有已实现的接口：</B> <DD>java.lang.Runnable, org.apache.hadoop.conf.Configurable, <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/ClientDatanodeProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的接口">ClientDatanodeProtocol</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/FSConstants.html" title="org.apache.hadoop.hdfs.protocol 中的接口">FSConstants</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/DataNodeMXBean.html" title="org.apache.hadoop.hdfs.server.datanode 中的接口">DataNodeMXBean</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/InterDatanodeProtocol.html" title="org.apache.hadoop.hdfs.server.protocol 中的接口">InterDatanodeProtocol</A>, org.apache.hadoop.ipc.VersionedProtocol</DD>
</DL>
<HR>
<DL>
<DT><PRE><FONT SIZE="-1">@InterfaceAudience.Private
</FONT>public class <B>DataNode</B><DT>extends org.apache.hadoop.conf.Configured<DT>implements <A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/InterDatanodeProtocol.html" title="org.apache.hadoop.hdfs.server.protocol 中的接口">InterDatanodeProtocol</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/ClientDatanodeProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的接口">ClientDatanodeProtocol</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/FSConstants.html" title="org.apache.hadoop.hdfs.protocol 中的接口">FSConstants</A>, java.lang.Runnable, <A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/DataNodeMXBean.html" title="org.apache.hadoop.hdfs.server.datanode 中的接口">DataNodeMXBean</A></DL>
</PRE>

<P>
DataNode is a class (and program) that stores a set of
 blocks for a DFS deployment.  A single deployment can
 have one or many DataNodes.  Each DataNode communicates
 regularly with a single NameNode.  It also communicates
 with client code and other DataNodes from time to time.

 DataNodes store a series of named blocks.  The DataNode
 allows client code to read these blocks, or to write new
 block data.  The DataNode may also, in response to instructions
 from its NameNode, delete blocks or copy blocks to/from other
 DataNodes.

 The DataNode maintains just one critical table:
   block-> stream of bytes (of BLOCK_SIZE or less)

 This info is stored on a local disk.  The DataNode
 reports the table's contents to the NameNode upon startup
 and every so often afterwards.

 DataNodes spend their lives in an endless loop of asking
 the NameNode for something to do.  A NameNode cannot connect
 to a DataNode directly; a NameNode simply returns values from
 functions invoked by a DataNode.

 DataNodes maintain an open server socket so that client code 
 or other DataNodes can read/write data.  The host/port for
 this server is reported to the NameNode, which then sends that
 information to clients or other DataNodes that might be interested.
<P>

<P>
<HR>

<P>
<!-- ======== NESTED CLASS SUMMARY ======== -->

<A NAME="nested_class_summary"><!-- --></A>
<TABLE BORDER="1" WIDTH="100%" CELLPADDING="3" CELLSPACING="0" SUMMARY="">
<TR BGCOLOR="#CCCCFF" CLASS="TableHeadingColor">
<TH ALIGN="left" COLSPAN="2"><FONT SIZE="+2">
<B>嵌套类摘要</B></FONT></TH>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;class</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/DataNode.RCRecoveryThreadTarget.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">DataNode.RCRecoveryThreadTarget</A></B></CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;rc(regenerating code)recovery thread target, changed on basis of CumulusRecovery. created at 2014-4-17. modified
 at 2014-4-24,2014-4-25.</TD>
</TR>
</TABLE>
&nbsp;<A NAME="nested_classes_inherited_from_class_org.apache.hadoop.hdfs.protocol.FSConstants"><!-- --></A>
<TABLE BORDER="1" WIDTH="100%" CELLPADDING="3" CELLSPACING="0" SUMMARY="">
<TR BGCOLOR="#EEEEFF" CLASS="TableSubHeadingColor">
<TH ALIGN="left"><B>从接口 org.apache.hadoop.hdfs.protocol.<A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/FSConstants.html" title="org.apache.hadoop.hdfs.protocol 中的接口">FSConstants</A> 继承的嵌套类/接口</B></TH>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD><CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/FSConstants.DatanodeReportType.html" title="org.apache.hadoop.hdfs.protocol 中的枚举">FSConstants.DatanodeReportType</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/FSConstants.SafeModeAction.html" title="org.apache.hadoop.hdfs.protocol 中的枚举">FSConstants.SafeModeAction</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/FSConstants.UpgradeAction.html" title="org.apache.hadoop.hdfs.protocol 中的枚举">FSConstants.UpgradeAction</A></CODE></TD>
</TR>
</TABLE>
&nbsp;
<!-- =========== FIELD SUMMARY =========== -->

<A NAME="field_summary"><!-- --></A>
<TABLE BORDER="1" WIDTH="100%" CELLPADDING="3" CELLSPACING="0" SUMMARY="">
<TR BGCOLOR="#CCCCFF" CLASS="TableHeadingColor">
<TH ALIGN="left" COLSPAN="2"><FONT SIZE="+2">
<B>字段摘要</B></FONT></TH>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;org.apache.hadoop.hdfs.server.datanode.DataBlockScanner</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/DataNode.html#blockScanner">blockScanner</A></B></CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;org.apache.hadoop.util.Daemon</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/DataNode.html#blockScannerThread">blockScannerThread</A></B></CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;<A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.html" title="org.apache.hadoop.hdfs.server.datanode 中的接口">FSDatasetInterface</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/DataNode.html#data">data</A></B></CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;java.lang.String</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/DataNode.html#DN_CLIENTTRACE_FORMAT">DN_CLIENTTRACE_FORMAT</A></B></CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;<A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/DatanodeRegistration.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">DatanodeRegistration</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/DataNode.html#dnRegistration">dnRegistration</A></B></CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;<A HREF="../../../../../../org/apache/hadoop/hdfs/server/monitor/ServernodeStator.html" title="org.apache.hadoop.hdfs.server.monitor 中的类">ServernodeStator</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/DataNode.html#dnStator">dnStator</A></B></CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;java.lang.String</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/DataNode.html#EMPTY_DEL_HINT">EMPTY_DEL_HINT</A></B></CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;org.apache.hadoop.ipc.Server</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/DataNode.html#ipcServer">ipcServer</A></B></CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;org.apache.commons.logging.Log</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/DataNode.html#LOG">LOG</A></B></CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;<A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/DatanodeProtocol.html" title="org.apache.hadoop.hdfs.server.protocol 中的接口">DatanodeProtocol</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/DataNode.html#namenode">namenode</A></B></CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
</TABLE>
&nbsp;<A NAME="fields_inherited_from_class_org.apache.hadoop.hdfs.server.protocol.InterDatanodeProtocol"><!-- --></A>
<TABLE BORDER="1" WIDTH="100%" CELLPADDING="3" CELLSPACING="0" SUMMARY="">
<TR BGCOLOR="#EEEEFF" CLASS="TableSubHeadingColor">
<TH ALIGN="left"><B>从接口 org.apache.hadoop.hdfs.server.protocol.<A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/InterDatanodeProtocol.html" title="org.apache.hadoop.hdfs.server.protocol 中的接口">InterDatanodeProtocol</A> 继承的字段</B></TH>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD><CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/InterDatanodeProtocol.html#versionID">versionID</A></CODE></TD>
</TR>
</TABLE>
&nbsp;<A NAME="fields_inherited_from_class_org.apache.hadoop.hdfs.protocol.ClientDatanodeProtocol"><!-- --></A>
<TABLE BORDER="1" WIDTH="100%" CELLPADDING="3" CELLSPACING="0" SUMMARY="">
<TR BGCOLOR="#EEEEFF" CLASS="TableSubHeadingColor">
<TH ALIGN="left"><B>从接口 org.apache.hadoop.hdfs.protocol.<A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/ClientDatanodeProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的接口">ClientDatanodeProtocol</A> 继承的字段</B></TH>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD><CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/ClientDatanodeProtocol.html#versionID">versionID</A></CODE></TD>
</TR>
</TABLE>
&nbsp;<A NAME="fields_inherited_from_class_org.apache.hadoop.hdfs.protocol.FSConstants"><!-- --></A>
<TABLE BORDER="1" WIDTH="100%" CELLPADDING="3" CELLSPACING="0" SUMMARY="">
<TR BGCOLOR="#EEEEFF" CLASS="TableSubHeadingColor">
<TH ALIGN="left"><B>从接口 org.apache.hadoop.hdfs.protocol.<A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/FSConstants.html" title="org.apache.hadoop.hdfs.protocol 中的接口">FSConstants</A> 继承的字段</B></TH>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD><CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/FSConstants.html#BLOCK_INVALIDATE_CHUNK">BLOCK_INVALIDATE_CHUNK</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/FSConstants.html#BLOCKREPORT_INITIAL_DELAY">BLOCKREPORT_INITIAL_DELAY</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/FSConstants.html#BLOCKREPORT_INTERVAL">BLOCKREPORT_INTERVAL</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/FSConstants.html#BUFFER_SIZE">BUFFER_SIZE</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/FSConstants.html#DEFAULT_BLOCK_SIZE">DEFAULT_BLOCK_SIZE</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/FSConstants.html#DEFAULT_BYTES_PER_CHECKSUM">DEFAULT_BYTES_PER_CHECKSUM</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/FSConstants.html#DEFAULT_DATA_SOCKET_SIZE">DEFAULT_DATA_SOCKET_SIZE</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/FSConstants.html#DEFAULT_FILE_BUFFER_SIZE">DEFAULT_FILE_BUFFER_SIZE</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/FSConstants.html#DEFAULT_REPLICATION_FACTOR">DEFAULT_REPLICATION_FACTOR</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/FSConstants.html#DEFAULT_WRITE_PACKET_SIZE">DEFAULT_WRITE_PACKET_SIZE</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/FSConstants.html#HDFS_URI_SCHEME">HDFS_URI_SCHEME</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/FSConstants.html#HEARTBEAT_INTERVAL">HEARTBEAT_INTERVAL</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/FSConstants.html#LAYOUT_VERSION">LAYOUT_VERSION</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/FSConstants.html#LEASE_HARDLIMIT_PERIOD">LEASE_HARDLIMIT_PERIOD</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/FSConstants.html#LEASE_RECOVER_PERIOD">LEASE_RECOVER_PERIOD</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/FSConstants.html#LEASE_SOFTLIMIT_PERIOD">LEASE_SOFTLIMIT_PERIOD</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/FSConstants.html#MAX_PATH_DEPTH">MAX_PATH_DEPTH</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/FSConstants.html#MAX_PATH_LENGTH">MAX_PATH_LENGTH</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/FSConstants.html#MIN_BLOCKS_FOR_WRITE">MIN_BLOCKS_FOR_WRITE</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/FSConstants.html#QUOTA_DONT_SET">QUOTA_DONT_SET</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/FSConstants.html#QUOTA_RESET">QUOTA_RESET</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/FSConstants.html#SIZE_OF_INTEGER">SIZE_OF_INTEGER</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/FSConstants.html#SMALL_BUFFER_SIZE">SMALL_BUFFER_SIZE</A></CODE></TD>
</TR>
</TABLE>
&nbsp;
<!-- ========== METHOD SUMMARY =========== -->

<A NAME="method_summary"><!-- --></A>
<TABLE BORDER="1" WIDTH="100%" CELLPADDING="3" CELLSPACING="0" SUMMARY="">
<TR BGCOLOR="#CCCCFF" CLASS="TableHeadingColor">
<TH ALIGN="left" COLSPAN="2"><FONT SIZE="+2">
<B>方法摘要</B></FONT></TH>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;<A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/LocatedBlock.html" title="org.apache.hadoop.hdfs.protocol 中的类">LocatedBlock</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/DataNode.html#beginRCRecovery(org.apache.hadoop.hdfs.protocol.DatanodeInfo, org.apache.hadoop.hdfs.protocol.Block[], byte[])">beginRCRecovery</A></B>(<A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/DatanodeInfo.html" title="org.apache.hadoop.hdfs.protocol 中的类">DatanodeInfo</A>&nbsp;helperDatanodeInfo,
                <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/Block.html" title="org.apache.hadoop.hdfs.protocol 中的类">Block</A>[]&nbsp;computeBlocks,
                byte[]&nbsp;failednodeVector)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;new comer inform a helper node to start rc in RC(regenerating code)recovery work. created at 2041-4-17. modified
 at 2014-4-24</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>protected &nbsp;void</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/DataNode.html#checkDiskError()">checkDiskError</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Check if there is a disk failure and if so, handle the error</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>protected &nbsp;void</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/DataNode.html#checkDiskError(java.lang.Exception)">checkDiskError</A></B>(java.lang.Exception&nbsp;e)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Check if there is no space in disk</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/DataNode.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">DataNode</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/DataNode.html#createDataNode(java.lang.String[], org.apache.hadoop.conf.Configuration)">createDataNode</A></B>(java.lang.String[]&nbsp;args,
               org.apache.hadoop.conf.Configuration&nbsp;conf)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Instantiate & Start a single datanode daemon and wait for it to finish.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/DataNode.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">DataNode</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/DataNode.html#createDataNode(java.lang.String[], org.apache.hadoop.conf.Configuration, org.apache.hadoop.hdfs.server.datanode.SecureDataNodeStarter.SecureResources)">createDataNode</A></B>(java.lang.String[]&nbsp;args,
               org.apache.hadoop.conf.Configuration&nbsp;conf,
               <A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/SecureDataNodeStarter.SecureResources.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">SecureDataNodeStarter.SecureResources</A>&nbsp;resources)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Instantiate & Start a single datanode daemon and wait for it to finish.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/InterDatanodeProtocol.html" title="org.apache.hadoop.hdfs.server.protocol 中的接口">InterDatanodeProtocol</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/DataNode.html#createInterDataNodeProtocolProxy(org.apache.hadoop.hdfs.protocol.DatanodeID, org.apache.hadoop.conf.Configuration, int)">createInterDataNodeProtocolProxy</A></B>(<A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/DatanodeID.html" title="org.apache.hadoop.hdfs.protocol 中的类">DatanodeID</A>&nbsp;datanodeid,
                                 org.apache.hadoop.conf.Configuration&nbsp;conf,
                                 int&nbsp;socketTimeout)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;java.net.InetSocketAddress</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/DataNode.html#createSocketAddr(java.lang.String)">createSocketAddr</A></B>(java.lang.String&nbsp;target)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<B>已过时。</B>&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;void</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/DataNode.html#endRCRecovery(org.apache.hadoop.hdfs.protocol.Block)">endRCRecovery</A></B>(<A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/Block.html" title="org.apache.hadoop.hdfs.protocol 中的类">Block</A>&nbsp;block)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;new comer inform a helper node to end rc in RC(regenerating code)recovery work. created at 2041-4-24</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/DataNode.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">DataNode</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/DataNode.html#getDataNode()">getDataNode</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Return the DataNode object</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;<A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/DatanodeRegistration.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">DatanodeRegistration</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/DataNode.html#getDatanodeRegistration()">getDatanodeRegistration</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Return DatanodeRegistration</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;<A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.html" title="org.apache.hadoop.hdfs.server.datanode 中的接口">FSDatasetInterface</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/DataNode.html#getFSDataset()">getFSDataset</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;This method is used for testing.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;java.lang.String</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/DataNode.html#getHttpPort()">getHttpPort</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Gets the http port.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;java.net.InetSocketAddress</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/DataNode.html#getInfoAddr(org.apache.hadoop.conf.Configuration)">getInfoAddr</A></B>(org.apache.hadoop.conf.Configuration&nbsp;conf)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Determine the http server's effective addr</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;int</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/DataNode.html#getInfoPort()">getInfoPort</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;java.net.InetSocketAddress</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/DataNode.html#getNameNodeAddr()">getNameNodeAddr</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;java.lang.String</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/DataNode.html#getNamenodeAddress()">getNamenodeAddress</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Gets the namenode IP address.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;java.net.InetSocketAddress</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/DataNode.html#getNameNodeAddrForClient()">getNameNodeAddrForClient</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;long</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/DataNode.html#getProtocolVersion(java.lang.String, long)">getProtocolVersion</A></B>(java.lang.String&nbsp;protocol,
                   long&nbsp;clientVersion)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;long</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/DataNode.html#getReplicaVisibleLength(org.apache.hadoop.hdfs.protocol.Block)">getReplicaVisibleLength</A></B>(<A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/Block.html" title="org.apache.hadoop.hdfs.protocol 中的类">Block</A>&nbsp;block)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Return the visible length of a replica.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;java.lang.String</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/DataNode.html#getRpcPort()">getRpcPort</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Gets the rpc port.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;java.net.InetSocketAddress</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/DataNode.html#getSelfAddr()">getSelfAddr</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;java.net.InetSocketAddress</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/DataNode.html#getStreamingAddr(org.apache.hadoop.conf.Configuration)">getStreamingAddr</A></B>(org.apache.hadoop.conf.Configuration&nbsp;conf)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;java.lang.String</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/DataNode.html#getVersion()">getVersion</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Gets the version of Hadoop.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;java.lang.String</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/DataNode.html#getVolumeInfo()">getVolumeInfo</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Returned information is a JSON representation of a map with 
 volume name as the key and value is a map of volume attribute 
 keys to its values</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;<A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/ReplicaRecoveryInfo.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">ReplicaRecoveryInfo</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/DataNode.html#initReplicaRecovery(org.apache.hadoop.hdfs.server.protocol.BlockRecoveryCommand.RecoveringBlock)">initReplicaRecovery</A></B>(<A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/BlockRecoveryCommand.RecoveringBlock.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">BlockRecoveryCommand.RecoveringBlock</A>&nbsp;rBlock)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Initialize a replica recovery.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/DataNode.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">DataNode</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/DataNode.html#instantiateDataNode(java.lang.String[], org.apache.hadoop.conf.Configuration)">instantiateDataNode</A></B>(java.lang.String[]&nbsp;args,
                    org.apache.hadoop.conf.Configuration&nbsp;conf)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Instantiate a single datanode object.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/DataNode.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">DataNode</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/DataNode.html#instantiateDataNode(java.lang.String[], org.apache.hadoop.conf.Configuration, org.apache.hadoop.hdfs.server.datanode.SecureDataNodeStarter.SecureResources)">instantiateDataNode</A></B>(java.lang.String[]&nbsp;args,
                    org.apache.hadoop.conf.Configuration&nbsp;conf,
                    <A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/SecureDataNodeStarter.SecureResources.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">SecureDataNodeStarter.SecureResources</A>&nbsp;resources)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Instantiate a single datanode object, along with its secure resources.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;void</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/DataNode.html#main(java.lang.String[])">main</A></B>(java.lang.String[]&nbsp;args)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>protected &nbsp;java.net.Socket</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/DataNode.html#newSocket()">newSocket</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Creates either NIO or regular depending on socketWriteTimeout.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>protected &nbsp;void</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/DataNode.html#notifyNamenodeReceivedBlock(org.apache.hadoop.hdfs.protocol.Block, java.lang.String)">notifyNamenodeReceivedBlock</A></B>(<A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/Block.html" title="org.apache.hadoop.hdfs.protocol 中的类">Block</A>&nbsp;block,
                            java.lang.String&nbsp;delHint)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;void</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/DataNode.html#offerService()">offerService</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Main loop for the DataNode.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;org.apache.hadoop.util.Daemon</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/DataNode.html#recoverBlocks(java.util.Collection)">recoverBlocks</A></B>(java.util.Collection&lt;<A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/BlockRecoveryCommand.RecoveringBlock.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">BlockRecoveryCommand.RecoveringBlock</A>&gt;&nbsp;blocks)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;void</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/DataNode.html#run()">run</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;No matter what kind of exception we get, keep retrying to offerService().</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;void</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/DataNode.html#runDatanodeDaemon(org.apache.hadoop.hdfs.server.datanode.DataNode)">runDatanodeDaemon</A></B>(<A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/DataNode.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">DataNode</A>&nbsp;dn)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Start a single datanode daemon and wait for it to finish.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;void</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/DataNode.html#scheduleBlockReport(long)">scheduleBlockReport</A></B>(long&nbsp;delay)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;This methods  arranges for the data node to send the block report at the next heartbeat.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;void</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/DataNode.html#secureMain(java.lang.String[], org.apache.hadoop.hdfs.server.datanode.SecureDataNodeStarter.SecureResources)">secureMain</A></B>(java.lang.String[]&nbsp;args,
           <A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/SecureDataNodeStarter.SecureResources.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">SecureDataNodeStarter.SecureResources</A>&nbsp;resources)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;void</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/DataNode.html#setNewStorageID(org.apache.hadoop.hdfs.server.protocol.DatanodeRegistration)">setNewStorageID</A></B>(<A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/DatanodeRegistration.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">DatanodeRegistration</A>&nbsp;dnReg)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;void</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/DataNode.html#shutdown()">shutdown</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Shut down this instance of the datanode.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;java.lang.String</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/DataNode.html#toString()">toString</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;<A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/Block.html" title="org.apache.hadoop.hdfs.protocol 中的类">Block</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/DataNode.html#updateReplicaUnderRecovery(org.apache.hadoop.hdfs.protocol.Block, long, long)">updateReplicaUnderRecovery</A></B>(<A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/Block.html" title="org.apache.hadoop.hdfs.protocol 中的类">Block</A>&nbsp;oldBlock,
                           long&nbsp;recoveryId,
                           long&nbsp;newLength)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Update replica with the new generation stamp and length.</TD>
</TR>
</TABLE>
&nbsp;<A NAME="methods_inherited_from_class_org.apache.hadoop.conf.Configured"><!-- --></A>
<TABLE BORDER="1" WIDTH="100%" CELLPADDING="3" CELLSPACING="0" SUMMARY="">
<TR BGCOLOR="#EEEEFF" CLASS="TableSubHeadingColor">
<TH ALIGN="left"><B>从类 org.apache.hadoop.conf.Configured 继承的方法</B></TH>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD><CODE>getConf, setConf</CODE></TD>
</TR>
</TABLE>
&nbsp;<A NAME="methods_inherited_from_class_java.lang.Object"><!-- --></A>
<TABLE BORDER="1" WIDTH="100%" CELLPADDING="3" CELLSPACING="0" SUMMARY="">
<TR BGCOLOR="#EEEEFF" CLASS="TableSubHeadingColor">
<TH ALIGN="left"><B>从类 java.lang.Object 继承的方法</B></TH>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD><CODE>clone, equals, finalize, getClass, hashCode, notify, notifyAll, wait, wait, wait</CODE></TD>
</TR>
</TABLE>
&nbsp;
<P>

<!-- ============ FIELD DETAIL =========== -->

<A NAME="field_detail"><!-- --></A>
<TABLE BORDER="1" WIDTH="100%" CELLPADDING="3" CELLSPACING="0" SUMMARY="">
<TR BGCOLOR="#CCCCFF" CLASS="TableHeadingColor">
<TH ALIGN="left" COLSPAN="1"><FONT SIZE="+2">
<B>字段详细信息</B></FONT></TH>
</TR>
</TABLE>

<A NAME="LOG"><!-- --></A><H3>
LOG</H3>
<PRE>
public static final org.apache.commons.logging.Log <B>LOG</B></PRE>
<DL>
<DL>
</DL>
</DL>
<HR>

<A NAME="DN_CLIENTTRACE_FORMAT"><!-- --></A><H3>
DN_CLIENTTRACE_FORMAT</H3>
<PRE>
public static final java.lang.String <B>DN_CLIENTTRACE_FORMAT</B></PRE>
<DL>
<DL>
<DT><B>另请参见：</B><DD><A HREF="../../../../../../constant-values.html#org.apache.hadoop.hdfs.server.datanode.DataNode.DN_CLIENTTRACE_FORMAT">常量字段值</A></DL>
</DL>
<HR>

<A NAME="namenode"><!-- --></A><H3>
namenode</H3>
<PRE>
public <A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/DatanodeProtocol.html" title="org.apache.hadoop.hdfs.server.protocol 中的接口">DatanodeProtocol</A> <B>namenode</B></PRE>
<DL>
<DL>
</DL>
</DL>
<HR>

<A NAME="data"><!-- --></A><H3>
data</H3>
<PRE>
public <A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.html" title="org.apache.hadoop.hdfs.server.datanode 中的接口">FSDatasetInterface</A> <B>data</B></PRE>
<DL>
<DL>
</DL>
</DL>
<HR>

<A NAME="dnRegistration"><!-- --></A><H3>
dnRegistration</H3>
<PRE>
public <A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/DatanodeRegistration.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">DatanodeRegistration</A> <B>dnRegistration</B></PRE>
<DL>
<DL>
</DL>
</DL>
<HR>

<A NAME="EMPTY_DEL_HINT"><!-- --></A><H3>
EMPTY_DEL_HINT</H3>
<PRE>
public static final java.lang.String <B>EMPTY_DEL_HINT</B></PRE>
<DL>
<DL>
<DT><B>另请参见：</B><DD><A HREF="../../../../../../constant-values.html#org.apache.hadoop.hdfs.server.datanode.DataNode.EMPTY_DEL_HINT">常量字段值</A></DL>
</DL>
<HR>

<A NAME="blockScanner"><!-- --></A><H3>
blockScanner</H3>
<PRE>
public org.apache.hadoop.hdfs.server.datanode.DataBlockScanner <B>blockScanner</B></PRE>
<DL>
<DL>
</DL>
</DL>
<HR>

<A NAME="blockScannerThread"><!-- --></A><H3>
blockScannerThread</H3>
<PRE>
public org.apache.hadoop.util.Daemon <B>blockScannerThread</B></PRE>
<DL>
<DL>
</DL>
</DL>
<HR>

<A NAME="ipcServer"><!-- --></A><H3>
ipcServer</H3>
<PRE>
public org.apache.hadoop.ipc.Server <B>ipcServer</B></PRE>
<DL>
<DL>
</DL>
</DL>
<HR>

<A NAME="dnStator"><!-- --></A><H3>
dnStator</H3>
<PRE>
public <A HREF="../../../../../../org/apache/hadoop/hdfs/server/monitor/ServernodeStator.html" title="org.apache.hadoop.hdfs.server.monitor 中的类">ServernodeStator</A> <B>dnStator</B></PRE>
<DL>
<DL>
</DL>
</DL>

<!-- ============ METHOD DETAIL ========== -->

<A NAME="method_detail"><!-- --></A>
<TABLE BORDER="1" WIDTH="100%" CELLPADDING="3" CELLSPACING="0" SUMMARY="">
<TR BGCOLOR="#CCCCFF" CLASS="TableHeadingColor">
<TH ALIGN="left" COLSPAN="1"><FONT SIZE="+2">
<B>方法详细信息</B></FONT></TH>
</TR>
</TABLE>

<A NAME="createSocketAddr(java.lang.String)"><!-- --></A><H3>
createSocketAddr</H3>
<PRE>
<FONT SIZE="-1">@Deprecated
</FONT>public static java.net.InetSocketAddress <B>createSocketAddr</B>(java.lang.String&nbsp;target)
                                                   throws java.io.IOException</PRE>
<DL>
<DD><B>已过时。</B>&nbsp;
<P>
<DD>Use <CODE>NetUtils.createSocketAddr(String)</CODE> instead.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="getInfoAddr(org.apache.hadoop.conf.Configuration)"><!-- --></A><H3>
getInfoAddr</H3>
<PRE>
public static java.net.InetSocketAddress <B>getInfoAddr</B>(org.apache.hadoop.conf.Configuration&nbsp;conf)</PRE>
<DL>
<DD>Determine the http server's effective addr
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
</DL>
</DD>
</DL>
<HR>

<A NAME="newSocket()"><!-- --></A><H3>
newSocket</H3>
<PRE>
protected java.net.Socket <B>newSocket</B>()
                             throws java.io.IOException</PRE>
<DL>
<DD>Creates either NIO or regular depending on socketWriteTimeout.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="getDataNode()"><!-- --></A><H3>
getDataNode</H3>
<PRE>
public static <A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/DataNode.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">DataNode</A> <B>getDataNode</B>()</PRE>
<DL>
<DD>Return the DataNode object
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
</DL>
</DD>
</DL>
<HR>

<A NAME="createInterDataNodeProtocolProxy(org.apache.hadoop.hdfs.protocol.DatanodeID, org.apache.hadoop.conf.Configuration, int)"><!-- --></A><H3>
createInterDataNodeProtocolProxy</H3>
<PRE>
public static <A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/InterDatanodeProtocol.html" title="org.apache.hadoop.hdfs.server.protocol 中的接口">InterDatanodeProtocol</A> <B>createInterDataNodeProtocolProxy</B>(<A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/DatanodeID.html" title="org.apache.hadoop.hdfs.protocol 中的类">DatanodeID</A>&nbsp;datanodeid,
                                                                     org.apache.hadoop.conf.Configuration&nbsp;conf,
                                                                     int&nbsp;socketTimeout)
                                                              throws java.io.IOException</PRE>
<DL>
<DD><DL>
</DL>
</DD>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="getNameNodeAddr()"><!-- --></A><H3>
getNameNodeAddr</H3>
<PRE>
public java.net.InetSocketAddress <B>getNameNodeAddr</B>()</PRE>
<DL>
<DD><DL>
</DL>
</DD>
<DD><DL>
</DL>
</DD>
</DL>
<HR>

<A NAME="getNameNodeAddrForClient()"><!-- --></A><H3>
getNameNodeAddrForClient</H3>
<PRE>
public java.net.InetSocketAddress <B>getNameNodeAddrForClient</B>()</PRE>
<DL>
<DD><DL>
</DL>
</DD>
<DD><DL>
</DL>
</DD>
</DL>
<HR>

<A NAME="getSelfAddr()"><!-- --></A><H3>
getSelfAddr</H3>
<PRE>
public java.net.InetSocketAddress <B>getSelfAddr</B>()</PRE>
<DL>
<DD><DL>
</DL>
</DD>
<DD><DL>
</DL>
</DD>
</DL>
<HR>

<A NAME="getDatanodeRegistration()"><!-- --></A><H3>
getDatanodeRegistration</H3>
<PRE>
public <A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/DatanodeRegistration.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">DatanodeRegistration</A> <B>getDatanodeRegistration</B>()</PRE>
<DL>
<DD>Return DatanodeRegistration
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
</DL>
</DD>
</DL>
<HR>

<A NAME="setNewStorageID(org.apache.hadoop.hdfs.server.protocol.DatanodeRegistration)"><!-- --></A><H3>
setNewStorageID</H3>
<PRE>
public static void <B>setNewStorageID</B>(<A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/DatanodeRegistration.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">DatanodeRegistration</A>&nbsp;dnReg)</PRE>
<DL>
<DD><DL>
</DL>
</DD>
<DD><DL>
</DL>
</DD>
</DL>
<HR>

<A NAME="shutdown()"><!-- --></A><H3>
shutdown</H3>
<PRE>
public void <B>shutdown</B>()</PRE>
<DL>
<DD>Shut down this instance of the datanode.
 Returns only after shutdown is complete.
 This method can only be called by the offerService thread.
 Otherwise, deadlock might occur.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
</DL>
</DD>
</DL>
<HR>

<A NAME="checkDiskError(java.lang.Exception)"><!-- --></A><H3>
checkDiskError</H3>
<PRE>
protected void <B>checkDiskError</B>(java.lang.Exception&nbsp;e)
                       throws java.io.IOException</PRE>
<DL>
<DD>Check if there is no space in disk
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>参数：</B><DD><CODE>e</CODE> - that caused this checkDiskError call
<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="checkDiskError()"><!-- --></A><H3>
checkDiskError</H3>
<PRE>
protected void <B>checkDiskError</B>()</PRE>
<DL>
<DD>Check if there is a disk failure and if so, handle the error
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
</DL>
</DD>
</DL>
<HR>

<A NAME="offerService()"><!-- --></A><H3>
offerService</H3>
<PRE>
public void <B>offerService</B>()
                  throws java.lang.Exception</PRE>
<DL>
<DD>Main loop for the DataNode.  Runs until shutdown,
 forever calling remote NameNode functions.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>java.lang.Exception</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="notifyNamenodeReceivedBlock(org.apache.hadoop.hdfs.protocol.Block, java.lang.String)"><!-- --></A><H3>
notifyNamenodeReceivedBlock</H3>
<PRE>
protected void <B>notifyNamenodeReceivedBlock</B>(<A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/Block.html" title="org.apache.hadoop.hdfs.protocol 中的类">Block</A>&nbsp;block,
                                           java.lang.String&nbsp;delHint)</PRE>
<DL>
<DD><DL>
</DL>
</DD>
<DD><DL>
</DL>
</DD>
</DL>
<HR>

<A NAME="run()"><!-- --></A><H3>
run</H3>
<PRE>
public void <B>run</B>()</PRE>
<DL>
<DD>No matter what kind of exception we get, keep retrying to offerService().
 That's the loop that connects to the NameNode and provides basic DataNode
 functionality.

 Only stop when "shouldRun" is turned off (which can only happen at shutdown).
<P>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE>java.lang.Runnable</CODE> 中的 <CODE>run</CODE></DL>
</DD>
<DD><DL>
</DL>
</DD>
</DL>
<HR>

<A NAME="runDatanodeDaemon(org.apache.hadoop.hdfs.server.datanode.DataNode)"><!-- --></A><H3>
runDatanodeDaemon</H3>
<PRE>
public static void <B>runDatanodeDaemon</B>(<A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/DataNode.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">DataNode</A>&nbsp;dn)
                              throws java.io.IOException</PRE>
<DL>
<DD>Start a single datanode daemon and wait for it to finish.
  If this thread is specifically interrupted, it will stop waiting.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="instantiateDataNode(java.lang.String[], org.apache.hadoop.conf.Configuration)"><!-- --></A><H3>
instantiateDataNode</H3>
<PRE>
public static <A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/DataNode.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">DataNode</A> <B>instantiateDataNode</B>(java.lang.String[]&nbsp;args,
                                           org.apache.hadoop.conf.Configuration&nbsp;conf)
                                    throws java.io.IOException</PRE>
<DL>
<DD>Instantiate a single datanode object. This must be run by invoking
  <A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/DataNode.html#runDatanodeDaemon(org.apache.hadoop.hdfs.server.datanode.DataNode)"><CODE>runDatanodeDaemon(DataNode)</CODE></A> subsequently.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="instantiateDataNode(java.lang.String[], org.apache.hadoop.conf.Configuration, org.apache.hadoop.hdfs.server.datanode.SecureDataNodeStarter.SecureResources)"><!-- --></A><H3>
instantiateDataNode</H3>
<PRE>
public static <A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/DataNode.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">DataNode</A> <B>instantiateDataNode</B>(java.lang.String[]&nbsp;args,
                                           org.apache.hadoop.conf.Configuration&nbsp;conf,
                                           <A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/SecureDataNodeStarter.SecureResources.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">SecureDataNodeStarter.SecureResources</A>&nbsp;resources)
                                    throws java.io.IOException</PRE>
<DL>
<DD>Instantiate a single datanode object, along with its secure resources. 
 This must be run by invoking<A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/DataNode.html#runDatanodeDaemon(org.apache.hadoop.hdfs.server.datanode.DataNode)"><CODE>runDatanodeDaemon(DataNode)</CODE></A> 
 subsequently.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="createDataNode(java.lang.String[], org.apache.hadoop.conf.Configuration)"><!-- --></A><H3>
createDataNode</H3>
<PRE>
public static <A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/DataNode.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">DataNode</A> <B>createDataNode</B>(java.lang.String[]&nbsp;args,
                                      org.apache.hadoop.conf.Configuration&nbsp;conf)
                               throws java.io.IOException</PRE>
<DL>
<DD>Instantiate & Start a single datanode daemon and wait for it to finish.
  If this thread is specifically interrupted, it will stop waiting.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="createDataNode(java.lang.String[], org.apache.hadoop.conf.Configuration, org.apache.hadoop.hdfs.server.datanode.SecureDataNodeStarter.SecureResources)"><!-- --></A><H3>
createDataNode</H3>
<PRE>
<FONT SIZE="-1">@InterfaceAudience.Private
</FONT>public static <A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/DataNode.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">DataNode</A> <B>createDataNode</B>(java.lang.String[]&nbsp;args,
                                                                org.apache.hadoop.conf.Configuration&nbsp;conf,
                                                                <A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/SecureDataNodeStarter.SecureResources.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">SecureDataNodeStarter.SecureResources</A>&nbsp;resources)
                               throws java.io.IOException</PRE>
<DL>
<DD>Instantiate & Start a single datanode daemon and wait for it to finish.
  If this thread is specifically interrupted, it will stop waiting.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="toString()"><!-- --></A><H3>
toString</H3>
<PRE>
public java.lang.String <B>toString</B>()</PRE>
<DL>
<DD><DL>
<DT><B>覆盖：</B><DD>类 <CODE>java.lang.Object</CODE> 中的 <CODE>toString</CODE></DL>
</DD>
<DD><DL>
</DL>
</DD>
</DL>
<HR>

<A NAME="scheduleBlockReport(long)"><!-- --></A><H3>
scheduleBlockReport</H3>
<PRE>
public void <B>scheduleBlockReport</B>(long&nbsp;delay)</PRE>
<DL>
<DD>This methods  arranges for the data node to send the block report at the next heartbeat.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
</DL>
</DD>
</DL>
<HR>

<A NAME="getFSDataset()"><!-- --></A><H3>
getFSDataset</H3>
<PRE>
public <A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.html" title="org.apache.hadoop.hdfs.server.datanode 中的接口">FSDatasetInterface</A> <B>getFSDataset</B>()</PRE>
<DL>
<DD>This method is used for testing. 
 Examples are adding and deleting blocks directly.
 The most common usage will be when the data node's storage is similated.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>

<DT><B>返回：</B><DD>the fsdataset that stores the blocks</DL>
</DD>
</DL>
<HR>

<A NAME="secureMain(java.lang.String[], org.apache.hadoop.hdfs.server.datanode.SecureDataNodeStarter.SecureResources)"><!-- --></A><H3>
secureMain</H3>
<PRE>
public static void <B>secureMain</B>(java.lang.String[]&nbsp;args,
                              <A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/SecureDataNodeStarter.SecureResources.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">SecureDataNodeStarter.SecureResources</A>&nbsp;resources)</PRE>
<DL>
<DD><DL>
</DL>
</DD>
<DD><DL>
</DL>
</DD>
</DL>
<HR>

<A NAME="main(java.lang.String[])"><!-- --></A><H3>
main</H3>
<PRE>
public static void <B>main</B>(java.lang.String[]&nbsp;args)</PRE>
<DL>
<DD><DL>
</DL>
</DD>
<DD><DL>
</DL>
</DD>
</DL>
<HR>

<A NAME="recoverBlocks(java.util.Collection)"><!-- --></A><H3>
recoverBlocks</H3>
<PRE>
public org.apache.hadoop.util.Daemon <B>recoverBlocks</B>(java.util.Collection&lt;<A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/BlockRecoveryCommand.RecoveringBlock.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">BlockRecoveryCommand.RecoveringBlock</A>&gt;&nbsp;blocks)</PRE>
<DL>
<DD><DL>
</DL>
</DD>
<DD><DL>
</DL>
</DD>
</DL>
<HR>

<A NAME="initReplicaRecovery(org.apache.hadoop.hdfs.server.protocol.BlockRecoveryCommand.RecoveringBlock)"><!-- --></A><H3>
initReplicaRecovery</H3>
<PRE>
public <A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/ReplicaRecoveryInfo.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">ReplicaRecoveryInfo</A> <B>initReplicaRecovery</B>(<A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/BlockRecoveryCommand.RecoveringBlock.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">BlockRecoveryCommand.RecoveringBlock</A>&nbsp;rBlock)
                                        throws java.io.IOException</PRE>
<DL>
<DD><B>从接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/InterDatanodeProtocol.html#initReplicaRecovery(org.apache.hadoop.hdfs.server.protocol.BlockRecoveryCommand.RecoveringBlock)">InterDatanodeProtocol</A></CODE> 复制的描述</B></DD>
<DD>Initialize a replica recovery.
<P>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/InterDatanodeProtocol.html" title="org.apache.hadoop.hdfs.server.protocol 中的接口">InterDatanodeProtocol</A></CODE> 中的 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/InterDatanodeProtocol.html#initReplicaRecovery(org.apache.hadoop.hdfs.server.protocol.BlockRecoveryCommand.RecoveringBlock)">initReplicaRecovery</A></CODE></DL>
</DD>
<DD><DL>

<DT><B>返回：</B><DD>actual state of the replica on this data-node or 
 null if data-node does not have the replica.
<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="updateReplicaUnderRecovery(org.apache.hadoop.hdfs.protocol.Block, long, long)"><!-- --></A><H3>
updateReplicaUnderRecovery</H3>
<PRE>
public <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/Block.html" title="org.apache.hadoop.hdfs.protocol 中的类">Block</A> <B>updateReplicaUnderRecovery</B>(<A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/Block.html" title="org.apache.hadoop.hdfs.protocol 中的类">Block</A>&nbsp;oldBlock,
                                        long&nbsp;recoveryId,
                                        long&nbsp;newLength)
                                 throws java.io.IOException</PRE>
<DL>
<DD>Update replica with the new generation stamp and length.
<P>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/InterDatanodeProtocol.html" title="org.apache.hadoop.hdfs.server.protocol 中的接口">InterDatanodeProtocol</A></CODE> 中的 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/InterDatanodeProtocol.html#updateReplicaUnderRecovery(org.apache.hadoop.hdfs.protocol.Block, long, long)">updateReplicaUnderRecovery</A></CODE></DL>
</DD>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="beginRCRecovery(org.apache.hadoop.hdfs.protocol.DatanodeInfo, org.apache.hadoop.hdfs.protocol.Block[], byte[])"><!-- --></A><H3>
beginRCRecovery</H3>
<PRE>
public <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/LocatedBlock.html" title="org.apache.hadoop.hdfs.protocol 中的类">LocatedBlock</A> <B>beginRCRecovery</B>(<A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/DatanodeInfo.html" title="org.apache.hadoop.hdfs.protocol 中的类">DatanodeInfo</A>&nbsp;helperDatanodeInfo,
                                    <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/Block.html" title="org.apache.hadoop.hdfs.protocol 中的类">Block</A>[]&nbsp;computeBlocks,
                                    byte[]&nbsp;failednodeVector)
                             throws java.io.IOException</PRE>
<DL>
<DD>new comer inform a helper node to start rc in RC(regenerating code)recovery work. created at 2041-4-17. modified
 at 2014-4-24
<P>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/InterDatanodeProtocol.html" title="org.apache.hadoop.hdfs.server.protocol 中的接口">InterDatanodeProtocol</A></CODE> 中的 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/InterDatanodeProtocol.html#beginRCRecovery(org.apache.hadoop.hdfs.protocol.DatanodeInfo, org.apache.hadoop.hdfs.protocol.Block[], byte[])">beginRCRecovery</A></CODE></DL>
</DD>
<DD><DL>
<DT><B>参数：</B><DD><CODE>computeBlocks</CODE> - blocks who take part in liner computing<DD><CODE>failednodeVector</CODE> - row failed node in vondemendMatrix
<DT><B>返回：</B><DD>the liner computing result
<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="endRCRecovery(org.apache.hadoop.hdfs.protocol.Block)"><!-- --></A><H3>
endRCRecovery</H3>
<PRE>
public void <B>endRCRecovery</B>(<A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/Block.html" title="org.apache.hadoop.hdfs.protocol 中的类">Block</A>&nbsp;block)
                   throws java.io.IOException</PRE>
<DL>
<DD>new comer inform a helper node to end rc in RC(regenerating code)recovery work. created at 2041-4-24
<P>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/InterDatanodeProtocol.html" title="org.apache.hadoop.hdfs.server.protocol 中的接口">InterDatanodeProtocol</A></CODE> 中的 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/InterDatanodeProtocol.html#endRCRecovery(org.apache.hadoop.hdfs.protocol.Block)">endRCRecovery</A></CODE></DL>
</DD>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="getProtocolVersion(java.lang.String, long)"><!-- --></A><H3>
getProtocolVersion</H3>
<PRE>
public long <B>getProtocolVersion</B>(java.lang.String&nbsp;protocol,
                               long&nbsp;clientVersion)
                        throws java.io.IOException</PRE>
<DL>
<DD>
<P>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE>org.apache.hadoop.ipc.VersionedProtocol</CODE> 中的 <CODE>getProtocolVersion</CODE></DL>
</DD>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="getReplicaVisibleLength(org.apache.hadoop.hdfs.protocol.Block)"><!-- --></A><H3>
getReplicaVisibleLength</H3>
<PRE>
public long <B>getReplicaVisibleLength</B>(<A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/Block.html" title="org.apache.hadoop.hdfs.protocol 中的类">Block</A>&nbsp;block)
                             throws java.io.IOException</PRE>
<DL>
<DD>Return the visible length of a replica.
<P>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/ClientDatanodeProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的接口">ClientDatanodeProtocol</A></CODE> 中的 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/ClientDatanodeProtocol.html#getReplicaVisibleLength(org.apache.hadoop.hdfs.protocol.Block)">getReplicaVisibleLength</A></CODE></DL>
</DD>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="getStreamingAddr(org.apache.hadoop.conf.Configuration)"><!-- --></A><H3>
getStreamingAddr</H3>
<PRE>
public static java.net.InetSocketAddress <B>getStreamingAddr</B>(org.apache.hadoop.conf.Configuration&nbsp;conf)</PRE>
<DL>
<DD><DL>
</DL>
</DD>
<DD><DL>
</DL>
</DD>
</DL>
<HR>

<A NAME="getVersion()"><!-- --></A><H3>
getVersion</H3>
<PRE>
public java.lang.String <B>getVersion</B>()</PRE>
<DL>
<DD><B>从接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/DataNodeMXBean.html#getVersion()">DataNodeMXBean</A></CODE> 复制的描述</B></DD>
<DD>Gets the version of Hadoop.
<P>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/DataNodeMXBean.html" title="org.apache.hadoop.hdfs.server.datanode 中的接口">DataNodeMXBean</A></CODE> 中的 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/DataNodeMXBean.html#getVersion()">getVersion</A></CODE></DL>
</DD>
<DD><DL>

<DT><B>返回：</B><DD>the version of Hadoop</DL>
</DD>
</DL>
<HR>

<A NAME="getRpcPort()"><!-- --></A><H3>
getRpcPort</H3>
<PRE>
public java.lang.String <B>getRpcPort</B>()</PRE>
<DL>
<DD><B>从接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/DataNodeMXBean.html#getRpcPort()">DataNodeMXBean</A></CODE> 复制的描述</B></DD>
<DD>Gets the rpc port.
<P>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/DataNodeMXBean.html" title="org.apache.hadoop.hdfs.server.datanode 中的接口">DataNodeMXBean</A></CODE> 中的 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/DataNodeMXBean.html#getRpcPort()">getRpcPort</A></CODE></DL>
</DD>
<DD><DL>

<DT><B>返回：</B><DD>the rpc port</DL>
</DD>
</DL>
<HR>

<A NAME="getHttpPort()"><!-- --></A><H3>
getHttpPort</H3>
<PRE>
public java.lang.String <B>getHttpPort</B>()</PRE>
<DL>
<DD><B>从接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/DataNodeMXBean.html#getHttpPort()">DataNodeMXBean</A></CODE> 复制的描述</B></DD>
<DD>Gets the http port.
<P>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/DataNodeMXBean.html" title="org.apache.hadoop.hdfs.server.datanode 中的接口">DataNodeMXBean</A></CODE> 中的 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/DataNodeMXBean.html#getHttpPort()">getHttpPort</A></CODE></DL>
</DD>
<DD><DL>

<DT><B>返回：</B><DD>the http port</DL>
</DD>
</DL>
<HR>

<A NAME="getInfoPort()"><!-- --></A><H3>
getInfoPort</H3>
<PRE>
public int <B>getInfoPort</B>()</PRE>
<DL>
<DD><DL>
</DL>
</DD>
<DD><DL>
</DL>
</DD>
</DL>
<HR>

<A NAME="getNamenodeAddress()"><!-- --></A><H3>
getNamenodeAddress</H3>
<PRE>
public java.lang.String <B>getNamenodeAddress</B>()</PRE>
<DL>
<DD><B>从接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/DataNodeMXBean.html#getNamenodeAddress()">DataNodeMXBean</A></CODE> 复制的描述</B></DD>
<DD>Gets the namenode IP address.
<P>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/DataNodeMXBean.html" title="org.apache.hadoop.hdfs.server.datanode 中的接口">DataNodeMXBean</A></CODE> 中的 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/DataNodeMXBean.html#getNamenodeAddress()">getNamenodeAddress</A></CODE></DL>
</DD>
<DD><DL>

<DT><B>返回：</B><DD>the namenode IP address</DL>
</DD>
</DL>
<HR>

<A NAME="getVolumeInfo()"><!-- --></A><H3>
getVolumeInfo</H3>
<PRE>
public java.lang.String <B>getVolumeInfo</B>()</PRE>
<DL>
<DD>Returned information is a JSON representation of a map with 
 volume name as the key and value is a map of volume attribute 
 keys to its values
<P>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/DataNodeMXBean.html" title="org.apache.hadoop.hdfs.server.datanode 中的接口">DataNodeMXBean</A></CODE> 中的 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/DataNodeMXBean.html#getVolumeInfo()">getVolumeInfo</A></CODE></DL>
</DD>
<DD><DL>

<DT><B>返回：</B><DD>the volume info</DL>
</DD>
</DL>
<!-- ========= END OF CLASS DATA ========= -->
<HR>


<!-- ======= START OF BOTTOM NAVBAR ====== -->
<A NAME="navbar_bottom"><!-- --></A>
<A HREF="#skip-navbar_bottom" title="跳过导航链接"></A>
<TABLE BORDER="0" WIDTH="100%" CELLPADDING="1" CELLSPACING="0" SUMMARY="">
<TR>
<TD COLSPAN=2 BGCOLOR="#EEEEFF" CLASS="NavBarCell1">
<A NAME="navbar_bottom_firstrow"><!-- --></A>
<TABLE BORDER="0" CELLPADDING="0" CELLSPACING="3" SUMMARY="">
  <TR ALIGN="center" VALIGN="top">
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="../../../../../../overview-summary.html"><FONT CLASS="NavBarFont1"><B>概述</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="package-summary.html"><FONT CLASS="NavBarFont1"><B>软件包</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#FFFFFF" CLASS="NavBarCell1Rev"> &nbsp;<FONT CLASS="NavBarFont1Rev"><B>类</B></FONT>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="class-use/DataNode.html"><FONT CLASS="NavBarFont1"><B>使用</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="package-tree.html"><FONT CLASS="NavBarFont1"><B>树</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="../../../../../../deprecated-list.html"><FONT CLASS="NavBarFont1"><B>已过时</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="../../../../../../index-all.html"><FONT CLASS="NavBarFont1"><B>索引</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="../../../../../../help-doc.html"><FONT CLASS="NavBarFont1"><B>帮助</B></FONT></A>&nbsp;</TD>
  </TR>
</TABLE>
</TD>
<TD ALIGN="right" VALIGN="top" ROWSPAN=3><EM>
</EM>
</TD>
</TR>

<TR>
<TD BGCOLOR="white" CLASS="NavBarCell2"><FONT SIZE="-2">
&nbsp;上一个类&nbsp;
&nbsp;<A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/DataNode.RCRecoveryThreadTarget.html" title="org.apache.hadoop.hdfs.server.datanode 中的类"><B>下一个类</B></A></FONT></TD>
<TD BGCOLOR="white" CLASS="NavBarCell2"><FONT SIZE="-2">
  <A HREF="../../../../../../index.html?org/apache/hadoop/hdfs/server/datanode/DataNode.html" target="_top"><B>框架</B></A>  &nbsp;
&nbsp;<A HREF="DataNode.html" target="_top"><B>无框架</B></A>  &nbsp;
&nbsp;<SCRIPT type="text/javascript">
  <!--
  if(window==top) {
    document.writeln('<A HREF="../../../../../../allclasses-noframe.html"><B>所有类</B></A>');
  }
  //-->
</SCRIPT>
<NOSCRIPT>
  <A HREF="../../../../../../allclasses-noframe.html"><B>所有类</B></A>
</NOSCRIPT>


</FONT></TD>
</TR>
<TR>
<TD VALIGN="top" CLASS="NavBarCell3"><FONT SIZE="-2">
  摘要：&nbsp;<A HREF="#nested_class_summary">嵌套</A>&nbsp;|&nbsp;<A HREF="#field_summary">字段</A>&nbsp;|&nbsp;构造方法&nbsp;|&nbsp;<A HREF="#method_summary">方法</A></FONT></TD>
<TD VALIGN="top" CLASS="NavBarCell3"><FONT SIZE="-2">
详细信息：&nbsp;<A HREF="#field_detail">字段</A>&nbsp;|&nbsp;构造方法&nbsp;|&nbsp;<A HREF="#method_detail">方法</A></FONT></TD>
</TR>
</TABLE>
<A NAME="skip-navbar_bottom"></A>
<!-- ======== END OF BOTTOM NAVBAR ======= -->

<HR>
Copyright &copy; 2009 The Apache Software Foundation
</BODY>
</HTML>
