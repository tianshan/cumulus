<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<!--NewPage-->
<HTML>
<HEAD>
<!-- Generated by javadoc (build 1.6.0_18) on Sun May 03 20:19:35 CST 2015 -->
<TITLE>
NameNode (Hadoop-Hdfs 0.22.1-SNAPSHOT API)
</TITLE>

<META NAME="date" CONTENT="2015-05-03">

<LINK REL ="stylesheet" TYPE="text/css" HREF="../../../../../../stylesheet.css" TITLE="Style">

<SCRIPT type="text/javascript">
function windowTitle()
{
    if (location.href.indexOf('is-external=true') == -1) {
        parent.document.title="NameNode (Hadoop-Hdfs 0.22.1-SNAPSHOT API)";
    }
}
</SCRIPT>
<NOSCRIPT>
</NOSCRIPT>

</HEAD>

<BODY BGCOLOR="white" onload="windowTitle();">
<HR>


<!-- ========= START OF TOP NAVBAR ======= -->
<A NAME="navbar_top"><!-- --></A>
<A HREF="#skip-navbar_top" title="跳过导航链接"></A>
<TABLE BORDER="0" WIDTH="100%" CELLPADDING="1" CELLSPACING="0" SUMMARY="">
<TR>
<TD COLSPAN=2 BGCOLOR="#EEEEFF" CLASS="NavBarCell1">
<A NAME="navbar_top_firstrow"><!-- --></A>
<TABLE BORDER="0" CELLPADDING="0" CELLSPACING="3" SUMMARY="">
  <TR ALIGN="center" VALIGN="top">
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="../../../../../../overview-summary.html"><FONT CLASS="NavBarFont1"><B>概述</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="package-summary.html"><FONT CLASS="NavBarFont1"><B>软件包</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#FFFFFF" CLASS="NavBarCell1Rev"> &nbsp;<FONT CLASS="NavBarFont1Rev"><B>类</B></FONT>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="class-use/NameNode.html"><FONT CLASS="NavBarFont1"><B>使用</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="package-tree.html"><FONT CLASS="NavBarFont1"><B>树</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="../../../../../../deprecated-list.html"><FONT CLASS="NavBarFont1"><B>已过时</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="../../../../../../index-all.html"><FONT CLASS="NavBarFont1"><B>索引</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="../../../../../../help-doc.html"><FONT CLASS="NavBarFont1"><B>帮助</B></FONT></A>&nbsp;</TD>
  </TR>
</TABLE>
</TD>
<TD ALIGN="right" VALIGN="top" ROWSPAN=3><EM>
</EM>
</TD>
</TR>

<TR>
<TD BGCOLOR="white" CLASS="NavBarCell2"><FONT SIZE="-2">
&nbsp;<A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/MonitorServlet.html" title="org.apache.hadoop.hdfs.server.namenode 中的类"><B>上一个类</B></A>&nbsp;
&nbsp;<A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NamenodeFsck.html" title="org.apache.hadoop.hdfs.server.namenode 中的类"><B>下一个类</B></A></FONT></TD>
<TD BGCOLOR="white" CLASS="NavBarCell2"><FONT SIZE="-2">
  <A HREF="../../../../../../index.html?org/apache/hadoop/hdfs/server/namenode/NameNode.html" target="_top"><B>框架</B></A>  &nbsp;
&nbsp;<A HREF="NameNode.html" target="_top"><B>无框架</B></A>  &nbsp;
&nbsp;<SCRIPT type="text/javascript">
  <!--
  if(window==top) {
    document.writeln('<A HREF="../../../../../../allclasses-noframe.html"><B>所有类</B></A>');
  }
  //-->
</SCRIPT>
<NOSCRIPT>
  <A HREF="../../../../../../allclasses-noframe.html"><B>所有类</B></A>
</NOSCRIPT>


</FONT></TD>
</TR>
<TR>
<TD VALIGN="top" CLASS="NavBarCell3"><FONT SIZE="-2">
  摘要：&nbsp;嵌套&nbsp;|&nbsp;<A HREF="#field_summary">字段</A>&nbsp;|&nbsp;<A HREF="#constructor_summary">构造方法</A>&nbsp;|&nbsp;<A HREF="#method_summary">方法</A></FONT></TD>
<TD VALIGN="top" CLASS="NavBarCell3"><FONT SIZE="-2">
详细信息：&nbsp;<A HREF="#field_detail">字段</A>&nbsp;|&nbsp;<A HREF="#constructor_detail">构造方法</A>&nbsp;|&nbsp;<A HREF="#method_detail">方法</A></FONT></TD>
</TR>
</TABLE>
<A NAME="skip-navbar_top"></A>
<!-- ========= END OF TOP NAVBAR ========= -->

<HR>
<!-- ======== START OF CLASS DATA ======== -->
<H2>
<FONT SIZE="-1">
org.apache.hadoop.hdfs.server.namenode</FONT>
<BR>
类 NameNode</H2>
<PRE>
java.lang.Object
  <IMG SRC="../../../../../../resources/inherit.gif" ALT="继承者 "><B>org.apache.hadoop.hdfs.server.namenode.NameNode</B>
</PRE>
<DL>
<DT><B>所有已实现的接口：</B> <DD><A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的接口">ClientProtocol</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/FSConstants.html" title="org.apache.hadoop.hdfs.protocol 中的接口">FSConstants</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/DatanodeProtocol.html" title="org.apache.hadoop.hdfs.server.protocol 中的接口">DatanodeProtocol</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/NamenodeProtocol.html" title="org.apache.hadoop.hdfs.server.protocol 中的接口">NamenodeProtocol</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/NamenodeProtocols.html" title="org.apache.hadoop.hdfs.server.protocol 中的接口">NamenodeProtocols</A>, org.apache.hadoop.ipc.VersionedProtocol, org.apache.hadoop.security.authorize.RefreshAuthorizationPolicyProtocol, org.apache.hadoop.security.RefreshUserMappingsProtocol</DD>
</DL>
<DL>
<DT><B>直接已知子类：</B> <DD><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/BackupNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">BackupNode</A></DD>
</DL>
<HR>
<DL>
<DT><PRE><FONT SIZE="-1">@InterfaceAudience.Private
</FONT>public class <B>NameNode</B><DT>extends java.lang.Object<DT>implements <A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/NamenodeProtocols.html" title="org.apache.hadoop.hdfs.server.protocol 中的接口">NamenodeProtocols</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/FSConstants.html" title="org.apache.hadoop.hdfs.protocol 中的接口">FSConstants</A></DL>
</PRE>

<P>
NameNode serves as both directory namespace manager and
 "inode table" for the Hadoop DFS.  There is a single NameNode
 running in any DFS deployment.  (Well, except when there
 is a second backup/failover NameNode.)

 The NameNode controls two critical tables:
   1)  filename->blocksequence (namespace)
   2)  block->machinelist ("inodes")

 The first table is stored on disk and is very precious.
 The second table is rebuilt every time the NameNode comes
 up.

 'NameNode' refers to both this class as well as the 'NameNode server'.
 The 'FSNamesystem' class actually performs most of the filesystem
 management.  The majority of the 'NameNode' class itself is concerned
 with exposing the IPC interface and the http server to the outside world,
 plus some configuration management.

 NameNode implements the ClientProtocol interface, which allows
 clients to ask for DFS services.  ClientProtocol is not
 designed for direct use by authors of DFS client code.  End-users
 should instead use the org.apache.nutch.hadoop.fs.FileSystem class.

 NameNode also implements the DatanodeProtocol interface, used by
 DataNode programs that actually store DFS data blocks.  These
 methods are invoked repeatedly and automatically by all the
 DataNodes in a DFS deployment.

 NameNode also implements the NamenodeProtocol interface, used by
 secondary namenodes or rebalancing processes to get partial namenode's
 state, for example partial blocksMap etc.
<P>

<P>
<HR>

<P>
<!-- ======== NESTED CLASS SUMMARY ======== -->

<A NAME="nested_class_summary"><!-- --></A>
<TABLE BORDER="1" WIDTH="100%" CELLPADDING="3" CELLSPACING="0" SUMMARY="">
<TR BGCOLOR="#CCCCFF" CLASS="TableHeadingColor">
<TH ALIGN="left" COLSPAN="2"><FONT SIZE="+2">
<B>嵌套类摘要</B></FONT></TH>
</TR>
</TABLE>
&nbsp;<A NAME="nested_classes_inherited_from_class_org.apache.hadoop.hdfs.protocol.FSConstants"><!-- --></A>
<TABLE BORDER="1" WIDTH="100%" CELLPADDING="3" CELLSPACING="0" SUMMARY="">
<TR BGCOLOR="#EEEEFF" CLASS="TableSubHeadingColor">
<TH ALIGN="left"><B>从接口 org.apache.hadoop.hdfs.protocol.<A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/FSConstants.html" title="org.apache.hadoop.hdfs.protocol 中的接口">FSConstants</A> 继承的嵌套类/接口</B></TH>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD><CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/FSConstants.DatanodeReportType.html" title="org.apache.hadoop.hdfs.protocol 中的枚举">FSConstants.DatanodeReportType</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/FSConstants.SafeModeAction.html" title="org.apache.hadoop.hdfs.protocol 中的枚举">FSConstants.SafeModeAction</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/FSConstants.UpgradeAction.html" title="org.apache.hadoop.hdfs.protocol 中的枚举">FSConstants.UpgradeAction</A></CODE></TD>
</TR>
</TABLE>
&nbsp;
<!-- =========== FIELD SUMMARY =========== -->

<A NAME="field_summary"><!-- --></A>
<TABLE BORDER="1" WIDTH="100%" CELLPADDING="3" CELLSPACING="0" SUMMARY="">
<TR BGCOLOR="#CCCCFF" CLASS="TableHeadingColor">
<TH ALIGN="left" COLSPAN="2"><FONT SIZE="+2">
<B>字段摘要</B></FONT></TH>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;int</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNode.html#DEFAULT_PORT">DEFAULT_PORT</A></B></CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>protected &nbsp;java.net.InetSocketAddress</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNode.html#httpAddress">httpAddress</A></B></CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;HTTP server address</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>protected &nbsp;org.apache.hadoop.http.HttpServer</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNode.html#httpServer">httpServer</A></B></CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;httpServer</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;org.apache.commons.logging.Log</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNode.html#LOG">LOG</A></B></CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>protected &nbsp;<A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FSNamesystem</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNode.html#namesystem">namesystem</A></B></CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>protected &nbsp;<A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/NamenodeRegistration.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">NamenodeRegistration</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNode.html#nodeRegistration">nodeRegistration</A></B></CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Registration information of this name-node</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>protected &nbsp;<A HREF="../../../../../../org/apache/hadoop/hdfs/server/common/HdfsConstants.NamenodeRole.html" title="org.apache.hadoop.hdfs.server.common 中的枚举">HdfsConstants.NamenodeRole</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNode.html#role">role</A></B></CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>protected &nbsp;java.net.InetSocketAddress</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNode.html#rpcAddress">rpcAddress</A></B></CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;RPC server address</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>protected &nbsp;java.net.InetSocketAddress</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNode.html#serviceRPCAddress">serviceRPCAddress</A></B></CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;RPC server for DN address</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>protected &nbsp;org.apache.hadoop.ipc.Server</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNode.html#serviceRpcServer">serviceRpcServer</A></B></CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;RPC server for HDFS Services communication.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;org.apache.commons.logging.Log</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNode.html#stateChangeLog">stateChangeLog</A></B></CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>protected &nbsp;boolean</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNode.html#stopRequested">stopRequested</A></B></CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;only used for testing purposes</TD>
</TR>
</TABLE>
&nbsp;<A NAME="fields_inherited_from_class_org.apache.hadoop.hdfs.protocol.ClientProtocol"><!-- --></A>
<TABLE BORDER="1" WIDTH="100%" CELLPADDING="3" CELLSPACING="0" SUMMARY="">
<TR BGCOLOR="#EEEEFF" CLASS="TableSubHeadingColor">
<TH ALIGN="left"><B>从接口 org.apache.hadoop.hdfs.protocol.<A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的接口">ClientProtocol</A> 继承的字段</B></TH>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD><CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html#GET_STATS_CAPACITY_IDX">GET_STATS_CAPACITY_IDX</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html#GET_STATS_CORRUPT_BLOCKS_IDX">GET_STATS_CORRUPT_BLOCKS_IDX</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html#GET_STATS_MISSING_BLOCKS_IDX">GET_STATS_MISSING_BLOCKS_IDX</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html#GET_STATS_REMAINING_IDX">GET_STATS_REMAINING_IDX</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html#GET_STATS_UNDER_REPLICATED_IDX">GET_STATS_UNDER_REPLICATED_IDX</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html#GET_STATS_USED_IDX">GET_STATS_USED_IDX</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html#versionID">versionID</A></CODE></TD>
</TR>
</TABLE>
&nbsp;<A NAME="fields_inherited_from_class_org.apache.hadoop.hdfs.server.protocol.DatanodeProtocol"><!-- --></A>
<TABLE BORDER="1" WIDTH="100%" CELLPADDING="3" CELLSPACING="0" SUMMARY="">
<TR BGCOLOR="#EEEEFF" CLASS="TableSubHeadingColor">
<TH ALIGN="left"><B>从接口 org.apache.hadoop.hdfs.server.protocol.<A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/DatanodeProtocol.html" title="org.apache.hadoop.hdfs.server.protocol 中的接口">DatanodeProtocol</A> 继承的字段</B></TH>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD><CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/DatanodeProtocol.html#DISK_ERROR">DISK_ERROR</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/DatanodeProtocol.html#DNA_ACCESSKEYUPDATE">DNA_ACCESSKEYUPDATE</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/DatanodeProtocol.html#DNA_CUMULUS_RECOVERY">DNA_CUMULUS_RECOVERY</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/DatanodeProtocol.html#DNA_FINALIZE">DNA_FINALIZE</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/DatanodeProtocol.html#DNA_INVALIDATE">DNA_INVALIDATE</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/DatanodeProtocol.html#DNA_RC_RECOVERY">DNA_RC_RECOVERY</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/DatanodeProtocol.html#DNA_RECOVERBLOCK">DNA_RECOVERBLOCK</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/DatanodeProtocol.html#DNA_REGISTER">DNA_REGISTER</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/DatanodeProtocol.html#DNA_SHUTDOWN">DNA_SHUTDOWN</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/DatanodeProtocol.html#DNA_TRANSFER">DNA_TRANSFER</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/DatanodeProtocol.html#DNA_UNKNOWN">DNA_UNKNOWN</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/DatanodeProtocol.html#FATAL_DISK_ERROR">FATAL_DISK_ERROR</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/DatanodeProtocol.html#INVALID_BLOCK">INVALID_BLOCK</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/DatanodeProtocol.html#NOTIFY">NOTIFY</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/DatanodeProtocol.html#versionID">versionID</A></CODE></TD>
</TR>
</TABLE>
&nbsp;<A NAME="fields_inherited_from_class_org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol"><!-- --></A>
<TABLE BORDER="1" WIDTH="100%" CELLPADDING="3" CELLSPACING="0" SUMMARY="">
<TR BGCOLOR="#EEEEFF" CLASS="TableSubHeadingColor">
<TH ALIGN="left"><B>从接口 org.apache.hadoop.hdfs.server.protocol.<A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/NamenodeProtocol.html" title="org.apache.hadoop.hdfs.server.protocol 中的接口">NamenodeProtocol</A> 继承的字段</B></TH>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD><CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/NamenodeProtocol.html#ACT_CHECKPOINT">ACT_CHECKPOINT</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/NamenodeProtocol.html#ACT_SHUTDOWN">ACT_SHUTDOWN</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/NamenodeProtocol.html#ACT_UNKNOWN">ACT_UNKNOWN</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/NamenodeProtocol.html#FATAL">FATAL</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/NamenodeProtocol.html#JA_CHECKPOINT_TIME">JA_CHECKPOINT_TIME</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/NamenodeProtocol.html#JA_IS_ALIVE">JA_IS_ALIVE</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/NamenodeProtocol.html#JA_JOURNAL">JA_JOURNAL</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/NamenodeProtocol.html#JA_JSPOOL_START">JA_JSPOOL_START</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/NamenodeProtocol.html#NOTIFY">NOTIFY</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/NamenodeProtocol.html#versionID">versionID</A></CODE></TD>
</TR>
</TABLE>
&nbsp;<A NAME="fields_inherited_from_class_org.apache.hadoop.security.authorize.RefreshAuthorizationPolicyProtocol"><!-- --></A>
<TABLE BORDER="1" WIDTH="100%" CELLPADDING="3" CELLSPACING="0" SUMMARY="">
<TR BGCOLOR="#EEEEFF" CLASS="TableSubHeadingColor">
<TH ALIGN="left"><B>从接口 org.apache.hadoop.security.authorize.RefreshAuthorizationPolicyProtocol 继承的字段</B></TH>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD><CODE>versionID</CODE></TD>
</TR>
</TABLE>
&nbsp;<A NAME="fields_inherited_from_class_org.apache.hadoop.security.RefreshUserMappingsProtocol"><!-- --></A>
<TABLE BORDER="1" WIDTH="100%" CELLPADDING="3" CELLSPACING="0" SUMMARY="">
<TR BGCOLOR="#EEEEFF" CLASS="TableSubHeadingColor">
<TH ALIGN="left"><B>从接口 org.apache.hadoop.security.RefreshUserMappingsProtocol 继承的字段</B></TH>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD><CODE>versionID</CODE></TD>
</TR>
</TABLE>
&nbsp;<A NAME="fields_inherited_from_class_org.apache.hadoop.hdfs.protocol.FSConstants"><!-- --></A>
<TABLE BORDER="1" WIDTH="100%" CELLPADDING="3" CELLSPACING="0" SUMMARY="">
<TR BGCOLOR="#EEEEFF" CLASS="TableSubHeadingColor">
<TH ALIGN="left"><B>从接口 org.apache.hadoop.hdfs.protocol.<A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/FSConstants.html" title="org.apache.hadoop.hdfs.protocol 中的接口">FSConstants</A> 继承的字段</B></TH>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD><CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/FSConstants.html#BLOCK_INVALIDATE_CHUNK">BLOCK_INVALIDATE_CHUNK</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/FSConstants.html#BLOCKREPORT_INITIAL_DELAY">BLOCKREPORT_INITIAL_DELAY</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/FSConstants.html#BLOCKREPORT_INTERVAL">BLOCKREPORT_INTERVAL</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/FSConstants.html#BUFFER_SIZE">BUFFER_SIZE</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/FSConstants.html#DEFAULT_BLOCK_SIZE">DEFAULT_BLOCK_SIZE</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/FSConstants.html#DEFAULT_BYTES_PER_CHECKSUM">DEFAULT_BYTES_PER_CHECKSUM</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/FSConstants.html#DEFAULT_DATA_SOCKET_SIZE">DEFAULT_DATA_SOCKET_SIZE</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/FSConstants.html#DEFAULT_FILE_BUFFER_SIZE">DEFAULT_FILE_BUFFER_SIZE</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/FSConstants.html#DEFAULT_REPLICATION_FACTOR">DEFAULT_REPLICATION_FACTOR</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/FSConstants.html#DEFAULT_WRITE_PACKET_SIZE">DEFAULT_WRITE_PACKET_SIZE</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/FSConstants.html#HDFS_URI_SCHEME">HDFS_URI_SCHEME</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/FSConstants.html#HEARTBEAT_INTERVAL">HEARTBEAT_INTERVAL</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/FSConstants.html#LAYOUT_VERSION">LAYOUT_VERSION</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/FSConstants.html#LEASE_HARDLIMIT_PERIOD">LEASE_HARDLIMIT_PERIOD</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/FSConstants.html#LEASE_RECOVER_PERIOD">LEASE_RECOVER_PERIOD</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/FSConstants.html#LEASE_SOFTLIMIT_PERIOD">LEASE_SOFTLIMIT_PERIOD</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/FSConstants.html#MAX_PATH_DEPTH">MAX_PATH_DEPTH</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/FSConstants.html#MAX_PATH_LENGTH">MAX_PATH_LENGTH</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/FSConstants.html#MIN_BLOCKS_FOR_WRITE">MIN_BLOCKS_FOR_WRITE</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/FSConstants.html#QUOTA_DONT_SET">QUOTA_DONT_SET</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/FSConstants.html#QUOTA_RESET">QUOTA_RESET</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/FSConstants.html#SIZE_OF_INTEGER">SIZE_OF_INTEGER</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/FSConstants.html#SMALL_BUFFER_SIZE">SMALL_BUFFER_SIZE</A></CODE></TD>
</TR>
</TABLE>
&nbsp;
<!-- ======== CONSTRUCTOR SUMMARY ======== -->

<A NAME="constructor_summary"><!-- --></A>
<TABLE BORDER="1" WIDTH="100%" CELLPADDING="3" CELLSPACING="0" SUMMARY="">
<TR BGCOLOR="#CCCCFF" CLASS="TableHeadingColor">
<TH ALIGN="left" COLSPAN="2"><FONT SIZE="+2">
<B>构造方法摘要</B></FONT></TH>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNode.html#NameNode(org.apache.hadoop.conf.Configuration)">NameNode</A></B>(org.apache.hadoop.conf.Configuration&nbsp;conf)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Start NameNode.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>protected </CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNode.html#NameNode(org.apache.hadoop.conf.Configuration, org.apache.hadoop.hdfs.server.common.HdfsConstants.NamenodeRole)">NameNode</A></B>(org.apache.hadoop.conf.Configuration&nbsp;conf,
         <A HREF="../../../../../../org/apache/hadoop/hdfs/server/common/HdfsConstants.NamenodeRole.html" title="org.apache.hadoop.hdfs.server.common 中的枚举">HdfsConstants.NamenodeRole</A>&nbsp;role)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
</TABLE>
&nbsp;
<!-- ========== METHOD SUMMARY =========== -->

<A NAME="method_summary"><!-- --></A>
<TABLE BORDER="1" WIDTH="100%" CELLPADDING="3" CELLSPACING="0" SUMMARY="">
<TR BGCOLOR="#CCCCFF" CLASS="TableHeadingColor">
<TH ALIGN="left" COLSPAN="2"><FONT SIZE="+2">
<B>方法摘要</B></FONT></TH>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;void</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNode.html#abandonBlock(org.apache.hadoop.hdfs.protocol.Block, java.lang.String, java.lang.String)">abandonBlock</A></B>(<A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/Block.html" title="org.apache.hadoop.hdfs.protocol 中的类">Block</A>&nbsp;b,
             java.lang.String&nbsp;src,
             java.lang.String&nbsp;holder)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The client needs to give up on the block.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;<A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/LocatedBlock.html" title="org.apache.hadoop.hdfs.protocol 中的类">LocatedBlock</A>[]</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNode.html#addBlock(java.lang.String, java.lang.String, org.apache.hadoop.hdfs.protocol.Block, org.apache.hadoop.hdfs.protocol.DatanodeInfo[])">addBlock</A></B>(java.lang.String&nbsp;src,
         java.lang.String&nbsp;clientName,
         <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/Block.html" title="org.apache.hadoop.hdfs.protocol 中的类">Block</A>&nbsp;previous,
         <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/DatanodeInfo.html" title="org.apache.hadoop.hdfs.protocol 中的类">DatanodeInfo</A>[]&nbsp;excludedNodes)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;A client that wants to write an additional block to the 
 indicated filename (which must currently be open for writing)
 should call addBlock().</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;<A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/LocatedBlock.html" title="org.apache.hadoop.hdfs.protocol 中的类">LocatedBlock</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNode.html#append(java.lang.String, java.lang.String)">append</A></B>(java.lang.String&nbsp;src,
       java.lang.String&nbsp;clientName)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Append to the end of the file.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;void</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNode.html#blockReceived(org.apache.hadoop.hdfs.server.protocol.DatanodeRegistration, org.apache.hadoop.hdfs.protocol.Block[], java.lang.String[])">blockReceived</A></B>(<A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/DatanodeRegistration.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">DatanodeRegistration</A>&nbsp;nodeReg,
              <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/Block.html" title="org.apache.hadoop.hdfs.protocol 中的类">Block</A>[]&nbsp;blocks,
              java.lang.String[]&nbsp;delHints)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;blockReceived() allows the DataNode to tell the NameNode about
 recently-received block data, with a hint for pereferred replica
 to be deleted when there is any excessive blocks.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;<A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/DatanodeCommand.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">DatanodeCommand</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNode.html#blockReport(org.apache.hadoop.hdfs.server.protocol.DatanodeRegistration, long[])">blockReport</A></B>(<A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/DatanodeRegistration.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">DatanodeRegistration</A>&nbsp;nodeReg,
            long[]&nbsp;blocks)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;blockReport() tells the NameNode about all the locally-stored blocks.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;void</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNode.html#cancelDelegationToken(org.apache.hadoop.security.token.Token)">cancelDelegationToken</A></B>(org.apache.hadoop.security.token.Token&lt;<A HREF="../../../../../../org/apache/hadoop/hdfs/security/token/delegation/DelegationTokenIdentifier.html" title="org.apache.hadoop.hdfs.security.token.delegation 中的类">DelegationTokenIdentifier</A>&gt;&nbsp;token)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Cancel an existing delegation token.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;void</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNode.html#commitBlockSynchronization(org.apache.hadoop.hdfs.protocol.Block, long, long, boolean, boolean, org.apache.hadoop.hdfs.protocol.DatanodeID[])">commitBlockSynchronization</A></B>(<A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/Block.html" title="org.apache.hadoop.hdfs.protocol 中的类">Block</A>&nbsp;block,
                           long&nbsp;newgenerationstamp,
                           long&nbsp;newlength,
                           boolean&nbsp;closeFile,
                           boolean&nbsp;deleteblock,
                           <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/DatanodeID.html" title="org.apache.hadoop.hdfs.protocol 中的类">DatanodeID</A>[]&nbsp;newtargets)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Commit block synchronization in lease recovery</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;boolean</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNode.html#complete(java.lang.String, java.lang.String, org.apache.hadoop.hdfs.protocol.Block[])">complete</A></B>(java.lang.String&nbsp;src,
         java.lang.String&nbsp;clientName,
         <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/Block.html" title="org.apache.hadoop.hdfs.protocol 中的类">Block</A>[]&nbsp;blks)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;modified by Vither Chien, we dont need the param lastblock, we 
 complete the file instead.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;void</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNode.html#concat(java.lang.String, java.lang.String[])">concat</A></B>(java.lang.String&nbsp;trg,
       java.lang.String[]&nbsp;src)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Moves blocks from srcs to trg and delete srcs</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;void</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNode.html#create(java.lang.String, org.apache.hadoop.fs.permission.FsPermission, java.lang.String, org.apache.hadoop.io.EnumSetWritable, boolean, short, long)">create</A></B>(java.lang.String&nbsp;src,
       org.apache.hadoop.fs.permission.FsPermission&nbsp;masked,
       java.lang.String&nbsp;clientName,
       org.apache.hadoop.io.EnumSetWritable&lt;org.apache.hadoop.fs.CreateFlag&gt;&nbsp;flag,
       boolean&nbsp;createParent,
       short&nbsp;replication,
       long&nbsp;blockSize)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Create a new file entry in the namespace.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;<A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/CodingMatrix.html" title="org.apache.hadoop.hdfs.protocol 中的类">CodingMatrix</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNode.html#create(java.lang.String, long, long, org.apache.hadoop.fs.permission.FsPermission, java.lang.String, org.apache.hadoop.io.EnumSetWritable, boolean)">create</A></B>(java.lang.String&nbsp;src,
       long&nbsp;fileSize,
       long&nbsp;packetSize,
       org.apache.hadoop.fs.permission.FsPermission&nbsp;masked,
       java.lang.String&nbsp;clientName,
       org.apache.hadoop.io.EnumSetWritable&lt;org.apache.hadoop.fs.CreateFlag&gt;&nbsp;flag,
       boolean&nbsp;createParent)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">NameNode</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNode.html#createNameNode(java.lang.String[], org.apache.hadoop.conf.Configuration)">createNameNode</A></B>(java.lang.String[]&nbsp;argv,
               org.apache.hadoop.conf.Configuration&nbsp;conf)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;void</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNode.html#createSymlink(java.lang.String, java.lang.String, org.apache.hadoop.fs.permission.FsPermission, boolean)">createSymlink</A></B>(java.lang.String&nbsp;target,
              java.lang.String&nbsp;link,
              org.apache.hadoop.fs.permission.FsPermission&nbsp;dirPerms,
              boolean&nbsp;createParent)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Create symlink to a file or directory.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;boolean</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNode.html#delete(java.lang.String)">delete</A></B>(java.lang.String&nbsp;src)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<B>已过时。</B>&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;boolean</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNode.html#delete(java.lang.String, boolean)">delete</A></B>(java.lang.String&nbsp;src,
       boolean&nbsp;recursive)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Delete the given file or directory from the file system.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;<A HREF="../../../../../../org/apache/hadoop/hdfs/server/common/UpgradeStatusReport.html" title="org.apache.hadoop.hdfs.server.common 中的类">UpgradeStatusReport</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNode.html#distributedUpgradeProgress(org.apache.hadoop.hdfs.protocol.FSConstants.UpgradeAction)">distributedUpgradeProgress</A></B>(<A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/FSConstants.UpgradeAction.html" title="org.apache.hadoop.hdfs.protocol 中的枚举">FSConstants.UpgradeAction</A>&nbsp;action)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Report distributed upgrade progress or force current upgrade to proceed.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;void</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNode.html#endCheckpoint(org.apache.hadoop.hdfs.server.protocol.NamenodeRegistration, org.apache.hadoop.hdfs.server.namenode.CheckpointSignature)">endCheckpoint</A></B>(<A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/NamenodeRegistration.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">NamenodeRegistration</A>&nbsp;registration,
              <A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/CheckpointSignature.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">CheckpointSignature</A>&nbsp;sig)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;A request to the active name-node to finalize
 previously started checkpoint.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;void</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNode.html#errorReport(org.apache.hadoop.hdfs.server.protocol.DatanodeRegistration, int, java.lang.String)">errorReport</A></B>(<A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/DatanodeRegistration.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">DatanodeRegistration</A>&nbsp;nodeReg,
            int&nbsp;errorCode,
            java.lang.String&nbsp;msg)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Handle an error report from a datanode.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;void</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNode.html#errorReport(org.apache.hadoop.hdfs.server.protocol.NamenodeRegistration, int, java.lang.String)">errorReport</A></B>(<A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/NamenodeRegistration.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">NamenodeRegistration</A>&nbsp;registration,
            int&nbsp;errorCode,
            java.lang.String&nbsp;msg)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Report to the active name-node an error occurred on a subordinate node.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;void</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNode.html#finalizeUpgrade()">finalizeUpgrade</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Finalize previous upgrade.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;void</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNode.html#format(org.apache.hadoop.conf.Configuration)">format</A></B>(org.apache.hadoop.conf.Configuration&nbsp;conf)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Format a new filesystem.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;void</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNode.html#fsync(java.lang.String, java.lang.String)">fsync</A></B>(java.lang.String&nbsp;src,
      java.lang.String&nbsp;clientName)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Write all metadata for this file into persistent storage.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;java.net.InetSocketAddress</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNode.html#getAddress(org.apache.hadoop.conf.Configuration)">getAddress</A></B>(org.apache.hadoop.conf.Configuration&nbsp;conf)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;java.net.InetSocketAddress</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNode.html#getAddress(java.lang.String)">getAddress</A></B>(java.lang.String&nbsp;address)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;<A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/LocatedBlocks.html" title="org.apache.hadoop.hdfs.protocol 中的类">LocatedBlocks</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNode.html#getAllBlocksLocations(java.lang.String)">getAllBlocksLocations</A></B>(java.lang.String&nbsp;src)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;<A HREF="../../../../../../org/apache/hadoop/hdfs/security/token/block/ExportedBlockKeys.html" title="org.apache.hadoop.hdfs.security.token.block 中的类">ExportedBlockKeys</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNode.html#getBlockKeys()">getBlockKeys</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Get the current block keys</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;<A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/LocatedBlocks.html" title="org.apache.hadoop.hdfs.protocol 中的类">LocatedBlocks</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNode.html#getBlockLocations(java.lang.String, long, long)">getBlockLocations</A></B>(java.lang.String&nbsp;src,
                  long&nbsp;offset,
                  long&nbsp;length)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Get locations of the blocks of the specified file within the specified range.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;<A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/BlocksWithLocations.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">BlocksWithLocations</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNode.html#getBlocks(org.apache.hadoop.hdfs.protocol.DatanodeInfo, long)">getBlocks</A></B>(<A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/DatanodeInfo.html" title="org.apache.hadoop.hdfs.protocol 中的类">DatanodeInfo</A>&nbsp;datanode,
          long&nbsp;size)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Get a list of blocks belonging to <code>datanode</code>
 whose total size equals <code>size</code>.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;<A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/CodingMatrix.html" title="org.apache.hadoop.hdfs.protocol 中的类">CodingMatrix</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNode.html#getCodingMatrix(java.lang.String)">getCodingMatrix</A></B>(java.lang.String&nbsp;src)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;org.apache.hadoop.fs.ContentSummary</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNode.html#getContentSummary(java.lang.String)">getContentSummary</A></B>(java.lang.String&nbsp;path)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Get <CODE>ContentSummary</CODE> rooted at the specified directory.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;<A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/DatanodeInfo.html" title="org.apache.hadoop.hdfs.protocol 中的类">DatanodeInfo</A>[]</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNode.html#getDatanodeReport(org.apache.hadoop.hdfs.protocol.FSConstants.DatanodeReportType)">getDatanodeReport</A></B>(<A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/FSConstants.DatanodeReportType.html" title="org.apache.hadoop.hdfs.protocol 中的枚举">FSConstants.DatanodeReportType</A>&nbsp;type)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Get a report on the system's current datanodes.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;org.apache.hadoop.security.token.Token&lt;<A HREF="../../../../../../org/apache/hadoop/hdfs/security/token/delegation/DelegationTokenIdentifier.html" title="org.apache.hadoop.hdfs.security.token.delegation 中的类">DelegationTokenIdentifier</A>&gt;</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNode.html#getDelegationToken(org.apache.hadoop.io.Text)">getDelegationToken</A></B>(org.apache.hadoop.io.Text&nbsp;renewer)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Get a valid Delegation Token.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;long</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNode.html#getEditLogSize()">getEditLogSize</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<B>已过时。</B>&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;<A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/HdfsFileStatus.html" title="org.apache.hadoop.hdfs.protocol 中的类">HdfsFileStatus</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNode.html#getFileInfo(java.lang.String)">getFileInfo</A></B>(java.lang.String&nbsp;src)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Get the file info for a specific file.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;long</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNode.html#getFileLength(java.lang.String)">getFileLength</A></B>(java.lang.String&nbsp;src)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;<A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/HdfsFileStatus.html" title="org.apache.hadoop.hdfs.protocol 中的类">HdfsFileStatus</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNode.html#getFileLinkInfo(java.lang.String)">getFileLinkInfo</A></B>(java.lang.String&nbsp;src)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Get the file info for a specific file.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;<A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/FSImage.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FSImage</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNode.html#getFSImage()">getFSImage</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;java.io.File</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNode.html#getFsImageName()">getFsImageName</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Returns the name of the fsImage file</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;java.io.File[]</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNode.html#getFsImageNameCheckpoint()">getFsImageNameCheckpoint</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Returns the name of the fsImage file uploaded by periodic
 checkpointing</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;java.lang.String</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNode.html#getHostPortString(java.net.InetSocketAddress)">getHostPortString</A></B>(java.net.InetSocketAddress&nbsp;addr)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Compose a "host:port" string from the address.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;java.net.InetSocketAddress</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNode.html#getHttpAddress()">getHttpAddress</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Returns the address of the NameNodes http server, 
 which is used to access the name-node web UI.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>protected &nbsp;java.net.InetSocketAddress</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNode.html#getHttpServerAddress(org.apache.hadoop.conf.Configuration)">getHttpServerAddress</A></B>(org.apache.hadoop.conf.Configuration&nbsp;conf)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;java.lang.String</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNode.html#getInfoServer(org.apache.hadoop.conf.Configuration)">getInfoServer</A></B>(org.apache.hadoop.conf.Configuration&nbsp;conf)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;java.lang.String</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNode.html#getLinkTarget(java.lang.String)">getLinkTarget</A></B>(java.lang.String&nbsp;path)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Return the target of the given symlink.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;<A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/DirectoryListing.html" title="org.apache.hadoop.hdfs.protocol 中的类">DirectoryListing</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNode.html#getListing(java.lang.String, byte[], boolean)">getListing</A></B>(java.lang.String&nbsp;src,
           byte[]&nbsp;startAfter,
           boolean&nbsp;needLocation)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Get a partial listing of the indicated directory</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;java.net.InetSocketAddress</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNode.html#getNameNodeAddress()">getNameNodeAddress</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Returns the address on which the NameNodes is listening to.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/metrics/NameNodeMetrics.html" title="org.apache.hadoop.hdfs.server.namenode.metrics 中的类">NameNodeMetrics</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNode.html#getNameNodeMetrics()">getNameNodeMetrics</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;long</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNode.html#getPreferredBlockSize(java.lang.String)">getPreferredBlockSize</A></B>(java.lang.String&nbsp;filename)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Get the block size for the given file.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;long</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNode.html#getProtocolVersion(java.lang.String, long)">getProtocolVersion</A></B>(java.lang.String&nbsp;protocol,
                   long&nbsp;clientVersion)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;<A HREF="../../../../../../org/apache/hadoop/hdfs/server/common/HdfsConstants.NamenodeRole.html" title="org.apache.hadoop.hdfs.server.common 中的枚举">HdfsConstants.NamenodeRole</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNode.html#getRole()">getRole</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>protected &nbsp;java.net.InetSocketAddress</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNode.html#getRpcServerAddress(org.apache.hadoop.conf.Configuration)">getRpcServerAddress</A></B>(org.apache.hadoop.conf.Configuration&nbsp;conf)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;org.apache.hadoop.fs.FsServerDefaults</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNode.html#getServerDefaults()">getServerDefaults</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Get server default values for a number of configuration params.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;<A HREF="../../../../../../org/apache/hadoop/hdfs/server/monitor/ServernodeStator.html" title="org.apache.hadoop.hdfs.server.monitor 中的类">ServernodeStator</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNode.html#getServernodeStator()">getServernodeStator</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;java.net.InetSocketAddress</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNode.html#getServiceAddress(org.apache.hadoop.conf.Configuration, boolean)">getServiceAddress</A></B>(org.apache.hadoop.conf.Configuration&nbsp;conf,
                  boolean&nbsp;fallback)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Fetches the address for services to use when connecting to namenode
 based on the value of fallback returns null if the special
 address is not specified or returns the default namenode address
 to be used by both clients and services.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>protected &nbsp;java.net.InetSocketAddress</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNode.html#getServiceRpcServerAddress(org.apache.hadoop.conf.Configuration)">getServiceRpcServerAddress</A></B>(org.apache.hadoop.conf.Configuration&nbsp;conf)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Given a configuration get the address of the service rpc server
 If the service rpc is not configured returns null</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;long[]</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNode.html#getStats()">getStats</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Get a set of statistics about the filesystem.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;java.net.URI</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNode.html#getUri(java.net.InetSocketAddress)">getUri</A></B>(java.net.InetSocketAddress&nbsp;namenode)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>protected &nbsp;void</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNode.html#initialize(org.apache.hadoop.conf.Configuration)">initialize</A></B>(org.apache.hadoop.conf.Configuration&nbsp;conf)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Initialize name-node.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;boolean</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNode.html#isInSafeMode()">isInSafeMode</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Is the cluster currently in safe mode?</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;void</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNode.html#join()">join</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Wait for service to finish.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;void</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNode.html#journal(org.apache.hadoop.hdfs.server.protocol.NamenodeRegistration, int, int, byte[])">journal</A></B>(<A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/NamenodeRegistration.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">NamenodeRegistration</A>&nbsp;registration,
        int&nbsp;jAction,
        int&nbsp;length,
        byte[]&nbsp;args)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Journal edit records.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;long</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNode.html#journalSize(org.apache.hadoop.hdfs.server.protocol.NamenodeRegistration)">journalSize</A></B>(<A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/NamenodeRegistration.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">NamenodeRegistration</A>&nbsp;registration)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Get the size of the active name-node journal (edit log) in bytes.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;java.util.Collection&lt;org.apache.hadoop.hdfs.server.namenode.FSNamesystem.CorruptFileBlockInfo&gt;</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNode.html#listCorruptFileBlocks(java.lang.String, java.lang.String)">listCorruptFileBlocks</A></B>(java.lang.String&nbsp;path,
                      java.lang.String&nbsp;startBlockAfter)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>protected &nbsp;void</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNode.html#loadNamesystem(org.apache.hadoop.conf.Configuration)">loadNamesystem</A></B>(org.apache.hadoop.conf.Configuration&nbsp;conf)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;void</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNode.html#main(java.lang.String[])">main</A></B>(java.lang.String[]&nbsp;argv)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;void</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNode.html#metaSave(java.lang.String)">metaSave</A></B>(java.lang.String&nbsp;filename)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Dumps namenode state into specified file</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;boolean</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNode.html#mkdirs(java.lang.String, org.apache.hadoop.fs.permission.FsPermission, boolean)">mkdirs</A></B>(java.lang.String&nbsp;src,
       org.apache.hadoop.fs.permission.FsPermission&nbsp;masked,
       boolean&nbsp;createParent)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Create a directory (or hierarchy of directories) with the given
 name and permission.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;<A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/UpgradeCommand.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">UpgradeCommand</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNode.html#processUpgradeCommand(org.apache.hadoop.hdfs.server.protocol.UpgradeCommand)">processUpgradeCommand</A></B>(<A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/UpgradeCommand.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">UpgradeCommand</A>&nbsp;comm)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;This is a very general way to send a command to the name-node during
 distributed upgrade process.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;boolean</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNode.html#recoverLease(java.lang.String, java.lang.String)">recoverLease</A></B>(java.lang.String&nbsp;src,
             java.lang.String&nbsp;clientName)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Start lease recovery.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;void</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNode.html#refreshNodes()">refreshNodes</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Refresh the list of datanodes that the namenode should allow to  
 connect.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;void</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNode.html#refreshServiceAcl()">refreshServiceAcl</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;void</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNode.html#refreshSuperUserGroupsConfiguration()">refreshSuperUserGroupsConfiguration</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;void</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNode.html#refreshUserToGroupsMappings()">refreshUserToGroupsMappings</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;<A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/NamenodeRegistration.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">NamenodeRegistration</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNode.html#register(org.apache.hadoop.hdfs.server.protocol.NamenodeRegistration)">register</A></B>(<A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/NamenodeRegistration.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">NamenodeRegistration</A>&nbsp;registration)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Register a subordinate name-node like backup node.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;<A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/DatanodeRegistration.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">DatanodeRegistration</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNode.html#registerDatanode(org.apache.hadoop.hdfs.server.protocol.DatanodeRegistration)">registerDatanode</A></B>(<A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/DatanodeRegistration.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">DatanodeRegistration</A>&nbsp;nodeReg)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Register Datanode.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;boolean</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNode.html#rename(java.lang.String, java.lang.String)">rename</A></B>(java.lang.String&nbsp;src,
       java.lang.String&nbsp;dst)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<B>已过时。</B>&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;void</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNode.html#rename(java.lang.String, java.lang.String, org.apache.hadoop.fs.Options.Rename...)">rename</A></B>(java.lang.String&nbsp;src,
       java.lang.String&nbsp;dst,
       org.apache.hadoop.fs.Options.Rename...&nbsp;options)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Rename src to dst.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;long</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNode.html#renewDelegationToken(org.apache.hadoop.security.token.Token)">renewDelegationToken</A></B>(org.apache.hadoop.security.token.Token&lt;<A HREF="../../../../../../org/apache/hadoop/hdfs/security/token/delegation/DelegationTokenIdentifier.html" title="org.apache.hadoop.hdfs.security.token.delegation 中的类">DelegationTokenIdentifier</A>&gt;&nbsp;token)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Renew an existing delegation token.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;void</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNode.html#renewLease(java.lang.String)">renewLease</A></B>(java.lang.String&nbsp;clientName)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Client programs can cause stateful changes in the NameNode
 that affect other clients.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;void</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNode.html#reportBadBlocks(org.apache.hadoop.hdfs.protocol.LocatedBlock[])">reportBadBlocks</A></B>(<A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/LocatedBlock.html" title="org.apache.hadoop.hdfs.protocol 中的类">LocatedBlock</A>[]&nbsp;blocks)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The client has detected an error on the specified located blocks 
 and is reporting them to the server.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;boolean</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNode.html#restoreFailedStorage(java.lang.String)">restoreFailedStorage</A></B>(java.lang.String&nbsp;arg)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Enable/Disable restore failed storage.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;<A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/CheckpointSignature.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">CheckpointSignature</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNode.html#rollEditLog()">rollEditLog</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<B>已过时。</B>&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;void</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNode.html#rollFsImage(org.apache.hadoop.hdfs.server.namenode.CheckpointSignature)">rollFsImage</A></B>(<A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/CheckpointSignature.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">CheckpointSignature</A>&nbsp;sig)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<B>已过时。</B>&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;void</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNode.html#saveNamespace()">saveNamespace</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Save namespace image.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;<A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/DatanodeCommand.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">DatanodeCommand</A>[]</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNode.html#sendHeartbeat(org.apache.hadoop.hdfs.server.protocol.DatanodeRegistration, long, long, long, org.apache.hadoop.hdfs.server.monitor.ServernodeCPUStatus, org.apache.hadoop.hdfs.server.monitor.ServernodeMEMStatus, org.apache.hadoop.hdfs.server.monitor.ServernodeNETStatus[], org.apache.hadoop.hdfs.server.monitor.ServernodeIOStatus[], int, int, int)">sendHeartbeat</A></B>(<A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/DatanodeRegistration.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">DatanodeRegistration</A>&nbsp;nodeReg,
              long&nbsp;capacity,
              long&nbsp;dfsUsed,
              long&nbsp;remaining,
              <A HREF="../../../../../../org/apache/hadoop/hdfs/server/monitor/ServernodeCPUStatus.html" title="org.apache.hadoop.hdfs.server.monitor 中的类">ServernodeCPUStatus</A>&nbsp;cpuStatus,
              <A HREF="../../../../../../org/apache/hadoop/hdfs/server/monitor/ServernodeMEMStatus.html" title="org.apache.hadoop.hdfs.server.monitor 中的类">ServernodeMEMStatus</A>&nbsp;memStatus,
              <A HREF="../../../../../../org/apache/hadoop/hdfs/server/monitor/ServernodeNETStatus.html" title="org.apache.hadoop.hdfs.server.monitor 中的类">ServernodeNETStatus</A>[]&nbsp;netStatus,
              <A HREF="../../../../../../org/apache/hadoop/hdfs/server/monitor/ServernodeIOStatus.html" title="org.apache.hadoop.hdfs.server.monitor 中的类">ServernodeIOStatus</A>[]&nbsp;ioStatus,
              int&nbsp;xmitsInProgress,
              int&nbsp;xceiverCount,
              int&nbsp;failedVolumes)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Data node notify the name node that it is alive 
 Return an array of block-oriented commands for the datanode to execute.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>protected &nbsp;void</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNode.html#setHttpServerAddress(org.apache.hadoop.conf.Configuration)">setHttpServerAddress</A></B>(org.apache.hadoop.conf.Configuration&nbsp;conf)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;void</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNode.html#setOwner(java.lang.String, java.lang.String, java.lang.String)">setOwner</A></B>(java.lang.String&nbsp;src,
         java.lang.String&nbsp;username,
         java.lang.String&nbsp;groupname)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Set Owner of a path (i.e. a file or a directory).</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;void</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNode.html#setPermission(java.lang.String, org.apache.hadoop.fs.permission.FsPermission)">setPermission</A></B>(java.lang.String&nbsp;src,
              org.apache.hadoop.fs.permission.FsPermission&nbsp;permissions)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Set permissions for an existing file/directory.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;void</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNode.html#setQuota(java.lang.String, long, long)">setQuota</A></B>(java.lang.String&nbsp;path,
         long&nbsp;namespaceQuota,
         long&nbsp;diskspaceQuota)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Set the quota for a directory.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;boolean</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNode.html#setReplication(java.lang.String, short)">setReplication</A></B>(java.lang.String&nbsp;src,
               short&nbsp;replication)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Set replication for an existing file.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>protected &nbsp;void</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNode.html#setRpcServerAddress(org.apache.hadoop.conf.Configuration)">setRpcServerAddress</A></B>(org.apache.hadoop.conf.Configuration&nbsp;conf)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>protected &nbsp;void</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNode.html#setRpcServiceServerAddress(org.apache.hadoop.conf.Configuration)">setRpcServiceServerAddress</A></B>(org.apache.hadoop.conf.Configuration&nbsp;conf)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Modifies the configuration passed to contain the service rpc address setting</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;boolean</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNode.html#setSafeMode(org.apache.hadoop.hdfs.protocol.FSConstants.SafeModeAction)">setSafeMode</A></B>(<A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/FSConstants.SafeModeAction.html" title="org.apache.hadoop.hdfs.protocol 中的枚举">FSConstants.SafeModeAction</A>&nbsp;action)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Enter, leave or get safe mode.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;void</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNode.html#setServiceAddress(org.apache.hadoop.conf.Configuration, java.lang.String)">setServiceAddress</A></B>(org.apache.hadoop.conf.Configuration&nbsp;conf,
                  java.lang.String&nbsp;address)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Set the configuration property for the service rpc address
 to address</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;void</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNode.html#setTimes(java.lang.String, long, long)">setTimes</A></B>(java.lang.String&nbsp;src,
         long&nbsp;mtime,
         long&nbsp;atime)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Sets the modification and access time of the file to the specified time.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;<A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/NamenodeCommand.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">NamenodeCommand</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNode.html#startCheckpoint(org.apache.hadoop.hdfs.server.protocol.NamenodeRegistration)">startCheckpoint</A></B>(<A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/NamenodeRegistration.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">NamenodeRegistration</A>&nbsp;registration)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;A request to the active name-node to start a checkpoint.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;void</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNode.html#stop()">stop</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Stop all NameNode threads and wait for all to finish.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;<A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/LocatedBlock.html" title="org.apache.hadoop.hdfs.protocol 中的类">LocatedBlock</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNode.html#updateBlockForPipeline(org.apache.hadoop.hdfs.protocol.Block, java.lang.String)">updateBlockForPipeline</A></B>(<A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/Block.html" title="org.apache.hadoop.hdfs.protocol 中的类">Block</A>&nbsp;block,
                       java.lang.String&nbsp;clientName)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Get a new generation stamp together with an access token for 
 a block under construction
 
 This method is called only when a client needs to recover a failed
 pipeline or set up a pipeline for appending to a block.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;void</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNode.html#updatePipeline(java.lang.String, org.apache.hadoop.hdfs.protocol.Block, org.apache.hadoop.hdfs.protocol.Block, org.apache.hadoop.hdfs.protocol.DatanodeID[])">updatePipeline</A></B>(java.lang.String&nbsp;clientName,
               <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/Block.html" title="org.apache.hadoop.hdfs.protocol 中的类">Block</A>&nbsp;oldBlock,
               <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/Block.html" title="org.apache.hadoop.hdfs.protocol 中的类">Block</A>&nbsp;newBlock,
               <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/DatanodeID.html" title="org.apache.hadoop.hdfs.protocol 中的类">DatanodeID</A>[]&nbsp;newNodes)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Update a pipeline for a block under construction</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;void</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNode.html#verifyRequest(org.apache.hadoop.hdfs.server.protocol.NodeRegistration)">verifyRequest</A></B>(<A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/NodeRegistration.html" title="org.apache.hadoop.hdfs.server.protocol 中的接口">NodeRegistration</A>&nbsp;nodeReg)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Verify request.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;void</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNode.html#verifyVersion(int)">verifyVersion</A></B>(int&nbsp;version)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Verify version.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;<A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/NamespaceInfo.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">NamespaceInfo</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNode.html#versionRequest()">versionRequest</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Request name-node version and storage information.</TD>
</TR>
</TABLE>
&nbsp;<A NAME="methods_inherited_from_class_java.lang.Object"><!-- --></A>
<TABLE BORDER="1" WIDTH="100%" CELLPADDING="3" CELLSPACING="0" SUMMARY="">
<TR BGCOLOR="#EEEEFF" CLASS="TableSubHeadingColor">
<TH ALIGN="left"><B>从类 java.lang.Object 继承的方法</B></TH>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD><CODE>clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait</CODE></TD>
</TR>
</TABLE>
&nbsp;
<P>

<!-- ============ FIELD DETAIL =========== -->

<A NAME="field_detail"><!-- --></A>
<TABLE BORDER="1" WIDTH="100%" CELLPADDING="3" CELLSPACING="0" SUMMARY="">
<TR BGCOLOR="#CCCCFF" CLASS="TableHeadingColor">
<TH ALIGN="left" COLSPAN="1"><FONT SIZE="+2">
<B>字段详细信息</B></FONT></TH>
</TR>
</TABLE>

<A NAME="DEFAULT_PORT"><!-- --></A><H3>
DEFAULT_PORT</H3>
<PRE>
public static final int <B>DEFAULT_PORT</B></PRE>
<DL>
<DL>
<DT><B>另请参见：</B><DD><A HREF="../../../../../../constant-values.html#org.apache.hadoop.hdfs.server.namenode.NameNode.DEFAULT_PORT">常量字段值</A></DL>
</DL>
<HR>

<A NAME="LOG"><!-- --></A><H3>
LOG</H3>
<PRE>
public static final org.apache.commons.logging.Log <B>LOG</B></PRE>
<DL>
<DL>
</DL>
</DL>
<HR>

<A NAME="stateChangeLog"><!-- --></A><H3>
stateChangeLog</H3>
<PRE>
public static final org.apache.commons.logging.Log <B>stateChangeLog</B></PRE>
<DL>
<DL>
</DL>
</DL>
<HR>

<A NAME="namesystem"><!-- --></A><H3>
namesystem</H3>
<PRE>
protected <A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FSNamesystem</A> <B>namesystem</B></PRE>
<DL>
<DL>
</DL>
</DL>
<HR>

<A NAME="role"><!-- --></A><H3>
role</H3>
<PRE>
protected <A HREF="../../../../../../org/apache/hadoop/hdfs/server/common/HdfsConstants.NamenodeRole.html" title="org.apache.hadoop.hdfs.server.common 中的枚举">HdfsConstants.NamenodeRole</A> <B>role</B></PRE>
<DL>
<DL>
</DL>
</DL>
<HR>

<A NAME="serviceRpcServer"><!-- --></A><H3>
serviceRpcServer</H3>
<PRE>
protected org.apache.hadoop.ipc.Server <B>serviceRpcServer</B></PRE>
<DL>
<DD>RPC server for HDFS Services communication.
      BackupNode, Datanodes and all other services
      should be connecting to this server if it is
      configured. Clients should only go to NameNode#server
<P>
<DL>
</DL>
</DL>
<HR>

<A NAME="rpcAddress"><!-- --></A><H3>
rpcAddress</H3>
<PRE>
protected java.net.InetSocketAddress <B>rpcAddress</B></PRE>
<DL>
<DD>RPC server address
<P>
<DL>
</DL>
</DL>
<HR>

<A NAME="serviceRPCAddress"><!-- --></A><H3>
serviceRPCAddress</H3>
<PRE>
protected java.net.InetSocketAddress <B>serviceRPCAddress</B></PRE>
<DL>
<DD>RPC server for DN address
<P>
<DL>
</DL>
</DL>
<HR>

<A NAME="httpServer"><!-- --></A><H3>
httpServer</H3>
<PRE>
protected org.apache.hadoop.http.HttpServer <B>httpServer</B></PRE>
<DL>
<DD>httpServer
<P>
<DL>
</DL>
</DL>
<HR>

<A NAME="httpAddress"><!-- --></A><H3>
httpAddress</H3>
<PRE>
protected java.net.InetSocketAddress <B>httpAddress</B></PRE>
<DL>
<DD>HTTP server address
<P>
<DL>
</DL>
</DL>
<HR>

<A NAME="stopRequested"><!-- --></A><H3>
stopRequested</H3>
<PRE>
protected boolean <B>stopRequested</B></PRE>
<DL>
<DD>only used for testing purposes
<P>
<DL>
</DL>
</DL>
<HR>

<A NAME="nodeRegistration"><!-- --></A><H3>
nodeRegistration</H3>
<PRE>
protected <A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/NamenodeRegistration.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">NamenodeRegistration</A> <B>nodeRegistration</B></PRE>
<DL>
<DD>Registration information of this name-node
<P>
<DL>
</DL>
</DL>

<!-- ========= CONSTRUCTOR DETAIL ======== -->

<A NAME="constructor_detail"><!-- --></A>
<TABLE BORDER="1" WIDTH="100%" CELLPADDING="3" CELLSPACING="0" SUMMARY="">
<TR BGCOLOR="#CCCCFF" CLASS="TableHeadingColor">
<TH ALIGN="left" COLSPAN="1"><FONT SIZE="+2">
<B>构造方法详细信息</B></FONT></TH>
</TR>
</TABLE>

<A NAME="NameNode(org.apache.hadoop.conf.Configuration)"><!-- --></A><H3>
NameNode</H3>
<PRE>
public <B>NameNode</B>(org.apache.hadoop.conf.Configuration&nbsp;conf)
         throws java.io.IOException</PRE>
<DL>
<DD>Start NameNode.
 <p>
 The name-node can be started with one of the following startup options:
 <ul> 
 <li><A HREF="../../../../../../org/apache/hadoop/hdfs/server/common/HdfsConstants.StartupOption.html#REGULAR"><CODE>REGULAR</CODE></A> - normal name node startup</li>
 <li><A HREF="../../../../../../org/apache/hadoop/hdfs/server/common/HdfsConstants.StartupOption.html#FORMAT"><CODE>FORMAT</CODE></A> - format name node</li>
 <li><A HREF="../../../../../../org/apache/hadoop/hdfs/server/common/HdfsConstants.StartupOption.html#BACKUP"><CODE>BACKUP</CODE></A> - start backup node</li>
 <li><A HREF="../../../../../../org/apache/hadoop/hdfs/server/common/HdfsConstants.StartupOption.html#CHECKPOINT"><CODE>CHECKPOINT</CODE></A> - start checkpoint node</li>
 <li><A HREF="../../../../../../org/apache/hadoop/hdfs/server/common/HdfsConstants.StartupOption.html#UPGRADE"><CODE>UPGRADE</CODE></A> - start the cluster  
 upgrade and create a snapshot of the current file system state</li> 
 <li><A HREF="../../../../../../org/apache/hadoop/hdfs/server/common/HdfsConstants.StartupOption.html#ROLLBACK"><CODE>ROLLBACK</CODE></A> - roll the  
            cluster back to the previous state</li>
 <li><A HREF="../../../../../../org/apache/hadoop/hdfs/server/common/HdfsConstants.StartupOption.html#FINALIZE"><CODE>FINALIZE</CODE></A> - finalize 
            previous upgrade</li>
 <li><A HREF="../../../../../../org/apache/hadoop/hdfs/server/common/HdfsConstants.StartupOption.html#IMPORT"><CODE>IMPORT</CODE></A> - import checkpoint</li>
 </ul>
 The option is passed via configuration field: 
 <tt>dfs.namenode.startup</tt>
 
 The conf will be modified to reflect the actual ports on which 
 the NameNode is up and running if the user passes the port as
 <code>zero</code> in the conf.
<P>
<DL>
<DT><B>参数：</B><DD><CODE>conf</CODE> - confirguration
<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DL>
<HR>

<A NAME="NameNode(org.apache.hadoop.conf.Configuration, org.apache.hadoop.hdfs.server.common.HdfsConstants.NamenodeRole)"><!-- --></A><H3>
NameNode</H3>
<PRE>
protected <B>NameNode</B>(org.apache.hadoop.conf.Configuration&nbsp;conf,
                   <A HREF="../../../../../../org/apache/hadoop/hdfs/server/common/HdfsConstants.NamenodeRole.html" title="org.apache.hadoop.hdfs.server.common 中的枚举">HdfsConstants.NamenodeRole</A>&nbsp;role)
            throws java.io.IOException</PRE>
<DL>
<DL>

<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DL>

<!-- ============ METHOD DETAIL ========== -->

<A NAME="method_detail"><!-- --></A>
<TABLE BORDER="1" WIDTH="100%" CELLPADDING="3" CELLSPACING="0" SUMMARY="">
<TR BGCOLOR="#CCCCFF" CLASS="TableHeadingColor">
<TH ALIGN="left" COLSPAN="1"><FONT SIZE="+2">
<B>方法详细信息</B></FONT></TH>
</TR>
</TABLE>

<A NAME="getProtocolVersion(java.lang.String, long)"><!-- --></A><H3>
getProtocolVersion</H3>
<PRE>
public long <B>getProtocolVersion</B>(java.lang.String&nbsp;protocol,
                               long&nbsp;clientVersion)
                        throws java.io.IOException</PRE>
<DL>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE>org.apache.hadoop.ipc.VersionedProtocol</CODE> 中的 <CODE>getProtocolVersion</CODE></DL>
</DD>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="format(org.apache.hadoop.conf.Configuration)"><!-- --></A><H3>
format</H3>
<PRE>
public static void <B>format</B>(org.apache.hadoop.conf.Configuration&nbsp;conf)
                   throws java.io.IOException</PRE>
<DL>
<DD>Format a new filesystem.  Destroys any filesystem that may already
 exist at this location.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="getNameNodeMetrics()"><!-- --></A><H3>
getNameNodeMetrics</H3>
<PRE>
public static <A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/metrics/NameNodeMetrics.html" title="org.apache.hadoop.hdfs.server.namenode.metrics 中的类">NameNodeMetrics</A> <B>getNameNodeMetrics</B>()</PRE>
<DL>
<DD><DL>
</DL>
</DD>
<DD><DL>
</DL>
</DD>
</DL>
<HR>

<A NAME="getAddress(java.lang.String)"><!-- --></A><H3>
getAddress</H3>
<PRE>
public static java.net.InetSocketAddress <B>getAddress</B>(java.lang.String&nbsp;address)</PRE>
<DL>
<DD><DL>
</DL>
</DD>
<DD><DL>
</DL>
</DD>
</DL>
<HR>

<A NAME="setServiceAddress(org.apache.hadoop.conf.Configuration, java.lang.String)"><!-- --></A><H3>
setServiceAddress</H3>
<PRE>
public static void <B>setServiceAddress</B>(org.apache.hadoop.conf.Configuration&nbsp;conf,
                                     java.lang.String&nbsp;address)</PRE>
<DL>
<DD>Set the configuration property for the service rpc address
 to address
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
</DL>
</DD>
</DL>
<HR>

<A NAME="getServiceAddress(org.apache.hadoop.conf.Configuration, boolean)"><!-- --></A><H3>
getServiceAddress</H3>
<PRE>
public static java.net.InetSocketAddress <B>getServiceAddress</B>(org.apache.hadoop.conf.Configuration&nbsp;conf,
                                                           boolean&nbsp;fallback)</PRE>
<DL>
<DD>Fetches the address for services to use when connecting to namenode
 based on the value of fallback returns null if the special
 address is not specified or returns the default namenode address
 to be used by both clients and services.
 Services here are datanodes, backup node, any non client connection
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
</DL>
</DD>
</DL>
<HR>

<A NAME="getAddress(org.apache.hadoop.conf.Configuration)"><!-- --></A><H3>
getAddress</H3>
<PRE>
public static java.net.InetSocketAddress <B>getAddress</B>(org.apache.hadoop.conf.Configuration&nbsp;conf)</PRE>
<DL>
<DD><DL>
</DL>
</DD>
<DD><DL>
</DL>
</DD>
</DL>
<HR>

<A NAME="getUri(java.net.InetSocketAddress)"><!-- --></A><H3>
getUri</H3>
<PRE>
public static java.net.URI <B>getUri</B>(java.net.InetSocketAddress&nbsp;namenode)</PRE>
<DL>
<DD><DL>
</DL>
</DD>
<DD><DL>
</DL>
</DD>
</DL>
<HR>

<A NAME="getHostPortString(java.net.InetSocketAddress)"><!-- --></A><H3>
getHostPortString</H3>
<PRE>
public static java.lang.String <B>getHostPortString</B>(java.net.InetSocketAddress&nbsp;addr)</PRE>
<DL>
<DD>Compose a "host:port" string from the address.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
</DL>
</DD>
</DL>
<HR>

<A NAME="getRole()"><!-- --></A><H3>
getRole</H3>
<PRE>
public <A HREF="../../../../../../org/apache/hadoop/hdfs/server/common/HdfsConstants.NamenodeRole.html" title="org.apache.hadoop.hdfs.server.common 中的枚举">HdfsConstants.NamenodeRole</A> <B>getRole</B>()</PRE>
<DL>
<DD><DL>
</DL>
</DD>
<DD><DL>
</DL>
</DD>
</DL>
<HR>

<A NAME="getServiceRpcServerAddress(org.apache.hadoop.conf.Configuration)"><!-- --></A><H3>
getServiceRpcServerAddress</H3>
<PRE>
protected java.net.InetSocketAddress <B>getServiceRpcServerAddress</B>(org.apache.hadoop.conf.Configuration&nbsp;conf)
                                                         throws java.io.IOException</PRE>
<DL>
<DD>Given a configuration get the address of the service rpc server
 If the service rpc is not configured returns null
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="getRpcServerAddress(org.apache.hadoop.conf.Configuration)"><!-- --></A><H3>
getRpcServerAddress</H3>
<PRE>
protected java.net.InetSocketAddress <B>getRpcServerAddress</B>(org.apache.hadoop.conf.Configuration&nbsp;conf)
                                                  throws java.io.IOException</PRE>
<DL>
<DD><DL>
</DL>
</DD>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="setRpcServiceServerAddress(org.apache.hadoop.conf.Configuration)"><!-- --></A><H3>
setRpcServiceServerAddress</H3>
<PRE>
protected void <B>setRpcServiceServerAddress</B>(org.apache.hadoop.conf.Configuration&nbsp;conf)</PRE>
<DL>
<DD>Modifies the configuration passed to contain the service rpc address setting
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
</DL>
</DD>
</DL>
<HR>

<A NAME="setRpcServerAddress(org.apache.hadoop.conf.Configuration)"><!-- --></A><H3>
setRpcServerAddress</H3>
<PRE>
protected void <B>setRpcServerAddress</B>(org.apache.hadoop.conf.Configuration&nbsp;conf)</PRE>
<DL>
<DD><DL>
</DL>
</DD>
<DD><DL>
</DL>
</DD>
</DL>
<HR>

<A NAME="getHttpServerAddress(org.apache.hadoop.conf.Configuration)"><!-- --></A><H3>
getHttpServerAddress</H3>
<PRE>
protected java.net.InetSocketAddress <B>getHttpServerAddress</B>(org.apache.hadoop.conf.Configuration&nbsp;conf)</PRE>
<DL>
<DD><DL>
</DL>
</DD>
<DD><DL>
</DL>
</DD>
</DL>
<HR>

<A NAME="setHttpServerAddress(org.apache.hadoop.conf.Configuration)"><!-- --></A><H3>
setHttpServerAddress</H3>
<PRE>
protected void <B>setHttpServerAddress</B>(org.apache.hadoop.conf.Configuration&nbsp;conf)</PRE>
<DL>
<DD><DL>
</DL>
</DD>
<DD><DL>
</DL>
</DD>
</DL>
<HR>

<A NAME="loadNamesystem(org.apache.hadoop.conf.Configuration)"><!-- --></A><H3>
loadNamesystem</H3>
<PRE>
protected void <B>loadNamesystem</B>(org.apache.hadoop.conf.Configuration&nbsp;conf)
                       throws java.io.IOException</PRE>
<DL>
<DD><DL>
</DL>
</DD>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="initialize(org.apache.hadoop.conf.Configuration)"><!-- --></A><H3>
initialize</H3>
<PRE>
protected void <B>initialize</B>(org.apache.hadoop.conf.Configuration&nbsp;conf)
                   throws java.io.IOException</PRE>
<DL>
<DD>Initialize name-node.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>参数：</B><DD><CODE>conf</CODE> - the configuration
<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="getInfoServer(org.apache.hadoop.conf.Configuration)"><!-- --></A><H3>
getInfoServer</H3>
<PRE>
public static java.lang.String <B>getInfoServer</B>(org.apache.hadoop.conf.Configuration&nbsp;conf)</PRE>
<DL>
<DD><DL>
</DL>
</DD>
<DD><DL>
</DL>
</DD>
</DL>
<HR>

<A NAME="join()"><!-- --></A><H3>
join</H3>
<PRE>
public void <B>join</B>()</PRE>
<DL>
<DD>Wait for service to finish.
 (Normally, it runs forever.)
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
</DL>
</DD>
</DL>
<HR>

<A NAME="stop()"><!-- --></A><H3>
stop</H3>
<PRE>
public void <B>stop</B>()</PRE>
<DL>
<DD>Stop all NameNode threads and wait for all to finish.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
</DL>
</DD>
</DL>
<HR>

<A NAME="getBlocks(org.apache.hadoop.hdfs.protocol.DatanodeInfo, long)"><!-- --></A><H3>
getBlocks</H3>
<PRE>
public <A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/BlocksWithLocations.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">BlocksWithLocations</A> <B>getBlocks</B>(<A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/DatanodeInfo.html" title="org.apache.hadoop.hdfs.protocol 中的类">DatanodeInfo</A>&nbsp;datanode,
                                     long&nbsp;size)
                              throws java.io.IOException</PRE>
<DL>
<DD><B>从接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/NamenodeProtocol.html#getBlocks(org.apache.hadoop.hdfs.protocol.DatanodeInfo, long)">NamenodeProtocol</A></CODE> 复制的描述</B></DD>
<DD>Get a list of blocks belonging to <code>datanode</code>
 whose total size equals <code>size</code>.
<P>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/NamenodeProtocol.html" title="org.apache.hadoop.hdfs.server.protocol 中的接口">NamenodeProtocol</A></CODE> 中的 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/NamenodeProtocol.html#getBlocks(org.apache.hadoop.hdfs.protocol.DatanodeInfo, long)">getBlocks</A></CODE></DL>
</DD>
<DD><DL>
<DT><B>参数：</B><DD><CODE>datanode</CODE> - a data node<DD><CODE>size</CODE> - requested size
<DT><B>返回：</B><DD>a list of blocks & their locations
<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE><DT><B>另请参见：</B><DD><A HREF="../../../../../../org/apache/hadoop/hdfs/server/balancer/Balancer.html" title="org.apache.hadoop.hdfs.server.balancer 中的类"><CODE>Balancer</CODE></A></DL>
</DD>
</DL>
<HR>

<A NAME="getBlockKeys()"><!-- --></A><H3>
getBlockKeys</H3>
<PRE>
public <A HREF="../../../../../../org/apache/hadoop/hdfs/security/token/block/ExportedBlockKeys.html" title="org.apache.hadoop.hdfs.security.token.block 中的类">ExportedBlockKeys</A> <B>getBlockKeys</B>()
                               throws java.io.IOException</PRE>
<DL>
<DD>Get the current block keys
<P>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/NamenodeProtocol.html" title="org.apache.hadoop.hdfs.server.protocol 中的接口">NamenodeProtocol</A></CODE> 中的 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/NamenodeProtocol.html#getBlockKeys()">getBlockKeys</A></CODE></DL>
</DD>
<DD><DL>

<DT><B>返回：</B><DD>ExportedBlockKeys containing current block keys
<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="errorReport(org.apache.hadoop.hdfs.server.protocol.NamenodeRegistration, int, java.lang.String)"><!-- --></A><H3>
errorReport</H3>
<PRE>
public void <B>errorReport</B>(<A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/NamenodeRegistration.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">NamenodeRegistration</A>&nbsp;registration,
                        int&nbsp;errorCode,
                        java.lang.String&nbsp;msg)
                 throws java.io.IOException</PRE>
<DL>
<DD><B>从接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/NamenodeProtocol.html#errorReport(org.apache.hadoop.hdfs.server.protocol.NamenodeRegistration, int, java.lang.String)">NamenodeProtocol</A></CODE> 复制的描述</B></DD>
<DD>Report to the active name-node an error occurred on a subordinate node.
 Depending on the error code the active node may decide to unregister the
 reporting node.
<P>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/NamenodeProtocol.html" title="org.apache.hadoop.hdfs.server.protocol 中的接口">NamenodeProtocol</A></CODE> 中的 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/NamenodeProtocol.html#errorReport(org.apache.hadoop.hdfs.server.protocol.NamenodeRegistration, int, java.lang.String)">errorReport</A></CODE></DL>
</DD>
<DD><DL>
<DT><B>参数：</B><DD><CODE>registration</CODE> - requesting node.<DD><CODE>errorCode</CODE> - indicates the error<DD><CODE>msg</CODE> - free text description of the error
<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="register(org.apache.hadoop.hdfs.server.protocol.NamenodeRegistration)"><!-- --></A><H3>
register</H3>
<PRE>
public <A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/NamenodeRegistration.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">NamenodeRegistration</A> <B>register</B>(<A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/NamenodeRegistration.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">NamenodeRegistration</A>&nbsp;registration)
                              throws java.io.IOException</PRE>
<DL>
<DD><B>从接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/NamenodeProtocol.html#register(org.apache.hadoop.hdfs.server.protocol.NamenodeRegistration)">NamenodeProtocol</A></CODE> 复制的描述</B></DD>
<DD>Register a subordinate name-node like backup node.
<P>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/NamenodeProtocol.html" title="org.apache.hadoop.hdfs.server.protocol 中的接口">NamenodeProtocol</A></CODE> 中的 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/NamenodeProtocol.html#register(org.apache.hadoop.hdfs.server.protocol.NamenodeRegistration)">register</A></CODE></DL>
</DD>
<DD><DL>

<DT><B>返回：</B><DD><A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/NamenodeRegistration.html" title="org.apache.hadoop.hdfs.server.protocol 中的类"><CODE>NamenodeRegistration</CODE></A> of the node,
          which this node has just registered with.
<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="startCheckpoint(org.apache.hadoop.hdfs.server.protocol.NamenodeRegistration)"><!-- --></A><H3>
startCheckpoint</H3>
<PRE>
public <A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/NamenodeCommand.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">NamenodeCommand</A> <B>startCheckpoint</B>(<A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/NamenodeRegistration.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">NamenodeRegistration</A>&nbsp;registration)
                                throws java.io.IOException</PRE>
<DL>
<DD><B>从接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/NamenodeProtocol.html#startCheckpoint(org.apache.hadoop.hdfs.server.protocol.NamenodeRegistration)">NamenodeProtocol</A></CODE> 复制的描述</B></DD>
<DD>A request to the active name-node to start a checkpoint.
 The name-node should decide whether to admit it or reject.
 The name-node also decides what should be done with the backup node
 image before and after the checkpoint.
<P>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/NamenodeProtocol.html" title="org.apache.hadoop.hdfs.server.protocol 中的接口">NamenodeProtocol</A></CODE> 中的 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/NamenodeProtocol.html#startCheckpoint(org.apache.hadoop.hdfs.server.protocol.NamenodeRegistration)">startCheckpoint</A></CODE></DL>
</DD>
<DD><DL>
<DT><B>参数：</B><DD><CODE>registration</CODE> - the requesting node
<DT><B>返回：</B><DD><A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/CheckpointCommand.html" title="org.apache.hadoop.hdfs.server.protocol 中的类"><CODE>CheckpointCommand</CODE></A> if checkpoint is allowed.
<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE><DT><B>另请参见：</B><DD><A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/CheckpointCommand.html" title="org.apache.hadoop.hdfs.server.protocol 中的类"><CODE>CheckpointCommand</CODE></A>, 
<A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/NamenodeCommand.html" title="org.apache.hadoop.hdfs.server.protocol 中的类"><CODE>NamenodeCommand</CODE></A>, 
<A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/NamenodeProtocol.html#ACT_SHUTDOWN"><CODE>NamenodeProtocol.ACT_SHUTDOWN</CODE></A></DL>
</DD>
</DL>
<HR>

<A NAME="endCheckpoint(org.apache.hadoop.hdfs.server.protocol.NamenodeRegistration, org.apache.hadoop.hdfs.server.namenode.CheckpointSignature)"><!-- --></A><H3>
endCheckpoint</H3>
<PRE>
public void <B>endCheckpoint</B>(<A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/NamenodeRegistration.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">NamenodeRegistration</A>&nbsp;registration,
                          <A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/CheckpointSignature.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">CheckpointSignature</A>&nbsp;sig)
                   throws java.io.IOException</PRE>
<DL>
<DD><B>从接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/NamenodeProtocol.html#endCheckpoint(org.apache.hadoop.hdfs.server.protocol.NamenodeRegistration, org.apache.hadoop.hdfs.server.namenode.CheckpointSignature)">NamenodeProtocol</A></CODE> 复制的描述</B></DD>
<DD>A request to the active name-node to finalize
 previously started checkpoint.
<P>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/NamenodeProtocol.html" title="org.apache.hadoop.hdfs.server.protocol 中的接口">NamenodeProtocol</A></CODE> 中的 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/NamenodeProtocol.html#endCheckpoint(org.apache.hadoop.hdfs.server.protocol.NamenodeRegistration, org.apache.hadoop.hdfs.server.namenode.CheckpointSignature)">endCheckpoint</A></CODE></DL>
</DD>
<DD><DL>
<DT><B>参数：</B><DD><CODE>registration</CODE> - the requesting node<DD><CODE>sig</CODE> - <code>CheckpointSignature</code> which identifies the checkpoint.
<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="journalSize(org.apache.hadoop.hdfs.server.protocol.NamenodeRegistration)"><!-- --></A><H3>
journalSize</H3>
<PRE>
public long <B>journalSize</B>(<A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/NamenodeRegistration.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">NamenodeRegistration</A>&nbsp;registration)
                 throws java.io.IOException</PRE>
<DL>
<DD><B>从接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/NamenodeProtocol.html#journalSize(org.apache.hadoop.hdfs.server.protocol.NamenodeRegistration)">NamenodeProtocol</A></CODE> 复制的描述</B></DD>
<DD>Get the size of the active name-node journal (edit log) in bytes.
<P>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/NamenodeProtocol.html" title="org.apache.hadoop.hdfs.server.protocol 中的接口">NamenodeProtocol</A></CODE> 中的 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/NamenodeProtocol.html#journalSize(org.apache.hadoop.hdfs.server.protocol.NamenodeRegistration)">journalSize</A></CODE></DL>
</DD>
<DD><DL>
<DT><B>参数：</B><DD><CODE>registration</CODE> - the requesting node
<DT><B>返回：</B><DD>The number of bytes in the journal.
<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="journal(org.apache.hadoop.hdfs.server.protocol.NamenodeRegistration, int, int, byte[])"><!-- --></A><H3>
journal</H3>
<PRE>
public void <B>journal</B>(<A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/NamenodeRegistration.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">NamenodeRegistration</A>&nbsp;registration,
                    int&nbsp;jAction,
                    int&nbsp;length,
                    byte[]&nbsp;args)
             throws java.io.IOException</PRE>
<DL>
<DD><B>从接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/NamenodeProtocol.html#journal(org.apache.hadoop.hdfs.server.protocol.NamenodeRegistration, int, int, byte[])">NamenodeProtocol</A></CODE> 复制的描述</B></DD>
<DD>Journal edit records.
 This message is sent by the active name-node to the backup node
 via <code>EditLogBackupOutputStream</code> in order to synchronize meta-data
 changes with the backup namespace image.
<P>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/NamenodeProtocol.html" title="org.apache.hadoop.hdfs.server.protocol 中的接口">NamenodeProtocol</A></CODE> 中的 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/NamenodeProtocol.html#journal(org.apache.hadoop.hdfs.server.protocol.NamenodeRegistration, int, int, byte[])">journal</A></CODE></DL>
</DD>
<DD><DL>
<DT><B>参数：</B><DD><CODE>registration</CODE> - active node registration<DD><CODE>jAction</CODE> - journal action<DD><CODE>length</CODE> - length of the byte array<DD><CODE>args</CODE> - byte array containing serialized journal records
<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="getDelegationToken(org.apache.hadoop.io.Text)"><!-- --></A><H3>
getDelegationToken</H3>
<PRE>
public org.apache.hadoop.security.token.Token&lt;<A HREF="../../../../../../org/apache/hadoop/hdfs/security/token/delegation/DelegationTokenIdentifier.html" title="org.apache.hadoop.hdfs.security.token.delegation 中的类">DelegationTokenIdentifier</A>&gt; <B>getDelegationToken</B>(org.apache.hadoop.io.Text&nbsp;renewer)
                                                                                     throws java.io.IOException</PRE>
<DL>
<DD><B>从接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html#getDelegationToken(org.apache.hadoop.io.Text)">ClientProtocol</A></CODE> 复制的描述</B></DD>
<DD>Get a valid Delegation Token.
<P>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的接口">ClientProtocol</A></CODE> 中的 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html#getDelegationToken(org.apache.hadoop.io.Text)">getDelegationToken</A></CODE></DL>
</DD>
<DD><DL>
<DT><B>参数：</B><DD><CODE>renewer</CODE> - the designated renewer for the token
<DT><B>返回：</B><DD>Token<DelegationTokenIdentifier>
<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="renewDelegationToken(org.apache.hadoop.security.token.Token)"><!-- --></A><H3>
renewDelegationToken</H3>
<PRE>
public long <B>renewDelegationToken</B>(org.apache.hadoop.security.token.Token&lt;<A HREF="../../../../../../org/apache/hadoop/hdfs/security/token/delegation/DelegationTokenIdentifier.html" title="org.apache.hadoop.hdfs.security.token.delegation 中的类">DelegationTokenIdentifier</A>&gt;&nbsp;token)
                          throws org.apache.hadoop.security.token.SecretManager.InvalidToken,
                                 java.io.IOException</PRE>
<DL>
<DD><B>从接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html#renewDelegationToken(org.apache.hadoop.security.token.Token)">ClientProtocol</A></CODE> 复制的描述</B></DD>
<DD>Renew an existing delegation token.
<P>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的接口">ClientProtocol</A></CODE> 中的 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html#renewDelegationToken(org.apache.hadoop.security.token.Token)">renewDelegationToken</A></CODE></DL>
</DD>
<DD><DL>
<DT><B>参数：</B><DD><CODE>token</CODE> - delegation token obtained earlier
<DT><B>返回：</B><DD>the new expiration time
<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE>
<DD><CODE>org.apache.hadoop.security.token.SecretManager.InvalidToken</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="cancelDelegationToken(org.apache.hadoop.security.token.Token)"><!-- --></A><H3>
cancelDelegationToken</H3>
<PRE>
public void <B>cancelDelegationToken</B>(org.apache.hadoop.security.token.Token&lt;<A HREF="../../../../../../org/apache/hadoop/hdfs/security/token/delegation/DelegationTokenIdentifier.html" title="org.apache.hadoop.hdfs.security.token.delegation 中的类">DelegationTokenIdentifier</A>&gt;&nbsp;token)
                           throws java.io.IOException</PRE>
<DL>
<DD><B>从接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html#cancelDelegationToken(org.apache.hadoop.security.token.Token)">ClientProtocol</A></CODE> 复制的描述</B></DD>
<DD>Cancel an existing delegation token.
<P>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的接口">ClientProtocol</A></CODE> 中的 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html#cancelDelegationToken(org.apache.hadoop.security.token.Token)">cancelDelegationToken</A></CODE></DL>
</DD>
<DD><DL>
<DT><B>参数：</B><DD><CODE>token</CODE> - delegation token
<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="getBlockLocations(java.lang.String, long, long)"><!-- --></A><H3>
getBlockLocations</H3>
<PRE>
public <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/LocatedBlocks.html" title="org.apache.hadoop.hdfs.protocol 中的类">LocatedBlocks</A> <B>getBlockLocations</B>(java.lang.String&nbsp;src,
                                       long&nbsp;offset,
                                       long&nbsp;length)
                                throws java.io.IOException</PRE>
<DL>
<DD>Get locations of the blocks of the specified file within the specified range.
 DataNode locations for each block are sorted by
 the proximity to the client.
 <p>
 Return <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/LocatedBlocks.html" title="org.apache.hadoop.hdfs.protocol 中的类"><CODE>LocatedBlocks</CODE></A> which contains
 file length, blocks and their locations.
 DataNode locations for each block are sorted by
 the distance to the client's address.
 <p>
 The client will then have to contact 
 one of the indicated DataNodes to obtain the actual data.
<P>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的接口">ClientProtocol</A></CODE> 中的 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html#getBlockLocations(java.lang.String, long, long)">getBlockLocations</A></CODE></DL>
</DD>
<DD><DL>
<DT><B>参数：</B><DD><CODE>src</CODE> - file name<DD><CODE>offset</CODE> - range start offset<DD><CODE>length</CODE> - range length
<DT><B>返回：</B><DD>file length and array of blocks with their locations
<DT><B>抛出：</B>
<DD><CODE>org.apache.hadoop.security.AccessControlException</CODE> - If access is denied
<DD><CODE>java.io.FileNotFoundException</CODE> - If file <code>src</code> does not exist
<DD><CODE>org.apache.hadoop.fs.UnresolvedLinkException</CODE> - If <code>src</code> contains a symlink
<DD><CODE>java.io.IOException</CODE> - If an I/O error occurred</DL>
</DD>
</DL>
<HR>

<A NAME="getServerDefaults()"><!-- --></A><H3>
getServerDefaults</H3>
<PRE>
public org.apache.hadoop.fs.FsServerDefaults <B>getServerDefaults</B>()
                                                        throws java.io.IOException</PRE>
<DL>
<DD>Get server default values for a number of configuration params.
<P>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的接口">ClientProtocol</A></CODE> 中的 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html#getServerDefaults()">getServerDefaults</A></CODE></DL>
</DD>
<DD><DL>

<DT><B>返回：</B><DD>a set of server default configuration values
<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="create(java.lang.String, org.apache.hadoop.fs.permission.FsPermission, java.lang.String, org.apache.hadoop.io.EnumSetWritable, boolean, short, long)"><!-- --></A><H3>
create</H3>
<PRE>
public void <B>create</B>(java.lang.String&nbsp;src,
                   org.apache.hadoop.fs.permission.FsPermission&nbsp;masked,
                   java.lang.String&nbsp;clientName,
                   org.apache.hadoop.io.EnumSetWritable&lt;org.apache.hadoop.fs.CreateFlag&gt;&nbsp;flag,
                   boolean&nbsp;createParent,
                   short&nbsp;replication,
                   long&nbsp;blockSize)
            throws java.io.IOException</PRE>
<DL>
<DD>Create a new file entry in the namespace.
 <p>
 This will create an empty file specified by the source path.
 The path should reflect a full path originated at the root.
 The name-node does not have a notion of "current" directory for a client.
 <p>
 Once created, the file is visible and available for read to other clients.
 Although, other clients cannot <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html#delete(java.lang.String, boolean)"><CODE>ClientProtocol.delete(String, boolean)</CODE></A>, re-create or 
 <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html#rename(java.lang.String, java.lang.String)"><CODE>ClientProtocol.rename(String, String)</CODE></A> it until the file is completed
 or explicitly as a result of lease expiration.
 <p>
 Blocks have a maximum size.  Clients that intend to create
 multi-block files must also use 
 <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html#addBlock(java.lang.String, java.lang.String, org.apache.hadoop.hdfs.protocol.Block, org.apache.hadoop.hdfs.protocol.DatanodeInfo[])"><CODE>ClientProtocol.addBlock(String, String, Block, DatanodeInfo[])</CODE></A>
<P>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的接口">ClientProtocol</A></CODE> 中的 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html#create(java.lang.String, org.apache.hadoop.fs.permission.FsPermission, java.lang.String, org.apache.hadoop.io.EnumSetWritable, boolean, short, long)">create</A></CODE></DL>
</DD>
<DD><DL>
<DT><B>参数：</B><DD><CODE>src</CODE> - path of the file being created.<DD><CODE>masked</CODE> - masked permission.<DD><CODE>clientName</CODE> - name of the current client.<DD><CODE>flag</CODE> - indicates whether the file should be 
 overwritten if it already exists or create if it does not exist or append.<DD><CODE>createParent</CODE> - create missing parent directory if true<DD><CODE>replication</CODE> - block replication factor.<DD><CODE>blockSize</CODE> - maximum block size.
<DT><B>抛出：</B>
<DD><CODE>org.apache.hadoop.security.AccessControlException</CODE> - If access is denied
<DD><CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/AlreadyBeingCreatedException.html" title="org.apache.hadoop.hdfs.protocol 中的类">AlreadyBeingCreatedException</A></CODE> - if the path does not exist.
<DD><CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/DSQuotaExceededException.html" title="org.apache.hadoop.hdfs.protocol 中的类">DSQuotaExceededException</A></CODE> - If file creation violates disk space 
           quota restriction
<DD><CODE>org.apache.hadoop.fs.FileAlreadyExistsException</CODE> - If file <code>src</code> already exists
<DD><CODE>java.io.FileNotFoundException</CODE> - If parent of <code>src</code> does not exist
           and <code>createParent</code> is false
<DD><CODE>org.apache.hadoop.fs.ParentNotDirectoryException</CODE> - If parent of <code>src</code> is not a
           directory.
<DD><CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/NSQuotaExceededException.html" title="org.apache.hadoop.hdfs.protocol 中的类">NSQuotaExceededException</A></CODE> - If file creation violates name space 
           quota restriction
<DD><CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/SafeModeException.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">SafeModeException</A></CODE> - create not allowed in safemode
<DD><CODE>org.apache.hadoop.fs.UnresolvedLinkException</CODE> - If <code>src</code> contains a symlink
<DD><CODE>java.io.IOException</CODE> - If an I/O error occurred

 RuntimeExceptions:</DL>
</DD>
</DL>
<HR>

<A NAME="create(java.lang.String, long, long, org.apache.hadoop.fs.permission.FsPermission, java.lang.String, org.apache.hadoop.io.EnumSetWritable, boolean)"><!-- --></A><H3>
create</H3>
<PRE>
public <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/CodingMatrix.html" title="org.apache.hadoop.hdfs.protocol 中的类">CodingMatrix</A> <B>create</B>(java.lang.String&nbsp;src,
                           long&nbsp;fileSize,
                           long&nbsp;packetSize,
                           org.apache.hadoop.fs.permission.FsPermission&nbsp;masked,
                           java.lang.String&nbsp;clientName,
                           org.apache.hadoop.io.EnumSetWritable&lt;org.apache.hadoop.fs.CreateFlag&gt;&nbsp;flag,
                           boolean&nbsp;createParent)
                    throws java.io.IOException</PRE>
<DL>
<DD>
<P>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的接口">ClientProtocol</A></CODE> 中的 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html#create(java.lang.String, long, long, org.apache.hadoop.fs.permission.FsPermission, java.lang.String, org.apache.hadoop.io.EnumSetWritable, boolean)">create</A></CODE></DL>
</DD>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="append(java.lang.String, java.lang.String)"><!-- --></A><H3>
append</H3>
<PRE>
public <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/LocatedBlock.html" title="org.apache.hadoop.hdfs.protocol 中的类">LocatedBlock</A> <B>append</B>(java.lang.String&nbsp;src,
                           java.lang.String&nbsp;clientName)
                    throws java.io.IOException</PRE>
<DL>
<DD>Append to the end of the file.
<P>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的接口">ClientProtocol</A></CODE> 中的 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html#append(java.lang.String, java.lang.String)">append</A></CODE></DL>
</DD>
<DD><DL>
<DT><B>参数：</B><DD><CODE>src</CODE> - path of the file being created.<DD><CODE>clientName</CODE> - name of the current client.
<DT><B>返回：</B><DD>information about the last partial block if any.
<DT><B>抛出：</B>
<DD><CODE>org.apache.hadoop.security.AccessControlException</CODE> - if permission to append file is 
 denied by the system. As usually on the client side the exception will 
 be wrapped into <CODE>RemoteException</CODE>.
 Allows appending to an existing file if the server is
 configured with the parameter dfs.support.append set to true, otherwise
 throws an IOException.
<DD><CODE>java.io.FileNotFoundException</CODE> - If file <code>src</code> is not found
<DD><CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/DSQuotaExceededException.html" title="org.apache.hadoop.hdfs.protocol 中的类">DSQuotaExceededException</A></CODE> - If append violates disk space quota 
           restriction
<DD><CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/SafeModeException.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">SafeModeException</A></CODE> - append not allowed in safemode
<DD><CODE>org.apache.hadoop.fs.UnresolvedLinkException</CODE> - If <code>src</code> contains a symlink
<DD><CODE>java.io.IOException</CODE> - If an I/O error occurred.

 RuntimeExceptions:</DL>
</DD>
</DL>
<HR>

<A NAME="recoverLease(java.lang.String, java.lang.String)"><!-- --></A><H3>
recoverLease</H3>
<PRE>
public boolean <B>recoverLease</B>(java.lang.String&nbsp;src,
                            java.lang.String&nbsp;clientName)
                     throws java.io.IOException</PRE>
<DL>
<DD>Start lease recovery.
 Lightweight NameNode operation to trigger lease recovery
<P>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的接口">ClientProtocol</A></CODE> 中的 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html#recoverLease(java.lang.String, java.lang.String)">recoverLease</A></CODE></DL>
</DD>
<DD><DL>
<DT><B>参数：</B><DD><CODE>src</CODE> - path of the file to start lease recovery<DD><CODE>clientName</CODE> - name of the current client
<DT><B>返回：</B><DD>true if the file is already closed
<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="setReplication(java.lang.String, short)"><!-- --></A><H3>
setReplication</H3>
<PRE>
public boolean <B>setReplication</B>(java.lang.String&nbsp;src,
                              short&nbsp;replication)
                       throws java.io.IOException</PRE>
<DL>
<DD>Set replication for an existing file.
 <p>
 The NameNode sets replication to the new value and returns.
 The actual block replication is not expected to be performed during  
 this method call. The blocks will be populated or removed in the 
 background as the result of the routine block maintenance procedures.
<P>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的接口">ClientProtocol</A></CODE> 中的 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html#setReplication(java.lang.String, short)">setReplication</A></CODE></DL>
</DD>
<DD><DL>
<DT><B>参数：</B><DD><CODE>src</CODE> - file name<DD><CODE>replication</CODE> - new replication
<DT><B>返回：</B><DD>true if successful;
         false if file does not exist or is a directory
<DT><B>抛出：</B>
<DD><CODE>org.apache.hadoop.security.AccessControlException</CODE> - If access is denied
<DD><CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/DSQuotaExceededException.html" title="org.apache.hadoop.hdfs.protocol 中的类">DSQuotaExceededException</A></CODE> - If replication violates disk space 
           quota restriction
<DD><CODE>java.io.FileNotFoundException</CODE> - If file <code>src</code> is not found
<DD><CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/SafeModeException.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">SafeModeException</A></CODE> - not allowed in safemode
<DD><CODE>org.apache.hadoop.fs.UnresolvedLinkException</CODE> - if <code>src</code> contains a symlink
<DD><CODE>java.io.IOException</CODE> - If an I/O error occurred</DL>
</DD>
</DL>
<HR>

<A NAME="setPermission(java.lang.String, org.apache.hadoop.fs.permission.FsPermission)"><!-- --></A><H3>
setPermission</H3>
<PRE>
public void <B>setPermission</B>(java.lang.String&nbsp;src,
                          org.apache.hadoop.fs.permission.FsPermission&nbsp;permissions)
                   throws java.io.IOException</PRE>
<DL>
<DD>Set permissions for an existing file/directory.
<P>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的接口">ClientProtocol</A></CODE> 中的 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html#setPermission(java.lang.String, org.apache.hadoop.fs.permission.FsPermission)">setPermission</A></CODE></DL>
</DD>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>org.apache.hadoop.security.AccessControlException</CODE> - If access is denied
<DD><CODE>java.io.FileNotFoundException</CODE> - If file <code>src</code> is not found
<DD><CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/SafeModeException.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">SafeModeException</A></CODE> - not allowed in safemode
<DD><CODE>org.apache.hadoop.fs.UnresolvedLinkException</CODE> - If <code>src</code> contains a symlink
<DD><CODE>java.io.IOException</CODE> - If an I/O error occurred</DL>
</DD>
</DL>
<HR>

<A NAME="setOwner(java.lang.String, java.lang.String, java.lang.String)"><!-- --></A><H3>
setOwner</H3>
<PRE>
public void <B>setOwner</B>(java.lang.String&nbsp;src,
                     java.lang.String&nbsp;username,
                     java.lang.String&nbsp;groupname)
              throws java.io.IOException</PRE>
<DL>
<DD>Set Owner of a path (i.e. a file or a directory).
 The parameters username and groupname cannot both be null.
<P>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的接口">ClientProtocol</A></CODE> 中的 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html#setOwner(java.lang.String, java.lang.String, java.lang.String)">setOwner</A></CODE></DL>
</DD>
<DD><DL>
<DD><CODE>username</CODE> - If it is null, the original username remains unchanged.<DD><CODE>groupname</CODE> - If it is null, the original groupname remains unchanged.
<DT><B>抛出：</B>
<DD><CODE>org.apache.hadoop.security.AccessControlException</CODE> - If access is denied
<DD><CODE>java.io.FileNotFoundException</CODE> - If file <code>src</code> is not found
<DD><CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/SafeModeException.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">SafeModeException</A></CODE> - not allowed in safemode
<DD><CODE>org.apache.hadoop.fs.UnresolvedLinkException</CODE> - If <code>src</code> contains a symlink
<DD><CODE>java.io.IOException</CODE> - If an I/O error occurred</DL>
</DD>
</DL>
<HR>

<A NAME="addBlock(java.lang.String, java.lang.String, org.apache.hadoop.hdfs.protocol.Block, org.apache.hadoop.hdfs.protocol.DatanodeInfo[])"><!-- --></A><H3>
addBlock</H3>
<PRE>
public <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/LocatedBlock.html" title="org.apache.hadoop.hdfs.protocol 中的类">LocatedBlock</A>[] <B>addBlock</B>(java.lang.String&nbsp;src,
                               java.lang.String&nbsp;clientName,
                               <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/Block.html" title="org.apache.hadoop.hdfs.protocol 中的类">Block</A>&nbsp;previous,
                               <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/DatanodeInfo.html" title="org.apache.hadoop.hdfs.protocol 中的类">DatanodeInfo</A>[]&nbsp;excludedNodes)
                        throws java.io.IOException</PRE>
<DL>
<DD><B>从接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html#addBlock(java.lang.String, java.lang.String, org.apache.hadoop.hdfs.protocol.Block, org.apache.hadoop.hdfs.protocol.DatanodeInfo[])">ClientProtocol</A></CODE> 复制的描述</B></DD>
<DD>A client that wants to write an additional block to the 
 indicated filename (which must currently be open for writing)
 should call addBlock().  

 addBlock() allocates a new block and datanodes the block data
 should be replicated to.
 
 addBlock() also commits the previous block by reporting
 to the name-node the actual generation stamp and the length
 of the block that the client has transmitted to data-nodes.
<P>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的接口">ClientProtocol</A></CODE> 中的 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html#addBlock(java.lang.String, java.lang.String, org.apache.hadoop.hdfs.protocol.Block, org.apache.hadoop.hdfs.protocol.DatanodeInfo[])">addBlock</A></CODE></DL>
</DD>
<DD><DL>
<DT><B>参数：</B><DD><CODE>src</CODE> - the file being created<DD><CODE>clientName</CODE> - the name of the client that adds the block<DD><CODE>previous</CODE> - previous block<DD><CODE>excludedNodes</CODE> - a list of nodes that should not be
 allocated for the current block
<DT><B>返回：</B><DD>LocatedBlock allocated block information.
<DT><B>抛出：</B>
<DD><CODE>org.apache.hadoop.security.AccessControlException</CODE> - If access is denied
<DD><CODE>java.io.FileNotFoundException</CODE> - If file <code>src</code> is not found
<DD><CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NotReplicatedYetException.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">NotReplicatedYetException</A></CODE> - previous blocks of the file are not
           replicated yet. Blocks cannot be added until replication
           completes.
<DD><CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/SafeModeException.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">SafeModeException</A></CODE> - create not allowed in safemode
<DD><CODE>org.apache.hadoop.fs.UnresolvedLinkException</CODE> - If <code>src</code> contains a symlink
<DD><CODE>java.io.IOException</CODE> - If an I/O error occurred</DL>
</DD>
</DL>
<HR>

<A NAME="abandonBlock(org.apache.hadoop.hdfs.protocol.Block, java.lang.String, java.lang.String)"><!-- --></A><H3>
abandonBlock</H3>
<PRE>
public void <B>abandonBlock</B>(<A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/Block.html" title="org.apache.hadoop.hdfs.protocol 中的类">Block</A>&nbsp;b,
                         java.lang.String&nbsp;src,
                         java.lang.String&nbsp;holder)
                  throws java.io.IOException</PRE>
<DL>
<DD>The client needs to give up on the block.
<P>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的接口">ClientProtocol</A></CODE> 中的 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html#abandonBlock(org.apache.hadoop.hdfs.protocol.Block, java.lang.String, java.lang.String)">abandonBlock</A></CODE></DL>
</DD>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>org.apache.hadoop.security.AccessControlException</CODE> - If access is denied
<DD><CODE>java.io.FileNotFoundException</CODE> - file <code>src</code> is not found
<DD><CODE>org.apache.hadoop.fs.UnresolvedLinkException</CODE> - If <code>src</code> contains a symlink
<DD><CODE>java.io.IOException</CODE> - If an I/O error occurred</DL>
</DD>
</DL>
<HR>

<A NAME="complete(java.lang.String, java.lang.String, org.apache.hadoop.hdfs.protocol.Block[])"><!-- --></A><H3>
complete</H3>
<PRE>
public boolean <B>complete</B>(java.lang.String&nbsp;src,
                        java.lang.String&nbsp;clientName,
                        <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/Block.html" title="org.apache.hadoop.hdfs.protocol 中的类">Block</A>[]&nbsp;blks)
                 throws java.io.IOException</PRE>
<DL>
<DD>modified by Vither Chien, we dont need the param lastblock, we 
 complete the file instead.
 The client is done writing data to the given filename, and would 
 like to complete it.  

 The function returns whether the file has been closed successfully.
 If the function returns false, the caller should try again.
 
 close() also commits the last block of the file by reporting
 to the name-node the actual generation stamp and the length
 of the block that the client has transmitted to data-nodes.

 A call to complete() will not return true until all the file's
 blocks have been replicated the minimum number of times.  Thus,
 DataNode failures may cause a client to call complete() several
 times before succeeding.
<P>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的接口">ClientProtocol</A></CODE> 中的 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html#complete(java.lang.String, java.lang.String, org.apache.hadoop.hdfs.protocol.Block[])">complete</A></CODE></DL>
</DD>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>org.apache.hadoop.security.AccessControlException</CODE> - If access is denied
<DD><CODE>java.io.FileNotFoundException</CODE> - If file <code>src</code> is not found
<DD><CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/SafeModeException.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">SafeModeException</A></CODE> - create not allowed in safemode
<DD><CODE>org.apache.hadoop.fs.UnresolvedLinkException</CODE> - If <code>src</code> contains a symlink
<DD><CODE>java.io.IOException</CODE> - If an I/O error occurred</DL>
</DD>
</DL>
<HR>

<A NAME="reportBadBlocks(org.apache.hadoop.hdfs.protocol.LocatedBlock[])"><!-- --></A><H3>
reportBadBlocks</H3>
<PRE>
public void <B>reportBadBlocks</B>(<A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/LocatedBlock.html" title="org.apache.hadoop.hdfs.protocol 中的类">LocatedBlock</A>[]&nbsp;blocks)
                     throws java.io.IOException</PRE>
<DL>
<DD>The client has detected an error on the specified located blocks 
 and is reporting them to the server.  For now, the namenode will 
 mark the block as corrupt.  In the future we might 
 check the blocks are actually corrupt.
<P>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的接口">ClientProtocol</A></CODE> 中的 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html#reportBadBlocks(org.apache.hadoop.hdfs.protocol.LocatedBlock[])">reportBadBlocks</A></CODE><DT><B>指定者：</B><DD>接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/DatanodeProtocol.html" title="org.apache.hadoop.hdfs.server.protocol 中的接口">DatanodeProtocol</A></CODE> 中的 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/DatanodeProtocol.html#reportBadBlocks(org.apache.hadoop.hdfs.protocol.LocatedBlock[])">reportBadBlocks</A></CODE></DL>
</DD>
<DD><DL>
<DT><B>参数：</B><DD><CODE>blocks</CODE> - Array of located blocks to report
<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="updateBlockForPipeline(org.apache.hadoop.hdfs.protocol.Block, java.lang.String)"><!-- --></A><H3>
updateBlockForPipeline</H3>
<PRE>
public <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/LocatedBlock.html" title="org.apache.hadoop.hdfs.protocol 中的类">LocatedBlock</A> <B>updateBlockForPipeline</B>(<A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/Block.html" title="org.apache.hadoop.hdfs.protocol 中的类">Block</A>&nbsp;block,
                                           java.lang.String&nbsp;clientName)
                                    throws java.io.IOException</PRE>
<DL>
<DD>Get a new generation stamp together with an access token for 
 a block under construction
 
 This method is called only when a client needs to recover a failed
 pipeline or set up a pipeline for appending to a block.
<P>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的接口">ClientProtocol</A></CODE> 中的 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html#updateBlockForPipeline(org.apache.hadoop.hdfs.protocol.Block, java.lang.String)">updateBlockForPipeline</A></CODE></DL>
</DD>
<DD><DL>
<DT><B>参数：</B><DD><CODE>block</CODE> - a block<DD><CODE>clientName</CODE> - the name of the client
<DT><B>返回：</B><DD>a located block with a new generation stamp and an access token
<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE> - if any error occurs</DL>
</DD>
</DL>
<HR>

<A NAME="updatePipeline(java.lang.String, org.apache.hadoop.hdfs.protocol.Block, org.apache.hadoop.hdfs.protocol.Block, org.apache.hadoop.hdfs.protocol.DatanodeID[])"><!-- --></A><H3>
updatePipeline</H3>
<PRE>
public void <B>updatePipeline</B>(java.lang.String&nbsp;clientName,
                           <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/Block.html" title="org.apache.hadoop.hdfs.protocol 中的类">Block</A>&nbsp;oldBlock,
                           <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/Block.html" title="org.apache.hadoop.hdfs.protocol 中的类">Block</A>&nbsp;newBlock,
                           <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/DatanodeID.html" title="org.apache.hadoop.hdfs.protocol 中的类">DatanodeID</A>[]&nbsp;newNodes)
                    throws java.io.IOException</PRE>
<DL>
<DD><B>从接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html#updatePipeline(java.lang.String, org.apache.hadoop.hdfs.protocol.Block, org.apache.hadoop.hdfs.protocol.Block, org.apache.hadoop.hdfs.protocol.DatanodeID[])">ClientProtocol</A></CODE> 复制的描述</B></DD>
<DD>Update a pipeline for a block under construction
<P>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的接口">ClientProtocol</A></CODE> 中的 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html#updatePipeline(java.lang.String, org.apache.hadoop.hdfs.protocol.Block, org.apache.hadoop.hdfs.protocol.Block, org.apache.hadoop.hdfs.protocol.DatanodeID[])">updatePipeline</A></CODE></DL>
</DD>
<DD><DL>
<DT><B>参数：</B><DD><CODE>clientName</CODE> - the name of the client<DD><CODE>oldBlock</CODE> - the old block<DD><CODE>newBlock</CODE> - the new block containing new generation stamp and length<DD><CODE>newNodes</CODE> - datanodes in the pipeline
<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE> - if any error occurs</DL>
</DD>
</DL>
<HR>

<A NAME="commitBlockSynchronization(org.apache.hadoop.hdfs.protocol.Block, long, long, boolean, boolean, org.apache.hadoop.hdfs.protocol.DatanodeID[])"><!-- --></A><H3>
commitBlockSynchronization</H3>
<PRE>
public void <B>commitBlockSynchronization</B>(<A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/Block.html" title="org.apache.hadoop.hdfs.protocol 中的类">Block</A>&nbsp;block,
                                       long&nbsp;newgenerationstamp,
                                       long&nbsp;newlength,
                                       boolean&nbsp;closeFile,
                                       boolean&nbsp;deleteblock,
                                       <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/DatanodeID.html" title="org.apache.hadoop.hdfs.protocol 中的类">DatanodeID</A>[]&nbsp;newtargets)
                                throws java.io.IOException</PRE>
<DL>
<DD>Commit block synchronization in lease recovery
<P>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/DatanodeProtocol.html" title="org.apache.hadoop.hdfs.server.protocol 中的接口">DatanodeProtocol</A></CODE> 中的 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/DatanodeProtocol.html#commitBlockSynchronization(org.apache.hadoop.hdfs.protocol.Block, long, long, boolean, boolean, org.apache.hadoop.hdfs.protocol.DatanodeID[])">commitBlockSynchronization</A></CODE></DL>
</DD>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="getPreferredBlockSize(java.lang.String)"><!-- --></A><H3>
getPreferredBlockSize</H3>
<PRE>
public long <B>getPreferredBlockSize</B>(java.lang.String&nbsp;filename)
                           throws java.io.IOException</PRE>
<DL>
<DD><B>从接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html#getPreferredBlockSize(java.lang.String)">ClientProtocol</A></CODE> 复制的描述</B></DD>
<DD>Get the block size for the given file.
<P>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的接口">ClientProtocol</A></CODE> 中的 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html#getPreferredBlockSize(java.lang.String)">getPreferredBlockSize</A></CODE></DL>
</DD>
<DD><DL>
<DT><B>参数：</B><DD><CODE>filename</CODE> - The name of the file
<DT><B>返回：</B><DD>The number of bytes in each block
<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE>
<DD><CODE>org.apache.hadoop.fs.UnresolvedLinkException</CODE> - if the path contains a symlink.</DL>
</DD>
</DL>
<HR>

<A NAME="rename(java.lang.String, java.lang.String)"><!-- --></A><H3>
rename</H3>
<PRE>
<FONT SIZE="-1">@Deprecated
</FONT>public boolean <B>rename</B>(java.lang.String&nbsp;src,
                                 java.lang.String&nbsp;dst)
               throws java.io.IOException</PRE>
<DL>
<DD><B>已过时。</B>&nbsp;
<P>
<DD>Rename an item in the file system namespace.
<P>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的接口">ClientProtocol</A></CODE> 中的 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html#rename(java.lang.String, java.lang.String)">rename</A></CODE></DL>
</DD>
<DD><DL>
<DT><B>参数：</B><DD><CODE>src</CODE> - existing file or directory name.<DD><CODE>dst</CODE> - new name.
<DT><B>返回：</B><DD>true if successful, or false if the old name does not exist
 or if the new name already belongs to the namespace.
<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE> - an I/O error occurred</DL>
</DD>
</DL>
<HR>

<A NAME="concat(java.lang.String, java.lang.String[])"><!-- --></A><H3>
concat</H3>
<PRE>
public void <B>concat</B>(java.lang.String&nbsp;trg,
                   java.lang.String[]&nbsp;src)
            throws java.io.IOException</PRE>
<DL>
<DD>Moves blocks from srcs to trg and delete srcs
<P>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的接口">ClientProtocol</A></CODE> 中的 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html#concat(java.lang.String, java.lang.String[])">concat</A></CODE></DL>
</DD>
<DD><DL>
<DT><B>参数：</B><DD><CODE>trg</CODE> - existing file<DD><CODE>src</CODE> - - list of existing files (same block size, same replication)
<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE> - if some arguments are invalid
<DD><CODE>org.apache.hadoop.fs.UnresolvedLinkException</CODE> - if <code>trg</code> or <code>srcs</code>
           contains a symlink</DL>
</DD>
</DL>
<HR>

<A NAME="rename(java.lang.String, java.lang.String, org.apache.hadoop.fs.Options.Rename...)"><!-- --></A><H3>
rename</H3>
<PRE>
public void <B>rename</B>(java.lang.String&nbsp;src,
                   java.lang.String&nbsp;dst,
                   org.apache.hadoop.fs.Options.Rename...&nbsp;options)
            throws java.io.IOException</PRE>
<DL>
<DD>Rename src to dst.
 <ul>
 <li>Fails if src is a file and dst is a directory.
 <li>Fails if src is a directory and dst is a file.
 <li>Fails if the parent of dst does not exist or is a file.
 </ul>
 <p>
 Without OVERWRITE option, rename fails if the dst already exists.
 With OVERWRITE option, rename overwrites the dst, if it is a file 
 or an empty directory. Rename fails if dst is a non-empty directory.
 <p>
 This implementation of rename is atomic.
 <p>
<P>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的接口">ClientProtocol</A></CODE> 中的 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html#rename(java.lang.String, java.lang.String, org.apache.hadoop.fs.Options.Rename...)">rename</A></CODE></DL>
</DD>
<DD><DL>
<DT><B>参数：</B><DD><CODE>src</CODE> - existing file or directory name.<DD><CODE>dst</CODE> - new name.<DD><CODE>options</CODE> - Rename options
<DT><B>抛出：</B>
<DD><CODE>org.apache.hadoop.security.AccessControlException</CODE> - If access is denied
<DD><CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/DSQuotaExceededException.html" title="org.apache.hadoop.hdfs.protocol 中的类">DSQuotaExceededException</A></CODE> - If rename violates disk space 
           quota restriction
<DD><CODE>org.apache.hadoop.fs.FileAlreadyExistsException</CODE> - If <code>dst</code> already exists and
           <code>options</options> has <CODE>Options.Rename.OVERWRITE</CODE> option
           false.
<DD><CODE>java.io.FileNotFoundException</CODE> - If <code>src</code> does not exist
<DD><CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/NSQuotaExceededException.html" title="org.apache.hadoop.hdfs.protocol 中的类">NSQuotaExceededException</A></CODE> - If rename violates namespace 
           quota restriction
<DD><CODE>org.apache.hadoop.fs.ParentNotDirectoryException</CODE> - If parent of <code>dst</code> 
           is not a directory
<DD><CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/SafeModeException.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">SafeModeException</A></CODE> - rename not allowed in safemode
<DD><CODE>org.apache.hadoop.fs.UnresolvedLinkException</CODE> - If <code>src</code> or
           <code>dst</code> contains a symlink
<DD><CODE>java.io.IOException</CODE> - If an I/O error occurred</DL>
</DD>
</DL>
<HR>

<A NAME="delete(java.lang.String)"><!-- --></A><H3>
delete</H3>
<PRE>
<FONT SIZE="-1">@Deprecated
</FONT>public boolean <B>delete</B>(java.lang.String&nbsp;src)
               throws java.io.IOException</PRE>
<DL>
<DD><B>已过时。</B>&nbsp;
<P>
<DD><B>从接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html#delete(java.lang.String)">ClientProtocol</A></CODE> 复制的描述</B></DD>
<DD>Delete the given file or directory from the file system.
 <p>
 Any blocks belonging to the deleted files will be garbage-collected.
<P>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的接口">ClientProtocol</A></CODE> 中的 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html#delete(java.lang.String)">delete</A></CODE></DL>
</DD>
<DD><DL>
<DT><B>参数：</B><DD><CODE>src</CODE> - existing name.
<DT><B>返回：</B><DD>true only if the existing file or directory was actually removed 
 from the file system.
<DT><B>抛出：</B>
<DD><CODE>org.apache.hadoop.fs.UnresolvedLinkException</CODE> - if <code>src</code> contains a symlink.
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="delete(java.lang.String, boolean)"><!-- --></A><H3>
delete</H3>
<PRE>
public boolean <B>delete</B>(java.lang.String&nbsp;src,
                      boolean&nbsp;recursive)
               throws java.io.IOException</PRE>
<DL>
<DD>Delete the given file or directory from the file system.
 <p>
 same as delete but provides a way to avoid accidentally 
 deleting non empty directories programmatically.
<P>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的接口">ClientProtocol</A></CODE> 中的 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html#delete(java.lang.String, boolean)">delete</A></CODE></DL>
</DD>
<DD><DL>
<DT><B>参数：</B><DD><CODE>src</CODE> - existing name<DD><CODE>recursive</CODE> - if true deletes a non empty directory recursively,
 else throws an exception.
<DT><B>返回：</B><DD>true only if the existing file or directory was actually removed 
 from the file system.
<DT><B>抛出：</B>
<DD><CODE>org.apache.hadoop.security.AccessControlException</CODE> - If access is denied
<DD><CODE>java.io.FileNotFoundException</CODE> - If file <code>src</code> is not found
<DD><CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/SafeModeException.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">SafeModeException</A></CODE> - create not allowed in safemode
<DD><CODE>org.apache.hadoop.fs.UnresolvedLinkException</CODE> - If <code>src</code> contains a symlink
<DD><CODE>java.io.IOException</CODE> - If an I/O error occurred</DL>
</DD>
</DL>
<HR>

<A NAME="mkdirs(java.lang.String, org.apache.hadoop.fs.permission.FsPermission, boolean)"><!-- --></A><H3>
mkdirs</H3>
<PRE>
public boolean <B>mkdirs</B>(java.lang.String&nbsp;src,
                      org.apache.hadoop.fs.permission.FsPermission&nbsp;masked,
                      boolean&nbsp;createParent)
               throws java.io.IOException</PRE>
<DL>
<DD>Create a directory (or hierarchy of directories) with the given
 name and permission.
<P>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的接口">ClientProtocol</A></CODE> 中的 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html#mkdirs(java.lang.String, org.apache.hadoop.fs.permission.FsPermission, boolean)">mkdirs</A></CODE></DL>
</DD>
<DD><DL>
<DT><B>参数：</B><DD><CODE>src</CODE> - The path of the directory being created<DD><CODE>masked</CODE> - The masked permission of the directory being created<DD><CODE>createParent</CODE> - create missing parent directory if true
<DT><B>返回：</B><DD>True if the operation success.
<DT><B>抛出：</B>
<DD><CODE>org.apache.hadoop.security.AccessControlException</CODE> - If access is denied
<DD><CODE>org.apache.hadoop.fs.FileAlreadyExistsException</CODE> - If <code>src</code> already exists
<DD><CODE>java.io.FileNotFoundException</CODE> - If parent of <code>src</code> does not exist
           and <code>createParent</code> is false
<DD><CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/NSQuotaExceededException.html" title="org.apache.hadoop.hdfs.protocol 中的类">NSQuotaExceededException</A></CODE> - If file creation violates quota restriction
<DD><CODE>org.apache.hadoop.fs.ParentNotDirectoryException</CODE> - If parent of <code>src</code> 
           is not a directory
<DD><CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/SafeModeException.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">SafeModeException</A></CODE> - create not allowed in safemode
<DD><CODE>org.apache.hadoop.fs.UnresolvedLinkException</CODE> - If <code>src</code> contains a symlink
<DD><CODE>java.io.IOException</CODE> - If an I/O error occurred.

 RunTimeExceptions:</DL>
</DD>
</DL>
<HR>

<A NAME="renewLease(java.lang.String)"><!-- --></A><H3>
renewLease</H3>
<PRE>
public void <B>renewLease</B>(java.lang.String&nbsp;clientName)
                throws java.io.IOException</PRE>
<DL>
<DD><B>从接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html#renewLease(java.lang.String)">ClientProtocol</A></CODE> 复制的描述</B></DD>
<DD>Client programs can cause stateful changes in the NameNode
 that affect other clients.  A client may obtain a file and 
 neither abandon nor complete it.  A client might hold a series
 of locks that prevent other clients from proceeding.
 Clearly, it would be bad if a client held a bunch of locks
 that it never gave up.  This can happen easily if the client
 dies unexpectedly.
 <p>
 So, the NameNode will revoke the locks and live file-creates
 for clients that it thinks have died.  A client tells the
 NameNode that it is still alive by periodically calling
 renewLease().  If a certain amount of time passes since
 the last call to renewLease(), the NameNode assumes the
 client has died.
<P>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的接口">ClientProtocol</A></CODE> 中的 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html#renewLease(java.lang.String)">renewLease</A></CODE></DL>
</DD>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>org.apache.hadoop.security.AccessControlException</CODE> - permission denied
<DD><CODE>java.io.IOException</CODE> - If an I/O error occurred</DL>
</DD>
</DL>
<HR>

<A NAME="getListing(java.lang.String, byte[], boolean)"><!-- --></A><H3>
getListing</H3>
<PRE>
public <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/DirectoryListing.html" title="org.apache.hadoop.hdfs.protocol 中的类">DirectoryListing</A> <B>getListing</B>(java.lang.String&nbsp;src,
                                   byte[]&nbsp;startAfter,
                                   boolean&nbsp;needLocation)
                            throws java.io.IOException</PRE>
<DL>
<DD><B>从接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html#getListing(java.lang.String, byte[], boolean)">ClientProtocol</A></CODE> 复制的描述</B></DD>
<DD>Get a partial listing of the indicated directory
<P>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的接口">ClientProtocol</A></CODE> 中的 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html#getListing(java.lang.String, byte[], boolean)">getListing</A></CODE></DL>
</DD>
<DD><DL>
<DT><B>参数：</B><DD><CODE>src</CODE> - the directory name<DD><CODE>startAfter</CODE> - the name to start listing after encoded in java UTF8<DD><CODE>needLocation</CODE> - if the FileStatus should contain block locations
<DT><B>返回：</B><DD>a partial listing starting after startAfter
<DT><B>抛出：</B>
<DD><CODE>org.apache.hadoop.security.AccessControlException</CODE> - permission denied
<DD><CODE>java.io.FileNotFoundException</CODE> - file <code>src</code> is not found
<DD><CODE>org.apache.hadoop.fs.UnresolvedLinkException</CODE> - If <code>src</code> contains a symlink
<DD><CODE>java.io.IOException</CODE> - If an I/O error occurred</DL>
</DD>
</DL>
<HR>

<A NAME="getFileInfo(java.lang.String)"><!-- --></A><H3>
getFileInfo</H3>
<PRE>
public <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/HdfsFileStatus.html" title="org.apache.hadoop.hdfs.protocol 中的类">HdfsFileStatus</A> <B>getFileInfo</B>(java.lang.String&nbsp;src)
                           throws java.io.IOException</PRE>
<DL>
<DD>Get the file info for a specific file.
<P>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的接口">ClientProtocol</A></CODE> 中的 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html#getFileInfo(java.lang.String)">getFileInfo</A></CODE></DL>
</DD>
<DD><DL>
<DT><B>参数：</B><DD><CODE>src</CODE> - The string representation of the path to the file
<DT><B>返回：</B><DD>object containing information regarding the file
         or null if file not found
<DT><B>抛出：</B>
<DD><CODE>org.apache.hadoop.security.AccessControlException</CODE> - permission denied
<DD><CODE>java.io.FileNotFoundException</CODE> - file <code>src</code> is not found
<DD><CODE>org.apache.hadoop.fs.UnresolvedLinkException</CODE> - if the path contains a symlink.
<DD><CODE>java.io.IOException</CODE> - If an I/O error occurred</DL>
</DD>
</DL>
<HR>

<A NAME="getFileLinkInfo(java.lang.String)"><!-- --></A><H3>
getFileLinkInfo</H3>
<PRE>
public <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/HdfsFileStatus.html" title="org.apache.hadoop.hdfs.protocol 中的类">HdfsFileStatus</A> <B>getFileLinkInfo</B>(java.lang.String&nbsp;src)
                               throws java.io.IOException</PRE>
<DL>
<DD>Get the file info for a specific file. If the path refers to a 
 symlink then the FileStatus of the symlink is returned.
<P>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的接口">ClientProtocol</A></CODE> 中的 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html#getFileLinkInfo(java.lang.String)">getFileLinkInfo</A></CODE></DL>
</DD>
<DD><DL>
<DT><B>参数：</B><DD><CODE>src</CODE> - The string representation of the path to the file
<DT><B>返回：</B><DD>object containing information regarding the file
         or null if file not found
<DT><B>抛出：</B>
<DD><CODE>org.apache.hadoop.security.AccessControlException</CODE> - permission denied
<DD><CODE>org.apache.hadoop.fs.UnresolvedLinkException</CODE> - if <code>src</code> contains a symlink
<DD><CODE>java.io.IOException</CODE> - If an I/O error occurred</DL>
</DD>
</DL>
<HR>

<A NAME="getStats()"><!-- --></A><H3>
getStats</H3>
<PRE>
public long[] <B>getStats</B>()</PRE>
<DL>
<DD><B>从接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html#getStats()">ClientProtocol</A></CODE> 复制的描述</B></DD>
<DD>Get a set of statistics about the filesystem.
 Right now, only three values are returned.
 <ul>
 <li> [0] contains the total storage capacity of the system, in bytes.</li>
 <li> [1] contains the total used space of the system, in bytes.</li>
 <li> [2] contains the available storage of the system, in bytes.</li>
 <li> [3] contains number of under replicated blocks in the system.</li>
 <li> [4] contains number of blocks with a corrupt replica. </li>
 <li> [5] contains number of blocks without any good replicas left. </li>
 </ul>
 Use public constants like <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html#GET_STATS_CAPACITY_IDX"><CODE>ClientProtocol.GET_STATS_CAPACITY_IDX</CODE></A> in place of 
 actual numbers to index into the array.
<P>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的接口">ClientProtocol</A></CODE> 中的 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html#getStats()">getStats</A></CODE></DL>
</DD>
<DD><DL>
</DL>
</DD>
</DL>
<HR>

<A NAME="getDatanodeReport(org.apache.hadoop.hdfs.protocol.FSConstants.DatanodeReportType)"><!-- --></A><H3>
getDatanodeReport</H3>
<PRE>
public <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/DatanodeInfo.html" title="org.apache.hadoop.hdfs.protocol 中的类">DatanodeInfo</A>[] <B>getDatanodeReport</B>(<A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/FSConstants.DatanodeReportType.html" title="org.apache.hadoop.hdfs.protocol 中的枚举">FSConstants.DatanodeReportType</A>&nbsp;type)
                                 throws java.io.IOException</PRE>
<DL>
<DD><B>从接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html#getDatanodeReport(org.apache.hadoop.hdfs.protocol.FSConstants.DatanodeReportType)">ClientProtocol</A></CODE> 复制的描述</B></DD>
<DD>Get a report on the system's current datanodes.
 One DatanodeInfo object is returned for each DataNode.
 Return live datanodes if type is LIVE; dead datanodes if type is DEAD;
 otherwise all datanodes if type is ALL.
<P>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的接口">ClientProtocol</A></CODE> 中的 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html#getDatanodeReport(org.apache.hadoop.hdfs.protocol.FSConstants.DatanodeReportType)">getDatanodeReport</A></CODE></DL>
</DD>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="setSafeMode(org.apache.hadoop.hdfs.protocol.FSConstants.SafeModeAction)"><!-- --></A><H3>
setSafeMode</H3>
<PRE>
public boolean <B>setSafeMode</B>(<A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/FSConstants.SafeModeAction.html" title="org.apache.hadoop.hdfs.protocol 中的枚举">FSConstants.SafeModeAction</A>&nbsp;action)
                    throws java.io.IOException</PRE>
<DL>
<DD><B>从接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html#setSafeMode(org.apache.hadoop.hdfs.protocol.FSConstants.SafeModeAction)">ClientProtocol</A></CODE> 复制的描述</B></DD>
<DD>Enter, leave or get safe mode.
 <p>
 Safe mode is a name node state when it
 <ol><li>does not accept changes to name space (read-only), and</li>
 <li>does not replicate or delete blocks.</li></ol>
 
 <p>
 Safe mode is entered automatically at name node startup.
 Safe mode can also be entered manually using
 <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html#setSafeMode(org.apache.hadoop.hdfs.protocol.FSConstants.SafeModeAction)"><CODE>setSafeMode(SafeModeAction.SAFEMODE_GET)</CODE></A>.
 <p>
 At startup the name node accepts data node reports collecting
 information about block locations.
 In order to leave safe mode it needs to collect a configurable
 percentage called threshold of blocks, which satisfy the minimal 
 replication condition.
 The minimal replication condition is that each block must have at least
 <tt>dfs.namenode.replication.min</tt> replicas.
 When the threshold is reached the name node extends safe mode
 for a configurable amount of time
 to let the remaining data nodes to check in before it
 will start replicating missing blocks.
 Then the name node leaves safe mode.
 <p>
 If safe mode is turned on manually using
 <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html#setSafeMode(org.apache.hadoop.hdfs.protocol.FSConstants.SafeModeAction)"><CODE>setSafeMode(SafeModeAction.SAFEMODE_ENTER)</CODE></A>
 then the name node stays in safe mode until it is manually turned off
 using <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html#setSafeMode(org.apache.hadoop.hdfs.protocol.FSConstants.SafeModeAction)"><CODE>setSafeMode(SafeModeAction.SAFEMODE_LEAVE)</CODE></A>.
 Current state of the name node can be verified using
 <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html#setSafeMode(org.apache.hadoop.hdfs.protocol.FSConstants.SafeModeAction)"><CODE>setSafeMode(SafeModeAction.SAFEMODE_GET)</CODE></A>
 <h4>Configuration parameters:</h4>
 <tt>dfs.safemode.threshold.pct</tt> is the threshold parameter.<br>
 <tt>dfs.safemode.extension</tt> is the safe mode extension parameter.<br>
 <tt>dfs.namenode.replication.min</tt> is the minimal replication parameter.
 
 <h4>Special cases:</h4>
 The name node does not enter safe mode at startup if the threshold is 
 set to 0 or if the name space is empty.<br>
 If the threshold is set to 1 then all blocks need to have at least 
 minimal replication.<br>
 If the threshold value is greater than 1 then the name node will not be 
 able to turn off safe mode automatically.<br>
 Safe mode can always be turned off manually.
<P>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的接口">ClientProtocol</A></CODE> 中的 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html#setSafeMode(org.apache.hadoop.hdfs.protocol.FSConstants.SafeModeAction)">setSafeMode</A></CODE></DL>
</DD>
<DD><DL>
<DT><B>参数：</B><DD><CODE>action</CODE> - <ul> <li>0 leave safe mode;</li>
                <li>1 enter safe mode;</li>
                <li>2 get safe mode state.</li></ul>
<DT><B>返回：</B><DD><ul><li>0 if the safe mode is OFF or</li> 
         <li>1 if the safe mode is ON.</li></ul>
<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="isInSafeMode()"><!-- --></A><H3>
isInSafeMode</H3>
<PRE>
public boolean <B>isInSafeMode</B>()</PRE>
<DL>
<DD>Is the cluster currently in safe mode?
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
</DL>
</DD>
</DL>
<HR>

<A NAME="restoreFailedStorage(java.lang.String)"><!-- --></A><H3>
restoreFailedStorage</H3>
<PRE>
public boolean <B>restoreFailedStorage</B>(java.lang.String&nbsp;arg)
                             throws org.apache.hadoop.security.AccessControlException</PRE>
<DL>
<DD><B>从接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html#restoreFailedStorage(java.lang.String)">ClientProtocol</A></CODE> 复制的描述</B></DD>
<DD>Enable/Disable restore failed storage.
 <p>
 sets flag to enable restore of failed storage replicas
<P>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的接口">ClientProtocol</A></CODE> 中的 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html#restoreFailedStorage(java.lang.String)">restoreFailedStorage</A></CODE></DL>
</DD>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>org.apache.hadoop.security.AccessControlException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="saveNamespace()"><!-- --></A><H3>
saveNamespace</H3>
<PRE>
public void <B>saveNamespace</B>()
                   throws java.io.IOException</PRE>
<DL>
<DD><B>从接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html#saveNamespace()">ClientProtocol</A></CODE> 复制的描述</B></DD>
<DD>Save namespace image.
 <p>
 Saves current namespace into storage directories and reset edits log.
 Requires superuser privilege and safe mode.
<P>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的接口">ClientProtocol</A></CODE> 中的 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html#saveNamespace()">saveNamespace</A></CODE></DL>
</DD>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>org.apache.hadoop.security.AccessControlException</CODE> - if the superuser privilege is violated.
<DD><CODE>java.io.IOException</CODE> - if image creation failed.</DL>
</DD>
</DL>
<HR>

<A NAME="refreshNodes()"><!-- --></A><H3>
refreshNodes</H3>
<PRE>
public void <B>refreshNodes</B>()
                  throws java.io.IOException</PRE>
<DL>
<DD>Refresh the list of datanodes that the namenode should allow to  
 connect.  Re-reads conf by creating new HdfsConfiguration object and 
 uses the files list in the configuration to update the list.
<P>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的接口">ClientProtocol</A></CODE> 中的 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html#refreshNodes()">refreshNodes</A></CODE></DL>
</DD>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="getEditLogSize()"><!-- --></A><H3>
getEditLogSize</H3>
<PRE>
<FONT SIZE="-1">@Deprecated
</FONT>public long <B>getEditLogSize</B>()
                    throws java.io.IOException</PRE>
<DL>
<DD><B>已过时。</B>&nbsp;
<P>
<DD>Returns the size of the current edit log.
<P>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/NamenodeProtocol.html" title="org.apache.hadoop.hdfs.server.protocol 中的接口">NamenodeProtocol</A></CODE> 中的 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/NamenodeProtocol.html#getEditLogSize()">getEditLogSize</A></CODE></DL>
</DD>
<DD><DL>

<DT><B>返回：</B><DD>The number of bytes in the current edit log.
<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="rollEditLog()"><!-- --></A><H3>
rollEditLog</H3>
<PRE>
<FONT SIZE="-1">@Deprecated
</FONT>public <A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/CheckpointSignature.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">CheckpointSignature</A> <B>rollEditLog</B>()
                                throws java.io.IOException</PRE>
<DL>
<DD><B>已过时。</B>&nbsp;
<P>
<DD>Roll the edit log.
<P>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/NamenodeProtocol.html" title="org.apache.hadoop.hdfs.server.protocol 中的接口">NamenodeProtocol</A></CODE> 中的 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/NamenodeProtocol.html#rollEditLog()">rollEditLog</A></CODE></DL>
</DD>
<DD><DL>

<DT><B>返回：</B><DD>a unique token to identify this transaction.
<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="rollFsImage(org.apache.hadoop.hdfs.server.namenode.CheckpointSignature)"><!-- --></A><H3>
rollFsImage</H3>
<PRE>
<FONT SIZE="-1">@Deprecated
</FONT>public void <B>rollFsImage</B>(<A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/CheckpointSignature.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">CheckpointSignature</A>&nbsp;sig)
                 throws java.io.IOException</PRE>
<DL>
<DD><B>已过时。</B>&nbsp;
<P>
<DD>Roll the image
<P>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/NamenodeProtocol.html" title="org.apache.hadoop.hdfs.server.protocol 中的接口">NamenodeProtocol</A></CODE> 中的 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/NamenodeProtocol.html#rollFsImage(org.apache.hadoop.hdfs.server.namenode.CheckpointSignature)">rollFsImage</A></CODE></DL>
</DD>
<DD><DL>
<DT><B>参数：</B><DD><CODE>sig</CODE> - the signature of this checkpoint (old fsimage)
<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="finalizeUpgrade()"><!-- --></A><H3>
finalizeUpgrade</H3>
<PRE>
public void <B>finalizeUpgrade</B>()
                     throws java.io.IOException</PRE>
<DL>
<DD><B>从接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html#finalizeUpgrade()">ClientProtocol</A></CODE> 复制的描述</B></DD>
<DD>Finalize previous upgrade.
 Remove file system state saved during the upgrade.
 The upgrade will become irreversible.
<P>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的接口">ClientProtocol</A></CODE> 中的 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html#finalizeUpgrade()">finalizeUpgrade</A></CODE></DL>
</DD>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="distributedUpgradeProgress(org.apache.hadoop.hdfs.protocol.FSConstants.UpgradeAction)"><!-- --></A><H3>
distributedUpgradeProgress</H3>
<PRE>
public <A HREF="../../../../../../org/apache/hadoop/hdfs/server/common/UpgradeStatusReport.html" title="org.apache.hadoop.hdfs.server.common 中的类">UpgradeStatusReport</A> <B>distributedUpgradeProgress</B>(<A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/FSConstants.UpgradeAction.html" title="org.apache.hadoop.hdfs.protocol 中的枚举">FSConstants.UpgradeAction</A>&nbsp;action)
                                               throws java.io.IOException</PRE>
<DL>
<DD><B>从接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html#distributedUpgradeProgress(org.apache.hadoop.hdfs.protocol.FSConstants.UpgradeAction)">ClientProtocol</A></CODE> 复制的描述</B></DD>
<DD>Report distributed upgrade progress or force current upgrade to proceed.
<P>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的接口">ClientProtocol</A></CODE> 中的 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html#distributedUpgradeProgress(org.apache.hadoop.hdfs.protocol.FSConstants.UpgradeAction)">distributedUpgradeProgress</A></CODE></DL>
</DD>
<DD><DL>
<DT><B>参数：</B><DD><CODE>action</CODE> - <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/FSConstants.UpgradeAction.html" title="org.apache.hadoop.hdfs.protocol 中的枚举"><CODE>FSConstants.UpgradeAction</CODE></A> to perform
<DT><B>返回：</B><DD>upgrade status information or null if no upgrades are in progress
<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="metaSave(java.lang.String)"><!-- --></A><H3>
metaSave</H3>
<PRE>
public void <B>metaSave</B>(java.lang.String&nbsp;filename)
              throws java.io.IOException</PRE>
<DL>
<DD>Dumps namenode state into specified file
<P>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的接口">ClientProtocol</A></CODE> 中的 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html#metaSave(java.lang.String)">metaSave</A></CODE></DL>
</DD>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="listCorruptFileBlocks(java.lang.String, java.lang.String)"><!-- --></A><H3>
listCorruptFileBlocks</H3>
<PRE>
public java.util.Collection&lt;org.apache.hadoop.hdfs.server.namenode.FSNamesystem.CorruptFileBlockInfo&gt; <B>listCorruptFileBlocks</B>(java.lang.String&nbsp;path,
                                                                                                                            java.lang.String&nbsp;startBlockAfter)
                                                                                                                     throws org.apache.hadoop.security.AccessControlException,
                                                                                                                            java.io.IOException</PRE>
<DL>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>参数：</B><DD><CODE>path</CODE> - Sub-tree used in querying corrupt files<DD><CODE>startBlockAfter</CODE> - Paging support---pass in the last block returned from the previous
          call and some # of corrupt blocks after that point are returned
<DT><B>返回：</B><DD>a list in which each entry describes a corrupt file/block
<DT><B>抛出：</B>
<DD><CODE>org.apache.hadoop.security.AccessControlException</CODE>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="getContentSummary(java.lang.String)"><!-- --></A><H3>
getContentSummary</H3>
<PRE>
public org.apache.hadoop.fs.ContentSummary <B>getContentSummary</B>(java.lang.String&nbsp;path)
                                                      throws java.io.IOException</PRE>
<DL>
<DD>Get <CODE>ContentSummary</CODE> rooted at the specified directory.
<P>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的接口">ClientProtocol</A></CODE> 中的 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html#getContentSummary(java.lang.String)">getContentSummary</A></CODE></DL>
</DD>
<DD><DL>
<DT><B>参数：</B><DD><CODE>path</CODE> - The string representation of the path
<DT><B>抛出：</B>
<DD><CODE>org.apache.hadoop.security.AccessControlException</CODE> - permission denied
<DD><CODE>java.io.FileNotFoundException</CODE> - file <code>path</code> is not found
<DD><CODE>org.apache.hadoop.fs.UnresolvedLinkException</CODE> - if <code>path</code> contains a symlink.
<DD><CODE>java.io.IOException</CODE> - If an I/O error occurred</DL>
</DD>
</DL>
<HR>

<A NAME="setQuota(java.lang.String, long, long)"><!-- --></A><H3>
setQuota</H3>
<PRE>
public void <B>setQuota</B>(java.lang.String&nbsp;path,
                     long&nbsp;namespaceQuota,
                     long&nbsp;diskspaceQuota)
              throws java.io.IOException</PRE>
<DL>
<DD>Set the quota for a directory.
<P>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的接口">ClientProtocol</A></CODE> 中的 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html#setQuota(java.lang.String, long, long)">setQuota</A></CODE></DL>
</DD>
<DD><DL>
<DT><B>参数：</B><DD><CODE>path</CODE> - The string representation of the path to the directory<DD><CODE>namespaceQuota</CODE> - Limit on the number of names in the tree rooted 
                       at the directory<DD><CODE>diskspaceQuota</CODE> - Limit on disk space occupied all the files under
                       this directory. 
 <br><br>
                       
 The quota can have three types of values : (1) 0 or more will set 
 the quota to that value, (2) <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/FSConstants.html#QUOTA_DONT_SET"><CODE>FSConstants.QUOTA_DONT_SET</CODE></A>  implies 
 the quota will not be changed, and (3) <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/FSConstants.html#QUOTA_RESET"><CODE>FSConstants.QUOTA_RESET</CODE></A> 
 implies the quota will be reset. Any other value is a runtime error.
<DT><B>抛出：</B>
<DD><CODE>org.apache.hadoop.security.AccessControlException</CODE> - permission denied
<DD><CODE>java.io.FileNotFoundException</CODE> - file <code>path</code> is not found
<DD><CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/QuotaExceededException.html" title="org.apache.hadoop.hdfs.protocol 中的类">QuotaExceededException</A></CODE> - if the directory size 
           is greater than the given quota
<DD><CODE>org.apache.hadoop.fs.UnresolvedLinkException</CODE> - if the <code>path</code> contains a symlink.
<DD><CODE>java.io.IOException</CODE> - If an I/O error occurred</DL>
</DD>
</DL>
<HR>

<A NAME="fsync(java.lang.String, java.lang.String)"><!-- --></A><H3>
fsync</H3>
<PRE>
public void <B>fsync</B>(java.lang.String&nbsp;src,
                  java.lang.String&nbsp;clientName)
           throws java.io.IOException</PRE>
<DL>
<DD>Write all metadata for this file into persistent storage.
 The file must be currently open for writing.
<P>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的接口">ClientProtocol</A></CODE> 中的 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html#fsync(java.lang.String, java.lang.String)">fsync</A></CODE></DL>
</DD>
<DD><DL>
<DT><B>参数：</B><DD><CODE>src</CODE> - The string representation of the path<DD><CODE>clientName</CODE> - The string representation of the client
<DT><B>抛出：</B>
<DD><CODE>org.apache.hadoop.security.AccessControlException</CODE> - permission denied
<DD><CODE>java.io.FileNotFoundException</CODE> - file <code>src</code> is not found
<DD><CODE>org.apache.hadoop.fs.UnresolvedLinkException</CODE> - if <code>src</code> contains a symlink.
<DD><CODE>java.io.IOException</CODE> - If an I/O error occurred</DL>
</DD>
</DL>
<HR>

<A NAME="setTimes(java.lang.String, long, long)"><!-- --></A><H3>
setTimes</H3>
<PRE>
public void <B>setTimes</B>(java.lang.String&nbsp;src,
                     long&nbsp;mtime,
                     long&nbsp;atime)
              throws java.io.IOException</PRE>
<DL>
<DD><B>从接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html#setTimes(java.lang.String, long, long)">ClientProtocol</A></CODE> 复制的描述</B></DD>
<DD>Sets the modification and access time of the file to the specified time.
<P>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的接口">ClientProtocol</A></CODE> 中的 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html#setTimes(java.lang.String, long, long)">setTimes</A></CODE></DL>
</DD>
<DD><DL>
<DT><B>参数：</B><DD><CODE>src</CODE> - The string representation of the path<DD><CODE>mtime</CODE> - The number of milliseconds since Jan 1, 1970.
              Setting mtime to -1 means that modification time should not be set
              by this call.<DD><CODE>atime</CODE> - The number of milliseconds since Jan 1, 1970.
              Setting atime to -1 means that access time should not be set
              by this call.
<DT><B>抛出：</B>
<DD><CODE>org.apache.hadoop.security.AccessControlException</CODE> - permission denied
<DD><CODE>java.io.FileNotFoundException</CODE> - file <code>src</code> is not found
<DD><CODE>org.apache.hadoop.fs.UnresolvedLinkException</CODE> - if <code>src</code> contains a symlink.
<DD><CODE>java.io.IOException</CODE> - If an I/O error occurred</DL>
</DD>
</DL>
<HR>

<A NAME="createSymlink(java.lang.String, java.lang.String, org.apache.hadoop.fs.permission.FsPermission, boolean)"><!-- --></A><H3>
createSymlink</H3>
<PRE>
public void <B>createSymlink</B>(java.lang.String&nbsp;target,
                          java.lang.String&nbsp;link,
                          org.apache.hadoop.fs.permission.FsPermission&nbsp;dirPerms,
                          boolean&nbsp;createParent)
                   throws java.io.IOException</PRE>
<DL>
<DD><B>从接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html#createSymlink(java.lang.String, java.lang.String, org.apache.hadoop.fs.permission.FsPermission, boolean)">ClientProtocol</A></CODE> 复制的描述</B></DD>
<DD>Create symlink to a file or directory.
<P>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的接口">ClientProtocol</A></CODE> 中的 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html#createSymlink(java.lang.String, java.lang.String, org.apache.hadoop.fs.permission.FsPermission, boolean)">createSymlink</A></CODE></DL>
</DD>
<DD><DL>
<DT><B>参数：</B><DD><CODE>target</CODE> - The path of the destination that the
               link points to.<DD><CODE>link</CODE> - The path of the link being created.<DD><CODE>dirPerms</CODE> - permissions to use when creating parent directories<DD><CODE>createParent</CODE> - - if true then missing parent dirs are created
                       if false then parent must exist
<DT><B>抛出：</B>
<DD><CODE>org.apache.hadoop.security.AccessControlException</CODE> - permission denied
<DD><CODE>org.apache.hadoop.fs.FileAlreadyExistsException</CODE> - If file <code>link</code> already exists
<DD><CODE>java.io.FileNotFoundException</CODE> - If parent of <code>link</code> does not exist
           and <code>createParent</code> is false
<DD><CODE>org.apache.hadoop.fs.ParentNotDirectoryException</CODE> - If parent of <code>link</code> is not a
           directory.
<DD><CODE>org.apache.hadoop.fs.UnresolvedLinkException</CODE> - if <code>link</target> contains a symlink.
<DD><CODE>java.io.IOException</CODE> - If an I/O error occurred</DL>
</DD>
</DL>
<HR>

<A NAME="getLinkTarget(java.lang.String)"><!-- --></A><H3>
getLinkTarget</H3>
<PRE>
public java.lang.String <B>getLinkTarget</B>(java.lang.String&nbsp;path)
                               throws java.io.IOException</PRE>
<DL>
<DD><B>从接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html#getLinkTarget(java.lang.String)">ClientProtocol</A></CODE> 复制的描述</B></DD>
<DD>Return the target of the given symlink. If there is an intermediate
 symlink in the path (ie a symlink leading up to the final path component)
 then the given path is returned with this symlink resolved.
<P>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的接口">ClientProtocol</A></CODE> 中的 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html#getLinkTarget(java.lang.String)">getLinkTarget</A></CODE></DL>
</DD>
<DD><DL>
<DT><B>参数：</B><DD><CODE>path</CODE> - The path with a link that needs resolution.
<DT><B>返回：</B><DD>The path after resolving the first symbolic link in the path.
<DT><B>抛出：</B>
<DD><CODE>org.apache.hadoop.security.AccessControlException</CODE> - permission denied
<DD><CODE>java.io.FileNotFoundException</CODE> - If <code>path</code> does not exist
<DD><CODE>java.io.IOException</CODE> - If the given path does not refer to a symlink
           or an I/O error occurred</DL>
</DD>
</DL>
<HR>

<A NAME="registerDatanode(org.apache.hadoop.hdfs.server.protocol.DatanodeRegistration)"><!-- --></A><H3>
registerDatanode</H3>
<PRE>
public <A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/DatanodeRegistration.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">DatanodeRegistration</A> <B>registerDatanode</B>(<A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/DatanodeRegistration.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">DatanodeRegistration</A>&nbsp;nodeReg)
                                      throws java.io.IOException</PRE>
<DL>
<DD><B>从接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/DatanodeProtocol.html#registerDatanode(org.apache.hadoop.hdfs.server.protocol.DatanodeRegistration)">DatanodeProtocol</A></CODE> 复制的描述</B></DD>
<DD>Register Datanode.
<P>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/DatanodeProtocol.html" title="org.apache.hadoop.hdfs.server.protocol 中的接口">DatanodeProtocol</A></CODE> 中的 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/DatanodeProtocol.html#registerDatanode(org.apache.hadoop.hdfs.server.protocol.DatanodeRegistration)">registerDatanode</A></CODE></DL>
</DD>
<DD><DL>

<DT><B>返回：</B><DD>updated <A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/DatanodeRegistration.html" title="org.apache.hadoop.hdfs.server.protocol 中的类"><CODE>DatanodeRegistration</CODE></A>, which contains 
 new storageID if the datanode did not have one and
 registration ID for further communication.
<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE><DT><B>另请参见：</B><DD><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/DataNode.html#dnRegistration"><CODE>DataNode.dnRegistration</CODE></A>, 
<A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#registerDatanode(org.apache.hadoop.hdfs.server.protocol.DatanodeRegistration)"><CODE>FSNamesystem.registerDatanode(DatanodeRegistration)</CODE></A></DL>
</DD>
</DL>
<HR>

<A NAME="sendHeartbeat(org.apache.hadoop.hdfs.server.protocol.DatanodeRegistration, long, long, long, org.apache.hadoop.hdfs.server.monitor.ServernodeCPUStatus, org.apache.hadoop.hdfs.server.monitor.ServernodeMEMStatus, org.apache.hadoop.hdfs.server.monitor.ServernodeNETStatus[], org.apache.hadoop.hdfs.server.monitor.ServernodeIOStatus[], int, int, int)"><!-- --></A><H3>
sendHeartbeat</H3>
<PRE>
public <A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/DatanodeCommand.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">DatanodeCommand</A>[] <B>sendHeartbeat</B>(<A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/DatanodeRegistration.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">DatanodeRegistration</A>&nbsp;nodeReg,
                                       long&nbsp;capacity,
                                       long&nbsp;dfsUsed,
                                       long&nbsp;remaining,
                                       <A HREF="../../../../../../org/apache/hadoop/hdfs/server/monitor/ServernodeCPUStatus.html" title="org.apache.hadoop.hdfs.server.monitor 中的类">ServernodeCPUStatus</A>&nbsp;cpuStatus,
                                       <A HREF="../../../../../../org/apache/hadoop/hdfs/server/monitor/ServernodeMEMStatus.html" title="org.apache.hadoop.hdfs.server.monitor 中的类">ServernodeMEMStatus</A>&nbsp;memStatus,
                                       <A HREF="../../../../../../org/apache/hadoop/hdfs/server/monitor/ServernodeNETStatus.html" title="org.apache.hadoop.hdfs.server.monitor 中的类">ServernodeNETStatus</A>[]&nbsp;netStatus,
                                       <A HREF="../../../../../../org/apache/hadoop/hdfs/server/monitor/ServernodeIOStatus.html" title="org.apache.hadoop.hdfs.server.monitor 中的类">ServernodeIOStatus</A>[]&nbsp;ioStatus,
                                       int&nbsp;xmitsInProgress,
                                       int&nbsp;xceiverCount,
                                       int&nbsp;failedVolumes)
                                throws java.io.IOException</PRE>
<DL>
<DD>Data node notify the name node that it is alive 
 Return an array of block-oriented commands for the datanode to execute.
 This will be either a transfer or a delete operation.
<P>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/DatanodeProtocol.html" title="org.apache.hadoop.hdfs.server.protocol 中的接口">DatanodeProtocol</A></CODE> 中的 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/DatanodeProtocol.html#sendHeartbeat(org.apache.hadoop.hdfs.server.protocol.DatanodeRegistration, long, long, long, org.apache.hadoop.hdfs.server.monitor.ServernodeCPUStatus, org.apache.hadoop.hdfs.server.monitor.ServernodeMEMStatus, org.apache.hadoop.hdfs.server.monitor.ServernodeNETStatus[], org.apache.hadoop.hdfs.server.monitor.ServernodeIOStatus[], int, int, int)">sendHeartbeat</A></CODE></DL>
</DD>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="blockReport(org.apache.hadoop.hdfs.server.protocol.DatanodeRegistration, long[])"><!-- --></A><H3>
blockReport</H3>
<PRE>
public <A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/DatanodeCommand.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">DatanodeCommand</A> <B>blockReport</B>(<A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/DatanodeRegistration.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">DatanodeRegistration</A>&nbsp;nodeReg,
                                   long[]&nbsp;blocks)
                            throws java.io.IOException</PRE>
<DL>
<DD><B>从接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/DatanodeProtocol.html#blockReport(org.apache.hadoop.hdfs.server.protocol.DatanodeRegistration, long[])">DatanodeProtocol</A></CODE> 复制的描述</B></DD>
<DD>blockReport() tells the NameNode about all the locally-stored blocks.
 The NameNode returns an array of Blocks that have become obsolete
 and should be deleted.  This function is meant to upload *all*
 the locally-stored blocks.  It's invoked upon startup and then
 infrequently afterwards.
<P>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/DatanodeProtocol.html" title="org.apache.hadoop.hdfs.server.protocol 中的接口">DatanodeProtocol</A></CODE> 中的 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/DatanodeProtocol.html#blockReport(org.apache.hadoop.hdfs.server.protocol.DatanodeRegistration, long[])">blockReport</A></CODE></DL>
</DD>
<DD><DL>
<DD><CODE>blocks</CODE> - - the block list as an array of longs.
     Each block is represented as 2 longs.
     This is done instead of Block[] to reduce memory used by block reports.
<DT><B>返回：</B><DD>- the next command for DN to process.
<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="blockReceived(org.apache.hadoop.hdfs.server.protocol.DatanodeRegistration, org.apache.hadoop.hdfs.protocol.Block[], java.lang.String[])"><!-- --></A><H3>
blockReceived</H3>
<PRE>
public void <B>blockReceived</B>(<A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/DatanodeRegistration.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">DatanodeRegistration</A>&nbsp;nodeReg,
                          <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/Block.html" title="org.apache.hadoop.hdfs.protocol 中的类">Block</A>[]&nbsp;blocks,
                          java.lang.String[]&nbsp;delHints)
                   throws java.io.IOException</PRE>
<DL>
<DD><B>从接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/DatanodeProtocol.html#blockReceived(org.apache.hadoop.hdfs.server.protocol.DatanodeRegistration, org.apache.hadoop.hdfs.protocol.Block[], java.lang.String[])">DatanodeProtocol</A></CODE> 复制的描述</B></DD>
<DD>blockReceived() allows the DataNode to tell the NameNode about
 recently-received block data, with a hint for pereferred replica
 to be deleted when there is any excessive blocks.
 For example, whenever client code
 writes a new Block here, or another DataNode copies a Block to
 this DataNode, it will call blockReceived().
<P>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/DatanodeProtocol.html" title="org.apache.hadoop.hdfs.server.protocol 中的接口">DatanodeProtocol</A></CODE> 中的 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/DatanodeProtocol.html#blockReceived(org.apache.hadoop.hdfs.server.protocol.DatanodeRegistration, org.apache.hadoop.hdfs.protocol.Block[], java.lang.String[])">blockReceived</A></CODE></DL>
</DD>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="errorReport(org.apache.hadoop.hdfs.server.protocol.DatanodeRegistration, int, java.lang.String)"><!-- --></A><H3>
errorReport</H3>
<PRE>
public void <B>errorReport</B>(<A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/DatanodeRegistration.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">DatanodeRegistration</A>&nbsp;nodeReg,
                        int&nbsp;errorCode,
                        java.lang.String&nbsp;msg)
                 throws java.io.IOException</PRE>
<DL>
<DD>Handle an error report from a datanode.
<P>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/DatanodeProtocol.html" title="org.apache.hadoop.hdfs.server.protocol 中的接口">DatanodeProtocol</A></CODE> 中的 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/DatanodeProtocol.html#errorReport(org.apache.hadoop.hdfs.server.protocol.DatanodeRegistration, int, java.lang.String)">errorReport</A></CODE></DL>
</DD>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="versionRequest()"><!-- --></A><H3>
versionRequest</H3>
<PRE>
public <A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/NamespaceInfo.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">NamespaceInfo</A> <B>versionRequest</B>()
                             throws java.io.IOException</PRE>
<DL>
<DD><B>从接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/NamenodeProtocol.html#versionRequest()">NamenodeProtocol</A></CODE> 复制的描述</B></DD>
<DD>Request name-node version and storage information.
<P>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/DatanodeProtocol.html" title="org.apache.hadoop.hdfs.server.protocol 中的接口">DatanodeProtocol</A></CODE> 中的 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/DatanodeProtocol.html#versionRequest()">versionRequest</A></CODE><DT><B>指定者：</B><DD>接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/NamenodeProtocol.html" title="org.apache.hadoop.hdfs.server.protocol 中的接口">NamenodeProtocol</A></CODE> 中的 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/NamenodeProtocol.html#versionRequest()">versionRequest</A></CODE></DL>
</DD>
<DD><DL>

<DT><B>返回：</B><DD><A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/NamespaceInfo.html" title="org.apache.hadoop.hdfs.server.protocol 中的类"><CODE>NamespaceInfo</CODE></A> identifying versions and storage information 
          of the name-node
<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="processUpgradeCommand(org.apache.hadoop.hdfs.server.protocol.UpgradeCommand)"><!-- --></A><H3>
processUpgradeCommand</H3>
<PRE>
public <A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/UpgradeCommand.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">UpgradeCommand</A> <B>processUpgradeCommand</B>(<A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/UpgradeCommand.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">UpgradeCommand</A>&nbsp;comm)
                                     throws java.io.IOException</PRE>
<DL>
<DD><B>从接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/DatanodeProtocol.html#processUpgradeCommand(org.apache.hadoop.hdfs.server.protocol.UpgradeCommand)">DatanodeProtocol</A></CODE> 复制的描述</B></DD>
<DD>This is a very general way to send a command to the name-node during
 distributed upgrade process.
 
 The generosity is because the variety of upgrade commands is unpredictable.
 The reply from the name-node is also received in the form of an upgrade 
 command.
<P>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/DatanodeProtocol.html" title="org.apache.hadoop.hdfs.server.protocol 中的接口">DatanodeProtocol</A></CODE> 中的 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/DatanodeProtocol.html#processUpgradeCommand(org.apache.hadoop.hdfs.server.protocol.UpgradeCommand)">processUpgradeCommand</A></CODE></DL>
</DD>
<DD><DL>

<DT><B>返回：</B><DD>a reply in the form of an upgrade command
<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="verifyRequest(org.apache.hadoop.hdfs.server.protocol.NodeRegistration)"><!-- --></A><H3>
verifyRequest</H3>
<PRE>
public void <B>verifyRequest</B>(<A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/NodeRegistration.html" title="org.apache.hadoop.hdfs.server.protocol 中的接口">NodeRegistration</A>&nbsp;nodeReg)
                   throws java.io.IOException</PRE>
<DL>
<DD>Verify request.
 
 Verifies correctness of the datanode version, registration ID, and 
 if the datanode does not need to be shutdown.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>参数：</B><DD><CODE>nodeReg</CODE> - data node registration
<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="verifyVersion(int)"><!-- --></A><H3>
verifyVersion</H3>
<PRE>
public void <B>verifyVersion</B>(int&nbsp;version)
                   throws java.io.IOException</PRE>
<DL>
<DD>Verify version.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>参数：</B><DD><CODE>version</CODE> - 
<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="getFsImageName()"><!-- --></A><H3>
getFsImageName</H3>
<PRE>
public java.io.File <B>getFsImageName</B>()
                            throws java.io.IOException</PRE>
<DL>
<DD>Returns the name of the fsImage file
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="getFSImage()"><!-- --></A><H3>
getFSImage</H3>
<PRE>
public <A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/FSImage.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FSImage</A> <B>getFSImage</B>()</PRE>
<DL>
<DD><DL>
</DL>
</DD>
<DD><DL>
</DL>
</DD>
</DL>
<HR>

<A NAME="getFsImageNameCheckpoint()"><!-- --></A><H3>
getFsImageNameCheckpoint</H3>
<PRE>
public java.io.File[] <B>getFsImageNameCheckpoint</B>()
                                        throws java.io.IOException</PRE>
<DL>
<DD>Returns the name of the fsImage file uploaded by periodic
 checkpointing
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="getNameNodeAddress()"><!-- --></A><H3>
getNameNodeAddress</H3>
<PRE>
public java.net.InetSocketAddress <B>getNameNodeAddress</B>()</PRE>
<DL>
<DD>Returns the address on which the NameNodes is listening to.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>

<DT><B>返回：</B><DD>the address on which the NameNodes is listening to.</DL>
</DD>
</DL>
<HR>

<A NAME="getHttpAddress()"><!-- --></A><H3>
getHttpAddress</H3>
<PRE>
public java.net.InetSocketAddress <B>getHttpAddress</B>()</PRE>
<DL>
<DD>Returns the address of the NameNodes http server, 
 which is used to access the name-node web UI.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>

<DT><B>返回：</B><DD>the http address.</DL>
</DD>
</DL>
<HR>

<A NAME="refreshServiceAcl()"><!-- --></A><H3>
refreshServiceAcl</H3>
<PRE>
public void <B>refreshServiceAcl</B>()
                       throws java.io.IOException</PRE>
<DL>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE>org.apache.hadoop.security.authorize.RefreshAuthorizationPolicyProtocol</CODE> 中的 <CODE>refreshServiceAcl</CODE></DL>
</DD>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="refreshUserToGroupsMappings()"><!-- --></A><H3>
refreshUserToGroupsMappings</H3>
<PRE>
public void <B>refreshUserToGroupsMappings</B>()
                                 throws java.io.IOException</PRE>
<DL>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE>org.apache.hadoop.security.RefreshUserMappingsProtocol</CODE> 中的 <CODE>refreshUserToGroupsMappings</CODE></DL>
</DD>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="refreshSuperUserGroupsConfiguration()"><!-- --></A><H3>
refreshSuperUserGroupsConfiguration</H3>
<PRE>
public void <B>refreshSuperUserGroupsConfiguration</B>()</PRE>
<DL>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE>org.apache.hadoop.security.RefreshUserMappingsProtocol</CODE> 中的 <CODE>refreshSuperUserGroupsConfiguration</CODE></DL>
</DD>
<DD><DL>
</DL>
</DD>
</DL>
<HR>

<A NAME="createNameNode(java.lang.String[], org.apache.hadoop.conf.Configuration)"><!-- --></A><H3>
createNameNode</H3>
<PRE>
public static <A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">NameNode</A> <B>createNameNode</B>(java.lang.String[]&nbsp;argv,
                                      org.apache.hadoop.conf.Configuration&nbsp;conf)
                               throws java.io.IOException</PRE>
<DL>
<DD><DL>
</DL>
</DD>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="main(java.lang.String[])"><!-- --></A><H3>
main</H3>
<PRE>
public static void <B>main</B>(java.lang.String[]&nbsp;argv)
                 throws java.lang.Exception</PRE>
<DL>
<DD><DL>
</DL>
</DD>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>java.lang.Exception</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="getAllBlocksLocations(java.lang.String)"><!-- --></A><H3>
getAllBlocksLocations</H3>
<PRE>
public <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/LocatedBlocks.html" title="org.apache.hadoop.hdfs.protocol 中的类">LocatedBlocks</A> <B>getAllBlocksLocations</B>(java.lang.String&nbsp;src)
                                    throws java.io.IOException</PRE>
<DL>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的接口">ClientProtocol</A></CODE> 中的 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html#getAllBlocksLocations(java.lang.String)">getAllBlocksLocations</A></CODE></DL>
</DD>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="getCodingMatrix(java.lang.String)"><!-- --></A><H3>
getCodingMatrix</H3>
<PRE>
public <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/CodingMatrix.html" title="org.apache.hadoop.hdfs.protocol 中的类">CodingMatrix</A> <B>getCodingMatrix</B>(java.lang.String&nbsp;src)
                             throws org.apache.hadoop.fs.UnresolvedLinkException</PRE>
<DL>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的接口">ClientProtocol</A></CODE> 中的 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html#getCodingMatrix(java.lang.String)">getCodingMatrix</A></CODE></DL>
</DD>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>org.apache.hadoop.fs.UnresolvedLinkException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="getFileLength(java.lang.String)"><!-- --></A><H3>
getFileLength</H3>
<PRE>
public long <B>getFileLength</B>(java.lang.String&nbsp;src)
                   throws org.apache.hadoop.fs.UnresolvedLinkException</PRE>
<DL>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的接口">ClientProtocol</A></CODE> 中的 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html#getFileLength(java.lang.String)">getFileLength</A></CODE></DL>
</DD>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>org.apache.hadoop.fs.UnresolvedLinkException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="getServernodeStator()"><!-- --></A><H3>
getServernodeStator</H3>
<PRE>
public <A HREF="../../../../../../org/apache/hadoop/hdfs/server/monitor/ServernodeStator.html" title="org.apache.hadoop.hdfs.server.monitor 中的类">ServernodeStator</A> <B>getServernodeStator</B>()</PRE>
<DL>
<DD><DL>
</DL>
</DD>
<DD><DL>
</DL>
</DD>
</DL>
<!-- ========= END OF CLASS DATA ========= -->
<HR>


<!-- ======= START OF BOTTOM NAVBAR ====== -->
<A NAME="navbar_bottom"><!-- --></A>
<A HREF="#skip-navbar_bottom" title="跳过导航链接"></A>
<TABLE BORDER="0" WIDTH="100%" CELLPADDING="1" CELLSPACING="0" SUMMARY="">
<TR>
<TD COLSPAN=2 BGCOLOR="#EEEEFF" CLASS="NavBarCell1">
<A NAME="navbar_bottom_firstrow"><!-- --></A>
<TABLE BORDER="0" CELLPADDING="0" CELLSPACING="3" SUMMARY="">
  <TR ALIGN="center" VALIGN="top">
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="../../../../../../overview-summary.html"><FONT CLASS="NavBarFont1"><B>概述</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="package-summary.html"><FONT CLASS="NavBarFont1"><B>软件包</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#FFFFFF" CLASS="NavBarCell1Rev"> &nbsp;<FONT CLASS="NavBarFont1Rev"><B>类</B></FONT>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="class-use/NameNode.html"><FONT CLASS="NavBarFont1"><B>使用</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="package-tree.html"><FONT CLASS="NavBarFont1"><B>树</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="../../../../../../deprecated-list.html"><FONT CLASS="NavBarFont1"><B>已过时</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="../../../../../../index-all.html"><FONT CLASS="NavBarFont1"><B>索引</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="../../../../../../help-doc.html"><FONT CLASS="NavBarFont1"><B>帮助</B></FONT></A>&nbsp;</TD>
  </TR>
</TABLE>
</TD>
<TD ALIGN="right" VALIGN="top" ROWSPAN=3><EM>
</EM>
</TD>
</TR>

<TR>
<TD BGCOLOR="white" CLASS="NavBarCell2"><FONT SIZE="-2">
&nbsp;<A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/MonitorServlet.html" title="org.apache.hadoop.hdfs.server.namenode 中的类"><B>上一个类</B></A>&nbsp;
&nbsp;<A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NamenodeFsck.html" title="org.apache.hadoop.hdfs.server.namenode 中的类"><B>下一个类</B></A></FONT></TD>
<TD BGCOLOR="white" CLASS="NavBarCell2"><FONT SIZE="-2">
  <A HREF="../../../../../../index.html?org/apache/hadoop/hdfs/server/namenode/NameNode.html" target="_top"><B>框架</B></A>  &nbsp;
&nbsp;<A HREF="NameNode.html" target="_top"><B>无框架</B></A>  &nbsp;
&nbsp;<SCRIPT type="text/javascript">
  <!--
  if(window==top) {
    document.writeln('<A HREF="../../../../../../allclasses-noframe.html"><B>所有类</B></A>');
  }
  //-->
</SCRIPT>
<NOSCRIPT>
  <A HREF="../../../../../../allclasses-noframe.html"><B>所有类</B></A>
</NOSCRIPT>


</FONT></TD>
</TR>
<TR>
<TD VALIGN="top" CLASS="NavBarCell3"><FONT SIZE="-2">
  摘要：&nbsp;嵌套&nbsp;|&nbsp;<A HREF="#field_summary">字段</A>&nbsp;|&nbsp;<A HREF="#constructor_summary">构造方法</A>&nbsp;|&nbsp;<A HREF="#method_summary">方法</A></FONT></TD>
<TD VALIGN="top" CLASS="NavBarCell3"><FONT SIZE="-2">
详细信息：&nbsp;<A HREF="#field_detail">字段</A>&nbsp;|&nbsp;<A HREF="#constructor_detail">构造方法</A>&nbsp;|&nbsp;<A HREF="#method_detail">方法</A></FONT></TD>
</TR>
</TABLE>
<A NAME="skip-navbar_bottom"></A>
<!-- ======== END OF BOTTOM NAVBAR ======= -->

<HR>
Copyright &copy; 2009 The Apache Software Foundation
</BODY>
</HTML>
