<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<!--NewPage-->
<HTML>
<HEAD>
<!-- Generated by javadoc (build 1.6.0_18) on Sun May 03 20:19:35 CST 2015 -->
<TITLE>
FSNamesystem (Hadoop-Hdfs 0.22.1-SNAPSHOT API)
</TITLE>

<META NAME="date" CONTENT="2015-05-03">

<LINK REL ="stylesheet" TYPE="text/css" HREF="../../../../../../stylesheet.css" TITLE="Style">

<SCRIPT type="text/javascript">
function windowTitle()
{
    if (location.href.indexOf('is-external=true') == -1) {
        parent.document.title="FSNamesystem (Hadoop-Hdfs 0.22.1-SNAPSHOT API)";
    }
}
</SCRIPT>
<NOSCRIPT>
</NOSCRIPT>

</HEAD>

<BODY BGCOLOR="white" onload="windowTitle();">
<HR>


<!-- ========= START OF TOP NAVBAR ======= -->
<A NAME="navbar_top"><!-- --></A>
<A HREF="#skip-navbar_top" title="跳过导航链接"></A>
<TABLE BORDER="0" WIDTH="100%" CELLPADDING="1" CELLSPACING="0" SUMMARY="">
<TR>
<TD COLSPAN=2 BGCOLOR="#EEEEFF" CLASS="NavBarCell1">
<A NAME="navbar_top_firstrow"><!-- --></A>
<TABLE BORDER="0" CELLPADDING="0" CELLSPACING="3" SUMMARY="">
  <TR ALIGN="center" VALIGN="top">
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="../../../../../../overview-summary.html"><FONT CLASS="NavBarFont1"><B>概述</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="package-summary.html"><FONT CLASS="NavBarFont1"><B>软件包</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#FFFFFF" CLASS="NavBarCell1Rev"> &nbsp;<FONT CLASS="NavBarFont1Rev"><B>类</B></FONT>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="class-use/FSNamesystem.html"><FONT CLASS="NavBarFont1"><B>使用</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="package-tree.html"><FONT CLASS="NavBarFont1"><B>树</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="../../../../../../deprecated-list.html"><FONT CLASS="NavBarFont1"><B>已过时</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="../../../../../../index-all.html"><FONT CLASS="NavBarFont1"><B>索引</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="../../../../../../help-doc.html"><FONT CLASS="NavBarFont1"><B>帮助</B></FONT></A>&nbsp;</TD>
  </TR>
</TABLE>
</TD>
<TD ALIGN="right" VALIGN="top" ROWSPAN=3><EM>
</EM>
</TD>
</TR>

<TR>
<TD BGCOLOR="white" CLASS="NavBarCell2"><FONT SIZE="-2">
&nbsp;<A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/FSInodeInfo.html" title="org.apache.hadoop.hdfs.server.namenode 中的接口"><B>上一个类</B></A>&nbsp;
&nbsp;<A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/GetDelegationTokenServlet.html" title="org.apache.hadoop.hdfs.server.namenode 中的类"><B>下一个类</B></A></FONT></TD>
<TD BGCOLOR="white" CLASS="NavBarCell2"><FONT SIZE="-2">
  <A HREF="../../../../../../index.html?org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html" target="_top"><B>框架</B></A>  &nbsp;
&nbsp;<A HREF="FSNamesystem.html" target="_top"><B>无框架</B></A>  &nbsp;
&nbsp;<SCRIPT type="text/javascript">
  <!--
  if(window==top) {
    document.writeln('<A HREF="../../../../../../allclasses-noframe.html"><B>所有类</B></A>');
  }
  //-->
</SCRIPT>
<NOSCRIPT>
  <A HREF="../../../../../../allclasses-noframe.html"><B>所有类</B></A>
</NOSCRIPT>


</FONT></TD>
</TR>
<TR>
<TD VALIGN="top" CLASS="NavBarCell3"><FONT SIZE="-2">
  摘要：&nbsp;嵌套&nbsp;|&nbsp;<A HREF="#field_summary">字段</A>&nbsp;|&nbsp;构造方法&nbsp;|&nbsp;<A HREF="#method_summary">方法</A></FONT></TD>
<TD VALIGN="top" CLASS="NavBarCell3"><FONT SIZE="-2">
详细信息：&nbsp;<A HREF="#field_detail">字段</A>&nbsp;|&nbsp;构造方法&nbsp;|&nbsp;<A HREF="#method_detail">方法</A></FONT></TD>
</TR>
</TABLE>
<A NAME="skip-navbar_top"></A>
<!-- ========= END OF TOP NAVBAR ========= -->

<HR>
<!-- ======== START OF CLASS DATA ======== -->
<H2>
<FONT SIZE="-1">
org.apache.hadoop.hdfs.server.namenode</FONT>
<BR>
类 FSNamesystem</H2>
<PRE>
java.lang.Object
  <IMG SRC="../../../../../../resources/inherit.gif" ALT="继承者 "><B>org.apache.hadoop.hdfs.server.namenode.FSNamesystem</B>
</PRE>
<DL>
<DT><B>所有已实现的接口：</B> <DD><A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/FSConstants.html" title="org.apache.hadoop.hdfs.protocol 中的接口">FSConstants</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/FSClusterStats.html" title="org.apache.hadoop.hdfs.server.namenode 中的接口">FSClusterStats</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/metrics/FSNamesystemMBean.html" title="org.apache.hadoop.hdfs.server.namenode.metrics 中的接口">FSNamesystemMBean</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNodeMXBean.html" title="org.apache.hadoop.hdfs.server.namenode 中的接口">NameNodeMXBean</A></DD>
</DL>
<HR>
<DL>
<DT><PRE><FONT SIZE="-1">@InterfaceAudience.Private
</FONT>public class <B>FSNamesystem</B><DT>extends java.lang.Object<DT>implements <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/FSConstants.html" title="org.apache.hadoop.hdfs.protocol 中的接口">FSConstants</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/metrics/FSNamesystemMBean.html" title="org.apache.hadoop.hdfs.server.namenode.metrics 中的接口">FSNamesystemMBean</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/FSClusterStats.html" title="org.apache.hadoop.hdfs.server.namenode 中的接口">FSClusterStats</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNodeMXBean.html" title="org.apache.hadoop.hdfs.server.namenode 中的接口">NameNodeMXBean</A></DL>
</PRE>

<P>
FSNamesystem does the actual bookkeeping work for the
 DataNode.

 It tracks several important tables.

 1)  valid fsname --> blocklist  (kept on disk, logged)
 2)  Set of all valid blocks (inverted #1)
 3)  block --> machinelist (kept in memory, rebuilt dynamically from reports)
 4)  machine --> blocklist (inverted #2)
 5)  LRU cache of updated-heartbeat machines
<P>

<P>
<HR>

<P>
<!-- ======== NESTED CLASS SUMMARY ======== -->

<A NAME="nested_class_summary"><!-- --></A>
<TABLE BORDER="1" WIDTH="100%" CELLPADDING="3" CELLSPACING="0" SUMMARY="">
<TR BGCOLOR="#CCCCFF" CLASS="TableHeadingColor">
<TH ALIGN="left" COLSPAN="2"><FONT SIZE="+2">
<B>嵌套类摘要</B></FONT></TH>
</TR>
</TABLE>
&nbsp;<A NAME="nested_classes_inherited_from_class_org.apache.hadoop.hdfs.protocol.FSConstants"><!-- --></A>
<TABLE BORDER="1" WIDTH="100%" CELLPADDING="3" CELLSPACING="0" SUMMARY="">
<TR BGCOLOR="#EEEEFF" CLASS="TableSubHeadingColor">
<TH ALIGN="left"><B>从接口 org.apache.hadoop.hdfs.protocol.<A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/FSConstants.html" title="org.apache.hadoop.hdfs.protocol 中的接口">FSConstants</A> 继承的嵌套类/接口</B></TH>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD><CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/FSConstants.DatanodeReportType.html" title="org.apache.hadoop.hdfs.protocol 中的枚举">FSConstants.DatanodeReportType</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/FSConstants.SafeModeAction.html" title="org.apache.hadoop.hdfs.protocol 中的枚举">FSConstants.SafeModeAction</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/FSConstants.UpgradeAction.html" title="org.apache.hadoop.hdfs.protocol 中的枚举">FSConstants.UpgradeAction</A></CODE></TD>
</TR>
</TABLE>
&nbsp;
<!-- =========== FIELD SUMMARY =========== -->

<A NAME="field_summary"><!-- --></A>
<TABLE BORDER="1" WIDTH="100%" CELLPADDING="3" CELLSPACING="0" SUMMARY="">
<TR BGCOLOR="#CCCCFF" CLASS="TableHeadingColor">
<TH ALIGN="left" COLSPAN="2"><FONT SIZE="+2">
<B>字段摘要</B></FONT></TH>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;org.apache.commons.logging.Log</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#auditLog">auditLog</A></B></CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Logger for audit events, noting successful FSNamesystem operations.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;org.apache.hadoop.hdfs.server.namenode.FSDirectory</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#dir">dir</A></B></CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;<A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/LeaseManager.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">LeaseManager</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#leaseManager">leaseManager</A></B></CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;java.util.List&lt;<A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/DatanodeDescriptor.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">DatanodeDescriptor</A>&gt;</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#list">list</A></B></CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;org.apache.hadoop.util.Daemon</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#lmthread">lmthread</A></B></CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;org.apache.commons.logging.Log</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#LOG">LOG</A></B></CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;org.apache.hadoop.util.Daemon</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#replthread">replthread</A></B></CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
</TABLE>
&nbsp;<A NAME="fields_inherited_from_class_org.apache.hadoop.hdfs.protocol.FSConstants"><!-- --></A>
<TABLE BORDER="1" WIDTH="100%" CELLPADDING="3" CELLSPACING="0" SUMMARY="">
<TR BGCOLOR="#EEEEFF" CLASS="TableSubHeadingColor">
<TH ALIGN="left"><B>从接口 org.apache.hadoop.hdfs.protocol.<A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/FSConstants.html" title="org.apache.hadoop.hdfs.protocol 中的接口">FSConstants</A> 继承的字段</B></TH>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD><CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/FSConstants.html#BLOCK_INVALIDATE_CHUNK">BLOCK_INVALIDATE_CHUNK</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/FSConstants.html#BLOCKREPORT_INITIAL_DELAY">BLOCKREPORT_INITIAL_DELAY</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/FSConstants.html#BLOCKREPORT_INTERVAL">BLOCKREPORT_INTERVAL</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/FSConstants.html#BUFFER_SIZE">BUFFER_SIZE</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/FSConstants.html#DEFAULT_BLOCK_SIZE">DEFAULT_BLOCK_SIZE</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/FSConstants.html#DEFAULT_BYTES_PER_CHECKSUM">DEFAULT_BYTES_PER_CHECKSUM</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/FSConstants.html#DEFAULT_DATA_SOCKET_SIZE">DEFAULT_DATA_SOCKET_SIZE</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/FSConstants.html#DEFAULT_FILE_BUFFER_SIZE">DEFAULT_FILE_BUFFER_SIZE</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/FSConstants.html#DEFAULT_REPLICATION_FACTOR">DEFAULT_REPLICATION_FACTOR</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/FSConstants.html#DEFAULT_WRITE_PACKET_SIZE">DEFAULT_WRITE_PACKET_SIZE</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/FSConstants.html#HDFS_URI_SCHEME">HDFS_URI_SCHEME</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/FSConstants.html#HEARTBEAT_INTERVAL">HEARTBEAT_INTERVAL</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/FSConstants.html#LAYOUT_VERSION">LAYOUT_VERSION</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/FSConstants.html#LEASE_HARDLIMIT_PERIOD">LEASE_HARDLIMIT_PERIOD</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/FSConstants.html#LEASE_RECOVER_PERIOD">LEASE_RECOVER_PERIOD</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/FSConstants.html#LEASE_SOFTLIMIT_PERIOD">LEASE_SOFTLIMIT_PERIOD</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/FSConstants.html#MAX_PATH_DEPTH">MAX_PATH_DEPTH</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/FSConstants.html#MAX_PATH_LENGTH">MAX_PATH_LENGTH</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/FSConstants.html#MIN_BLOCKS_FOR_WRITE">MIN_BLOCKS_FOR_WRITE</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/FSConstants.html#QUOTA_DONT_SET">QUOTA_DONT_SET</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/FSConstants.html#QUOTA_RESET">QUOTA_RESET</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/FSConstants.html#SIZE_OF_INTEGER">SIZE_OF_INTEGER</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/FSConstants.html#SMALL_BUFFER_SIZE">SMALL_BUFFER_SIZE</A></CODE></TD>
</TR>
</TABLE>
&nbsp;
<!-- ========== METHOD SUMMARY =========== -->

<A NAME="method_summary"><!-- --></A>
<TABLE BORDER="1" WIDTH="100%" CELLPADDING="3" CELLSPACING="0" SUMMARY="">
<TR BGCOLOR="#CCCCFF" CLASS="TableHeadingColor">
<TH ALIGN="left" COLSPAN="2"><FONT SIZE="+2">
<B>方法摘要</B></FONT></TH>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;boolean</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#abandonBlock(org.apache.hadoop.hdfs.protocol.Block, java.lang.String, java.lang.String)">abandonBlock</A></B>(<A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/Block.html" title="org.apache.hadoop.hdfs.protocol 中的类">Block</A>&nbsp;b,
             java.lang.String&nbsp;src,
             java.lang.String&nbsp;holder)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The client would like to let go of the given block</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;void</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#blockReceived(org.apache.hadoop.hdfs.protocol.DatanodeID, org.apache.hadoop.hdfs.protocol.Block, java.lang.String)">blockReceived</A></B>(<A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/DatanodeID.html" title="org.apache.hadoop.hdfs.protocol 中的类">DatanodeID</A>&nbsp;nodeID,
              <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/Block.html" title="org.apache.hadoop.hdfs.protocol 中的类">Block</A>&nbsp;block,
              java.lang.String&nbsp;delHint)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The given node is reporting that it received a certain block.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;void</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#cancelDelegationToken(org.apache.hadoop.security.token.Token)">cancelDelegationToken</A></B>(org.apache.hadoop.security.token.Token&lt;<A HREF="../../../../../../org/apache/hadoop/hdfs/security/token/delegation/DelegationTokenIdentifier.html" title="org.apache.hadoop.hdfs.security.token.delegation 中的类">DelegationTokenIdentifier</A>&gt;&nbsp;token)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;void</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#close()">close</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Close down this file system manager.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;boolean</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#completeFile(java.lang.String, java.lang.String, org.apache.hadoop.hdfs.protocol.Block[])">completeFile</A></B>(java.lang.String&nbsp;src,
             java.lang.String&nbsp;holder,
             <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/Block.html" title="org.apache.hadoop.hdfs.protocol 中的类">Block</A>[]&nbsp;blks)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Complete in-progress write to the given file.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;int</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#computeDatanodeWork()">computeDatanodeWork</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Compute block replication and block invalidation work 
 that can be scheduled on data-nodes.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;void</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#concat(java.lang.String, java.lang.String[])">concat</A></B>(java.lang.String&nbsp;target,
       java.lang.String[]&nbsp;srcs)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Moves all the blocks from srcs and appends them to trg
 To avoid rollbacks we will verify validitity of ALL of the args
 before we start actual move.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;void</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#createSymlink(java.lang.String, java.lang.String, org.apache.hadoop.fs.permission.PermissionStatus, boolean)">createSymlink</A></B>(java.lang.String&nbsp;target,
              java.lang.String&nbsp;link,
              org.apache.hadoop.fs.permission.PermissionStatus&nbsp;dirPerms,
              boolean&nbsp;createParent)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Create a symbolic link.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;<A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/DatanodeInfo.html" title="org.apache.hadoop.hdfs.protocol 中的类">DatanodeInfo</A>[]</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#datanodeReport(org.apache.hadoop.hdfs.protocol.FSConstants.DatanodeReportType)">datanodeReport</A></B>(<A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/FSConstants.DatanodeReportType.html" title="org.apache.hadoop.hdfs.protocol 中的枚举">FSConstants.DatanodeReportType</A>&nbsp;type)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;boolean</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#delete(java.lang.String, boolean)">delete</A></B>(java.lang.String&nbsp;src,
       boolean&nbsp;recursive)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Remove the indicated file from namespace.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;void</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#DFSNodesStatus(java.util.ArrayList, java.util.ArrayList)">DFSNodesStatus</A></B>(java.util.ArrayList&lt;<A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/DatanodeDescriptor.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">DatanodeDescriptor</A>&gt;&nbsp;live,
               java.util.ArrayList&lt;<A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/DatanodeDescriptor.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">DatanodeDescriptor</A>&gt;&nbsp;dead)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;<A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/LocatedBlock.html" title="org.apache.hadoop.hdfs.protocol 中的类">LocatedBlock</A>[]</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#getAdditionalBlock(boolean, java.lang.String, java.lang.String, org.apache.hadoop.hdfs.protocol.Block, java.util.HashMap)">getAdditionalBlock</A></B>(boolean&nbsp;isRegeneratingCodeRecovery,
                   java.lang.String&nbsp;src,
                   java.lang.String&nbsp;clientName,
                   <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/Block.html" title="org.apache.hadoop.hdfs.protocol 中的类">Block</A>&nbsp;previous,
                   java.util.HashMap&lt;org.apache.hadoop.net.Node,org.apache.hadoop.net.Node&gt;&nbsp;excludedNodes)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;This method is a overload one of getAdditionalBlock(...).</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;<A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/LocatedBlock.html" title="org.apache.hadoop.hdfs.protocol 中的类">LocatedBlock</A>[]</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#getAdditionalBlock(java.lang.String, java.lang.String, org.apache.hadoop.hdfs.protocol.Block, java.util.HashMap)">getAdditionalBlock</A></B>(java.lang.String&nbsp;src,
                   java.lang.String&nbsp;clientName,
                   <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/Block.html" title="org.apache.hadoop.hdfs.protocol 中的类">Block</A>&nbsp;previous,
                   java.util.HashMap&lt;org.apache.hadoop.net.Node,org.apache.hadoop.net.Node&gt;&nbsp;excludedNodes)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The client would like to obtain an additional block for the indicated
 filename (which is being written-to).</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;<A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/LocatedBlocks.html" title="org.apache.hadoop.hdfs.protocol 中的类">LocatedBlocks</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#getAllBlocksLocationsInternal(java.lang.String)">getAllBlocksLocationsInternal</A></B>(java.lang.String&nbsp;src)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;int</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#getBlockCapacity()">getBlockCapacity</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;long</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#getBlocksTotal()">getBlocksTotal</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Get the total number of blocks in the system.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;long</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#getCapacityRemaining()">getCapacityRemaining</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Total non-used raw bytes.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;float</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#getCapacityRemainingPercent()">getCapacityRemainingPercent</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Total remaining space by data nodes as percentage of total capacity</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;long</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#getCapacityTotal()">getCapacityTotal</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Total raw bytes including non-dfs used space.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;long</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#getCapacityUsed()">getCapacityUsed</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Total used space by data nodes</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;long</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#getCapacityUsedNonDFS()">getCapacityUsedNonDFS</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Total used space by data nodes for non DFS purposes such
 as storing temporary files on the local file system</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;float</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#getCapacityUsedPercent()">getCapacityUsedPercent</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Total used space by data nodes as percentage of total capacity</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;<A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/CodingMatrix.html" title="org.apache.hadoop.hdfs.protocol 中的类">CodingMatrix</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#getCodingMatrix(java.lang.String)">getCodingMatrix</A></B>(java.lang.String&nbsp;src)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;long</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#getCorruptReplicaBlocks()">getCorruptReplicaBlocks</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Returns number of blocks with corrupt replicas</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;<A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/DatanodeDescriptor.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">DatanodeDescriptor</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#getDatanode(org.apache.hadoop.hdfs.protocol.DatanodeID)">getDatanode</A></B>(<A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/DatanodeID.html" title="org.apache.hadoop.hdfs.protocol 中的类">DatanodeID</A>&nbsp;nodeID)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Get data node by storage ID.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;<A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/DatanodeInfo.html" title="org.apache.hadoop.hdfs.protocol 中的类">DatanodeInfo</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#getDataNodeInfo(java.lang.String)">getDataNodeInfo</A></B>(java.lang.String&nbsp;name)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;java.util.ArrayList&lt;java.lang.String&gt;</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#getDeadDataNodesStorageID()">getDeadDataNodesStorageID</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;get the storageID of the datanodes who is/are dead</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;java.lang.String</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#getDeadNodes()">getDeadNodes</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Returned information is a JSON representation of map with host name as the
 key and value is a map of dead node attribute keys to its values</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;java.util.ArrayList&lt;<A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/DatanodeDescriptor.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">DatanodeDescriptor</A>&gt;</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#getDecommissioningNodes()">getDecommissioningNodes</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;java.util.ArrayList&lt;java.lang.String&gt;</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#getDecommissioningNodesStorageID()">getDecommissioningNodesStorageID</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;get the storageID of the datanodes who is/are decommissioning</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;java.lang.String</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#getDecomNodes()">getDecomNodes</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Returned information is a JSON representation of map with host name as the
 key and value is a map of decomisioning node attribute keys to its values</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;org.apache.hadoop.security.token.Token&lt;<A HREF="../../../../../../org/apache/hadoop/hdfs/security/token/delegation/DelegationTokenIdentifier.html" title="org.apache.hadoop.hdfs.security.token.delegation 中的类">DelegationTokenIdentifier</A>&gt;</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#getDelegationToken(org.apache.hadoop.io.Text)">getDelegationToken</A></B>(org.apache.hadoop.io.Text&nbsp;renewer)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;<A HREF="../../../../../../org/apache/hadoop/hdfs/security/token/delegation/DelegationTokenSecretManager.html" title="org.apache.hadoop.hdfs.security.token.delegation 中的类">DelegationTokenSecretManager</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#getDelegationTokenSecretManager()">getDelegationTokenSecretManager</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Returns the DelegationTokenSecretManager instance in the namesystem.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;long</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#getExcessBlocks()">getExcessBlocks</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;long</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#getFileLengthInternal(java.lang.String)">getFileLengthInternal</A></B>(java.lang.String&nbsp;src)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;long</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#getFilesTotal()">getFilesTotal</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Total number of files and directories</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;long</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#getFree()">getFree</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Gets total non-used raw bytes.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;<A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/metrics/FSNamesystemMetrics.html" title="org.apache.hadoop.hdfs.server.namenode.metrics 中的类">FSNamesystemMetrics</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#getFSNamesystemMetrics()">getFSNamesystemMetrics</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;get FSNamesystemMetrics</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;java.lang.String</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#getFSState()">getFSState</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The state of the file system: Safemode or Operational</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;long</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#getGenerationStamp()">getGenerationStamp</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Gets the generation stamp for this filesystem</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;<A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/DirectoryListing.html" title="org.apache.hadoop.hdfs.protocol 中的类">DirectoryListing</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#getListing(java.lang.String, byte[], boolean)">getListing</A></B>(java.lang.String&nbsp;src,
           byte[]&nbsp;startAfter,
           boolean&nbsp;needLocation)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Get a partial listing of the indicated directory</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;java.util.ArrayList&lt;java.lang.String&gt;</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#getLiveDataNodesStorageID()">getLiveDataNodesStorageID</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;get the storageID of the datanodes who is/are live</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;java.lang.String</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#getLiveNodes()">getLiveNodes</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Returned information is a JSON representation of map with host name as the
 key and value is a map of live node attribute keys to its values</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;long</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#getMissingBlocksCount()">getMissingBlocksCount</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;java.util.Collection&lt;java.net.URI&gt;</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#getNamespaceDirs(org.apache.hadoop.conf.Configuration)">getNamespaceDirs</A></B>(org.apache.hadoop.conf.Configuration&nbsp;conf)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;java.util.Collection&lt;java.net.URI&gt;</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#getNamespaceEditsDirs(org.apache.hadoop.conf.Configuration)">getNamespaceEditsDirs</A></B>(org.apache.hadoop.conf.Configuration&nbsp;conf)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;long</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#getNonDfsUsedSpace()">getNonDfsUsedSpace</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Gets total used space by data nodes for non DFS purposes such as storing
 temporary files on the local file system</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;int</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#getNumDeadDataNodes()">getNumDeadDataNodes</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Number of dead data nodes</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;int</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#getNumLiveDataNodes()">getNumLiveDataNodes</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Number of live data nodes</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;long</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#getPendingDeletionBlocks()">getPendingDeletionBlocks</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;long</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#getPendingReplicationBlocks()">getPendingReplicationBlocks</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Blocks pending to be replicated</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;float</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#getPercentRemaining()">getPercentRemaining</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Gets the total remaining space by data nodes as percentage of total 
 capacity</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;float</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#getPercentUsed()">getPercentUsed</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Gets the total used space by data nodes as percentage of total capacity</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;java.lang.String</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#getRegistrationID()">getRegistrationID</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Get registrationID for datanodes based on the namespaceID.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;java.lang.String</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#getSafemode()">getSafemode</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Gets the safemode status</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;long</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#getScheduledReplicationBlocks()">getScheduledReplicationBlocks</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Blocks scheduled for replication</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;java.util.Date</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#getStartTime()">getStartTime</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;java.util.Collection&lt;java.net.URI&gt;</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#getStorageDirs(org.apache.hadoop.conf.Configuration, java.lang.String)">getStorageDirs</A></B>(org.apache.hadoop.conf.Configuration&nbsp;conf,
               java.lang.String&nbsp;propertyName)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;int</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#getThreads()">getThreads</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Gets the number of threads.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;long</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#getTotal()">getTotal</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Gets total raw bytes including non-dfs used space.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;long</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#getTotalBlocks()">getTotalBlocks</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Gets the total numbers of blocks on the cluster.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;long</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#getTotalFiles()">getTotalFiles</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Gets the total number of files on the cluster</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;int</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#getTotalLoad()">getTotalLoad</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Total number of connections.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;long</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#getUnderReplicatedBlocks()">getUnderReplicatedBlocks</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Blocks under replicated</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>protected &nbsp;org.apache.hadoop.fs.permission.PermissionStatus</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#getUpgradePermission()">getUpgradePermission</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Return the default path permission when upgrading from releases with no
 permissions (<=0.15) to releases with permissions (>=0.16)</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;long</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#getUsed()">getUsed</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Gets the used space by data nodes.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;java.lang.String</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#getVersion()">getVersion</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Class representing Namenode information for JMX interfaces</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;boolean</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#isUpgradeFinalized()">isUpgradeFinalized</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Checks if upgrade is finalized.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;void</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#logUpdateMasterKey(org.apache.hadoop.security.token.delegation.DelegationKey)">logUpdateMasterKey</A></B>(org.apache.hadoop.security.token.delegation.DelegationKey&nbsp;key)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Log the updateMasterKey operation to edit logs</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;void</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#markBlockAsCorrupt(org.apache.hadoop.hdfs.protocol.Block, org.apache.hadoop.hdfs.protocol.DatanodeInfo)">markBlockAsCorrupt</A></B>(<A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/Block.html" title="org.apache.hadoop.hdfs.protocol 中的类">Block</A>&nbsp;blk,
                   <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/DatanodeInfo.html" title="org.apache.hadoop.hdfs.protocol 中的类">DatanodeInfo</A>&nbsp;dn)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Mark the block belonging to datanode as corrupt</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;boolean</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#mkdirs(java.lang.String, org.apache.hadoop.fs.permission.PermissionStatus, boolean)">mkdirs</A></B>(java.lang.String&nbsp;src,
       org.apache.hadoop.fs.permission.PermissionStatus&nbsp;permissions,
       boolean&nbsp;createParent)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Create all the necessary directories</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;int</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#numCorruptReplicas(org.apache.hadoop.hdfs.protocol.Block)">numCorruptReplicas</A></B>(<A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/Block.html" title="org.apache.hadoop.hdfs.protocol 中的类">Block</A>&nbsp;blk)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;void</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#processReport(org.apache.hadoop.hdfs.protocol.DatanodeID, org.apache.hadoop.hdfs.protocol.BlockListAsLongs)">processReport</A></B>(<A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/DatanodeID.html" title="org.apache.hadoop.hdfs.protocol 中的类">DatanodeID</A>&nbsp;nodeID,
              <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/BlockListAsLongs.html" title="org.apache.hadoop.hdfs.protocol 中的类">BlockListAsLongs</A>&nbsp;newReport)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The given node is reporting all its blocks.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;void</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#refreshNodes(org.apache.hadoop.conf.Configuration)">refreshNodes</A></B>(org.apache.hadoop.conf.Configuration&nbsp;conf)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Rereads the config to get hosts and exclude list file names.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;void</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#registerDatanode(org.apache.hadoop.hdfs.server.protocol.DatanodeRegistration)">registerDatanode</A></B>(<A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/DatanodeRegistration.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">DatanodeRegistration</A>&nbsp;nodeReg)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Register Datanode.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;void</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#removeDatanode(org.apache.hadoop.hdfs.protocol.DatanodeID)">removeDatanode</A></B>(<A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/DatanodeID.html" title="org.apache.hadoop.hdfs.protocol 中的类">DatanodeID</A>&nbsp;nodeID)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Remove a datanode descriptor.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;long</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#renewDelegationToken(org.apache.hadoop.security.token.Token)">renewDelegationToken</A></B>(org.apache.hadoop.security.token.Token&lt;<A HREF="../../../../../../org/apache/hadoop/hdfs/security/token/delegation/DelegationTokenIdentifier.html" title="org.apache.hadoop.hdfs.security.token.delegation 中的类">DelegationTokenIdentifier</A>&gt;&nbsp;token)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;void</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#setGenerationStamp(long)">setGenerationStamp</A></B>(long&nbsp;stamp)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Sets the generation stamp for this filesystem</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;void</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#setNodeReplicationLimit(int)">setNodeReplicationLimit</A></B>(int&nbsp;limit)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;void</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#setOwner(java.lang.String, java.lang.String, java.lang.String)">setOwner</A></B>(java.lang.String&nbsp;src,
         java.lang.String&nbsp;username,
         java.lang.String&nbsp;group)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Set owner for an existing file.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;void</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#setPermission(java.lang.String, org.apache.hadoop.fs.permission.FsPermission)">setPermission</A></B>(java.lang.String&nbsp;src,
              org.apache.hadoop.fs.permission.FsPermission&nbsp;permission)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Set permissions for an existing file.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;boolean</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#setReplication(java.lang.String, short)">setReplication</A></B>(java.lang.String&nbsp;src,
               short&nbsp;replication)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Set replication for an existing file.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;void</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#setTimes(java.lang.String, long, long)">setTimes</A></B>(java.lang.String&nbsp;src,
         long&nbsp;mtime,
         long&nbsp;atime)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;stores the modification and access time for this inode.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;void</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#shutdown()">shutdown</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;shutdown FSNamesystem</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;void</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#stopDecommission(org.apache.hadoop.hdfs.server.namenode.DatanodeDescriptor)">stopDecommission</A></B>(<A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/DatanodeDescriptor.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">DatanodeDescriptor</A>&nbsp;node)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Stop decommissioning the specified datanodes.</TD>
</TR>
</TABLE>
&nbsp;<A NAME="methods_inherited_from_class_java.lang.Object"><!-- --></A>
<TABLE BORDER="1" WIDTH="100%" CELLPADDING="3" CELLSPACING="0" SUMMARY="">
<TR BGCOLOR="#EEEEFF" CLASS="TableSubHeadingColor">
<TH ALIGN="left"><B>从类 java.lang.Object 继承的方法</B></TH>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD><CODE>clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait</CODE></TD>
</TR>
</TABLE>
&nbsp;
<P>

<!-- ============ FIELD DETAIL =========== -->

<A NAME="field_detail"><!-- --></A>
<TABLE BORDER="1" WIDTH="100%" CELLPADDING="3" CELLSPACING="0" SUMMARY="">
<TR BGCOLOR="#CCCCFF" CLASS="TableHeadingColor">
<TH ALIGN="left" COLSPAN="1"><FONT SIZE="+2">
<B>字段详细信息</B></FONT></TH>
</TR>
</TABLE>

<A NAME="LOG"><!-- --></A><H3>
LOG</H3>
<PRE>
public static final org.apache.commons.logging.Log <B>LOG</B></PRE>
<DL>
<DL>
</DL>
</DL>
<HR>

<A NAME="auditLog"><!-- --></A><H3>
auditLog</H3>
<PRE>
public static final org.apache.commons.logging.Log <B>auditLog</B></PRE>
<DL>
<DD>Logger for audit events, noting successful FSNamesystem operations. Emits
 to FSNamesystem.audit at INFO. Each event causes a set of tab-separated
 <code>key=value</code> pairs to be written for the following properties:
 <code>
 ugi=&lt;ugi in RPC&gt;
 ip=&lt;remote IP&gt;
 cmd=&lt;command&gt;
 src=&lt;src path&gt;
 dst=&lt;dst path (optional)&gt;
 perm=&lt;permissions (optional)&gt;
 </code>
<P>
<DL>
</DL>
</DL>
<HR>

<A NAME="dir"><!-- --></A><H3>
dir</H3>
<PRE>
public org.apache.hadoop.hdfs.server.namenode.FSDirectory <B>dir</B></PRE>
<DL>
<DL>
</DL>
</DL>
<HR>

<A NAME="list"><!-- --></A><H3>
list</H3>
<PRE>
public java.util.List&lt;<A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/DatanodeDescriptor.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">DatanodeDescriptor</A>&gt; <B>list</B></PRE>
<DL>
<DL>
</DL>
</DL>
<HR>

<A NAME="leaseManager"><!-- --></A><H3>
leaseManager</H3>
<PRE>
public <A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/LeaseManager.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">LeaseManager</A> <B>leaseManager</B></PRE>
<DL>
<DL>
</DL>
</DL>
<HR>

<A NAME="lmthread"><!-- --></A><H3>
lmthread</H3>
<PRE>
public org.apache.hadoop.util.Daemon <B>lmthread</B></PRE>
<DL>
<DL>
</DL>
</DL>
<HR>

<A NAME="replthread"><!-- --></A><H3>
replthread</H3>
<PRE>
public org.apache.hadoop.util.Daemon <B>replthread</B></PRE>
<DL>
<DL>
</DL>
</DL>

<!-- ============ METHOD DETAIL ========== -->

<A NAME="method_detail"><!-- --></A>
<TABLE BORDER="1" WIDTH="100%" CELLPADDING="3" CELLSPACING="0" SUMMARY="">
<TR BGCOLOR="#CCCCFF" CLASS="TableHeadingColor">
<TH ALIGN="left" COLSPAN="1"><FONT SIZE="+2">
<B>方法详细信息</B></FONT></TH>
</TR>
</TABLE>

<A NAME="getNamespaceDirs(org.apache.hadoop.conf.Configuration)"><!-- --></A><H3>
getNamespaceDirs</H3>
<PRE>
public static java.util.Collection&lt;java.net.URI&gt; <B>getNamespaceDirs</B>(org.apache.hadoop.conf.Configuration&nbsp;conf)</PRE>
<DL>
<DD><DL>
</DL>
</DD>
<DD><DL>
</DL>
</DD>
</DL>
<HR>

<A NAME="getStorageDirs(org.apache.hadoop.conf.Configuration, java.lang.String)"><!-- --></A><H3>
getStorageDirs</H3>
<PRE>
public static java.util.Collection&lt;java.net.URI&gt; <B>getStorageDirs</B>(org.apache.hadoop.conf.Configuration&nbsp;conf,
                                                                java.lang.String&nbsp;propertyName)</PRE>
<DL>
<DD><DL>
</DL>
</DD>
<DD><DL>
</DL>
</DD>
</DL>
<HR>

<A NAME="getNamespaceEditsDirs(org.apache.hadoop.conf.Configuration)"><!-- --></A><H3>
getNamespaceEditsDirs</H3>
<PRE>
public static java.util.Collection&lt;java.net.URI&gt; <B>getNamespaceEditsDirs</B>(org.apache.hadoop.conf.Configuration&nbsp;conf)</PRE>
<DL>
<DD><DL>
</DL>
</DD>
<DD><DL>
</DL>
</DD>
</DL>
<HR>

<A NAME="getUpgradePermission()"><!-- --></A><H3>
getUpgradePermission</H3>
<PRE>
protected org.apache.hadoop.fs.permission.PermissionStatus <B>getUpgradePermission</B>()</PRE>
<DL>
<DD>Return the default path permission when upgrading from releases with no
 permissions (<=0.15) to releases with permissions (>=0.16)
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
</DL>
</DD>
</DL>
<HR>

<A NAME="close()"><!-- --></A><H3>
close</H3>
<PRE>
public void <B>close</B>()</PRE>
<DL>
<DD>Close down this file system manager.
 Causes heartbeat and lease daemons to stop; waits briefly for
 them to finish, but a short timeout returns control back to caller.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
</DL>
</DD>
</DL>
<HR>

<A NAME="setPermission(java.lang.String, org.apache.hadoop.fs.permission.FsPermission)"><!-- --></A><H3>
setPermission</H3>
<PRE>
public void <B>setPermission</B>(java.lang.String&nbsp;src,
                          org.apache.hadoop.fs.permission.FsPermission&nbsp;permission)
                   throws org.apache.hadoop.security.AccessControlException,
                          java.io.FileNotFoundException,
                          <A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/SafeModeException.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">SafeModeException</A>,
                          org.apache.hadoop.fs.UnresolvedLinkException,
                          java.io.IOException</PRE>
<DL>
<DD>Set permissions for an existing file.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE>
<DD><CODE>org.apache.hadoop.security.AccessControlException</CODE>
<DD><CODE>java.io.FileNotFoundException</CODE>
<DD><CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/SafeModeException.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">SafeModeException</A></CODE>
<DD><CODE>org.apache.hadoop.fs.UnresolvedLinkException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="setOwner(java.lang.String, java.lang.String, java.lang.String)"><!-- --></A><H3>
setOwner</H3>
<PRE>
public void <B>setOwner</B>(java.lang.String&nbsp;src,
                     java.lang.String&nbsp;username,
                     java.lang.String&nbsp;group)
              throws org.apache.hadoop.security.AccessControlException,
                     java.io.FileNotFoundException,
                     <A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/SafeModeException.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">SafeModeException</A>,
                     org.apache.hadoop.fs.UnresolvedLinkException,
                     java.io.IOException</PRE>
<DL>
<DD>Set owner for an existing file.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE>
<DD><CODE>org.apache.hadoop.security.AccessControlException</CODE>
<DD><CODE>java.io.FileNotFoundException</CODE>
<DD><CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/SafeModeException.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">SafeModeException</A></CODE>
<DD><CODE>org.apache.hadoop.fs.UnresolvedLinkException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="concat(java.lang.String, java.lang.String[])"><!-- --></A><H3>
concat</H3>
<PRE>
public void <B>concat</B>(java.lang.String&nbsp;target,
                   java.lang.String[]&nbsp;srcs)
            throws java.io.IOException,
                   org.apache.hadoop.fs.UnresolvedLinkException</PRE>
<DL>
<DD>Moves all the blocks from srcs and appends them to trg
 To avoid rollbacks we will verify validitity of ALL of the args
 before we start actual move.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>参数：</B><DD><CODE>target</CODE> - <DD><CODE>srcs</CODE> - 
<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE>
<DD><CODE>org.apache.hadoop.fs.UnresolvedLinkException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="setTimes(java.lang.String, long, long)"><!-- --></A><H3>
setTimes</H3>
<PRE>
public void <B>setTimes</B>(java.lang.String&nbsp;src,
                     long&nbsp;mtime,
                     long&nbsp;atime)
              throws java.io.IOException,
                     org.apache.hadoop.fs.UnresolvedLinkException</PRE>
<DL>
<DD>stores the modification and access time for this inode. 
 The access time is precise upto an hour. The transaction, if needed, is
 written to the edits log but is not flushed.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE>
<DD><CODE>org.apache.hadoop.fs.UnresolvedLinkException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="createSymlink(java.lang.String, java.lang.String, org.apache.hadoop.fs.permission.PermissionStatus, boolean)"><!-- --></A><H3>
createSymlink</H3>
<PRE>
public void <B>createSymlink</B>(java.lang.String&nbsp;target,
                          java.lang.String&nbsp;link,
                          org.apache.hadoop.fs.permission.PermissionStatus&nbsp;dirPerms,
                          boolean&nbsp;createParent)
                   throws java.io.IOException,
                          org.apache.hadoop.fs.UnresolvedLinkException</PRE>
<DL>
<DD>Create a symbolic link.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE>
<DD><CODE>org.apache.hadoop.fs.UnresolvedLinkException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="setReplication(java.lang.String, short)"><!-- --></A><H3>
setReplication</H3>
<PRE>
public boolean <B>setReplication</B>(java.lang.String&nbsp;src,
                              short&nbsp;replication)
                       throws java.io.IOException,
                              org.apache.hadoop.fs.UnresolvedLinkException</PRE>
<DL>
<DD>Set replication for an existing file.
 
 The NameNode sets new replication and schedules either replication of 
 under-replicated data blocks or removal of the excessive block copies 
 if the blocks are over-replicated.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>参数：</B><DD><CODE>src</CODE> - file name<DD><CODE>replication</CODE> - new replication
<DT><B>返回：</B><DD>true if successful; 
         false if file does not exist or is a directory
<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE>
<DD><CODE>org.apache.hadoop.fs.UnresolvedLinkException</CODE><DT><B>另请参见：</B><DD><A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html#setReplication(java.lang.String, short)"><CODE>ClientProtocol.setReplication(String, short)</CODE></A></DL>
</DD>
</DL>
<HR>

<A NAME="getAdditionalBlock(java.lang.String, java.lang.String, org.apache.hadoop.hdfs.protocol.Block, java.util.HashMap)"><!-- --></A><H3>
getAdditionalBlock</H3>
<PRE>
public <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/LocatedBlock.html" title="org.apache.hadoop.hdfs.protocol 中的类">LocatedBlock</A>[] <B>getAdditionalBlock</B>(java.lang.String&nbsp;src,
                                         java.lang.String&nbsp;clientName,
                                         <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/Block.html" title="org.apache.hadoop.hdfs.protocol 中的类">Block</A>&nbsp;previous,
                                         java.util.HashMap&lt;org.apache.hadoop.net.Node,org.apache.hadoop.net.Node&gt;&nbsp;excludedNodes)
                                  throws <A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/LeaseExpiredException.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">LeaseExpiredException</A>,
                                         <A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NotReplicatedYetException.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">NotReplicatedYetException</A>,
                                         <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/QuotaExceededException.html" title="org.apache.hadoop.hdfs.protocol 中的类">QuotaExceededException</A>,
                                         <A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/SafeModeException.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">SafeModeException</A>,
                                         org.apache.hadoop.fs.UnresolvedLinkException,
                                         java.io.IOException</PRE>
<DL>
<DD>The client would like to obtain an additional block for the indicated
 filename (which is being written-to).  Return an array that consists
 of the block, plus a set of machines.  The first on this list should
 be where the client writes data.  Subsequent items in the list must
 be provided in the connection to the first datanode.

 Make sure the previous blocks have been reported by datanodes and
 are replicated.  Will return an empty 2-elt array if we want the
 client to "try again later".
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/LeaseExpiredException.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">LeaseExpiredException</A></CODE>
<DD><CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NotReplicatedYetException.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">NotReplicatedYetException</A></CODE>
<DD><CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/QuotaExceededException.html" title="org.apache.hadoop.hdfs.protocol 中的类">QuotaExceededException</A></CODE>
<DD><CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/SafeModeException.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">SafeModeException</A></CODE>
<DD><CODE>org.apache.hadoop.fs.UnresolvedLinkException</CODE>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="getAdditionalBlock(boolean, java.lang.String, java.lang.String, org.apache.hadoop.hdfs.protocol.Block, java.util.HashMap)"><!-- --></A><H3>
getAdditionalBlock</H3>
<PRE>
public <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/LocatedBlock.html" title="org.apache.hadoop.hdfs.protocol 中的类">LocatedBlock</A>[] <B>getAdditionalBlock</B>(boolean&nbsp;isRegeneratingCodeRecovery,
                                         java.lang.String&nbsp;src,
                                         java.lang.String&nbsp;clientName,
                                         <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/Block.html" title="org.apache.hadoop.hdfs.protocol 中的类">Block</A>&nbsp;previous,
                                         java.util.HashMap&lt;org.apache.hadoop.net.Node,org.apache.hadoop.net.Node&gt;&nbsp;excludedNodes)
                                  throws <A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/LeaseExpiredException.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">LeaseExpiredException</A>,
                                         <A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NotReplicatedYetException.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">NotReplicatedYetException</A>,
                                         <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/QuotaExceededException.html" title="org.apache.hadoop.hdfs.protocol 中的类">QuotaExceededException</A>,
                                         <A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/SafeModeException.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">SafeModeException</A>,
                                         org.apache.hadoop.fs.UnresolvedLinkException,
                                         java.io.IOException</PRE>
<DL>
<DD>This method is a overload one of getAdditionalBlock(...). Created at 2014-4-23.Modified at .
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/LeaseExpiredException.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">LeaseExpiredException</A></CODE>
<DD><CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NotReplicatedYetException.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">NotReplicatedYetException</A></CODE>
<DD><CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/QuotaExceededException.html" title="org.apache.hadoop.hdfs.protocol 中的类">QuotaExceededException</A></CODE>
<DD><CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/SafeModeException.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">SafeModeException</A></CODE>
<DD><CODE>org.apache.hadoop.fs.UnresolvedLinkException</CODE>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="abandonBlock(org.apache.hadoop.hdfs.protocol.Block, java.lang.String, java.lang.String)"><!-- --></A><H3>
abandonBlock</H3>
<PRE>
public boolean <B>abandonBlock</B>(<A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/Block.html" title="org.apache.hadoop.hdfs.protocol 中的类">Block</A>&nbsp;b,
                            java.lang.String&nbsp;src,
                            java.lang.String&nbsp;holder)
                     throws <A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/LeaseExpiredException.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">LeaseExpiredException</A>,
                            java.io.FileNotFoundException,
                            org.apache.hadoop.fs.UnresolvedLinkException,
                            java.io.IOException</PRE>
<DL>
<DD>The client would like to let go of the given block
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/LeaseExpiredException.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">LeaseExpiredException</A></CODE>
<DD><CODE>java.io.FileNotFoundException</CODE>
<DD><CODE>org.apache.hadoop.fs.UnresolvedLinkException</CODE>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="completeFile(java.lang.String, java.lang.String, org.apache.hadoop.hdfs.protocol.Block[])"><!-- --></A><H3>
completeFile</H3>
<PRE>
public boolean <B>completeFile</B>(java.lang.String&nbsp;src,
                            java.lang.String&nbsp;holder,
                            <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/Block.html" title="org.apache.hadoop.hdfs.protocol 中的类">Block</A>[]&nbsp;blks)
                     throws <A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/SafeModeException.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">SafeModeException</A>,
                            org.apache.hadoop.fs.UnresolvedLinkException,
                            java.io.IOException</PRE>
<DL>
<DD>Complete in-progress write to the given file.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>

<DT><B>返回：</B><DD>true if successful, false if the client should continue to retry
         (e.g if not all blocks have reached minimum replication yet)
<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE> - on error (eg lease mismatch, file not open, file deleted)
<DD><CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/SafeModeException.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">SafeModeException</A></CODE>
<DD><CODE>org.apache.hadoop.fs.UnresolvedLinkException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="markBlockAsCorrupt(org.apache.hadoop.hdfs.protocol.Block, org.apache.hadoop.hdfs.protocol.DatanodeInfo)"><!-- --></A><H3>
markBlockAsCorrupt</H3>
<PRE>
public void <B>markBlockAsCorrupt</B>(<A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/Block.html" title="org.apache.hadoop.hdfs.protocol 中的类">Block</A>&nbsp;blk,
                               <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/DatanodeInfo.html" title="org.apache.hadoop.hdfs.protocol 中的类">DatanodeInfo</A>&nbsp;dn)
                        throws java.io.IOException</PRE>
<DL>
<DD>Mark the block belonging to datanode as corrupt
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>参数：</B><DD><CODE>blk</CODE> - Block to be marked as corrupt<DD><CODE>dn</CODE> - Datanode which holds the corrupt replica
<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="delete(java.lang.String, boolean)"><!-- --></A><H3>
delete</H3>
<PRE>
public boolean <B>delete</B>(java.lang.String&nbsp;src,
                      boolean&nbsp;recursive)
               throws org.apache.hadoop.security.AccessControlException,
                      <A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/SafeModeException.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">SafeModeException</A>,
                      org.apache.hadoop.fs.UnresolvedLinkException,
                      java.io.IOException</PRE>
<DL>
<DD>Remove the indicated file from namespace.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>org.apache.hadoop.security.AccessControlException</CODE>
<DD><CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/SafeModeException.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">SafeModeException</A></CODE>
<DD><CODE>org.apache.hadoop.fs.UnresolvedLinkException</CODE>
<DD><CODE>java.io.IOException</CODE><DT><B>另请参见：</B><DD><A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html#delete(java.lang.String, boolean)"><CODE>for detailed descriptoin and 
 description of exceptions</CODE></A></DL>
</DD>
</DL>
<HR>

<A NAME="mkdirs(java.lang.String, org.apache.hadoop.fs.permission.PermissionStatus, boolean)"><!-- --></A><H3>
mkdirs</H3>
<PRE>
public boolean <B>mkdirs</B>(java.lang.String&nbsp;src,
                      org.apache.hadoop.fs.permission.PermissionStatus&nbsp;permissions,
                      boolean&nbsp;createParent)
               throws java.io.IOException,
                      org.apache.hadoop.fs.UnresolvedLinkException</PRE>
<DL>
<DD>Create all the necessary directories
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE>
<DD><CODE>org.apache.hadoop.fs.UnresolvedLinkException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="getListing(java.lang.String, byte[], boolean)"><!-- --></A><H3>
getListing</H3>
<PRE>
public <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/DirectoryListing.html" title="org.apache.hadoop.hdfs.protocol 中的类">DirectoryListing</A> <B>getListing</B>(java.lang.String&nbsp;src,
                                   byte[]&nbsp;startAfter,
                                   boolean&nbsp;needLocation)
                            throws org.apache.hadoop.security.AccessControlException,
                                   org.apache.hadoop.fs.UnresolvedLinkException,
                                   java.io.IOException</PRE>
<DL>
<DD>Get a partial listing of the indicated directory
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>参数：</B><DD><CODE>src</CODE> - the directory name<DD><CODE>startAfter</CODE> - the name to start after<DD><CODE>needLocation</CODE> - if blockLocations need to be returned
<DT><B>返回：</B><DD>a partial listing starting after startAfter
<DT><B>抛出：</B>
<DD><CODE>org.apache.hadoop.security.AccessControlException</CODE> - if access is denied
<DD><CODE>org.apache.hadoop.fs.UnresolvedLinkException</CODE> - if symbolic link is encountered
<DD><CODE>java.io.IOException</CODE> - if other I/O error occurred</DL>
</DD>
</DL>
<HR>

<A NAME="registerDatanode(org.apache.hadoop.hdfs.server.protocol.DatanodeRegistration)"><!-- --></A><H3>
registerDatanode</H3>
<PRE>
public void <B>registerDatanode</B>(<A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/DatanodeRegistration.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">DatanodeRegistration</A>&nbsp;nodeReg)
                      throws java.io.IOException</PRE>
<DL>
<DD>Register Datanode.
 <p>
 The purpose of registration is to identify whether the new datanode
 serves a new data storage, and will report new data block copies,
 which the namenode was not aware of; or the datanode is a replacement
 node for the data storage that was previously served by a different
 or the same (in terms of host:port) datanode.
 The data storages are distinguished by their storageIDs. When a new
 data storage is reported the namenode issues a new unique storageID.
 <p>
 Finally, the namenode returns its namespaceID as the registrationID
 for the datanodes. 
 namespaceID is a persistent attribute of the name space.
 The registrationID is checked every time the datanode is communicating
 with the namenode. 
 Datanodes with inappropriate registrationID are rejected.
 If the namenode stops, and then restarts it can restore its 
 namespaceID and will continue serving the datanodes that has previously
 registered with the namenode without restarting the whole cluster.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE><DT><B>另请参见：</B><DD><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/DataNode.html#register()"><CODE>DataNode.register()</CODE></A></DL>
</DD>
</DL>
<HR>

<A NAME="getRegistrationID()"><!-- --></A><H3>
getRegistrationID</H3>
<PRE>
public java.lang.String <B>getRegistrationID</B>()</PRE>
<DL>
<DD>Get registrationID for datanodes based on the namespaceID.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>

<DT><B>返回：</B><DD>registration ID<DT><B>另请参见：</B><DD><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#registerDatanode(org.apache.hadoop.hdfs.server.protocol.DatanodeRegistration)"><CODE>registerDatanode(DatanodeRegistration)</CODE></A>, 
<A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/FSImage.html#newNamespaceID()"><CODE>FSImage.newNamespaceID()</CODE></A></DL>
</DD>
</DL>
<HR>

<A NAME="computeDatanodeWork()"><!-- --></A><H3>
computeDatanodeWork</H3>
<PRE>
public int <B>computeDatanodeWork</B>()
                        throws java.io.IOException</PRE>
<DL>
<DD>Compute block replication and block invalidation work 
 that can be scheduled on data-nodes.
 The datanode will be informed of this work at the next heartbeat.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>

<DT><B>返回：</B><DD>number of blocks scheduled for replication or removal.
<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="setNodeReplicationLimit(int)"><!-- --></A><H3>
setNodeReplicationLimit</H3>
<PRE>
public void <B>setNodeReplicationLimit</B>(int&nbsp;limit)</PRE>
<DL>
<DD><DL>
</DL>
</DD>
<DD><DL>
</DL>
</DD>
</DL>
<HR>

<A NAME="removeDatanode(org.apache.hadoop.hdfs.protocol.DatanodeID)"><!-- --></A><H3>
removeDatanode</H3>
<PRE>
public void <B>removeDatanode</B>(<A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/DatanodeID.html" title="org.apache.hadoop.hdfs.protocol 中的类">DatanodeID</A>&nbsp;nodeID)
                    throws java.io.IOException</PRE>
<DL>
<DD>Remove a datanode descriptor.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>参数：</B><DD><CODE>nodeID</CODE> - datanode ID.
<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="processReport(org.apache.hadoop.hdfs.protocol.DatanodeID, org.apache.hadoop.hdfs.protocol.BlockListAsLongs)"><!-- --></A><H3>
processReport</H3>
<PRE>
public void <B>processReport</B>(<A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/DatanodeID.html" title="org.apache.hadoop.hdfs.protocol 中的类">DatanodeID</A>&nbsp;nodeID,
                          <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/BlockListAsLongs.html" title="org.apache.hadoop.hdfs.protocol 中的类">BlockListAsLongs</A>&nbsp;newReport)
                   throws java.io.IOException</PRE>
<DL>
<DD>The given node is reporting all its blocks.  Use this info to 
 update the (machine-->blocklist) and (block-->machinelist) tables.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="blockReceived(org.apache.hadoop.hdfs.protocol.DatanodeID, org.apache.hadoop.hdfs.protocol.Block, java.lang.String)"><!-- --></A><H3>
blockReceived</H3>
<PRE>
public void <B>blockReceived</B>(<A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/DatanodeID.html" title="org.apache.hadoop.hdfs.protocol 中的类">DatanodeID</A>&nbsp;nodeID,
                          <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/Block.html" title="org.apache.hadoop.hdfs.protocol 中的类">Block</A>&nbsp;block,
                          java.lang.String&nbsp;delHint)
                   throws java.io.IOException</PRE>
<DL>
<DD>The given node is reporting that it received a certain block.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="getMissingBlocksCount()"><!-- --></A><H3>
getMissingBlocksCount</H3>
<PRE>
public long <B>getMissingBlocksCount</B>()</PRE>
<DL>
<DD><DL>
</DL>
</DD>
<DD><DL>
</DL>
</DD>
</DL>
<HR>

<A NAME="getCapacityTotal()"><!-- --></A><H3>
getCapacityTotal</H3>
<PRE>
public long <B>getCapacityTotal</B>()</PRE>
<DL>
<DD>Total raw bytes including non-dfs used space.
<P>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/metrics/FSNamesystemMBean.html" title="org.apache.hadoop.hdfs.server.namenode.metrics 中的接口">FSNamesystemMBean</A></CODE> 中的 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/metrics/FSNamesystemMBean.html#getCapacityTotal()">getCapacityTotal</A></CODE></DL>
</DD>
<DD><DL>

<DT><B>返回：</B><DD>-  total capacity in bytes</DL>
</DD>
</DL>
<HR>

<A NAME="getCapacityUsed()"><!-- --></A><H3>
getCapacityUsed</H3>
<PRE>
public long <B>getCapacityUsed</B>()</PRE>
<DL>
<DD>Total used space by data nodes
<P>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/metrics/FSNamesystemMBean.html" title="org.apache.hadoop.hdfs.server.namenode.metrics 中的接口">FSNamesystemMBean</A></CODE> 中的 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/metrics/FSNamesystemMBean.html#getCapacityUsed()">getCapacityUsed</A></CODE></DL>
</DD>
<DD><DL>

<DT><B>返回：</B><DD>-  used capacity in bytes</DL>
</DD>
</DL>
<HR>

<A NAME="getCapacityUsedPercent()"><!-- --></A><H3>
getCapacityUsedPercent</H3>
<PRE>
public float <B>getCapacityUsedPercent</B>()</PRE>
<DL>
<DD>Total used space by data nodes as percentage of total capacity
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
</DL>
</DD>
</DL>
<HR>

<A NAME="getCapacityUsedNonDFS()"><!-- --></A><H3>
getCapacityUsedNonDFS</H3>
<PRE>
public long <B>getCapacityUsedNonDFS</B>()</PRE>
<DL>
<DD>Total used space by data nodes for non DFS purposes such
 as storing temporary files on the local file system
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
</DL>
</DD>
</DL>
<HR>

<A NAME="getCapacityRemaining()"><!-- --></A><H3>
getCapacityRemaining</H3>
<PRE>
public long <B>getCapacityRemaining</B>()</PRE>
<DL>
<DD>Total non-used raw bytes.
<P>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/metrics/FSNamesystemMBean.html" title="org.apache.hadoop.hdfs.server.namenode.metrics 中的接口">FSNamesystemMBean</A></CODE> 中的 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/metrics/FSNamesystemMBean.html#getCapacityRemaining()">getCapacityRemaining</A></CODE></DL>
</DD>
<DD><DL>

<DT><B>返回：</B><DD>-  free capacity in bytes</DL>
</DD>
</DL>
<HR>

<A NAME="getCapacityRemainingPercent()"><!-- --></A><H3>
getCapacityRemainingPercent</H3>
<PRE>
public float <B>getCapacityRemainingPercent</B>()</PRE>
<DL>
<DD>Total remaining space by data nodes as percentage of total capacity
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
</DL>
</DD>
</DL>
<HR>

<A NAME="getTotalLoad()"><!-- --></A><H3>
getTotalLoad</H3>
<PRE>
public int <B>getTotalLoad</B>()</PRE>
<DL>
<DD>Total number of connections.
<P>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/FSClusterStats.html" title="org.apache.hadoop.hdfs.server.namenode 中的接口">FSClusterStats</A></CODE> 中的 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/FSClusterStats.html#getTotalLoad()">getTotalLoad</A></CODE><DT><B>指定者：</B><DD>接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/metrics/FSNamesystemMBean.html" title="org.apache.hadoop.hdfs.server.namenode.metrics 中的接口">FSNamesystemMBean</A></CODE> 中的 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/metrics/FSNamesystemMBean.html#getTotalLoad()">getTotalLoad</A></CODE></DL>
</DD>
<DD><DL>

<DT><B>返回：</B><DD>-  total load of FSNamesystem</DL>
</DD>
</DL>
<HR>

<A NAME="datanodeReport(org.apache.hadoop.hdfs.protocol.FSConstants.DatanodeReportType)"><!-- --></A><H3>
datanodeReport</H3>
<PRE>
public <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/DatanodeInfo.html" title="org.apache.hadoop.hdfs.protocol 中的类">DatanodeInfo</A>[] <B>datanodeReport</B>(<A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/FSConstants.DatanodeReportType.html" title="org.apache.hadoop.hdfs.protocol 中的枚举">FSConstants.DatanodeReportType</A>&nbsp;type)
                              throws org.apache.hadoop.security.AccessControlException</PRE>
<DL>
<DD><DL>
</DL>
</DD>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>org.apache.hadoop.security.AccessControlException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="DFSNodesStatus(java.util.ArrayList, java.util.ArrayList)"><!-- --></A><H3>
DFSNodesStatus</H3>
<PRE>
public void <B>DFSNodesStatus</B>(java.util.ArrayList&lt;<A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/DatanodeDescriptor.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">DatanodeDescriptor</A>&gt;&nbsp;live,
                           java.util.ArrayList&lt;<A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/DatanodeDescriptor.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">DatanodeDescriptor</A>&gt;&nbsp;dead)</PRE>
<DL>
<DD><DL>
</DL>
</DD>
<DD><DL>
</DL>
</DD>
</DL>
<HR>

<A NAME="stopDecommission(org.apache.hadoop.hdfs.server.namenode.DatanodeDescriptor)"><!-- --></A><H3>
stopDecommission</H3>
<PRE>
public void <B>stopDecommission</B>(<A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/DatanodeDescriptor.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">DatanodeDescriptor</A>&nbsp;node)
                      throws java.io.IOException</PRE>
<DL>
<DD>Stop decommissioning the specified datanodes.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="getDataNodeInfo(java.lang.String)"><!-- --></A><H3>
getDataNodeInfo</H3>
<PRE>
public <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/DatanodeInfo.html" title="org.apache.hadoop.hdfs.protocol 中的类">DatanodeInfo</A> <B>getDataNodeInfo</B>(java.lang.String&nbsp;name)</PRE>
<DL>
<DD><DL>
</DL>
</DD>
<DD><DL>
</DL>
</DD>
</DL>
<HR>

<A NAME="getStartTime()"><!-- --></A><H3>
getStartTime</H3>
<PRE>
public java.util.Date <B>getStartTime</B>()</PRE>
<DL>
<DD><DL>
</DL>
</DD>
<DD><DL>
</DL>
</DD>
</DL>
<HR>

<A NAME="refreshNodes(org.apache.hadoop.conf.Configuration)"><!-- --></A><H3>
refreshNodes</H3>
<PRE>
public void <B>refreshNodes</B>(org.apache.hadoop.conf.Configuration&nbsp;conf)
                  throws java.io.IOException</PRE>
<DL>
<DD>Rereads the config to get hosts and exclude list file names.
 Rereads the files to update the hosts and exclude lists.  It
 checks if any of the hosts have changed states:
 1. Added to hosts  --> no further work needed here.
 2. Removed from hosts --> mark AdminState as decommissioned. 
 3. Added to exclude --> start decommission.
 4. Removed from exclude --> stop decommission.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="getDatanode(org.apache.hadoop.hdfs.protocol.DatanodeID)"><!-- --></A><H3>
getDatanode</H3>
<PRE>
public <A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/DatanodeDescriptor.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">DatanodeDescriptor</A> <B>getDatanode</B>(<A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/DatanodeID.html" title="org.apache.hadoop.hdfs.protocol 中的类">DatanodeID</A>&nbsp;nodeID)
                               throws java.io.IOException</PRE>
<DL>
<DD>Get data node by storage ID.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>参数：</B><DD><CODE>nodeID</CODE> - 
<DT><B>返回：</B><DD>DatanodeDescriptor or null if the node is not found.
<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="getBlocksTotal()"><!-- --></A><H3>
getBlocksTotal</H3>
<PRE>
public long <B>getBlocksTotal</B>()</PRE>
<DL>
<DD>Get the total number of blocks in the system.
<P>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/metrics/FSNamesystemMBean.html" title="org.apache.hadoop.hdfs.server.namenode.metrics 中的接口">FSNamesystemMBean</A></CODE> 中的 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/metrics/FSNamesystemMBean.html#getBlocksTotal()">getBlocksTotal</A></CODE></DL>
</DD>
<DD><DL>

<DT><B>返回：</B><DD>-  number of allocated blocks</DL>
</DD>
</DL>
<HR>

<A NAME="getFilesTotal()"><!-- --></A><H3>
getFilesTotal</H3>
<PRE>
public long <B>getFilesTotal</B>()</PRE>
<DL>
<DD><B>从接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/metrics/FSNamesystemMBean.html#getFilesTotal()">FSNamesystemMBean</A></CODE> 复制的描述</B></DD>
<DD>Total number of files and directories
<P>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/metrics/FSNamesystemMBean.html" title="org.apache.hadoop.hdfs.server.namenode.metrics 中的接口">FSNamesystemMBean</A></CODE> 中的 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/metrics/FSNamesystemMBean.html#getFilesTotal()">getFilesTotal</A></CODE></DL>
</DD>
<DD><DL>

<DT><B>返回：</B><DD>-  num of files and directories</DL>
</DD>
</DL>
<HR>

<A NAME="getPendingReplicationBlocks()"><!-- --></A><H3>
getPendingReplicationBlocks</H3>
<PRE>
public long <B>getPendingReplicationBlocks</B>()</PRE>
<DL>
<DD><B>从接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/metrics/FSNamesystemMBean.html#getPendingReplicationBlocks()">FSNamesystemMBean</A></CODE> 复制的描述</B></DD>
<DD>Blocks pending to be replicated
<P>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/metrics/FSNamesystemMBean.html" title="org.apache.hadoop.hdfs.server.namenode.metrics 中的接口">FSNamesystemMBean</A></CODE> 中的 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/metrics/FSNamesystemMBean.html#getPendingReplicationBlocks()">getPendingReplicationBlocks</A></CODE></DL>
</DD>
<DD><DL>

<DT><B>返回：</B><DD>-  num of blocks to be replicated</DL>
</DD>
</DL>
<HR>

<A NAME="getUnderReplicatedBlocks()"><!-- --></A><H3>
getUnderReplicatedBlocks</H3>
<PRE>
public long <B>getUnderReplicatedBlocks</B>()</PRE>
<DL>
<DD><B>从接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/metrics/FSNamesystemMBean.html#getUnderReplicatedBlocks()">FSNamesystemMBean</A></CODE> 复制的描述</B></DD>
<DD>Blocks under replicated
<P>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/metrics/FSNamesystemMBean.html" title="org.apache.hadoop.hdfs.server.namenode.metrics 中的接口">FSNamesystemMBean</A></CODE> 中的 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/metrics/FSNamesystemMBean.html#getUnderReplicatedBlocks()">getUnderReplicatedBlocks</A></CODE></DL>
</DD>
<DD><DL>

<DT><B>返回：</B><DD>-  num of blocks under replicated</DL>
</DD>
</DL>
<HR>

<A NAME="getCorruptReplicaBlocks()"><!-- --></A><H3>
getCorruptReplicaBlocks</H3>
<PRE>
public long <B>getCorruptReplicaBlocks</B>()</PRE>
<DL>
<DD>Returns number of blocks with corrupt replicas
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
</DL>
</DD>
</DL>
<HR>

<A NAME="getScheduledReplicationBlocks()"><!-- --></A><H3>
getScheduledReplicationBlocks</H3>
<PRE>
public long <B>getScheduledReplicationBlocks</B>()</PRE>
<DL>
<DD><B>从接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/metrics/FSNamesystemMBean.html#getScheduledReplicationBlocks()">FSNamesystemMBean</A></CODE> 复制的描述</B></DD>
<DD>Blocks scheduled for replication
<P>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/metrics/FSNamesystemMBean.html" title="org.apache.hadoop.hdfs.server.namenode.metrics 中的接口">FSNamesystemMBean</A></CODE> 中的 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/metrics/FSNamesystemMBean.html#getScheduledReplicationBlocks()">getScheduledReplicationBlocks</A></CODE></DL>
</DD>
<DD><DL>

<DT><B>返回：</B><DD>-  num of blocks scheduled for replication</DL>
</DD>
</DL>
<HR>

<A NAME="getPendingDeletionBlocks()"><!-- --></A><H3>
getPendingDeletionBlocks</H3>
<PRE>
public long <B>getPendingDeletionBlocks</B>()</PRE>
<DL>
<DD><DL>
</DL>
</DD>
<DD><DL>
</DL>
</DD>
</DL>
<HR>

<A NAME="getExcessBlocks()"><!-- --></A><H3>
getExcessBlocks</H3>
<PRE>
public long <B>getExcessBlocks</B>()</PRE>
<DL>
<DD><DL>
</DL>
</DD>
<DD><DL>
</DL>
</DD>
</DL>
<HR>

<A NAME="getBlockCapacity()"><!-- --></A><H3>
getBlockCapacity</H3>
<PRE>
public int <B>getBlockCapacity</B>()</PRE>
<DL>
<DD><DL>
</DL>
</DD>
<DD><DL>
</DL>
</DD>
</DL>
<HR>

<A NAME="getFSState()"><!-- --></A><H3>
getFSState</H3>
<PRE>
public java.lang.String <B>getFSState</B>()</PRE>
<DL>
<DD><B>从接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/metrics/FSNamesystemMBean.html#getFSState()">FSNamesystemMBean</A></CODE> 复制的描述</B></DD>
<DD>The state of the file system: Safemode or Operational
<P>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/metrics/FSNamesystemMBean.html" title="org.apache.hadoop.hdfs.server.namenode.metrics 中的接口">FSNamesystemMBean</A></CODE> 中的 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/metrics/FSNamesystemMBean.html#getFSState()">getFSState</A></CODE></DL>
</DD>
<DD><DL>

<DT><B>返回：</B><DD>the state</DL>
</DD>
</DL>
<HR>

<A NAME="getFSNamesystemMetrics()"><!-- --></A><H3>
getFSNamesystemMetrics</H3>
<PRE>
public <A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/metrics/FSNamesystemMetrics.html" title="org.apache.hadoop.hdfs.server.namenode.metrics 中的类">FSNamesystemMetrics</A> <B>getFSNamesystemMetrics</B>()</PRE>
<DL>
<DD>get FSNamesystemMetrics
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
</DL>
</DD>
</DL>
<HR>

<A NAME="shutdown()"><!-- --></A><H3>
shutdown</H3>
<PRE>
public void <B>shutdown</B>()</PRE>
<DL>
<DD>shutdown FSNamesystem
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
</DL>
</DD>
</DL>
<HR>

<A NAME="getNumLiveDataNodes()"><!-- --></A><H3>
getNumLiveDataNodes</H3>
<PRE>
public int <B>getNumLiveDataNodes</B>()</PRE>
<DL>
<DD>Number of live data nodes
<P>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/metrics/FSNamesystemMBean.html" title="org.apache.hadoop.hdfs.server.namenode.metrics 中的接口">FSNamesystemMBean</A></CODE> 中的 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/metrics/FSNamesystemMBean.html#getNumLiveDataNodes()">getNumLiveDataNodes</A></CODE></DL>
</DD>
<DD><DL>

<DT><B>返回：</B><DD>Number of live data nodes</DL>
</DD>
</DL>
<HR>

<A NAME="getNumDeadDataNodes()"><!-- --></A><H3>
getNumDeadDataNodes</H3>
<PRE>
public int <B>getNumDeadDataNodes</B>()</PRE>
<DL>
<DD>Number of dead data nodes
<P>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/metrics/FSNamesystemMBean.html" title="org.apache.hadoop.hdfs.server.namenode.metrics 中的接口">FSNamesystemMBean</A></CODE> 中的 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/metrics/FSNamesystemMBean.html#getNumDeadDataNodes()">getNumDeadDataNodes</A></CODE></DL>
</DD>
<DD><DL>

<DT><B>返回：</B><DD>Number of dead data nodes</DL>
</DD>
</DL>
<HR>

<A NAME="getLiveDataNodesStorageID()"><!-- --></A><H3>
getLiveDataNodesStorageID</H3>
<PRE>
public java.util.ArrayList&lt;java.lang.String&gt; <B>getLiveDataNodesStorageID</B>()</PRE>
<DL>
<DD>get the storageID of the datanodes who is/are live
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
</DL>
</DD>
</DL>
<HR>

<A NAME="getDeadDataNodesStorageID()"><!-- --></A><H3>
getDeadDataNodesStorageID</H3>
<PRE>
public java.util.ArrayList&lt;java.lang.String&gt; <B>getDeadDataNodesStorageID</B>()</PRE>
<DL>
<DD>get the storageID of the datanodes who is/are dead
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
</DL>
</DD>
</DL>
<HR>

<A NAME="getDecommissioningNodesStorageID()"><!-- --></A><H3>
getDecommissioningNodesStorageID</H3>
<PRE>
public java.util.ArrayList&lt;java.lang.String&gt; <B>getDecommissioningNodesStorageID</B>()</PRE>
<DL>
<DD>get the storageID of the datanodes who is/are decommissioning
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
</DL>
</DD>
</DL>
<HR>

<A NAME="setGenerationStamp(long)"><!-- --></A><H3>
setGenerationStamp</H3>
<PRE>
public void <B>setGenerationStamp</B>(long&nbsp;stamp)</PRE>
<DL>
<DD>Sets the generation stamp for this filesystem
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
</DL>
</DD>
</DL>
<HR>

<A NAME="getGenerationStamp()"><!-- --></A><H3>
getGenerationStamp</H3>
<PRE>
public long <B>getGenerationStamp</B>()</PRE>
<DL>
<DD>Gets the generation stamp for this filesystem
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
</DL>
</DD>
</DL>
<HR>

<A NAME="numCorruptReplicas(org.apache.hadoop.hdfs.protocol.Block)"><!-- --></A><H3>
numCorruptReplicas</H3>
<PRE>
public int <B>numCorruptReplicas</B>(<A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/Block.html" title="org.apache.hadoop.hdfs.protocol 中的类">Block</A>&nbsp;blk)</PRE>
<DL>
<DD><DL>
</DL>
</DD>
<DD><DL>
</DL>
</DD>
</DL>
<HR>

<A NAME="getDecommissioningNodes()"><!-- --></A><H3>
getDecommissioningNodes</H3>
<PRE>
public java.util.ArrayList&lt;<A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/DatanodeDescriptor.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">DatanodeDescriptor</A>&gt; <B>getDecommissioningNodes</B>()</PRE>
<DL>
<DD><DL>
</DL>
</DD>
<DD><DL>
</DL>
</DD>
</DL>
<HR>

<A NAME="getDelegationTokenSecretManager()"><!-- --></A><H3>
getDelegationTokenSecretManager</H3>
<PRE>
public <A HREF="../../../../../../org/apache/hadoop/hdfs/security/token/delegation/DelegationTokenSecretManager.html" title="org.apache.hadoop.hdfs.security.token.delegation 中的类">DelegationTokenSecretManager</A> <B>getDelegationTokenSecretManager</B>()</PRE>
<DL>
<DD>Returns the DelegationTokenSecretManager instance in the namesystem.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>

<DT><B>返回：</B><DD>delegation token secret manager object</DL>
</DD>
</DL>
<HR>

<A NAME="getDelegationToken(org.apache.hadoop.io.Text)"><!-- --></A><H3>
getDelegationToken</H3>
<PRE>
public org.apache.hadoop.security.token.Token&lt;<A HREF="../../../../../../org/apache/hadoop/hdfs/security/token/delegation/DelegationTokenIdentifier.html" title="org.apache.hadoop.hdfs.security.token.delegation 中的类">DelegationTokenIdentifier</A>&gt; <B>getDelegationToken</B>(org.apache.hadoop.io.Text&nbsp;renewer)
                                                                                     throws java.io.IOException</PRE>
<DL>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>参数：</B><DD><CODE>renewer</CODE> - 
<DT><B>返回：</B><DD>Token<DelegationTokenIdentifier>
<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="renewDelegationToken(org.apache.hadoop.security.token.Token)"><!-- --></A><H3>
renewDelegationToken</H3>
<PRE>
public long <B>renewDelegationToken</B>(org.apache.hadoop.security.token.Token&lt;<A HREF="../../../../../../org/apache/hadoop/hdfs/security/token/delegation/DelegationTokenIdentifier.html" title="org.apache.hadoop.hdfs.security.token.delegation 中的类">DelegationTokenIdentifier</A>&gt;&nbsp;token)
                          throws org.apache.hadoop.security.token.SecretManager.InvalidToken,
                                 java.io.IOException</PRE>
<DL>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>参数：</B><DD><CODE>token</CODE> - 
<DT><B>返回：</B><DD>New expiryTime of the token
<DT><B>抛出：</B>
<DD><CODE>org.apache.hadoop.security.token.SecretManager.InvalidToken</CODE>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="cancelDelegationToken(org.apache.hadoop.security.token.Token)"><!-- --></A><H3>
cancelDelegationToken</H3>
<PRE>
public void <B>cancelDelegationToken</B>(org.apache.hadoop.security.token.Token&lt;<A HREF="../../../../../../org/apache/hadoop/hdfs/security/token/delegation/DelegationTokenIdentifier.html" title="org.apache.hadoop.hdfs.security.token.delegation 中的类">DelegationTokenIdentifier</A>&gt;&nbsp;token)
                           throws java.io.IOException</PRE>
<DL>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>参数：</B><DD><CODE>token</CODE> - 
<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="logUpdateMasterKey(org.apache.hadoop.security.token.delegation.DelegationKey)"><!-- --></A><H3>
logUpdateMasterKey</H3>
<PRE>
public void <B>logUpdateMasterKey</B>(org.apache.hadoop.security.token.delegation.DelegationKey&nbsp;key)
                        throws java.io.IOException</PRE>
<DL>
<DD>Log the updateMasterKey operation to edit logs
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>参数：</B><DD><CODE>key</CODE> - new delegation key.
<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="getVersion()"><!-- --></A><H3>
getVersion</H3>
<PRE>
public java.lang.String <B>getVersion</B>()</PRE>
<DL>
<DD>Class representing Namenode information for JMX interfaces
<P>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNodeMXBean.html" title="org.apache.hadoop.hdfs.server.namenode 中的接口">NameNodeMXBean</A></CODE> 中的 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNodeMXBean.html#getVersion()">getVersion</A></CODE></DL>
</DD>
<DD><DL>

<DT><B>返回：</B><DD>the version</DL>
</DD>
</DL>
<HR>

<A NAME="getUsed()"><!-- --></A><H3>
getUsed</H3>
<PRE>
public long <B>getUsed</B>()</PRE>
<DL>
<DD><B>从接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNodeMXBean.html#getUsed()">NameNodeMXBean</A></CODE> 复制的描述</B></DD>
<DD>Gets the used space by data nodes.
<P>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNodeMXBean.html" title="org.apache.hadoop.hdfs.server.namenode 中的接口">NameNodeMXBean</A></CODE> 中的 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNodeMXBean.html#getUsed()">getUsed</A></CODE></DL>
</DD>
<DD><DL>

<DT><B>返回：</B><DD>the used space by data nodes</DL>
</DD>
</DL>
<HR>

<A NAME="getFree()"><!-- --></A><H3>
getFree</H3>
<PRE>
public long <B>getFree</B>()</PRE>
<DL>
<DD><B>从接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNodeMXBean.html#getFree()">NameNodeMXBean</A></CODE> 复制的描述</B></DD>
<DD>Gets total non-used raw bytes.
<P>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNodeMXBean.html" title="org.apache.hadoop.hdfs.server.namenode 中的接口">NameNodeMXBean</A></CODE> 中的 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNodeMXBean.html#getFree()">getFree</A></CODE></DL>
</DD>
<DD><DL>

<DT><B>返回：</B><DD>total non-used raw bytes</DL>
</DD>
</DL>
<HR>

<A NAME="getTotal()"><!-- --></A><H3>
getTotal</H3>
<PRE>
public long <B>getTotal</B>()</PRE>
<DL>
<DD><B>从接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNodeMXBean.html#getTotal()">NameNodeMXBean</A></CODE> 复制的描述</B></DD>
<DD>Gets total raw bytes including non-dfs used space.
<P>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNodeMXBean.html" title="org.apache.hadoop.hdfs.server.namenode 中的接口">NameNodeMXBean</A></CODE> 中的 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNodeMXBean.html#getTotal()">getTotal</A></CODE></DL>
</DD>
<DD><DL>

<DT><B>返回：</B><DD>the total raw bytes including non-dfs used space</DL>
</DD>
</DL>
<HR>

<A NAME="getSafemode()"><!-- --></A><H3>
getSafemode</H3>
<PRE>
public java.lang.String <B>getSafemode</B>()</PRE>
<DL>
<DD><B>从接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNodeMXBean.html#getSafemode()">NameNodeMXBean</A></CODE> 复制的描述</B></DD>
<DD>Gets the safemode status
<P>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNodeMXBean.html" title="org.apache.hadoop.hdfs.server.namenode 中的接口">NameNodeMXBean</A></CODE> 中的 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNodeMXBean.html#getSafemode()">getSafemode</A></CODE></DL>
</DD>
<DD><DL>

<DT><B>返回：</B><DD>the safemode status</DL>
</DD>
</DL>
<HR>

<A NAME="isUpgradeFinalized()"><!-- --></A><H3>
isUpgradeFinalized</H3>
<PRE>
public boolean <B>isUpgradeFinalized</B>()</PRE>
<DL>
<DD><B>从接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNodeMXBean.html#isUpgradeFinalized()">NameNodeMXBean</A></CODE> 复制的描述</B></DD>
<DD>Checks if upgrade is finalized.
<P>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNodeMXBean.html" title="org.apache.hadoop.hdfs.server.namenode 中的接口">NameNodeMXBean</A></CODE> 中的 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNodeMXBean.html#isUpgradeFinalized()">isUpgradeFinalized</A></CODE></DL>
</DD>
<DD><DL>

<DT><B>返回：</B><DD>true, if upgrade is finalized</DL>
</DD>
</DL>
<HR>

<A NAME="getNonDfsUsedSpace()"><!-- --></A><H3>
getNonDfsUsedSpace</H3>
<PRE>
public long <B>getNonDfsUsedSpace</B>()</PRE>
<DL>
<DD><B>从接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNodeMXBean.html#getNonDfsUsedSpace()">NameNodeMXBean</A></CODE> 复制的描述</B></DD>
<DD>Gets total used space by data nodes for non DFS purposes such as storing
 temporary files on the local file system
<P>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNodeMXBean.html" title="org.apache.hadoop.hdfs.server.namenode 中的接口">NameNodeMXBean</A></CODE> 中的 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNodeMXBean.html#getNonDfsUsedSpace()">getNonDfsUsedSpace</A></CODE></DL>
</DD>
<DD><DL>

<DT><B>返回：</B><DD>the non dfs space of the cluster</DL>
</DD>
</DL>
<HR>

<A NAME="getPercentUsed()"><!-- --></A><H3>
getPercentUsed</H3>
<PRE>
public float <B>getPercentUsed</B>()</PRE>
<DL>
<DD><B>从接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNodeMXBean.html#getPercentUsed()">NameNodeMXBean</A></CODE> 复制的描述</B></DD>
<DD>Gets the total used space by data nodes as percentage of total capacity
<P>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNodeMXBean.html" title="org.apache.hadoop.hdfs.server.namenode 中的接口">NameNodeMXBean</A></CODE> 中的 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNodeMXBean.html#getPercentUsed()">getPercentUsed</A></CODE></DL>
</DD>
<DD><DL>

<DT><B>返回：</B><DD>the percentage of used space on the cluster.</DL>
</DD>
</DL>
<HR>

<A NAME="getPercentRemaining()"><!-- --></A><H3>
getPercentRemaining</H3>
<PRE>
public float <B>getPercentRemaining</B>()</PRE>
<DL>
<DD><B>从接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNodeMXBean.html#getPercentRemaining()">NameNodeMXBean</A></CODE> 复制的描述</B></DD>
<DD>Gets the total remaining space by data nodes as percentage of total 
 capacity
<P>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNodeMXBean.html" title="org.apache.hadoop.hdfs.server.namenode 中的接口">NameNodeMXBean</A></CODE> 中的 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNodeMXBean.html#getPercentRemaining()">getPercentRemaining</A></CODE></DL>
</DD>
<DD><DL>

<DT><B>返回：</B><DD>the percentage of the remaining space on the cluster</DL>
</DD>
</DL>
<HR>

<A NAME="getTotalBlocks()"><!-- --></A><H3>
getTotalBlocks</H3>
<PRE>
public long <B>getTotalBlocks</B>()</PRE>
<DL>
<DD><B>从接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNodeMXBean.html#getTotalBlocks()">NameNodeMXBean</A></CODE> 复制的描述</B></DD>
<DD>Gets the total numbers of blocks on the cluster.
<P>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNodeMXBean.html" title="org.apache.hadoop.hdfs.server.namenode 中的接口">NameNodeMXBean</A></CODE> 中的 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNodeMXBean.html#getTotalBlocks()">getTotalBlocks</A></CODE></DL>
</DD>
<DD><DL>

<DT><B>返回：</B><DD>the total number of blocks of the cluster</DL>
</DD>
</DL>
<HR>

<A NAME="getTotalFiles()"><!-- --></A><H3>
getTotalFiles</H3>
<PRE>
public long <B>getTotalFiles</B>()</PRE>
<DL>
<DD><B>从接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNodeMXBean.html#getTotalFiles()">NameNodeMXBean</A></CODE> 复制的描述</B></DD>
<DD>Gets the total number of files on the cluster
<P>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNodeMXBean.html" title="org.apache.hadoop.hdfs.server.namenode 中的接口">NameNodeMXBean</A></CODE> 中的 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNodeMXBean.html#getTotalFiles()">getTotalFiles</A></CODE></DL>
</DD>
<DD><DL>

<DT><B>返回：</B><DD>the total number of files on the cluster</DL>
</DD>
</DL>
<HR>

<A NAME="getThreads()"><!-- --></A><H3>
getThreads</H3>
<PRE>
public int <B>getThreads</B>()</PRE>
<DL>
<DD><B>从接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNodeMXBean.html#getThreads()">NameNodeMXBean</A></CODE> 复制的描述</B></DD>
<DD>Gets the number of threads.
<P>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNodeMXBean.html" title="org.apache.hadoop.hdfs.server.namenode 中的接口">NameNodeMXBean</A></CODE> 中的 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNodeMXBean.html#getThreads()">getThreads</A></CODE></DL>
</DD>
<DD><DL>

<DT><B>返回：</B><DD>the number of threads</DL>
</DD>
</DL>
<HR>

<A NAME="getLiveNodes()"><!-- --></A><H3>
getLiveNodes</H3>
<PRE>
public java.lang.String <B>getLiveNodes</B>()</PRE>
<DL>
<DD>Returned information is a JSON representation of map with host name as the
 key and value is a map of live node attribute keys to its values
<P>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNodeMXBean.html" title="org.apache.hadoop.hdfs.server.namenode 中的接口">NameNodeMXBean</A></CODE> 中的 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNodeMXBean.html#getLiveNodes()">getLiveNodes</A></CODE></DL>
</DD>
<DD><DL>

<DT><B>返回：</B><DD>the live node information</DL>
</DD>
</DL>
<HR>

<A NAME="getDeadNodes()"><!-- --></A><H3>
getDeadNodes</H3>
<PRE>
public java.lang.String <B>getDeadNodes</B>()</PRE>
<DL>
<DD>Returned information is a JSON representation of map with host name as the
 key and value is a map of dead node attribute keys to its values
<P>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNodeMXBean.html" title="org.apache.hadoop.hdfs.server.namenode 中的接口">NameNodeMXBean</A></CODE> 中的 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNodeMXBean.html#getDeadNodes()">getDeadNodes</A></CODE></DL>
</DD>
<DD><DL>

<DT><B>返回：</B><DD>the dead node information</DL>
</DD>
</DL>
<HR>

<A NAME="getDecomNodes()"><!-- --></A><H3>
getDecomNodes</H3>
<PRE>
public java.lang.String <B>getDecomNodes</B>()</PRE>
<DL>
<DD>Returned information is a JSON representation of map with host name as the
 key and value is a map of decomisioning node attribute keys to its values
<P>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNodeMXBean.html" title="org.apache.hadoop.hdfs.server.namenode 中的接口">NameNodeMXBean</A></CODE> 中的 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/NameNodeMXBean.html#getDecomNodes()">getDecomNodes</A></CODE></DL>
</DD>
<DD><DL>

<DT><B>返回：</B><DD>the decommissioning node information</DL>
</DD>
</DL>
<HR>

<A NAME="getAllBlocksLocationsInternal(java.lang.String)"><!-- --></A><H3>
getAllBlocksLocationsInternal</H3>
<PRE>
public <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/LocatedBlocks.html" title="org.apache.hadoop.hdfs.protocol 中的类">LocatedBlocks</A> <B>getAllBlocksLocationsInternal</B>(java.lang.String&nbsp;src)
                                            throws java.io.IOException</PRE>
<DL>
<DD><DL>
</DL>
</DD>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="getFileLengthInternal(java.lang.String)"><!-- --></A><H3>
getFileLengthInternal</H3>
<PRE>
public long <B>getFileLengthInternal</B>(java.lang.String&nbsp;src)
                           throws org.apache.hadoop.fs.UnresolvedLinkException</PRE>
<DL>
<DD><DL>
</DL>
</DD>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>org.apache.hadoop.fs.UnresolvedLinkException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="getCodingMatrix(java.lang.String)"><!-- --></A><H3>
getCodingMatrix</H3>
<PRE>
public <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/CodingMatrix.html" title="org.apache.hadoop.hdfs.protocol 中的类">CodingMatrix</A> <B>getCodingMatrix</B>(java.lang.String&nbsp;src)
                             throws org.apache.hadoop.fs.UnresolvedLinkException</PRE>
<DL>
<DD><DL>
</DL>
</DD>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>org.apache.hadoop.fs.UnresolvedLinkException</CODE></DL>
</DD>
</DL>
<!-- ========= END OF CLASS DATA ========= -->
<HR>


<!-- ======= START OF BOTTOM NAVBAR ====== -->
<A NAME="navbar_bottom"><!-- --></A>
<A HREF="#skip-navbar_bottom" title="跳过导航链接"></A>
<TABLE BORDER="0" WIDTH="100%" CELLPADDING="1" CELLSPACING="0" SUMMARY="">
<TR>
<TD COLSPAN=2 BGCOLOR="#EEEEFF" CLASS="NavBarCell1">
<A NAME="navbar_bottom_firstrow"><!-- --></A>
<TABLE BORDER="0" CELLPADDING="0" CELLSPACING="3" SUMMARY="">
  <TR ALIGN="center" VALIGN="top">
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="../../../../../../overview-summary.html"><FONT CLASS="NavBarFont1"><B>概述</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="package-summary.html"><FONT CLASS="NavBarFont1"><B>软件包</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#FFFFFF" CLASS="NavBarCell1Rev"> &nbsp;<FONT CLASS="NavBarFont1Rev"><B>类</B></FONT>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="class-use/FSNamesystem.html"><FONT CLASS="NavBarFont1"><B>使用</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="package-tree.html"><FONT CLASS="NavBarFont1"><B>树</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="../../../../../../deprecated-list.html"><FONT CLASS="NavBarFont1"><B>已过时</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="../../../../../../index-all.html"><FONT CLASS="NavBarFont1"><B>索引</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="../../../../../../help-doc.html"><FONT CLASS="NavBarFont1"><B>帮助</B></FONT></A>&nbsp;</TD>
  </TR>
</TABLE>
</TD>
<TD ALIGN="right" VALIGN="top" ROWSPAN=3><EM>
</EM>
</TD>
</TR>

<TR>
<TD BGCOLOR="white" CLASS="NavBarCell2"><FONT SIZE="-2">
&nbsp;<A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/FSInodeInfo.html" title="org.apache.hadoop.hdfs.server.namenode 中的接口"><B>上一个类</B></A>&nbsp;
&nbsp;<A HREF="../../../../../../org/apache/hadoop/hdfs/server/namenode/GetDelegationTokenServlet.html" title="org.apache.hadoop.hdfs.server.namenode 中的类"><B>下一个类</B></A></FONT></TD>
<TD BGCOLOR="white" CLASS="NavBarCell2"><FONT SIZE="-2">
  <A HREF="../../../../../../index.html?org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html" target="_top"><B>框架</B></A>  &nbsp;
&nbsp;<A HREF="FSNamesystem.html" target="_top"><B>无框架</B></A>  &nbsp;
&nbsp;<SCRIPT type="text/javascript">
  <!--
  if(window==top) {
    document.writeln('<A HREF="../../../../../../allclasses-noframe.html"><B>所有类</B></A>');
  }
  //-->
</SCRIPT>
<NOSCRIPT>
  <A HREF="../../../../../../allclasses-noframe.html"><B>所有类</B></A>
</NOSCRIPT>


</FONT></TD>
</TR>
<TR>
<TD VALIGN="top" CLASS="NavBarCell3"><FONT SIZE="-2">
  摘要：&nbsp;嵌套&nbsp;|&nbsp;<A HREF="#field_summary">字段</A>&nbsp;|&nbsp;构造方法&nbsp;|&nbsp;<A HREF="#method_summary">方法</A></FONT></TD>
<TD VALIGN="top" CLASS="NavBarCell3"><FONT SIZE="-2">
详细信息：&nbsp;<A HREF="#field_detail">字段</A>&nbsp;|&nbsp;构造方法&nbsp;|&nbsp;<A HREF="#method_detail">方法</A></FONT></TD>
</TR>
</TABLE>
<A NAME="skip-navbar_bottom"></A>
<!-- ======== END OF BOTTOM NAVBAR ======= -->

<HR>
Copyright &copy; 2009 The Apache Software Foundation
</BODY>
</HTML>
