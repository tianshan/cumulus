<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<!--NewPage-->
<HTML>
<HEAD>
<!-- Generated by javadoc (build 1.6.0_18) on Sun May 03 20:19:34 CST 2015 -->
<TITLE>
FSDataset (Hadoop-Hdfs 0.22.1-SNAPSHOT API)
</TITLE>

<META NAME="date" CONTENT="2015-05-03">

<LINK REL ="stylesheet" TYPE="text/css" HREF="../../../../../../stylesheet.css" TITLE="Style">

<SCRIPT type="text/javascript">
function windowTitle()
{
    if (location.href.indexOf('is-external=true') == -1) {
        parent.document.title="FSDataset (Hadoop-Hdfs 0.22.1-SNAPSHOT API)";
    }
}
</SCRIPT>
<NOSCRIPT>
</NOSCRIPT>

</HEAD>

<BODY BGCOLOR="white" onload="windowTitle();">
<HR>


<!-- ========= START OF TOP NAVBAR ======= -->
<A NAME="navbar_top"><!-- --></A>
<A HREF="#skip-navbar_top" title="跳过导航链接"></A>
<TABLE BORDER="0" WIDTH="100%" CELLPADDING="1" CELLSPACING="0" SUMMARY="">
<TR>
<TD COLSPAN=2 BGCOLOR="#EEEEFF" CLASS="NavBarCell1">
<A NAME="navbar_top_firstrow"><!-- --></A>
<TABLE BORDER="0" CELLPADDING="0" CELLSPACING="3" SUMMARY="">
  <TR ALIGN="center" VALIGN="top">
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="../../../../../../overview-summary.html"><FONT CLASS="NavBarFont1"><B>概述</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="package-summary.html"><FONT CLASS="NavBarFont1"><B>软件包</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#FFFFFF" CLASS="NavBarCell1Rev"> &nbsp;<FONT CLASS="NavBarFont1Rev"><B>类</B></FONT>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="class-use/FSDataset.html"><FONT CLASS="NavBarFont1"><B>使用</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="package-tree.html"><FONT CLASS="NavBarFont1"><B>树</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="../../../../../../deprecated-list.html"><FONT CLASS="NavBarFont1"><B>已过时</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="../../../../../../index-all.html"><FONT CLASS="NavBarFont1"><B>索引</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="../../../../../../help-doc.html"><FONT CLASS="NavBarFont1"><B>帮助</B></FONT></A>&nbsp;</TD>
  </TR>
</TABLE>
</TD>
<TD ALIGN="right" VALIGN="top" ROWSPAN=3><EM>
</EM>
</TD>
</TR>

<TR>
<TD BGCOLOR="white" CLASS="NavBarCell2"><FONT SIZE="-2">
&nbsp;<A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/DirectoryScanner.html" title="org.apache.hadoop.hdfs.server.datanode 中的类"><B>上一个类</B></A>&nbsp;
&nbsp;<A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.html" title="org.apache.hadoop.hdfs.server.datanode 中的接口"><B>下一个类</B></A></FONT></TD>
<TD BGCOLOR="white" CLASS="NavBarCell2"><FONT SIZE="-2">
  <A HREF="../../../../../../index.html?org/apache/hadoop/hdfs/server/datanode/FSDataset.html" target="_top"><B>框架</B></A>  &nbsp;
&nbsp;<A HREF="FSDataset.html" target="_top"><B>无框架</B></A>  &nbsp;
&nbsp;<SCRIPT type="text/javascript">
  <!--
  if(window==top) {
    document.writeln('<A HREF="../../../../../../allclasses-noframe.html"><B>所有类</B></A>');
  }
  //-->
</SCRIPT>
<NOSCRIPT>
  <A HREF="../../../../../../allclasses-noframe.html"><B>所有类</B></A>
</NOSCRIPT>


</FONT></TD>
</TR>
<TR>
<TD VALIGN="top" CLASS="NavBarCell3"><FONT SIZE="-2">
  摘要：&nbsp;嵌套&nbsp;|&nbsp;<A HREF="#field_summary">字段</A>&nbsp;|&nbsp;<A HREF="#constructor_summary">构造方法</A>&nbsp;|&nbsp;<A HREF="#method_summary">方法</A></FONT></TD>
<TD VALIGN="top" CLASS="NavBarCell3"><FONT SIZE="-2">
详细信息：&nbsp;<A HREF="#field_detail">字段</A>&nbsp;|&nbsp;<A HREF="#constructor_detail">构造方法</A>&nbsp;|&nbsp;<A HREF="#method_detail">方法</A></FONT></TD>
</TR>
</TABLE>
<A NAME="skip-navbar_top"></A>
<!-- ========= END OF TOP NAVBAR ========= -->

<HR>
<!-- ======== START OF CLASS DATA ======== -->
<H2>
<FONT SIZE="-1">
org.apache.hadoop.hdfs.server.datanode</FONT>
<BR>
类 FSDataset</H2>
<PRE>
java.lang.Object
  <IMG SRC="../../../../../../resources/inherit.gif" ALT="继承者 "><B>org.apache.hadoop.hdfs.server.datanode.FSDataset</B>
</PRE>
<DL>
<DT><B>所有已实现的接口：</B> <DD><A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/FSConstants.html" title="org.apache.hadoop.hdfs.protocol 中的接口">FSConstants</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.html" title="org.apache.hadoop.hdfs.server.datanode 中的接口">FSDatasetInterface</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/metrics/FSDatasetMBean.html" title="org.apache.hadoop.hdfs.server.datanode.metrics 中的接口">FSDatasetMBean</A></DD>
</DL>
<HR>
<DL>
<DT><PRE><FONT SIZE="-1">@InterfaceAudience.Private
</FONT>public class <B>FSDataset</B><DT>extends java.lang.Object<DT>implements <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/FSConstants.html" title="org.apache.hadoop.hdfs.protocol 中的接口">FSConstants</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.html" title="org.apache.hadoop.hdfs.server.datanode 中的接口">FSDatasetInterface</A></DL>
</PRE>

<P>
FSDataset manages a set of data blocks.  Each block
 has a unique name and an extent on disk.
<P>

<P>
<HR>

<P>
<!-- ======== NESTED CLASS SUMMARY ======== -->

<A NAME="nested_class_summary"><!-- --></A>
<TABLE BORDER="1" WIDTH="100%" CELLPADDING="3" CELLSPACING="0" SUMMARY="">
<TR BGCOLOR="#CCCCFF" CLASS="TableHeadingColor">
<TH ALIGN="left" COLSPAN="2"><FONT SIZE="+2">
<B>嵌套类摘要</B></FONT></TH>
</TR>
</TABLE>
&nbsp;<A NAME="nested_classes_inherited_from_class_org.apache.hadoop.hdfs.protocol.FSConstants"><!-- --></A>
<TABLE BORDER="1" WIDTH="100%" CELLPADDING="3" CELLSPACING="0" SUMMARY="">
<TR BGCOLOR="#EEEEFF" CLASS="TableSubHeadingColor">
<TH ALIGN="left"><B>从接口 org.apache.hadoop.hdfs.protocol.<A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/FSConstants.html" title="org.apache.hadoop.hdfs.protocol 中的接口">FSConstants</A> 继承的嵌套类/接口</B></TH>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD><CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/FSConstants.DatanodeReportType.html" title="org.apache.hadoop.hdfs.protocol 中的枚举">FSConstants.DatanodeReportType</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/FSConstants.SafeModeAction.html" title="org.apache.hadoop.hdfs.protocol 中的枚举">FSConstants.SafeModeAction</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/FSConstants.UpgradeAction.html" title="org.apache.hadoop.hdfs.protocol 中的枚举">FSConstants.UpgradeAction</A></CODE></TD>
</TR>
</TABLE>
&nbsp;
<A NAME="nested_classes_inherited_from_class_org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface"><!-- --></A>
<TABLE BORDER="1" WIDTH="100%" CELLPADDING="3" CELLSPACING="0" SUMMARY="">
<TR BGCOLOR="#EEEEFF" CLASS="TableSubHeadingColor">
<TH ALIGN="left"><B>从接口 org.apache.hadoop.hdfs.server.datanode.<A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.html" title="org.apache.hadoop.hdfs.server.datanode 中的接口">FSDatasetInterface</A> 继承的嵌套类/接口</B></TH>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD><CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.BlockInputStreams.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">FSDatasetInterface.BlockInputStreams</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.BlockWriteStreams.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">FSDatasetInterface.BlockWriteStreams</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.MetaDataInputStream.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">FSDatasetInterface.MetaDataInputStream</A></CODE></TD>
</TR>
</TABLE>
&nbsp;
<!-- =========== FIELD SUMMARY =========== -->

<A NAME="field_summary"><!-- --></A>
<TABLE BORDER="1" WIDTH="100%" CELLPADDING="3" CELLSPACING="0" SUMMARY="">
<TR BGCOLOR="#CCCCFF" CLASS="TableHeadingColor">
<TH ALIGN="left" COLSPAN="2"><FONT SIZE="+2">
<B>字段摘要</B></FONT></TH>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;java.lang.String</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/FSDataset.html#METADATA_EXTENSION">METADATA_EXTENSION</A></B></CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;short</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/FSDataset.html#METADATA_VERSION">METADATA_VERSION</A></B></CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
</TABLE>
&nbsp;<A NAME="fields_inherited_from_class_org.apache.hadoop.hdfs.protocol.FSConstants"><!-- --></A>
<TABLE BORDER="1" WIDTH="100%" CELLPADDING="3" CELLSPACING="0" SUMMARY="">
<TR BGCOLOR="#EEEEFF" CLASS="TableSubHeadingColor">
<TH ALIGN="left"><B>从接口 org.apache.hadoop.hdfs.protocol.<A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/FSConstants.html" title="org.apache.hadoop.hdfs.protocol 中的接口">FSConstants</A> 继承的字段</B></TH>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD><CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/FSConstants.html#BLOCK_INVALIDATE_CHUNK">BLOCK_INVALIDATE_CHUNK</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/FSConstants.html#BLOCKREPORT_INITIAL_DELAY">BLOCKREPORT_INITIAL_DELAY</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/FSConstants.html#BLOCKREPORT_INTERVAL">BLOCKREPORT_INTERVAL</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/FSConstants.html#BUFFER_SIZE">BUFFER_SIZE</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/FSConstants.html#DEFAULT_BLOCK_SIZE">DEFAULT_BLOCK_SIZE</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/FSConstants.html#DEFAULT_BYTES_PER_CHECKSUM">DEFAULT_BYTES_PER_CHECKSUM</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/FSConstants.html#DEFAULT_DATA_SOCKET_SIZE">DEFAULT_DATA_SOCKET_SIZE</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/FSConstants.html#DEFAULT_FILE_BUFFER_SIZE">DEFAULT_FILE_BUFFER_SIZE</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/FSConstants.html#DEFAULT_REPLICATION_FACTOR">DEFAULT_REPLICATION_FACTOR</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/FSConstants.html#DEFAULT_WRITE_PACKET_SIZE">DEFAULT_WRITE_PACKET_SIZE</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/FSConstants.html#HDFS_URI_SCHEME">HDFS_URI_SCHEME</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/FSConstants.html#HEARTBEAT_INTERVAL">HEARTBEAT_INTERVAL</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/FSConstants.html#LAYOUT_VERSION">LAYOUT_VERSION</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/FSConstants.html#LEASE_HARDLIMIT_PERIOD">LEASE_HARDLIMIT_PERIOD</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/FSConstants.html#LEASE_RECOVER_PERIOD">LEASE_RECOVER_PERIOD</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/FSConstants.html#LEASE_SOFTLIMIT_PERIOD">LEASE_SOFTLIMIT_PERIOD</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/FSConstants.html#MAX_PATH_DEPTH">MAX_PATH_DEPTH</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/FSConstants.html#MAX_PATH_LENGTH">MAX_PATH_LENGTH</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/FSConstants.html#MIN_BLOCKS_FOR_WRITE">MIN_BLOCKS_FOR_WRITE</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/FSConstants.html#QUOTA_DONT_SET">QUOTA_DONT_SET</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/FSConstants.html#QUOTA_RESET">QUOTA_RESET</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/FSConstants.html#SIZE_OF_INTEGER">SIZE_OF_INTEGER</A>, <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/FSConstants.html#SMALL_BUFFER_SIZE">SMALL_BUFFER_SIZE</A></CODE></TD>
</TR>
</TABLE>
&nbsp;
<!-- ======== CONSTRUCTOR SUMMARY ======== -->

<A NAME="constructor_summary"><!-- --></A>
<TABLE BORDER="1" WIDTH="100%" CELLPADDING="3" CELLSPACING="0" SUMMARY="">
<TR BGCOLOR="#CCCCFF" CLASS="TableHeadingColor">
<TH ALIGN="left" COLSPAN="2"><FONT SIZE="+2">
<B>构造方法摘要</B></FONT></TH>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/FSDataset.html#FSDataset(org.apache.hadoop.hdfs.server.datanode.DataStorage, org.apache.hadoop.conf.Configuration)">FSDataset</A></B>(<A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/DataStorage.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">DataStorage</A>&nbsp;storage,
          org.apache.hadoop.conf.Configuration&nbsp;conf)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;An FSDataset has a directory where it loads its data files.</TD>
</TR>
</TABLE>
&nbsp;
<!-- ========== METHOD SUMMARY =========== -->

<A NAME="method_summary"><!-- --></A>
<TABLE BORDER="1" WIDTH="100%" CELLPADDING="3" CELLSPACING="0" SUMMARY="">
<TR BGCOLOR="#CCCCFF" CLASS="TableHeadingColor">
<TH ALIGN="left" COLSPAN="2"><FONT SIZE="+2">
<B>方法摘要</B></FONT></TH>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;void</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/FSDataset.html#adjustCrcChannelPosition(org.apache.hadoop.hdfs.protocol.Block, org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface.BlockWriteStreams, int)">adjustCrcChannelPosition</A></B>(<A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/Block.html" title="org.apache.hadoop.hdfs.protocol 中的类">Block</A>&nbsp;b,
                         <A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.BlockWriteStreams.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">FSDatasetInterface.BlockWriteStreams</A>&nbsp;streams,
                         int&nbsp;checksumSize)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Sets the offset in the meta file so that the
 last checksum will be overwritten.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;org.apache.hadoop.hdfs.server.datanode.ReplicaInPipelineInterface</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/FSDataset.html#append(org.apache.hadoop.hdfs.protocol.Block, long, long)">append</A></B>(<A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/Block.html" title="org.apache.hadoop.hdfs.protocol 中的类">Block</A>&nbsp;b,
       long&nbsp;newGS,
       long&nbsp;expectedBlockLen)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Append to a finalized replica and returns the meta info of the replica</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;void</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/FSDataset.html#checkAndUpdate(long, java.io.File, java.io.File, org.apache.hadoop.hdfs.server.datanode.FSDataset.FSVolume)">checkAndUpdate</A></B>(long&nbsp;blockId,
               java.io.File&nbsp;diskFile,
               java.io.File&nbsp;diskMetaFile,
               org.apache.hadoop.hdfs.server.datanode.FSDataset.FSVolume&nbsp;vol)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Reconcile the difference between blocks on the disk and blocks in
 volumeMap

 Check the given block for inconsistencies.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;void</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/FSDataset.html#checkDataDir()">checkDataDir</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;check if a data directory is healthy
 if some volumes failed - make sure to remove all the blocks that belong
 to these volumes</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;org.apache.hadoop.hdfs.server.datanode.ReplicaInPipelineInterface</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/FSDataset.html#createRbw(org.apache.hadoop.hdfs.protocol.Block)">createRbw</A></B>(<A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/Block.html" title="org.apache.hadoop.hdfs.protocol 中的类">Block</A>&nbsp;b)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Creates a RBW replica and returns the meta info of the replica</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;org.apache.hadoop.hdfs.server.datanode.ReplicaInPipelineInterface</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/FSDataset.html#createTemporary(org.apache.hadoop.hdfs.protocol.Block)">createTemporary</A></B>(<A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/Block.html" title="org.apache.hadoop.hdfs.protocol 中的类">Block</A>&nbsp;b)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Creates a temporary replica and returns the meta information of the replica</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;void</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/FSDataset.html#finalizeBlock(org.apache.hadoop.hdfs.protocol.Block)">finalizeBlock</A></B>(<A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/Block.html" title="org.apache.hadoop.hdfs.protocol 中的类">Block</A>&nbsp;b)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Complete the block write!</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;java.io.File</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/FSDataset.html#findBlockFile(long)">findBlockFile</A></B>(long&nbsp;blockId)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Return the block file for the given ID</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;java.io.File</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/FSDataset.html#getBlockFile(org.apache.hadoop.hdfs.protocol.Block)">getBlockFile</A></B>(<A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/Block.html" title="org.apache.hadoop.hdfs.protocol 中的类">Block</A>&nbsp;b)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Get File name for a given block.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;java.io.InputStream</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/FSDataset.html#getBlockInputStream(org.apache.hadoop.hdfs.protocol.Block)">getBlockInputStream</A></B>(<A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/Block.html" title="org.apache.hadoop.hdfs.protocol 中的类">Block</A>&nbsp;b)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Returns an input stream to read the contents of the specified block</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;java.io.InputStream</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/FSDataset.html#getBlockInputStream(org.apache.hadoop.hdfs.protocol.Block, long)">getBlockInputStream</A></B>(<A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/Block.html" title="org.apache.hadoop.hdfs.protocol 中的类">Block</A>&nbsp;b,
                    long&nbsp;seekOffset)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Returns an input stream at specified offset of the specified block</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;<A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/BlockListAsLongs.html" title="org.apache.hadoop.hdfs.protocol 中的类">BlockListAsLongs</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/FSDataset.html#getBlockReport()">getBlockReport</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Generates a block report from the in-memory block map.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;long</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/FSDataset.html#getCapacity()">getCapacity</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Return total capacity, used and unused</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;long</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/FSDataset.html#getDfsUsed()">getDfsUsed</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Return the total space used by dfs datanode</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;java.io.File</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/FSDataset.html#getFile(org.apache.hadoop.hdfs.protocol.Block)">getFile</A></B>(<A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/Block.html" title="org.apache.hadoop.hdfs.protocol 中的类">Block</A>&nbsp;b)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Turn the block identifier into a filename; ignore generation stamp!!!</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;long</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/FSDataset.html#getLength(org.apache.hadoop.hdfs.protocol.Block)">getLength</A></B>(<A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/Block.html" title="org.apache.hadoop.hdfs.protocol 中的类">Block</A>&nbsp;b)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Find the block's on-disk length</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;<A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.MetaDataInputStream.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">FSDatasetInterface.MetaDataInputStream</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/FSDataset.html#getMetaDataInputStream(org.apache.hadoop.hdfs.protocol.Block)">getMetaDataInputStream</A></B>(<A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/Block.html" title="org.apache.hadoop.hdfs.protocol 中的类">Block</A>&nbsp;b)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Returns metaData of block b as an input stream (and its length)</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;long</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/FSDataset.html#getMetaDataLength(org.apache.hadoop.hdfs.protocol.Block)">getMetaDataLength</A></B>(<A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/Block.html" title="org.apache.hadoop.hdfs.protocol 中的类">Block</A>&nbsp;b)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Returns the length of the metadata file of the specified block</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>protected &nbsp;java.io.File</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/FSDataset.html#getMetaFile(org.apache.hadoop.hdfs.protocol.Block)">getMetaFile</A></B>(<A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/Block.html" title="org.apache.hadoop.hdfs.protocol 中的类">Block</A>&nbsp;b)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;int</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/FSDataset.html#getNumFailedVolumes()">getNumFailedVolumes</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Return the number of failed volumes in the FSDataset.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;long</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/FSDataset.html#getRemaining()">getRemaining</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Return how many bytes can still be stored in the FSDataset</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;<A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/ReplicaInfo.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">ReplicaInfo</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/FSDataset.html#getReplica(long)">getReplica</A></B>(long&nbsp;blockId)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<B>已过时。</B>&nbsp;<I>use <A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/FSDataset.html#fetchReplicaInfo(long)"><CODE>fetchReplicaInfo(long)</CODE></A> instead.</I></TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;long</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/FSDataset.html#getReplicaVisibleLength(org.apache.hadoop.hdfs.protocol.Block)">getReplicaVisibleLength</A></B>(<A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/Block.html" title="org.apache.hadoop.hdfs.protocol 中的类">Block</A>&nbsp;block)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Get visible length of the specified replica.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;java.lang.String</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/FSDataset.html#getStorageInfo()">getStorageInfo</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Returns the storage id of the underlying storage</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;<A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/Block.html" title="org.apache.hadoop.hdfs.protocol 中的类">Block</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/FSDataset.html#getStoredBlock(long)">getStoredBlock</A></B>(long&nbsp;blkid)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;<A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.BlockInputStreams.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">FSDatasetInterface.BlockInputStreams</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/FSDataset.html#getTmpInputStreams(org.apache.hadoop.hdfs.protocol.Block, long, long)">getTmpInputStreams</A></B>(<A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/Block.html" title="org.apache.hadoop.hdfs.protocol 中的类">Block</A>&nbsp;b,
                   long&nbsp;blkOffset,
                   long&nbsp;ckoff)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Returns handles to the block file and its metadata file</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;boolean</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/FSDataset.html#hasEnoughResource()">hasEnoughResource</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Return true - if there are still valid volumes on the DataNode.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;<A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/ReplicaRecoveryInfo.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">ReplicaRecoveryInfo</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/FSDataset.html#initReplicaRecovery(org.apache.hadoop.hdfs.server.protocol.BlockRecoveryCommand.RecoveringBlock)">initReplicaRecovery</A></B>(<A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/BlockRecoveryCommand.RecoveringBlock.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">BlockRecoveryCommand.RecoveringBlock</A>&nbsp;rBlock)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Initialize a replica recovery.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;void</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/FSDataset.html#invalidate(org.apache.hadoop.hdfs.protocol.Block[])">invalidate</A></B>(<A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/Block.html" title="org.apache.hadoop.hdfs.protocol 中的类">Block</A>[]&nbsp;invalidBlks)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;We're informed that a block is no longer valid.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;boolean</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/FSDataset.html#isValidBlock(org.apache.hadoop.hdfs.protocol.Block)">isValidBlock</A></B>(<A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/Block.html" title="org.apache.hadoop.hdfs.protocol 中的类">Block</A>&nbsp;b)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Check whether the given block is a valid one.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;boolean</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/FSDataset.html#metaFileExists(org.apache.hadoop.hdfs.protocol.Block)">metaFileExists</A></B>(<A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/Block.html" title="org.apache.hadoop.hdfs.protocol 中的类">Block</A>&nbsp;b)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Does the meta file exist for this block?</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;org.apache.hadoop.hdfs.server.datanode.ReplicaInPipelineInterface</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/FSDataset.html#recoverAppend(org.apache.hadoop.hdfs.protocol.Block, long, long)">recoverAppend</A></B>(<A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/Block.html" title="org.apache.hadoop.hdfs.protocol 中的类">Block</A>&nbsp;b,
              long&nbsp;newGS,
              long&nbsp;expectedBlockLen)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Recover a failed append to a finalized replica
 and returns the meta info of the replica</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;void</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/FSDataset.html#recoverClose(org.apache.hadoop.hdfs.protocol.Block, long, long)">recoverClose</A></B>(<A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/Block.html" title="org.apache.hadoop.hdfs.protocol 中的类">Block</A>&nbsp;b,
             long&nbsp;newGS,
             long&nbsp;expectedBlockLen)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Recover a failed pipeline close
 It bumps the replica's generation stamp and finalize it if RBW replica</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;org.apache.hadoop.hdfs.server.datanode.ReplicaInPipelineInterface</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/FSDataset.html#recoverRbw(org.apache.hadoop.hdfs.protocol.Block, long, long, long)">recoverRbw</A></B>(<A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/Block.html" title="org.apache.hadoop.hdfs.protocol 中的类">Block</A>&nbsp;b,
           long&nbsp;newGS,
           long&nbsp;minBytesRcvd,
           long&nbsp;maxBytesRcvd)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Recovers a RBW replica and returns the meta info of the replica</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;void</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/FSDataset.html#shutdown()">shutdown</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Shutdown the FSDataset</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;java.lang.String</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/FSDataset.html#toString()">toString</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Stringifies the name of the storage</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;void</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/FSDataset.html#unfinalizeBlock(org.apache.hadoop.hdfs.protocol.Block)">unfinalizeBlock</A></B>(<A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/Block.html" title="org.apache.hadoop.hdfs.protocol 中的类">Block</A>&nbsp;b)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Remove the temporary block file (if any)</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;boolean</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/FSDataset.html#unlinkBlock(org.apache.hadoop.hdfs.protocol.Block, int)">unlinkBlock</A></B>(<A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/Block.html" title="org.apache.hadoop.hdfs.protocol 中的类">Block</A>&nbsp;block,
            int&nbsp;numLinks)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Make a copy of the block if this block is linked to an existing
 snapshot.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;<A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/ReplicaInfo.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">ReplicaInfo</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/FSDataset.html#updateReplicaUnderRecovery(org.apache.hadoop.hdfs.protocol.Block, long, long)">updateReplicaUnderRecovery</A></B>(<A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/Block.html" title="org.apache.hadoop.hdfs.protocol 中的类">Block</A>&nbsp;oldBlock,
                           long&nbsp;recoveryId,
                           long&nbsp;newlength)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Update replica's generation stamp and length and finalize it.</TD>
</TR>
</TABLE>
&nbsp;<A NAME="methods_inherited_from_class_java.lang.Object"><!-- --></A>
<TABLE BORDER="1" WIDTH="100%" CELLPADDING="3" CELLSPACING="0" SUMMARY="">
<TR BGCOLOR="#EEEEFF" CLASS="TableSubHeadingColor">
<TH ALIGN="left"><B>从类 java.lang.Object 继承的方法</B></TH>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD><CODE>clone, equals, finalize, getClass, hashCode, notify, notifyAll, wait, wait, wait</CODE></TD>
</TR>
</TABLE>
&nbsp;
<P>

<!-- ============ FIELD DETAIL =========== -->

<A NAME="field_detail"><!-- --></A>
<TABLE BORDER="1" WIDTH="100%" CELLPADDING="3" CELLSPACING="0" SUMMARY="">
<TR BGCOLOR="#CCCCFF" CLASS="TableHeadingColor">
<TH ALIGN="left" COLSPAN="1"><FONT SIZE="+2">
<B>字段详细信息</B></FONT></TH>
</TR>
</TABLE>

<A NAME="METADATA_EXTENSION"><!-- --></A><H3>
METADATA_EXTENSION</H3>
<PRE>
public static final java.lang.String <B>METADATA_EXTENSION</B></PRE>
<DL>
<DL>
<DT><B>另请参见：</B><DD><A HREF="../../../../../../constant-values.html#org.apache.hadoop.hdfs.server.datanode.FSDataset.METADATA_EXTENSION">常量字段值</A></DL>
</DL>
<HR>

<A NAME="METADATA_VERSION"><!-- --></A><H3>
METADATA_VERSION</H3>
<PRE>
public static final short <B>METADATA_VERSION</B></PRE>
<DL>
<DL>
<DT><B>另请参见：</B><DD><A HREF="../../../../../../constant-values.html#org.apache.hadoop.hdfs.server.datanode.FSDataset.METADATA_VERSION">常量字段值</A></DL>
</DL>

<!-- ========= CONSTRUCTOR DETAIL ======== -->

<A NAME="constructor_detail"><!-- --></A>
<TABLE BORDER="1" WIDTH="100%" CELLPADDING="3" CELLSPACING="0" SUMMARY="">
<TR BGCOLOR="#CCCCFF" CLASS="TableHeadingColor">
<TH ALIGN="left" COLSPAN="1"><FONT SIZE="+2">
<B>构造方法详细信息</B></FONT></TH>
</TR>
</TABLE>

<A NAME="FSDataset(org.apache.hadoop.hdfs.server.datanode.DataStorage, org.apache.hadoop.conf.Configuration)"><!-- --></A><H3>
FSDataset</H3>
<PRE>
public <B>FSDataset</B>(<A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/DataStorage.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">DataStorage</A>&nbsp;storage,
                 org.apache.hadoop.conf.Configuration&nbsp;conf)
          throws java.io.IOException</PRE>
<DL>
<DD>An FSDataset has a directory where it loads its data files.
<P>
<DL>

<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DL>

<!-- ============ METHOD DETAIL ========== -->

<A NAME="method_detail"><!-- --></A>
<TABLE BORDER="1" WIDTH="100%" CELLPADDING="3" CELLSPACING="0" SUMMARY="">
<TR BGCOLOR="#CCCCFF" CLASS="TableHeadingColor">
<TH ALIGN="left" COLSPAN="1"><FONT SIZE="+2">
<B>方法详细信息</B></FONT></TH>
</TR>
</TABLE>

<A NAME="getMetaFile(org.apache.hadoop.hdfs.protocol.Block)"><!-- --></A><H3>
getMetaFile</H3>
<PRE>
protected java.io.File <B>getMetaFile</B>(<A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/Block.html" title="org.apache.hadoop.hdfs.protocol 中的类">Block</A>&nbsp;b)
                            throws java.io.IOException</PRE>
<DL>
<DD><DL>
</DL>
</DD>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="findBlockFile(long)"><!-- --></A><H3>
findBlockFile</H3>
<PRE>
public java.io.File <B>findBlockFile</B>(long&nbsp;blockId)</PRE>
<DL>
<DD>Return the block file for the given ID
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
</DL>
</DD>
</DL>
<HR>

<A NAME="getStoredBlock(long)"><!-- --></A><H3>
getStoredBlock</H3>
<PRE>
public <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/Block.html" title="org.apache.hadoop.hdfs.protocol 中的类">Block</A> <B>getStoredBlock</B>(long&nbsp;blkid)
                     throws java.io.IOException</PRE>
<DL>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.html" title="org.apache.hadoop.hdfs.server.datanode 中的接口">FSDatasetInterface</A></CODE> 中的 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.html#getStoredBlock(long)">getStoredBlock</A></CODE></DL>
</DD>
<DD><DL>

<DT><B>返回：</B><DD>the generation stamp stored with the block.
<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="metaFileExists(org.apache.hadoop.hdfs.protocol.Block)"><!-- --></A><H3>
metaFileExists</H3>
<PRE>
public boolean <B>metaFileExists</B>(<A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/Block.html" title="org.apache.hadoop.hdfs.protocol 中的类">Block</A>&nbsp;b)
                       throws java.io.IOException</PRE>
<DL>
<DD><B>从接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.html#metaFileExists(org.apache.hadoop.hdfs.protocol.Block)">FSDatasetInterface</A></CODE> 复制的描述</B></DD>
<DD>Does the meta file exist for this block?
<P>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.html" title="org.apache.hadoop.hdfs.server.datanode 中的接口">FSDatasetInterface</A></CODE> 中的 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.html#metaFileExists(org.apache.hadoop.hdfs.protocol.Block)">metaFileExists</A></CODE></DL>
</DD>
<DD><DL>
<DT><B>参数：</B><DD><CODE>b</CODE> - - the block
<DT><B>返回：</B><DD>true of the metafile for specified block exits
<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="getMetaDataLength(org.apache.hadoop.hdfs.protocol.Block)"><!-- --></A><H3>
getMetaDataLength</H3>
<PRE>
public long <B>getMetaDataLength</B>(<A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/Block.html" title="org.apache.hadoop.hdfs.protocol 中的类">Block</A>&nbsp;b)
                       throws java.io.IOException</PRE>
<DL>
<DD><B>从接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.html#getMetaDataLength(org.apache.hadoop.hdfs.protocol.Block)">FSDatasetInterface</A></CODE> 复制的描述</B></DD>
<DD>Returns the length of the metadata file of the specified block
<P>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.html" title="org.apache.hadoop.hdfs.server.datanode 中的接口">FSDatasetInterface</A></CODE> 中的 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.html#getMetaDataLength(org.apache.hadoop.hdfs.protocol.Block)">getMetaDataLength</A></CODE></DL>
</DD>
<DD><DL>
<DT><B>参数：</B><DD><CODE>b</CODE> - - the block for which the metadata length is desired
<DT><B>返回：</B><DD>the length of the metadata file for the specified block.
<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="getMetaDataInputStream(org.apache.hadoop.hdfs.protocol.Block)"><!-- --></A><H3>
getMetaDataInputStream</H3>
<PRE>
public <A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.MetaDataInputStream.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">FSDatasetInterface.MetaDataInputStream</A> <B>getMetaDataInputStream</B>(<A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/Block.html" title="org.apache.hadoop.hdfs.protocol 中的类">Block</A>&nbsp;b)
                                                              throws java.io.IOException</PRE>
<DL>
<DD><B>从接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.html#getMetaDataInputStream(org.apache.hadoop.hdfs.protocol.Block)">FSDatasetInterface</A></CODE> 复制的描述</B></DD>
<DD>Returns metaData of block b as an input stream (and its length)
<P>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.html" title="org.apache.hadoop.hdfs.server.datanode 中的接口">FSDatasetInterface</A></CODE> 中的 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.html#getMetaDataInputStream(org.apache.hadoop.hdfs.protocol.Block)">getMetaDataInputStream</A></CODE></DL>
</DD>
<DD><DL>
<DT><B>参数：</B><DD><CODE>b</CODE> - - the block
<DT><B>返回：</B><DD>the metadata input stream;
<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="getDfsUsed()"><!-- --></A><H3>
getDfsUsed</H3>
<PRE>
public long <B>getDfsUsed</B>()
                throws java.io.IOException</PRE>
<DL>
<DD>Return the total space used by dfs datanode
<P>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/metrics/FSDatasetMBean.html" title="org.apache.hadoop.hdfs.server.datanode.metrics 中的接口">FSDatasetMBean</A></CODE> 中的 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/metrics/FSDatasetMBean.html#getDfsUsed()">getDfsUsed</A></CODE></DL>
</DD>
<DD><DL>

<DT><B>返回：</B><DD>the total space used by dfs datanode
<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="hasEnoughResource()"><!-- --></A><H3>
hasEnoughResource</H3>
<PRE>
public boolean <B>hasEnoughResource</B>()</PRE>
<DL>
<DD>Return true - if there are still valid volumes on the DataNode.
<P>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.html" title="org.apache.hadoop.hdfs.server.datanode 中的接口">FSDatasetInterface</A></CODE> 中的 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.html#hasEnoughResource()">hasEnoughResource</A></CODE></DL>
</DD>
<DD><DL>

<DT><B>返回：</B><DD>true if more than the minimum number of valid volumes are left 
 in the FSDataSet.</DL>
</DD>
</DL>
<HR>

<A NAME="getCapacity()"><!-- --></A><H3>
getCapacity</H3>
<PRE>
public long <B>getCapacity</B>()
                 throws java.io.IOException</PRE>
<DL>
<DD>Return total capacity, used and unused
<P>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/metrics/FSDatasetMBean.html" title="org.apache.hadoop.hdfs.server.datanode.metrics 中的接口">FSDatasetMBean</A></CODE> 中的 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/metrics/FSDatasetMBean.html#getCapacity()">getCapacity</A></CODE></DL>
</DD>
<DD><DL>

<DT><B>返回：</B><DD>total capacity of storage (used and unused)
<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="getRemaining()"><!-- --></A><H3>
getRemaining</H3>
<PRE>
public long <B>getRemaining</B>()
                  throws java.io.IOException</PRE>
<DL>
<DD>Return how many bytes can still be stored in the FSDataset
<P>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/metrics/FSDatasetMBean.html" title="org.apache.hadoop.hdfs.server.datanode.metrics 中的接口">FSDatasetMBean</A></CODE> 中的 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/metrics/FSDatasetMBean.html#getRemaining()">getRemaining</A></CODE></DL>
</DD>
<DD><DL>

<DT><B>返回：</B><DD>The amount of free storage space
<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="getNumFailedVolumes()"><!-- --></A><H3>
getNumFailedVolumes</H3>
<PRE>
public int <B>getNumFailedVolumes</B>()</PRE>
<DL>
<DD>Return the number of failed volumes in the FSDataset.
<P>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/metrics/FSDatasetMBean.html" title="org.apache.hadoop.hdfs.server.datanode.metrics 中的接口">FSDatasetMBean</A></CODE> 中的 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/metrics/FSDatasetMBean.html#getNumFailedVolumes()">getNumFailedVolumes</A></CODE></DL>
</DD>
<DD><DL>

<DT><B>返回：</B><DD>The number of failed volumes in the datanode.</DL>
</DD>
</DL>
<HR>

<A NAME="getLength(org.apache.hadoop.hdfs.protocol.Block)"><!-- --></A><H3>
getLength</H3>
<PRE>
public long <B>getLength</B>(<A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/Block.html" title="org.apache.hadoop.hdfs.protocol 中的类">Block</A>&nbsp;b)
               throws java.io.IOException</PRE>
<DL>
<DD>Find the block's on-disk length
<P>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.html" title="org.apache.hadoop.hdfs.server.datanode 中的接口">FSDatasetInterface</A></CODE> 中的 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.html#getLength(org.apache.hadoop.hdfs.protocol.Block)">getLength</A></CODE></DL>
</DD>
<DD><DL>

<DT><B>返回：</B><DD>the specified block's on-disk length (excluding metadta)
<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="getBlockFile(org.apache.hadoop.hdfs.protocol.Block)"><!-- --></A><H3>
getBlockFile</H3>
<PRE>
public java.io.File <B>getBlockFile</B>(<A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/Block.html" title="org.apache.hadoop.hdfs.protocol 中的类">Block</A>&nbsp;b)
                          throws java.io.IOException</PRE>
<DL>
<DD>Get File name for a given block.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="getBlockInputStream(org.apache.hadoop.hdfs.protocol.Block)"><!-- --></A><H3>
getBlockInputStream</H3>
<PRE>
public java.io.InputStream <B>getBlockInputStream</B>(<A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/Block.html" title="org.apache.hadoop.hdfs.protocol 中的类">Block</A>&nbsp;b)
                                        throws java.io.IOException</PRE>
<DL>
<DD><B>从接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.html#getBlockInputStream(org.apache.hadoop.hdfs.protocol.Block)">FSDatasetInterface</A></CODE> 复制的描述</B></DD>
<DD>Returns an input stream to read the contents of the specified block
<P>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.html" title="org.apache.hadoop.hdfs.server.datanode 中的接口">FSDatasetInterface</A></CODE> 中的 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.html#getBlockInputStream(org.apache.hadoop.hdfs.protocol.Block)">getBlockInputStream</A></CODE></DL>
</DD>
<DD><DL>

<DT><B>返回：</B><DD>an input stream to read the contents of the specified block
<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="getBlockInputStream(org.apache.hadoop.hdfs.protocol.Block, long)"><!-- --></A><H3>
getBlockInputStream</H3>
<PRE>
public java.io.InputStream <B>getBlockInputStream</B>(<A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/Block.html" title="org.apache.hadoop.hdfs.protocol 中的类">Block</A>&nbsp;b,
                                               long&nbsp;seekOffset)
                                        throws java.io.IOException</PRE>
<DL>
<DD><B>从接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.html#getBlockInputStream(org.apache.hadoop.hdfs.protocol.Block, long)">FSDatasetInterface</A></CODE> 复制的描述</B></DD>
<DD>Returns an input stream at specified offset of the specified block
<P>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.html" title="org.apache.hadoop.hdfs.server.datanode 中的接口">FSDatasetInterface</A></CODE> 中的 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.html#getBlockInputStream(org.apache.hadoop.hdfs.protocol.Block, long)">getBlockInputStream</A></CODE></DL>
</DD>
<DD><DL>

<DT><B>返回：</B><DD>an input stream to read the contents of the specified block,
  starting at the offset
<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="getTmpInputStreams(org.apache.hadoop.hdfs.protocol.Block, long, long)"><!-- --></A><H3>
getTmpInputStreams</H3>
<PRE>
public <A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.BlockInputStreams.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">FSDatasetInterface.BlockInputStreams</A> <B>getTmpInputStreams</B>(<A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/Block.html" title="org.apache.hadoop.hdfs.protocol 中的类">Block</A>&nbsp;b,
                                                               long&nbsp;blkOffset,
                                                               long&nbsp;ckoff)
                                                        throws java.io.IOException</PRE>
<DL>
<DD>Returns handles to the block file and its metadata file
<P>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.html" title="org.apache.hadoop.hdfs.server.datanode 中的接口">FSDatasetInterface</A></CODE> 中的 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.html#getTmpInputStreams(org.apache.hadoop.hdfs.protocol.Block, long, long)">getTmpInputStreams</A></CODE></DL>
</DD>
<DD><DL>

<DT><B>返回：</B><DD>an input stream to read the contents of the specified block,
  starting at the offset
<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="unlinkBlock(org.apache.hadoop.hdfs.protocol.Block, int)"><!-- --></A><H3>
unlinkBlock</H3>
<PRE>
public boolean <B>unlinkBlock</B>(<A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/Block.html" title="org.apache.hadoop.hdfs.protocol 中的类">Block</A>&nbsp;block,
                           int&nbsp;numLinks)
                    throws java.io.IOException</PRE>
<DL>
<DD>Make a copy of the block if this block is linked to an existing
 snapshot. This ensures that modifying this block does not modify
 data in any existing snapshots.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>参数：</B><DD><CODE>block</CODE> - Block<DD><CODE>numLinks</CODE> - Unlink if the number of links exceed this value
<DT><B>返回：</B><DD>- true if the specified block was unlinked or the block
           is not in any snapshot.
<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="append(org.apache.hadoop.hdfs.protocol.Block, long, long)"><!-- --></A><H3>
append</H3>
<PRE>
public org.apache.hadoop.hdfs.server.datanode.ReplicaInPipelineInterface <B>append</B>(<A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/Block.html" title="org.apache.hadoop.hdfs.protocol 中的类">Block</A>&nbsp;b,
                                                                                long&nbsp;newGS,
                                                                                long&nbsp;expectedBlockLen)
                                                                         throws java.io.IOException</PRE>
<DL>
<DD><B>从接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.html#append(org.apache.hadoop.hdfs.protocol.Block, long, long)">FSDatasetInterface</A></CODE> 复制的描述</B></DD>
<DD>Append to a finalized replica and returns the meta info of the replica
<P>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.html" title="org.apache.hadoop.hdfs.server.datanode 中的接口">FSDatasetInterface</A></CODE> 中的 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.html#append(org.apache.hadoop.hdfs.protocol.Block, long, long)">append</A></CODE></DL>
</DD>
<DD><DL>
<DT><B>参数：</B><DD><CODE>b</CODE> - block<DD><CODE>newGS</CODE> - the new generation stamp for the replica<DD><CODE>expectedBlockLen</CODE> - the number of bytes the replica is expected to have
<DT><B>返回：</B><DD>the meata info of the replica which is being written to
<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="recoverAppend(org.apache.hadoop.hdfs.protocol.Block, long, long)"><!-- --></A><H3>
recoverAppend</H3>
<PRE>
public org.apache.hadoop.hdfs.server.datanode.ReplicaInPipelineInterface <B>recoverAppend</B>(<A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/Block.html" title="org.apache.hadoop.hdfs.protocol 中的类">Block</A>&nbsp;b,
                                                                                       long&nbsp;newGS,
                                                                                       long&nbsp;expectedBlockLen)
                                                                                throws java.io.IOException</PRE>
<DL>
<DD><B>从接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.html#recoverAppend(org.apache.hadoop.hdfs.protocol.Block, long, long)">FSDatasetInterface</A></CODE> 复制的描述</B></DD>
<DD>Recover a failed append to a finalized replica
 and returns the meta info of the replica
<P>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.html" title="org.apache.hadoop.hdfs.server.datanode 中的接口">FSDatasetInterface</A></CODE> 中的 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.html#recoverAppend(org.apache.hadoop.hdfs.protocol.Block, long, long)">recoverAppend</A></CODE></DL>
</DD>
<DD><DL>
<DT><B>参数：</B><DD><CODE>b</CODE> - block<DD><CODE>newGS</CODE> - the new generation stamp for the replica<DD><CODE>expectedBlockLen</CODE> - the number of bytes the replica is expected to have
<DT><B>返回：</B><DD>the meta info of the replica which is being written to
<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="recoverClose(org.apache.hadoop.hdfs.protocol.Block, long, long)"><!-- --></A><H3>
recoverClose</H3>
<PRE>
public void <B>recoverClose</B>(<A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/Block.html" title="org.apache.hadoop.hdfs.protocol 中的类">Block</A>&nbsp;b,
                         long&nbsp;newGS,
                         long&nbsp;expectedBlockLen)
                  throws java.io.IOException</PRE>
<DL>
<DD><B>从接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.html#recoverClose(org.apache.hadoop.hdfs.protocol.Block, long, long)">FSDatasetInterface</A></CODE> 复制的描述</B></DD>
<DD>Recover a failed pipeline close
 It bumps the replica's generation stamp and finalize it if RBW replica
<P>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.html" title="org.apache.hadoop.hdfs.server.datanode 中的接口">FSDatasetInterface</A></CODE> 中的 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.html#recoverClose(org.apache.hadoop.hdfs.protocol.Block, long, long)">recoverClose</A></CODE></DL>
</DD>
<DD><DL>
<DT><B>参数：</B><DD><CODE>b</CODE> - block<DD><CODE>newGS</CODE> - the new generation stamp for the replica<DD><CODE>expectedBlockLen</CODE> - the number of bytes the replica is expected to have
<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="createRbw(org.apache.hadoop.hdfs.protocol.Block)"><!-- --></A><H3>
createRbw</H3>
<PRE>
public org.apache.hadoop.hdfs.server.datanode.ReplicaInPipelineInterface <B>createRbw</B>(<A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/Block.html" title="org.apache.hadoop.hdfs.protocol 中的类">Block</A>&nbsp;b)
                                                                            throws java.io.IOException</PRE>
<DL>
<DD><B>从接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.html#createRbw(org.apache.hadoop.hdfs.protocol.Block)">FSDatasetInterface</A></CODE> 复制的描述</B></DD>
<DD>Creates a RBW replica and returns the meta info of the replica
<P>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.html" title="org.apache.hadoop.hdfs.server.datanode 中的接口">FSDatasetInterface</A></CODE> 中的 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.html#createRbw(org.apache.hadoop.hdfs.protocol.Block)">createRbw</A></CODE></DL>
</DD>
<DD><DL>
<DT><B>参数：</B><DD><CODE>b</CODE> - block
<DT><B>返回：</B><DD>the meta info of the replica which is being written to
<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE> - if an error occurs</DL>
</DD>
</DL>
<HR>

<A NAME="recoverRbw(org.apache.hadoop.hdfs.protocol.Block, long, long, long)"><!-- --></A><H3>
recoverRbw</H3>
<PRE>
public org.apache.hadoop.hdfs.server.datanode.ReplicaInPipelineInterface <B>recoverRbw</B>(<A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/Block.html" title="org.apache.hadoop.hdfs.protocol 中的类">Block</A>&nbsp;b,
                                                                                    long&nbsp;newGS,
                                                                                    long&nbsp;minBytesRcvd,
                                                                                    long&nbsp;maxBytesRcvd)
                                                                             throws java.io.IOException</PRE>
<DL>
<DD><B>从接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.html#recoverRbw(org.apache.hadoop.hdfs.protocol.Block, long, long, long)">FSDatasetInterface</A></CODE> 复制的描述</B></DD>
<DD>Recovers a RBW replica and returns the meta info of the replica
<P>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.html" title="org.apache.hadoop.hdfs.server.datanode 中的接口">FSDatasetInterface</A></CODE> 中的 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.html#recoverRbw(org.apache.hadoop.hdfs.protocol.Block, long, long, long)">recoverRbw</A></CODE></DL>
</DD>
<DD><DL>
<DT><B>参数：</B><DD><CODE>b</CODE> - block<DD><CODE>newGS</CODE> - the new generation stamp for the replica<DD><CODE>minBytesRcvd</CODE> - the minimum number of bytes that the replica could have<DD><CODE>maxBytesRcvd</CODE> - the maximum number of bytes that the replica could have
<DT><B>返回：</B><DD>the meta info of the replica which is being written to
<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE> - if an error occurs</DL>
</DD>
</DL>
<HR>

<A NAME="createTemporary(org.apache.hadoop.hdfs.protocol.Block)"><!-- --></A><H3>
createTemporary</H3>
<PRE>
public org.apache.hadoop.hdfs.server.datanode.ReplicaInPipelineInterface <B>createTemporary</B>(<A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/Block.html" title="org.apache.hadoop.hdfs.protocol 中的类">Block</A>&nbsp;b)
                                                                                  throws java.io.IOException</PRE>
<DL>
<DD><B>从接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.html#createTemporary(org.apache.hadoop.hdfs.protocol.Block)">FSDatasetInterface</A></CODE> 复制的描述</B></DD>
<DD>Creates a temporary replica and returns the meta information of the replica
<P>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.html" title="org.apache.hadoop.hdfs.server.datanode 中的接口">FSDatasetInterface</A></CODE> 中的 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.html#createTemporary(org.apache.hadoop.hdfs.protocol.Block)">createTemporary</A></CODE></DL>
</DD>
<DD><DL>
<DT><B>参数：</B><DD><CODE>b</CODE> - block
<DT><B>返回：</B><DD>the meta info of the replica which is being written to
<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE> - if an error occurs</DL>
</DD>
</DL>
<HR>

<A NAME="adjustCrcChannelPosition(org.apache.hadoop.hdfs.protocol.Block, org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface.BlockWriteStreams, int)"><!-- --></A><H3>
adjustCrcChannelPosition</H3>
<PRE>
public void <B>adjustCrcChannelPosition</B>(<A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/Block.html" title="org.apache.hadoop.hdfs.protocol 中的类">Block</A>&nbsp;b,
                                     <A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.BlockWriteStreams.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">FSDatasetInterface.BlockWriteStreams</A>&nbsp;streams,
                                     int&nbsp;checksumSize)
                              throws java.io.IOException</PRE>
<DL>
<DD>Sets the offset in the meta file so that the
 last checksum will be overwritten.
<P>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.html" title="org.apache.hadoop.hdfs.server.datanode 中的接口">FSDatasetInterface</A></CODE> 中的 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.html#adjustCrcChannelPosition(org.apache.hadoop.hdfs.protocol.Block, org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface.BlockWriteStreams, int)">adjustCrcChannelPosition</A></CODE></DL>
</DD>
<DD><DL>
<DT><B>参数：</B><DD><CODE>b</CODE> - block<DD><CODE>streams</CODE> - The stream for the data file and checksum file<DD><CODE>checksumSize</CODE> - number of bytes each checksum has
<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="finalizeBlock(org.apache.hadoop.hdfs.protocol.Block)"><!-- --></A><H3>
finalizeBlock</H3>
<PRE>
public void <B>finalizeBlock</B>(<A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/Block.html" title="org.apache.hadoop.hdfs.protocol 中的类">Block</A>&nbsp;b)
                   throws java.io.IOException</PRE>
<DL>
<DD>Complete the block write!
<P>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.html" title="org.apache.hadoop.hdfs.server.datanode 中的接口">FSDatasetInterface</A></CODE> 中的 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.html#finalizeBlock(org.apache.hadoop.hdfs.protocol.Block)">finalizeBlock</A></CODE></DL>
</DD>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="unfinalizeBlock(org.apache.hadoop.hdfs.protocol.Block)"><!-- --></A><H3>
unfinalizeBlock</H3>
<PRE>
public void <B>unfinalizeBlock</B>(<A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/Block.html" title="org.apache.hadoop.hdfs.protocol 中的类">Block</A>&nbsp;b)
                     throws java.io.IOException</PRE>
<DL>
<DD>Remove the temporary block file (if any)
<P>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.html" title="org.apache.hadoop.hdfs.server.datanode 中的接口">FSDatasetInterface</A></CODE> 中的 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.html#unfinalizeBlock(org.apache.hadoop.hdfs.protocol.Block)">unfinalizeBlock</A></CODE></DL>
</DD>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="getBlockReport()"><!-- --></A><H3>
getBlockReport</H3>
<PRE>
public <A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/BlockListAsLongs.html" title="org.apache.hadoop.hdfs.protocol 中的类">BlockListAsLongs</A> <B>getBlockReport</B>()</PRE>
<DL>
<DD>Generates a block report from the in-memory block map.
<P>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.html" title="org.apache.hadoop.hdfs.server.datanode 中的接口">FSDatasetInterface</A></CODE> 中的 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.html#getBlockReport()">getBlockReport</A></CODE></DL>
</DD>
<DD><DL>

<DT><B>返回：</B><DD>- the block report - the full list of blocks stored</DL>
</DD>
</DL>
<HR>

<A NAME="isValidBlock(org.apache.hadoop.hdfs.protocol.Block)"><!-- --></A><H3>
isValidBlock</H3>
<PRE>
public boolean <B>isValidBlock</B>(<A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/Block.html" title="org.apache.hadoop.hdfs.protocol 中的类">Block</A>&nbsp;b)</PRE>
<DL>
<DD>Check whether the given block is a valid one.
 valid means finalized
<P>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.html" title="org.apache.hadoop.hdfs.server.datanode 中的接口">FSDatasetInterface</A></CODE> 中的 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.html#isValidBlock(org.apache.hadoop.hdfs.protocol.Block)">isValidBlock</A></CODE></DL>
</DD>
<DD><DL>

<DT><B>返回：</B><DD>- true if the specified block is valid</DL>
</DD>
</DL>
<HR>

<A NAME="invalidate(org.apache.hadoop.hdfs.protocol.Block[])"><!-- --></A><H3>
invalidate</H3>
<PRE>
public void <B>invalidate</B>(<A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/Block.html" title="org.apache.hadoop.hdfs.protocol 中的类">Block</A>[]&nbsp;invalidBlks)
                throws java.io.IOException</PRE>
<DL>
<DD>We're informed that a block is no longer valid.  We
 could lazily garbage-collect the block, but why bother?
 just get rid of it.
<P>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.html" title="org.apache.hadoop.hdfs.server.datanode 中的接口">FSDatasetInterface</A></CODE> 中的 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.html#invalidate(org.apache.hadoop.hdfs.protocol.Block[])">invalidate</A></CODE></DL>
</DD>
<DD><DL>
<DT><B>参数：</B><DD><CODE>invalidBlks</CODE> - - the blocks to be invalidated
<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="getFile(org.apache.hadoop.hdfs.protocol.Block)"><!-- --></A><H3>
getFile</H3>
<PRE>
public java.io.File <B>getFile</B>(<A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/Block.html" title="org.apache.hadoop.hdfs.protocol 中的类">Block</A>&nbsp;b)</PRE>
<DL>
<DD>Turn the block identifier into a filename; ignore generation stamp!!!
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
</DL>
</DD>
</DL>
<HR>

<A NAME="checkDataDir()"><!-- --></A><H3>
checkDataDir</H3>
<PRE>
public void <B>checkDataDir</B>()
                  throws org.apache.hadoop.util.DiskChecker.DiskErrorException</PRE>
<DL>
<DD>check if a data directory is healthy
 if some volumes failed - make sure to remove all the blocks that belong
 to these volumes
<P>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.html" title="org.apache.hadoop.hdfs.server.datanode 中的接口">FSDatasetInterface</A></CODE> 中的 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.html#checkDataDir()">checkDataDir</A></CODE></DL>
</DD>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>org.apache.hadoop.util.DiskChecker.DiskErrorException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="toString()"><!-- --></A><H3>
toString</H3>
<PRE>
public java.lang.String <B>toString</B>()</PRE>
<DL>
<DD><B>从接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.html#toString()">FSDatasetInterface</A></CODE> 复制的描述</B></DD>
<DD>Stringifies the name of the storage
<P>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.html" title="org.apache.hadoop.hdfs.server.datanode 中的接口">FSDatasetInterface</A></CODE> 中的 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.html#toString()">toString</A></CODE><DT><B>覆盖：</B><DD>类 <CODE>java.lang.Object</CODE> 中的 <CODE>toString</CODE></DL>
</DD>
<DD><DL>
</DL>
</DD>
</DL>
<HR>

<A NAME="shutdown()"><!-- --></A><H3>
shutdown</H3>
<PRE>
public void <B>shutdown</B>()</PRE>
<DL>
<DD><B>从接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.html#shutdown()">FSDatasetInterface</A></CODE> 复制的描述</B></DD>
<DD>Shutdown the FSDataset
<P>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.html" title="org.apache.hadoop.hdfs.server.datanode 中的接口">FSDatasetInterface</A></CODE> 中的 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.html#shutdown()">shutdown</A></CODE></DL>
</DD>
<DD><DL>
</DL>
</DD>
</DL>
<HR>

<A NAME="getStorageInfo()"><!-- --></A><H3>
getStorageInfo</H3>
<PRE>
public java.lang.String <B>getStorageInfo</B>()</PRE>
<DL>
<DD><B>从接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/metrics/FSDatasetMBean.html#getStorageInfo()">FSDatasetMBean</A></CODE> 复制的描述</B></DD>
<DD>Returns the storage id of the underlying storage
<P>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/metrics/FSDatasetMBean.html" title="org.apache.hadoop.hdfs.server.datanode.metrics 中的接口">FSDatasetMBean</A></CODE> 中的 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/metrics/FSDatasetMBean.html#getStorageInfo()">getStorageInfo</A></CODE></DL>
</DD>
<DD><DL>
</DL>
</DD>
</DL>
<HR>

<A NAME="checkAndUpdate(long, java.io.File, java.io.File, org.apache.hadoop.hdfs.server.datanode.FSDataset.FSVolume)"><!-- --></A><H3>
checkAndUpdate</H3>
<PRE>
public void <B>checkAndUpdate</B>(long&nbsp;blockId,
                           java.io.File&nbsp;diskFile,
                           java.io.File&nbsp;diskMetaFile,
                           org.apache.hadoop.hdfs.server.datanode.FSDataset.FSVolume&nbsp;vol)</PRE>
<DL>
<DD>Reconcile the difference between blocks on the disk and blocks in
 volumeMap

 Check the given block for inconsistencies. Look at the
 current state of the block and reconcile the differences as follows:
 <ul>
 <li>If the block file is missing, delete the block from volumeMap</li>
 <li>If the block file exists and the block is missing in volumeMap,
 add the block to volumeMap <li>
 <li>If generation stamp does not match, then update the block with right
 generation stamp</li>
 <li>If the block length in memory does not match the actual block file length
 then mark the block as corrupt and update the block length in memory</li>
 <li>If the file in <A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/ReplicaInfo.html" title="org.apache.hadoop.hdfs.server.datanode 中的类"><CODE>ReplicaInfo</CODE></A> does not match the file on
 the disk, update <A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/ReplicaInfo.html" title="org.apache.hadoop.hdfs.server.datanode 中的类"><CODE>ReplicaInfo</CODE></A> with the correct file</li>
 </ul>
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>参数：</B><DD><CODE>blockId</CODE> - Block that differs<DD><CODE>diskFile</CODE> - Block file on the disk<DD><CODE>diskMetaFile</CODE> - Metadata file from on the disk<DD><CODE>vol</CODE> - Volume of the block file</DL>
</DD>
</DL>
<HR>

<A NAME="getReplica(long)"><!-- --></A><H3>
getReplica</H3>
<PRE>
<FONT SIZE="-1">@Deprecated
</FONT>public <A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/ReplicaInfo.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">ReplicaInfo</A> <B>getReplica</B>(long&nbsp;blockId)</PRE>
<DL>
<DD><B>已过时。</B>&nbsp;<I>use <A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/FSDataset.html#fetchReplicaInfo(long)"><CODE>fetchReplicaInfo(long)</CODE></A> instead.</I>
<P>
<DD><B>从接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.html#getReplica(long)">FSDatasetInterface</A></CODE> 复制的描述</B></DD>
<DD>Get reference to the replica meta info in the replicasMap. 
 To be called from methods that are synchronized on <A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/FSDataset.html" title="org.apache.hadoop.hdfs.server.datanode 中的类"><CODE>FSDataset</CODE></A>
<P>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.html" title="org.apache.hadoop.hdfs.server.datanode 中的接口">FSDatasetInterface</A></CODE> 中的 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.html#getReplica(long)">getReplica</A></CODE></DL>
</DD>
<DD><DL>

<DT><B>返回：</B><DD>replica from the replicas map</DL>
</DD>
</DL>
<HR>

<A NAME="initReplicaRecovery(org.apache.hadoop.hdfs.server.protocol.BlockRecoveryCommand.RecoveringBlock)"><!-- --></A><H3>
initReplicaRecovery</H3>
<PRE>
public <A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/ReplicaRecoveryInfo.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">ReplicaRecoveryInfo</A> <B>initReplicaRecovery</B>(<A HREF="../../../../../../org/apache/hadoop/hdfs/server/protocol/BlockRecoveryCommand.RecoveringBlock.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">BlockRecoveryCommand.RecoveringBlock</A>&nbsp;rBlock)
                                        throws java.io.IOException</PRE>
<DL>
<DD><B>从接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.html#initReplicaRecovery(org.apache.hadoop.hdfs.server.protocol.BlockRecoveryCommand.RecoveringBlock)">FSDatasetInterface</A></CODE> 复制的描述</B></DD>
<DD>Initialize a replica recovery.
<P>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.html" title="org.apache.hadoop.hdfs.server.datanode 中的接口">FSDatasetInterface</A></CODE> 中的 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.html#initReplicaRecovery(org.apache.hadoop.hdfs.server.protocol.BlockRecoveryCommand.RecoveringBlock)">initReplicaRecovery</A></CODE></DL>
</DD>
<DD><DL>

<DT><B>返回：</B><DD>actual state of the replica on this data-node or 
 null if data-node does not have the replica.
<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="updateReplicaUnderRecovery(org.apache.hadoop.hdfs.protocol.Block, long, long)"><!-- --></A><H3>
updateReplicaUnderRecovery</H3>
<PRE>
public <A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/ReplicaInfo.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">ReplicaInfo</A> <B>updateReplicaUnderRecovery</B>(<A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/Block.html" title="org.apache.hadoop.hdfs.protocol 中的类">Block</A>&nbsp;oldBlock,
                                              long&nbsp;recoveryId,
                                              long&nbsp;newlength)
                                       throws java.io.IOException</PRE>
<DL>
<DD><B>从接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.html#updateReplicaUnderRecovery(org.apache.hadoop.hdfs.protocol.Block, long, long)">FSDatasetInterface</A></CODE> 复制的描述</B></DD>
<DD>Update replica's generation stamp and length and finalize it.
<P>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.html" title="org.apache.hadoop.hdfs.server.datanode 中的接口">FSDatasetInterface</A></CODE> 中的 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.html#updateReplicaUnderRecovery(org.apache.hadoop.hdfs.protocol.Block, long, long)">updateReplicaUnderRecovery</A></CODE></DL>
</DD>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="getReplicaVisibleLength(org.apache.hadoop.hdfs.protocol.Block)"><!-- --></A><H3>
getReplicaVisibleLength</H3>
<PRE>
public long <B>getReplicaVisibleLength</B>(<A HREF="../../../../../../org/apache/hadoop/hdfs/protocol/Block.html" title="org.apache.hadoop.hdfs.protocol 中的类">Block</A>&nbsp;block)
                             throws java.io.IOException</PRE>
<DL>
<DD><B>从接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.html#getReplicaVisibleLength(org.apache.hadoop.hdfs.protocol.Block)">FSDatasetInterface</A></CODE> 复制的描述</B></DD>
<DD>Get visible length of the specified replica.
<P>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.html" title="org.apache.hadoop.hdfs.server.datanode 中的接口">FSDatasetInterface</A></CODE> 中的 <CODE><A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.html#getReplicaVisibleLength(org.apache.hadoop.hdfs.protocol.Block)">getReplicaVisibleLength</A></CODE></DL>
</DD>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<!-- ========= END OF CLASS DATA ========= -->
<HR>


<!-- ======= START OF BOTTOM NAVBAR ====== -->
<A NAME="navbar_bottom"><!-- --></A>
<A HREF="#skip-navbar_bottom" title="跳过导航链接"></A>
<TABLE BORDER="0" WIDTH="100%" CELLPADDING="1" CELLSPACING="0" SUMMARY="">
<TR>
<TD COLSPAN=2 BGCOLOR="#EEEEFF" CLASS="NavBarCell1">
<A NAME="navbar_bottom_firstrow"><!-- --></A>
<TABLE BORDER="0" CELLPADDING="0" CELLSPACING="3" SUMMARY="">
  <TR ALIGN="center" VALIGN="top">
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="../../../../../../overview-summary.html"><FONT CLASS="NavBarFont1"><B>概述</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="package-summary.html"><FONT CLASS="NavBarFont1"><B>软件包</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#FFFFFF" CLASS="NavBarCell1Rev"> &nbsp;<FONT CLASS="NavBarFont1Rev"><B>类</B></FONT>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="class-use/FSDataset.html"><FONT CLASS="NavBarFont1"><B>使用</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="package-tree.html"><FONT CLASS="NavBarFont1"><B>树</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="../../../../../../deprecated-list.html"><FONT CLASS="NavBarFont1"><B>已过时</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="../../../../../../index-all.html"><FONT CLASS="NavBarFont1"><B>索引</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="../../../../../../help-doc.html"><FONT CLASS="NavBarFont1"><B>帮助</B></FONT></A>&nbsp;</TD>
  </TR>
</TABLE>
</TD>
<TD ALIGN="right" VALIGN="top" ROWSPAN=3><EM>
</EM>
</TD>
</TR>

<TR>
<TD BGCOLOR="white" CLASS="NavBarCell2"><FONT SIZE="-2">
&nbsp;<A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/DirectoryScanner.html" title="org.apache.hadoop.hdfs.server.datanode 中的类"><B>上一个类</B></A>&nbsp;
&nbsp;<A HREF="../../../../../../org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.html" title="org.apache.hadoop.hdfs.server.datanode 中的接口"><B>下一个类</B></A></FONT></TD>
<TD BGCOLOR="white" CLASS="NavBarCell2"><FONT SIZE="-2">
  <A HREF="../../../../../../index.html?org/apache/hadoop/hdfs/server/datanode/FSDataset.html" target="_top"><B>框架</B></A>  &nbsp;
&nbsp;<A HREF="FSDataset.html" target="_top"><B>无框架</B></A>  &nbsp;
&nbsp;<SCRIPT type="text/javascript">
  <!--
  if(window==top) {
    document.writeln('<A HREF="../../../../../../allclasses-noframe.html"><B>所有类</B></A>');
  }
  //-->
</SCRIPT>
<NOSCRIPT>
  <A HREF="../../../../../../allclasses-noframe.html"><B>所有类</B></A>
</NOSCRIPT>


</FONT></TD>
</TR>
<TR>
<TD VALIGN="top" CLASS="NavBarCell3"><FONT SIZE="-2">
  摘要：&nbsp;嵌套&nbsp;|&nbsp;<A HREF="#field_summary">字段</A>&nbsp;|&nbsp;<A HREF="#constructor_summary">构造方法</A>&nbsp;|&nbsp;<A HREF="#method_summary">方法</A></FONT></TD>
<TD VALIGN="top" CLASS="NavBarCell3"><FONT SIZE="-2">
详细信息：&nbsp;<A HREF="#field_detail">字段</A>&nbsp;|&nbsp;<A HREF="#constructor_detail">构造方法</A>&nbsp;|&nbsp;<A HREF="#method_detail">方法</A></FONT></TD>
</TR>
</TABLE>
<A NAME="skip-navbar_bottom"></A>
<!-- ======== END OF BOTTOM NAVBAR ======= -->

<HR>
Copyright &copy; 2009 The Apache Software Foundation
</BODY>
</HTML>
