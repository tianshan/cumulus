<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<!--NewPage-->
<HTML>
<HEAD>
<!-- Generated by javadoc (build 1.6.0_18) on Sun May 03 20:19:34 CST 2015 -->
<TITLE>
DistributedFileSystem (Hadoop-Hdfs 0.22.1-SNAPSHOT API)
</TITLE>

<META NAME="date" CONTENT="2015-05-03">

<LINK REL ="stylesheet" TYPE="text/css" HREF="../../../../stylesheet.css" TITLE="Style">

<SCRIPT type="text/javascript">
function windowTitle()
{
    if (location.href.indexOf('is-external=true') == -1) {
        parent.document.title="DistributedFileSystem (Hadoop-Hdfs 0.22.1-SNAPSHOT API)";
    }
}
</SCRIPT>
<NOSCRIPT>
</NOSCRIPT>

</HEAD>

<BODY BGCOLOR="white" onload="windowTitle();">
<HR>


<!-- ========= START OF TOP NAVBAR ======= -->
<A NAME="navbar_top"><!-- --></A>
<A HREF="#skip-navbar_top" title="跳过导航链接"></A>
<TABLE BORDER="0" WIDTH="100%" CELLPADDING="1" CELLSPACING="0" SUMMARY="">
<TR>
<TD COLSPAN=2 BGCOLOR="#EEEEFF" CLASS="NavBarCell1">
<A NAME="navbar_top_firstrow"><!-- --></A>
<TABLE BORDER="0" CELLPADDING="0" CELLSPACING="3" SUMMARY="">
  <TR ALIGN="center" VALIGN="top">
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="../../../../overview-summary.html"><FONT CLASS="NavBarFont1"><B>概述</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="package-summary.html"><FONT CLASS="NavBarFont1"><B>软件包</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#FFFFFF" CLASS="NavBarCell1Rev"> &nbsp;<FONT CLASS="NavBarFont1Rev"><B>类</B></FONT>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="class-use/DistributedFileSystem.html"><FONT CLASS="NavBarFont1"><B>使用</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="package-tree.html"><FONT CLASS="NavBarFont1"><B>树</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="../../../../deprecated-list.html"><FONT CLASS="NavBarFont1"><B>已过时</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="../../../../index-all.html"><FONT CLASS="NavBarFont1"><B>索引</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="../../../../help-doc.html"><FONT CLASS="NavBarFont1"><B>帮助</B></FONT></A>&nbsp;</TD>
  </TR>
</TABLE>
</TD>
<TD ALIGN="right" VALIGN="top" ROWSPAN=3><EM>
</EM>
</TD>
</TR>

<TR>
<TD BGCOLOR="white" CLASS="NavBarCell2"><FONT SIZE="-2">
&nbsp;<A HREF="../../../../org/apache/hadoop/hdfs/DFSUtil.ErrorSimulator.html" title="org.apache.hadoop.hdfs 中的类"><B>上一个类</B></A>&nbsp;
&nbsp;<A HREF="../../../../org/apache/hadoop/hdfs/DistributedFileSystem.DiskStatus.html" title="org.apache.hadoop.hdfs 中的类"><B>下一个类</B></A></FONT></TD>
<TD BGCOLOR="white" CLASS="NavBarCell2"><FONT SIZE="-2">
  <A HREF="../../../../index.html?org/apache/hadoop/hdfs/DistributedFileSystem.html" target="_top"><B>框架</B></A>  &nbsp;
&nbsp;<A HREF="DistributedFileSystem.html" target="_top"><B>无框架</B></A>  &nbsp;
&nbsp;<SCRIPT type="text/javascript">
  <!--
  if(window==top) {
    document.writeln('<A HREF="../../../../allclasses-noframe.html"><B>所有类</B></A>');
  }
  //-->
</SCRIPT>
<NOSCRIPT>
  <A HREF="../../../../allclasses-noframe.html"><B>所有类</B></A>
</NOSCRIPT>


</FONT></TD>
</TR>
<TR>
<TD VALIGN="top" CLASS="NavBarCell3"><FONT SIZE="-2">
  摘要：&nbsp;<A HREF="#nested_class_summary">嵌套</A>&nbsp;|&nbsp;<A HREF="#fields_inherited_from_class_org.apache.hadoop.fs.FileSystem">字段</A>&nbsp;|&nbsp;<A HREF="#constructor_summary">构造方法</A>&nbsp;|&nbsp;<A HREF="#method_summary">方法</A></FONT></TD>
<TD VALIGN="top" CLASS="NavBarCell3"><FONT SIZE="-2">
详细信息：&nbsp;字段&nbsp;|&nbsp;<A HREF="#constructor_detail">构造方法</A>&nbsp;|&nbsp;<A HREF="#method_detail">方法</A></FONT></TD>
</TR>
</TABLE>
<A NAME="skip-navbar_top"></A>
<!-- ========= END OF TOP NAVBAR ========= -->

<HR>
<!-- ======== START OF CLASS DATA ======== -->
<H2>
<FONT SIZE="-1">
org.apache.hadoop.hdfs</FONT>
<BR>
类 DistributedFileSystem</H2>
<PRE>
java.lang.Object
  <IMG SRC="../../../../resources/inherit.gif" ALT="继承者 ">org.apache.hadoop.conf.Configured
      <IMG SRC="../../../../resources/inherit.gif" ALT="继承者 ">org.apache.hadoop.fs.FileSystem
          <IMG SRC="../../../../resources/inherit.gif" ALT="继承者 "><B>org.apache.hadoop.hdfs.DistributedFileSystem</B>
</PRE>
<DL>
<DT><B>所有已实现的接口：</B> <DD>java.io.Closeable, org.apache.hadoop.conf.Configurable</DD>
</DL>
<HR>
<DL>
<DT><PRE><FONT SIZE="-1">@InterfaceAudience.Private
@InterfaceStability.Evolving
</FONT>public class <B>DistributedFileSystem</B><DT>extends org.apache.hadoop.fs.FileSystem</DL>
</PRE>

<P>
Implementation of the abstract FileSystem for the DFS system.
 This object is the way end-user code interacts with a Hadoop
 DistributedFileSystem.
<P>

<P>
<HR>

<P>
<!-- ======== NESTED CLASS SUMMARY ======== -->

<A NAME="nested_class_summary"><!-- --></A>
<TABLE BORDER="1" WIDTH="100%" CELLPADDING="3" CELLSPACING="0" SUMMARY="">
<TR BGCOLOR="#CCCCFF" CLASS="TableHeadingColor">
<TH ALIGN="left" COLSPAN="2"><FONT SIZE="+2">
<B>嵌套类摘要</B></FONT></TH>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;class</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/hadoop/hdfs/DistributedFileSystem.DiskStatus.html" title="org.apache.hadoop.hdfs 中的类">DistributedFileSystem.DiskStatus</A></B></CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<B>已过时。</B>&nbsp;<I>Use <CODE>FsStatus</CODE> instead</I></TD>
</TR>
</TABLE>
&nbsp;<A NAME="nested_classes_inherited_from_class_org.apache.hadoop.fs.FileSystem"><!-- --></A>
<TABLE BORDER="1" WIDTH="100%" CELLPADDING="3" CELLSPACING="0" SUMMARY="">
<TR BGCOLOR="#EEEEFF" CLASS="TableSubHeadingColor">
<TH ALIGN="left"><B>从类 org.apache.hadoop.fs.FileSystem 继承的嵌套类/接口</B></TH>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD><CODE>org.apache.hadoop.fs.FileSystem.Statistics</CODE></TD>
</TR>
</TABLE>
&nbsp;
<!-- =========== FIELD SUMMARY =========== -->

<A NAME="field_summary"><!-- --></A>
<TABLE BORDER="1" WIDTH="100%" CELLPADDING="3" CELLSPACING="0" SUMMARY="">
<TR BGCOLOR="#CCCCFF" CLASS="TableHeadingColor">
<TH ALIGN="left" COLSPAN="2"><FONT SIZE="+2">
<B>字段摘要</B></FONT></TH>
</TR>
</TABLE>
&nbsp;<A NAME="fields_inherited_from_class_org.apache.hadoop.fs.FileSystem"><!-- --></A>
<TABLE BORDER="1" WIDTH="100%" CELLPADDING="3" CELLSPACING="0" SUMMARY="">
<TR BGCOLOR="#EEEEFF" CLASS="TableSubHeadingColor">
<TH ALIGN="left"><B>从类 org.apache.hadoop.fs.FileSystem 继承的字段</B></TH>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD><CODE>DEFAULT_FS, FS_DEFAULT_NAME_KEY, LOG, statistics</CODE></TD>
</TR>
</TABLE>
&nbsp;
<!-- ======== CONSTRUCTOR SUMMARY ======== -->

<A NAME="constructor_summary"><!-- --></A>
<TABLE BORDER="1" WIDTH="100%" CELLPADDING="3" CELLSPACING="0" SUMMARY="">
<TR BGCOLOR="#CCCCFF" CLASS="TableHeadingColor">
<TH ALIGN="left" COLSPAN="2"><FONT SIZE="+2">
<B>构造方法摘要</B></FONT></TH>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD><CODE><B><A HREF="../../../../org/apache/hadoop/hdfs/DistributedFileSystem.html#DistributedFileSystem()">DistributedFileSystem</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD><CODE><B><A HREF="../../../../org/apache/hadoop/hdfs/DistributedFileSystem.html#DistributedFileSystem(java.net.InetSocketAddress, org.apache.hadoop.conf.Configuration)">DistributedFileSystem</A></B>(java.net.InetSocketAddress&nbsp;namenode,
                      org.apache.hadoop.conf.Configuration&nbsp;conf)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<B>已过时。</B>&nbsp;</TD>
</TR>
</TABLE>
&nbsp;
<!-- ========== METHOD SUMMARY =========== -->

<A NAME="method_summary"><!-- --></A>
<TABLE BORDER="1" WIDTH="100%" CELLPADDING="3" CELLSPACING="0" SUMMARY="">
<TR BGCOLOR="#CCCCFF" CLASS="TableHeadingColor">
<TH ALIGN="left" COLSPAN="2"><FONT SIZE="+2">
<B>方法摘要</B></FONT></TH>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;org.apache.hadoop.fs.FSDataOutputStream</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/hadoop/hdfs/DistributedFileSystem.html#append(org.apache.hadoop.fs.Path, int, org.apache.hadoop.util.Progressable)">append</A></B>(org.apache.hadoop.fs.Path&nbsp;f,
       int&nbsp;bufferSize,
       org.apache.hadoop.util.Progressable&nbsp;progress)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;This optional operation is not yet supported.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;void</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/hadoop/hdfs/DistributedFileSystem.html#cancelDelegationToken(org.apache.hadoop.security.token.Token)">cancelDelegationToken</A></B>(org.apache.hadoop.security.token.Token&lt;<A HREF="../../../../org/apache/hadoop/hdfs/security/token/delegation/DelegationTokenIdentifier.html" title="org.apache.hadoop.hdfs.security.token.delegation 中的类">DelegationTokenIdentifier</A>&gt;&nbsp;token)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Cancel an existing delegation token.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>protected &nbsp;void</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/hadoop/hdfs/DistributedFileSystem.html#checkPath(org.apache.hadoop.fs.Path)">checkPath</A></B>(org.apache.hadoop.fs.Path&nbsp;path)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Permit paths which explicitly specify the default port.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;void</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/hadoop/hdfs/DistributedFileSystem.html#close()">close</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;void</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/hadoop/hdfs/DistributedFileSystem.html#concat(org.apache.hadoop.fs.Path, org.apache.hadoop.fs.Path[])">concat</A></B>(org.apache.hadoop.fs.Path&nbsp;trg,
       org.apache.hadoop.fs.Path[]&nbsp;psrcs)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;THIS IS DFS only operations, it is not part of FileSystem
 move blocks from srcs to trg
 and delete srcs afterwards
 all blocks should be the same size</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;org.apache.hadoop.fs.FSDataOutputStream</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/hadoop/hdfs/DistributedFileSystem.html#create(org.apache.hadoop.fs.Path, org.apache.hadoop.fs.permission.FsPermission, boolean, int, short, long, org.apache.hadoop.util.Progressable)">create</A></B>(org.apache.hadoop.fs.Path&nbsp;f,
       org.apache.hadoop.fs.permission.FsPermission&nbsp;permission,
       boolean&nbsp;overwrite,
       int&nbsp;bufferSize,
       short&nbsp;replication,
       long&nbsp;blockSize,
       org.apache.hadoop.util.Progressable&nbsp;progress)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;org.apache.hadoop.fs.FSDataOutputStream</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/hadoop/hdfs/DistributedFileSystem.html#create(org.apache.hadoop.fs.Path, long, org.apache.hadoop.fs.permission.FsPermission, boolean, int, org.apache.hadoop.util.Progressable)">create</A></B>(org.apache.hadoop.fs.Path&nbsp;f,
       long&nbsp;fileSize,
       org.apache.hadoop.fs.permission.FsPermission&nbsp;permission,
       boolean&nbsp;overwrite,
       int&nbsp;bufferSize,
       org.apache.hadoop.util.Progressable&nbsp;progress)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;org.apache.hadoop.fs.FSDataOutputStream</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/hadoop/hdfs/DistributedFileSystem.html#createNonRecursive(org.apache.hadoop.fs.Path, org.apache.hadoop.fs.permission.FsPermission, java.util.EnumSet, int, short, long, org.apache.hadoop.util.Progressable)">createNonRecursive</A></B>(org.apache.hadoop.fs.Path&nbsp;f,
                   org.apache.hadoop.fs.permission.FsPermission&nbsp;permission,
                   java.util.EnumSet&lt;org.apache.hadoop.fs.CreateFlag&gt;&nbsp;flag,
                   int&nbsp;bufferSize,
                   short&nbsp;replication,
                   long&nbsp;blockSize,
                   org.apache.hadoop.util.Progressable&nbsp;progress)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Same as create(), except fails if parent directory doesn't already exist.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;boolean</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/hadoop/hdfs/DistributedFileSystem.html#delete(org.apache.hadoop.fs.Path, boolean)">delete</A></B>(org.apache.hadoop.fs.Path&nbsp;f,
       boolean&nbsp;recursive)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;<A HREF="../../../../org/apache/hadoop/hdfs/server/common/UpgradeStatusReport.html" title="org.apache.hadoop.hdfs.server.common 中的类">UpgradeStatusReport</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/hadoop/hdfs/DistributedFileSystem.html#distributedUpgradeProgress(org.apache.hadoop.hdfs.protocol.FSConstants.UpgradeAction)">distributedUpgradeProgress</A></B>(<A HREF="../../../../org/apache/hadoop/hdfs/protocol/FSConstants.UpgradeAction.html" title="org.apache.hadoop.hdfs.protocol 中的枚举">FSConstants.UpgradeAction</A>&nbsp;action)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;void</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/hadoop/hdfs/DistributedFileSystem.html#finalizeUpgrade()">finalizeUpgrade</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Finalize previously upgraded files system state.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;<A HREF="../../../../org/apache/hadoop/hdfs/DFSClient.html" title="org.apache.hadoop.hdfs 中的类">DFSClient</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/hadoop/hdfs/DistributedFileSystem.html#getClient()">getClient</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;org.apache.hadoop.fs.ContentSummary</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/hadoop/hdfs/DistributedFileSystem.html#getContentSummary(org.apache.hadoop.fs.Path)">getContentSummary</A></B>(org.apache.hadoop.fs.Path&nbsp;f)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;long</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/hadoop/hdfs/DistributedFileSystem.html#getCorruptBlocksCount()">getCorruptBlocksCount</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Returns count of blocks with at least one replica marked corrupt.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;<A HREF="../../../../org/apache/hadoop/hdfs/protocol/DatanodeInfo.html" title="org.apache.hadoop.hdfs.protocol 中的类">DatanodeInfo</A>[]</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/hadoop/hdfs/DistributedFileSystem.html#getDataNodeStats()">getDataNodeStats</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Return statistics for each datanode.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;long</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/hadoop/hdfs/DistributedFileSystem.html#getDefaultBlockSize()">getDefaultBlockSize</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>protected &nbsp;int</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/hadoop/hdfs/DistributedFileSystem.html#getDefaultPort()">getDefaultPort</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;short</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/hadoop/hdfs/DistributedFileSystem.html#getDefaultReplication()">getDefaultReplication</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;org.apache.hadoop.security.token.Token&lt;<A HREF="../../../../org/apache/hadoop/hdfs/security/token/delegation/DelegationTokenIdentifier.html" title="org.apache.hadoop.hdfs.security.token.delegation 中的类">DelegationTokenIdentifier</A>&gt;</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/hadoop/hdfs/DistributedFileSystem.html#getDelegationToken(java.lang.String)">getDelegationToken</A></B>(java.lang.String&nbsp;renewer)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;org.apache.hadoop.security.token.Token&lt;<A HREF="../../../../org/apache/hadoop/hdfs/security/token/delegation/DelegationTokenIdentifier.html" title="org.apache.hadoop.hdfs.security.token.delegation 中的类">DelegationTokenIdentifier</A>&gt;</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/hadoop/hdfs/DistributedFileSystem.html#getDelegationToken(org.apache.hadoop.io.Text)">getDelegationToken</A></B>(org.apache.hadoop.io.Text&nbsp;renewer)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<B>已过时。</B>&nbsp;<I>use <A HREF="../../../../org/apache/hadoop/hdfs/DistributedFileSystem.html#getDelegationToken(java.lang.String)"><CODE>getDelegationToken(String)</CODE></A></I></TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;<A HREF="../../../../org/apache/hadoop/hdfs/DistributedFileSystem.DiskStatus.html" title="org.apache.hadoop.hdfs 中的类">DistributedFileSystem.DiskStatus</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/hadoop/hdfs/DistributedFileSystem.html#getDiskStatus()">getDiskStatus</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<B>已过时。</B>&nbsp;<I>Use <CODE>FileSystem.getStatus()</CODE> 
 instead</I></TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;org.apache.hadoop.fs.BlockLocation[]</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/hadoop/hdfs/DistributedFileSystem.html#getFileBlockLocations(org.apache.hadoop.fs.FileStatus, long, long)">getFileBlockLocations</A></B>(org.apache.hadoop.fs.FileStatus&nbsp;file,
                      long&nbsp;start,
                      long&nbsp;len)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;org.apache.hadoop.fs.BlockLocation[]</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/hadoop/hdfs/DistributedFileSystem.html#getFileBlockLocations(org.apache.hadoop.fs.Path, long, long)">getFileBlockLocations</A></B>(org.apache.hadoop.fs.Path&nbsp;p,
                      long&nbsp;start,
                      long&nbsp;len)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;org.apache.hadoop.fs.MD5MD5CRC32FileChecksum</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/hadoop/hdfs/DistributedFileSystem.html#getFileChecksum(org.apache.hadoop.fs.Path)">getFileChecksum</A></B>(org.apache.hadoop.fs.Path&nbsp;f)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;org.apache.hadoop.fs.FileStatus</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/hadoop/hdfs/DistributedFileSystem.html#getFileStatus(org.apache.hadoop.fs.Path)">getFileStatus</A></B>(org.apache.hadoop.fs.Path&nbsp;f)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Returns the stat information about the file.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;org.apache.hadoop.fs.Path</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/hadoop/hdfs/DistributedFileSystem.html#getHomeDirectory()">getHomeDirectory</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;long</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/hadoop/hdfs/DistributedFileSystem.html#getMissingBlocksCount()">getMissingBlocksCount</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Returns count of blocks with no good replicas left.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;long</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/hadoop/hdfs/DistributedFileSystem.html#getRawCapacity()">getRawCapacity</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<B>已过时。</B>&nbsp;<I>Use <CODE>FileSystem.getStatus()</CODE> 
 instead</I></TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;long</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/hadoop/hdfs/DistributedFileSystem.html#getRawUsed()">getRawUsed</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<B>已过时。</B>&nbsp;<I>Use <CODE>FileSystem.getStatus()</CODE> 
 instead</I></TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;org.apache.hadoop.fs.FsServerDefaults</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/hadoop/hdfs/DistributedFileSystem.html#getServerDefaults()">getServerDefaults</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;org.apache.hadoop.fs.FsStatus</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/hadoop/hdfs/DistributedFileSystem.html#getStatus(org.apache.hadoop.fs.Path)">getStatus</A></B>(org.apache.hadoop.fs.Path&nbsp;p)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;long</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/hadoop/hdfs/DistributedFileSystem.html#getUnderReplicatedBlocksCount()">getUnderReplicatedBlocksCount</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Returns count of blocks with one of more replica missing.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;java.net.URI</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/hadoop/hdfs/DistributedFileSystem.html#getUri()">getUri</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;org.apache.hadoop.fs.Path</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/hadoop/hdfs/DistributedFileSystem.html#getWorkingDirectory()">getWorkingDirectory</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;void</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/hadoop/hdfs/DistributedFileSystem.html#initialize(java.net.URI, org.apache.hadoop.conf.Configuration)">initialize</A></B>(java.net.URI&nbsp;uri,
           org.apache.hadoop.conf.Configuration&nbsp;conf)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>protected &nbsp;org.apache.hadoop.fs.RemoteIterator&lt;org.apache.hadoop.fs.LocatedFileStatus&gt;</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/hadoop/hdfs/DistributedFileSystem.html#listLocatedStatus(org.apache.hadoop.fs.Path, org.apache.hadoop.fs.PathFilter)">listLocatedStatus</A></B>(org.apache.hadoop.fs.Path&nbsp;p,
                  org.apache.hadoop.fs.PathFilter&nbsp;filter)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;org.apache.hadoop.fs.FileStatus[]</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/hadoop/hdfs/DistributedFileSystem.html#listStatus(org.apache.hadoop.fs.Path)">listStatus</A></B>(org.apache.hadoop.fs.Path&nbsp;p)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;List all the entries of a directory

 Note that this operation is not atomic for a large directory.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;org.apache.hadoop.fs.Path</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/hadoop/hdfs/DistributedFileSystem.html#makeQualified(org.apache.hadoop.fs.Path)">makeQualified</A></B>(org.apache.hadoop.fs.Path&nbsp;path)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Normalize paths that explicitly specify the default port.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;void</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/hadoop/hdfs/DistributedFileSystem.html#metaSave(java.lang.String)">metaSave</A></B>(java.lang.String&nbsp;pathname)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;boolean</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/hadoop/hdfs/DistributedFileSystem.html#mkdir(org.apache.hadoop.fs.Path, org.apache.hadoop.fs.permission.FsPermission)">mkdir</A></B>(org.apache.hadoop.fs.Path&nbsp;f,
      org.apache.hadoop.fs.permission.FsPermission&nbsp;permission)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Create a directory with given name and permission, only when
 parent directory exists.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;boolean</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/hadoop/hdfs/DistributedFileSystem.html#mkdirs(org.apache.hadoop.fs.Path, org.apache.hadoop.fs.permission.FsPermission)">mkdirs</A></B>(org.apache.hadoop.fs.Path&nbsp;f,
       org.apache.hadoop.fs.permission.FsPermission&nbsp;permission)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;org.apache.hadoop.fs.FSDataInputStream</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/hadoop/hdfs/DistributedFileSystem.html#open(org.apache.hadoop.fs.Path, int)">open</A></B>(org.apache.hadoop.fs.Path&nbsp;f,
     int&nbsp;bufferSize)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>protected &nbsp;org.apache.hadoop.fs.FSDataOutputStream</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/hadoop/hdfs/DistributedFileSystem.html#primitiveCreate(org.apache.hadoop.fs.Path, org.apache.hadoop.fs.permission.FsPermission, java.util.EnumSet, int, short, long, org.apache.hadoop.util.Progressable, int)">primitiveCreate</A></B>(org.apache.hadoop.fs.Path&nbsp;f,
                org.apache.hadoop.fs.permission.FsPermission&nbsp;absolutePermission,
                java.util.EnumSet&lt;org.apache.hadoop.fs.CreateFlag&gt;&nbsp;flag,
                int&nbsp;bufferSize,
                short&nbsp;replication,
                long&nbsp;blockSize,
                org.apache.hadoop.util.Progressable&nbsp;progress,
                int&nbsp;bytesPerChecksum)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>protected &nbsp;boolean</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/hadoop/hdfs/DistributedFileSystem.html#primitiveMkdir(org.apache.hadoop.fs.Path, org.apache.hadoop.fs.permission.FsPermission)">primitiveMkdir</A></B>(org.apache.hadoop.fs.Path&nbsp;f,
               org.apache.hadoop.fs.permission.FsPermission&nbsp;absolutePermission)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;boolean</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/hadoop/hdfs/DistributedFileSystem.html#recoverLease(org.apache.hadoop.fs.Path)">recoverLease</A></B>(org.apache.hadoop.fs.Path&nbsp;f)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Start the lease recovery of a file</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;void</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/hadoop/hdfs/DistributedFileSystem.html#refreshNodes()">refreshNodes</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Refreshes the list of hosts and excluded hosts from the configured 
 files.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;boolean</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/hadoop/hdfs/DistributedFileSystem.html#rename(org.apache.hadoop.fs.Path, org.apache.hadoop.fs.Path)">rename</A></B>(org.apache.hadoop.fs.Path&nbsp;src,
       org.apache.hadoop.fs.Path&nbsp;dst)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;void</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/hadoop/hdfs/DistributedFileSystem.html#rename(org.apache.hadoop.fs.Path, org.apache.hadoop.fs.Path, org.apache.hadoop.fs.Options.Rename...)">rename</A></B>(org.apache.hadoop.fs.Path&nbsp;src,
       org.apache.hadoop.fs.Path&nbsp;dst,
       org.apache.hadoop.fs.Options.Rename...&nbsp;options)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
 This rename operation is guaranteed to be atomic.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;long</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/hadoop/hdfs/DistributedFileSystem.html#renewDelegationToken(org.apache.hadoop.security.token.Token)">renewDelegationToken</A></B>(org.apache.hadoop.security.token.Token&lt;<A HREF="../../../../org/apache/hadoop/hdfs/security/token/delegation/DelegationTokenIdentifier.html" title="org.apache.hadoop.hdfs.security.token.delegation 中的类">DelegationTokenIdentifier</A>&gt;&nbsp;token)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Renew an existing delegation token.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;boolean</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/hadoop/hdfs/DistributedFileSystem.html#reportChecksumFailure(org.apache.hadoop.fs.Path, org.apache.hadoop.fs.FSDataInputStream, long, org.apache.hadoop.fs.FSDataInputStream, long)">reportChecksumFailure</A></B>(org.apache.hadoop.fs.Path&nbsp;f,
                      org.apache.hadoop.fs.FSDataInputStream&nbsp;in,
                      long&nbsp;inPos,
                      org.apache.hadoop.fs.FSDataInputStream&nbsp;sums,
                      long&nbsp;sumsPos)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;We need to find the blocks that didn't match.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;boolean</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/hadoop/hdfs/DistributedFileSystem.html#restoreFailedStorage(java.lang.String)">restoreFailedStorage</A></B>(java.lang.String&nbsp;arg)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;enable/disable/check restoreFaileStorage</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;void</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/hadoop/hdfs/DistributedFileSystem.html#saveNamespace()">saveNamespace</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Save namespace image.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;void</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/hadoop/hdfs/DistributedFileSystem.html#setOwner(org.apache.hadoop.fs.Path, java.lang.String, java.lang.String)">setOwner</A></B>(org.apache.hadoop.fs.Path&nbsp;p,
         java.lang.String&nbsp;username,
         java.lang.String&nbsp;groupname)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;void</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/hadoop/hdfs/DistributedFileSystem.html#setPermission(org.apache.hadoop.fs.Path, org.apache.hadoop.fs.permission.FsPermission)">setPermission</A></B>(org.apache.hadoop.fs.Path&nbsp;p,
              org.apache.hadoop.fs.permission.FsPermission&nbsp;permission)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;void</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/hadoop/hdfs/DistributedFileSystem.html#setQuota(org.apache.hadoop.fs.Path, long, long)">setQuota</A></B>(org.apache.hadoop.fs.Path&nbsp;src,
         long&nbsp;namespaceQuota,
         long&nbsp;diskspaceQuota)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Set a directory's quotas</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;boolean</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/hadoop/hdfs/DistributedFileSystem.html#setReplication(org.apache.hadoop.fs.Path, short)">setReplication</A></B>(org.apache.hadoop.fs.Path&nbsp;src,
               short&nbsp;replication)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;boolean</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/hadoop/hdfs/DistributedFileSystem.html#setSafeMode(org.apache.hadoop.hdfs.protocol.FSConstants.SafeModeAction)">setSafeMode</A></B>(<A HREF="../../../../org/apache/hadoop/hdfs/protocol/FSConstants.SafeModeAction.html" title="org.apache.hadoop.hdfs.protocol 中的枚举">FSConstants.SafeModeAction</A>&nbsp;action)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Enter, leave or get safe mode.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;void</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/hadoop/hdfs/DistributedFileSystem.html#setTimes(org.apache.hadoop.fs.Path, long, long)">setTimes</A></B>(org.apache.hadoop.fs.Path&nbsp;p,
         long&nbsp;mtime,
         long&nbsp;atime)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;void</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/hadoop/hdfs/DistributedFileSystem.html#setVerifyChecksum(boolean)">setVerifyChecksum</A></B>(boolean&nbsp;verifyChecksum)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;void</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/hadoop/hdfs/DistributedFileSystem.html#setWorkingDirectory(org.apache.hadoop.fs.Path)">setWorkingDirectory</A></B>(org.apache.hadoop.fs.Path&nbsp;dir)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;java.lang.String</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/hadoop/hdfs/DistributedFileSystem.html#toString()">toString</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
</TABLE>
&nbsp;<A NAME="methods_inherited_from_class_org.apache.hadoop.fs.FileSystem"><!-- --></A>
<TABLE BORDER="1" WIDTH="100%" CELLPADDING="3" CELLSPACING="0" SUMMARY="">
<TR BGCOLOR="#EEEEFF" CLASS="TableSubHeadingColor">
<TH ALIGN="left"><B>从类 org.apache.hadoop.fs.FileSystem 继承的方法</B></TH>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD><CODE>append, append, clearStatistics, closeAll, closeAllForUGI, completeLocalOutput, copyFromLocalFile, copyFromLocalFile, copyFromLocalFile, copyFromLocalFile, copyToLocalFile, copyToLocalFile, create, create, create, create, create, create, create, create, create, create, createNewFile, delete, deleteOnExit, exists, get, get, get, getAllStatistics, getBlockSize, getCanonicalServiceName, getDefaultUri, getInitialWorkingDirectory, getLength, getLocal, getName, getNamed, getReplication, getStatistics, getStatistics, getStatus, getUsed, globStatus, globStatus, isDirectory, isFile, listFiles, listLocatedStatus, listStatus, listStatus, listStatus, mkdirs, mkdirs, moveFromLocalFile, moveFromLocalFile, moveToLocalFile, newInstance, newInstance, newInstance, newInstanceLocal, open, primitiveMkdir, printStatistics, processDeleteOnExit, setDefaultUri, setDefaultUri, startLocalOutput</CODE></TD>
</TR>
</TABLE>
&nbsp;<A NAME="methods_inherited_from_class_org.apache.hadoop.conf.Configured"><!-- --></A>
<TABLE BORDER="1" WIDTH="100%" CELLPADDING="3" CELLSPACING="0" SUMMARY="">
<TR BGCOLOR="#EEEEFF" CLASS="TableSubHeadingColor">
<TH ALIGN="left"><B>从类 org.apache.hadoop.conf.Configured 继承的方法</B></TH>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD><CODE>getConf, setConf</CODE></TD>
</TR>
</TABLE>
&nbsp;<A NAME="methods_inherited_from_class_java.lang.Object"><!-- --></A>
<TABLE BORDER="1" WIDTH="100%" CELLPADDING="3" CELLSPACING="0" SUMMARY="">
<TR BGCOLOR="#EEEEFF" CLASS="TableSubHeadingColor">
<TH ALIGN="left"><B>从类 java.lang.Object 继承的方法</B></TH>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD><CODE>clone, equals, finalize, getClass, hashCode, notify, notifyAll, wait, wait, wait</CODE></TD>
</TR>
</TABLE>
&nbsp;
<P>

<!-- ========= CONSTRUCTOR DETAIL ======== -->

<A NAME="constructor_detail"><!-- --></A>
<TABLE BORDER="1" WIDTH="100%" CELLPADDING="3" CELLSPACING="0" SUMMARY="">
<TR BGCOLOR="#CCCCFF" CLASS="TableHeadingColor">
<TH ALIGN="left" COLSPAN="1"><FONT SIZE="+2">
<B>构造方法详细信息</B></FONT></TH>
</TR>
</TABLE>

<A NAME="DistributedFileSystem()"><!-- --></A><H3>
DistributedFileSystem</H3>
<PRE>
public <B>DistributedFileSystem</B>()</PRE>
<DL>
</DL>
<HR>

<A NAME="DistributedFileSystem(java.net.InetSocketAddress, org.apache.hadoop.conf.Configuration)"><!-- --></A><H3>
DistributedFileSystem</H3>
<PRE>
<FONT SIZE="-1">@Deprecated
</FONT>public <B>DistributedFileSystem</B>(java.net.InetSocketAddress&nbsp;namenode,
                                        org.apache.hadoop.conf.Configuration&nbsp;conf)
                      throws java.io.IOException</PRE>
<DL>
<DD><B>已过时。</B>&nbsp;
<P>
<DL>

<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DL>

<!-- ============ METHOD DETAIL ========== -->

<A NAME="method_detail"><!-- --></A>
<TABLE BORDER="1" WIDTH="100%" CELLPADDING="3" CELLSPACING="0" SUMMARY="">
<TR BGCOLOR="#CCCCFF" CLASS="TableHeadingColor">
<TH ALIGN="left" COLSPAN="1"><FONT SIZE="+2">
<B>方法详细信息</B></FONT></TH>
</TR>
</TABLE>

<A NAME="getUri()"><!-- --></A><H3>
getUri</H3>
<PRE>
public java.net.URI <B>getUri</B>()</PRE>
<DL>
<DD><DL>
<DT><B>指定者：</B><DD>类 <CODE>org.apache.hadoop.fs.FileSystem</CODE> 中的 <CODE>getUri</CODE></DL>
</DD>
<DD><DL>
</DL>
</DD>
</DL>
<HR>

<A NAME="initialize(java.net.URI, org.apache.hadoop.conf.Configuration)"><!-- --></A><H3>
initialize</H3>
<PRE>
public void <B>initialize</B>(java.net.URI&nbsp;uri,
                       org.apache.hadoop.conf.Configuration&nbsp;conf)
                throws java.io.IOException</PRE>
<DL>
<DD><DL>
<DT><B>覆盖：</B><DD>类 <CODE>org.apache.hadoop.fs.FileSystem</CODE> 中的 <CODE>initialize</CODE></DL>
</DD>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="checkPath(org.apache.hadoop.fs.Path)"><!-- --></A><H3>
checkPath</H3>
<PRE>
protected void <B>checkPath</B>(org.apache.hadoop.fs.Path&nbsp;path)</PRE>
<DL>
<DD>Permit paths which explicitly specify the default port.
<P>
<DD><DL>
<DT><B>覆盖：</B><DD>类 <CODE>org.apache.hadoop.fs.FileSystem</CODE> 中的 <CODE>checkPath</CODE></DL>
</DD>
<DD><DL>
</DL>
</DD>
</DL>
<HR>

<A NAME="makeQualified(org.apache.hadoop.fs.Path)"><!-- --></A><H3>
makeQualified</H3>
<PRE>
public org.apache.hadoop.fs.Path <B>makeQualified</B>(org.apache.hadoop.fs.Path&nbsp;path)</PRE>
<DL>
<DD>Normalize paths that explicitly specify the default port.
<P>
<DD><DL>
<DT><B>覆盖：</B><DD>类 <CODE>org.apache.hadoop.fs.FileSystem</CODE> 中的 <CODE>makeQualified</CODE></DL>
</DD>
<DD><DL>
</DL>
</DD>
</DL>
<HR>

<A NAME="getWorkingDirectory()"><!-- --></A><H3>
getWorkingDirectory</H3>
<PRE>
public org.apache.hadoop.fs.Path <B>getWorkingDirectory</B>()</PRE>
<DL>
<DD><DL>
<DT><B>指定者：</B><DD>类 <CODE>org.apache.hadoop.fs.FileSystem</CODE> 中的 <CODE>getWorkingDirectory</CODE></DL>
</DD>
<DD><DL>
</DL>
</DD>
</DL>
<HR>

<A NAME="getDefaultBlockSize()"><!-- --></A><H3>
getDefaultBlockSize</H3>
<PRE>
public long <B>getDefaultBlockSize</B>()</PRE>
<DL>
<DD><DL>
<DT><B>覆盖：</B><DD>类 <CODE>org.apache.hadoop.fs.FileSystem</CODE> 中的 <CODE>getDefaultBlockSize</CODE></DL>
</DD>
<DD><DL>
</DL>
</DD>
</DL>
<HR>

<A NAME="getDefaultReplication()"><!-- --></A><H3>
getDefaultReplication</H3>
<PRE>
public short <B>getDefaultReplication</B>()</PRE>
<DL>
<DD><DL>
<DT><B>覆盖：</B><DD>类 <CODE>org.apache.hadoop.fs.FileSystem</CODE> 中的 <CODE>getDefaultReplication</CODE></DL>
</DD>
<DD><DL>
</DL>
</DD>
</DL>
<HR>

<A NAME="setWorkingDirectory(org.apache.hadoop.fs.Path)"><!-- --></A><H3>
setWorkingDirectory</H3>
<PRE>
public void <B>setWorkingDirectory</B>(org.apache.hadoop.fs.Path&nbsp;dir)</PRE>
<DL>
<DD><DL>
<DT><B>指定者：</B><DD>类 <CODE>org.apache.hadoop.fs.FileSystem</CODE> 中的 <CODE>setWorkingDirectory</CODE></DL>
</DD>
<DD><DL>
</DL>
</DD>
</DL>
<HR>

<A NAME="getHomeDirectory()"><!-- --></A><H3>
getHomeDirectory</H3>
<PRE>
public org.apache.hadoop.fs.Path <B>getHomeDirectory</B>()</PRE>
<DL>
<DD>
<P>
<DD><DL>
<DT><B>覆盖：</B><DD>类 <CODE>org.apache.hadoop.fs.FileSystem</CODE> 中的 <CODE>getHomeDirectory</CODE></DL>
</DD>
<DD><DL>
</DL>
</DD>
</DL>
<HR>

<A NAME="getFileBlockLocations(org.apache.hadoop.fs.FileStatus, long, long)"><!-- --></A><H3>
getFileBlockLocations</H3>
<PRE>
public org.apache.hadoop.fs.BlockLocation[] <B>getFileBlockLocations</B>(org.apache.hadoop.fs.FileStatus&nbsp;file,
                                                                  long&nbsp;start,
                                                                  long&nbsp;len)
                                                           throws java.io.IOException</PRE>
<DL>
<DD><DL>
<DT><B>覆盖：</B><DD>类 <CODE>org.apache.hadoop.fs.FileSystem</CODE> 中的 <CODE>getFileBlockLocations</CODE></DL>
</DD>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="getFileBlockLocations(org.apache.hadoop.fs.Path, long, long)"><!-- --></A><H3>
getFileBlockLocations</H3>
<PRE>
public org.apache.hadoop.fs.BlockLocation[] <B>getFileBlockLocations</B>(org.apache.hadoop.fs.Path&nbsp;p,
                                                                  long&nbsp;start,
                                                                  long&nbsp;len)
                                                           throws java.io.IOException</PRE>
<DL>
<DD><DL>
<DT><B>覆盖：</B><DD>类 <CODE>org.apache.hadoop.fs.FileSystem</CODE> 中的 <CODE>getFileBlockLocations</CODE></DL>
</DD>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="setVerifyChecksum(boolean)"><!-- --></A><H3>
setVerifyChecksum</H3>
<PRE>
public void <B>setVerifyChecksum</B>(boolean&nbsp;verifyChecksum)</PRE>
<DL>
<DD><DL>
<DT><B>覆盖：</B><DD>类 <CODE>org.apache.hadoop.fs.FileSystem</CODE> 中的 <CODE>setVerifyChecksum</CODE></DL>
</DD>
<DD><DL>
</DL>
</DD>
</DL>
<HR>

<A NAME="recoverLease(org.apache.hadoop.fs.Path)"><!-- --></A><H3>
recoverLease</H3>
<PRE>
public boolean <B>recoverLease</B>(org.apache.hadoop.fs.Path&nbsp;f)
                     throws java.io.IOException</PRE>
<DL>
<DD>Start the lease recovery of a file
<P>
<DD><DL>
<DT><B>参数：</B><DD><CODE>f</CODE> - a file
<DT><B>返回：</B><DD>true if the file is already closed
<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE> - if an error occurs</DL>
</DD>
</DL>
<HR>

<A NAME="open(org.apache.hadoop.fs.Path, int)"><!-- --></A><H3>
open</H3>
<PRE>
public org.apache.hadoop.fs.FSDataInputStream <B>open</B>(org.apache.hadoop.fs.Path&nbsp;f,
                                                   int&nbsp;bufferSize)
                                            throws java.io.IOException</PRE>
<DL>
<DD><DL>
<DT><B>指定者：</B><DD>类 <CODE>org.apache.hadoop.fs.FileSystem</CODE> 中的 <CODE>open</CODE></DL>
</DD>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="append(org.apache.hadoop.fs.Path, int, org.apache.hadoop.util.Progressable)"><!-- --></A><H3>
append</H3>
<PRE>
public org.apache.hadoop.fs.FSDataOutputStream <B>append</B>(org.apache.hadoop.fs.Path&nbsp;f,
                                                      int&nbsp;bufferSize,
                                                      org.apache.hadoop.util.Progressable&nbsp;progress)
                                               throws java.io.IOException</PRE>
<DL>
<DD>This optional operation is not yet supported.
<P>
<DD><DL>
<DT><B>指定者：</B><DD>类 <CODE>org.apache.hadoop.fs.FileSystem</CODE> 中的 <CODE>append</CODE></DL>
</DD>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="create(org.apache.hadoop.fs.Path, org.apache.hadoop.fs.permission.FsPermission, boolean, int, short, long, org.apache.hadoop.util.Progressable)"><!-- --></A><H3>
create</H3>
<PRE>
public org.apache.hadoop.fs.FSDataOutputStream <B>create</B>(org.apache.hadoop.fs.Path&nbsp;f,
                                                      org.apache.hadoop.fs.permission.FsPermission&nbsp;permission,
                                                      boolean&nbsp;overwrite,
                                                      int&nbsp;bufferSize,
                                                      short&nbsp;replication,
                                                      long&nbsp;blockSize,
                                                      org.apache.hadoop.util.Progressable&nbsp;progress)
                                               throws java.io.IOException</PRE>
<DL>
<DD><DL>
<DT><B>指定者：</B><DD>类 <CODE>org.apache.hadoop.fs.FileSystem</CODE> 中的 <CODE>create</CODE></DL>
</DD>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="create(org.apache.hadoop.fs.Path, long, org.apache.hadoop.fs.permission.FsPermission, boolean, int, org.apache.hadoop.util.Progressable)"><!-- --></A><H3>
create</H3>
<PRE>
public org.apache.hadoop.fs.FSDataOutputStream <B>create</B>(org.apache.hadoop.fs.Path&nbsp;f,
                                                      long&nbsp;fileSize,
                                                      org.apache.hadoop.fs.permission.FsPermission&nbsp;permission,
                                                      boolean&nbsp;overwrite,
                                                      int&nbsp;bufferSize,
                                                      org.apache.hadoop.util.Progressable&nbsp;progress)
                                               throws java.io.IOException</PRE>
<DL>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="primitiveCreate(org.apache.hadoop.fs.Path, org.apache.hadoop.fs.permission.FsPermission, java.util.EnumSet, int, short, long, org.apache.hadoop.util.Progressable, int)"><!-- --></A><H3>
primitiveCreate</H3>
<PRE>
protected org.apache.hadoop.fs.FSDataOutputStream <B>primitiveCreate</B>(org.apache.hadoop.fs.Path&nbsp;f,
                                                                  org.apache.hadoop.fs.permission.FsPermission&nbsp;absolutePermission,
                                                                  java.util.EnumSet&lt;org.apache.hadoop.fs.CreateFlag&gt;&nbsp;flag,
                                                                  int&nbsp;bufferSize,
                                                                  short&nbsp;replication,
                                                                  long&nbsp;blockSize,
                                                                  org.apache.hadoop.util.Progressable&nbsp;progress,
                                                                  int&nbsp;bytesPerChecksum)
                                                           throws java.io.IOException</PRE>
<DL>
<DD><DL>
<DT><B>覆盖：</B><DD>类 <CODE>org.apache.hadoop.fs.FileSystem</CODE> 中的 <CODE>primitiveCreate</CODE></DL>
</DD>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="createNonRecursive(org.apache.hadoop.fs.Path, org.apache.hadoop.fs.permission.FsPermission, java.util.EnumSet, int, short, long, org.apache.hadoop.util.Progressable)"><!-- --></A><H3>
createNonRecursive</H3>
<PRE>
public org.apache.hadoop.fs.FSDataOutputStream <B>createNonRecursive</B>(org.apache.hadoop.fs.Path&nbsp;f,
                                                                  org.apache.hadoop.fs.permission.FsPermission&nbsp;permission,
                                                                  java.util.EnumSet&lt;org.apache.hadoop.fs.CreateFlag&gt;&nbsp;flag,
                                                                  int&nbsp;bufferSize,
                                                                  short&nbsp;replication,
                                                                  long&nbsp;blockSize,
                                                                  org.apache.hadoop.util.Progressable&nbsp;progress)
                                                           throws java.io.IOException</PRE>
<DL>
<DD>Same as create(), except fails if parent directory doesn't already exist.
<P>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="setReplication(org.apache.hadoop.fs.Path, short)"><!-- --></A><H3>
setReplication</H3>
<PRE>
public boolean <B>setReplication</B>(org.apache.hadoop.fs.Path&nbsp;src,
                              short&nbsp;replication)
                       throws java.io.IOException</PRE>
<DL>
<DD><DL>
<DT><B>覆盖：</B><DD>类 <CODE>org.apache.hadoop.fs.FileSystem</CODE> 中的 <CODE>setReplication</CODE></DL>
</DD>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="concat(org.apache.hadoop.fs.Path, org.apache.hadoop.fs.Path[])"><!-- --></A><H3>
concat</H3>
<PRE>
public void <B>concat</B>(org.apache.hadoop.fs.Path&nbsp;trg,
                   org.apache.hadoop.fs.Path[]&nbsp;psrcs)
            throws java.io.IOException</PRE>
<DL>
<DD>THIS IS DFS only operations, it is not part of FileSystem
 move blocks from srcs to trg
 and delete srcs afterwards
 all blocks should be the same size
<P>
<DD><DL>
<DT><B>参数：</B><DD><CODE>trg</CODE> - existing file to append to<DD><CODE>psrcs</CODE> - list of files (same block size, same replication)
<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="rename(org.apache.hadoop.fs.Path, org.apache.hadoop.fs.Path)"><!-- --></A><H3>
rename</H3>
<PRE>
public boolean <B>rename</B>(org.apache.hadoop.fs.Path&nbsp;src,
                      org.apache.hadoop.fs.Path&nbsp;dst)
               throws java.io.IOException</PRE>
<DL>
<DD>
<P>
<DD><DL>
<DT><B>指定者：</B><DD>类 <CODE>org.apache.hadoop.fs.FileSystem</CODE> 中的 <CODE>rename</CODE></DL>
</DD>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="rename(org.apache.hadoop.fs.Path, org.apache.hadoop.fs.Path, org.apache.hadoop.fs.Options.Rename...)"><!-- --></A><H3>
rename</H3>
<PRE>
public void <B>rename</B>(org.apache.hadoop.fs.Path&nbsp;src,
                   org.apache.hadoop.fs.Path&nbsp;dst,
                   org.apache.hadoop.fs.Options.Rename...&nbsp;options)
            throws java.io.IOException</PRE>
<DL>
<DD>
 This rename operation is guaranteed to be atomic.
<P>
<DD><DL>
<DT><B>覆盖：</B><DD>类 <CODE>org.apache.hadoop.fs.FileSystem</CODE> 中的 <CODE>rename</CODE></DL>
</DD>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="delete(org.apache.hadoop.fs.Path, boolean)"><!-- --></A><H3>
delete</H3>
<PRE>
public boolean <B>delete</B>(org.apache.hadoop.fs.Path&nbsp;f,
                      boolean&nbsp;recursive)
               throws java.io.IOException</PRE>
<DL>
<DD><DL>
<DT><B>指定者：</B><DD>类 <CODE>org.apache.hadoop.fs.FileSystem</CODE> 中的 <CODE>delete</CODE></DL>
</DD>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="getContentSummary(org.apache.hadoop.fs.Path)"><!-- --></A><H3>
getContentSummary</H3>
<PRE>
public org.apache.hadoop.fs.ContentSummary <B>getContentSummary</B>(org.apache.hadoop.fs.Path&nbsp;f)
                                                      throws java.io.IOException</PRE>
<DL>
<DD>
<P>
<DD><DL>
<DT><B>覆盖：</B><DD>类 <CODE>org.apache.hadoop.fs.FileSystem</CODE> 中的 <CODE>getContentSummary</CODE></DL>
</DD>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="setQuota(org.apache.hadoop.fs.Path, long, long)"><!-- --></A><H3>
setQuota</H3>
<PRE>
public void <B>setQuota</B>(org.apache.hadoop.fs.Path&nbsp;src,
                     long&nbsp;namespaceQuota,
                     long&nbsp;diskspaceQuota)
              throws java.io.IOException</PRE>
<DL>
<DD>Set a directory's quotas
<P>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE><DT><B>另请参见：</B><DD><A HREF="../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html#setQuota(java.lang.String, long, long)"><CODE>ClientProtocol.setQuota(String, long, long)</CODE></A></DL>
</DD>
</DL>
<HR>

<A NAME="listStatus(org.apache.hadoop.fs.Path)"><!-- --></A><H3>
listStatus</H3>
<PRE>
public org.apache.hadoop.fs.FileStatus[] <B>listStatus</B>(org.apache.hadoop.fs.Path&nbsp;p)
                                             throws java.io.IOException</PRE>
<DL>
<DD>List all the entries of a directory

 Note that this operation is not atomic for a large directory.
 The entries of a directory may be fetched from NameNode multiple times.
 It only guarantees that  each name occurs once if a directory
 undergoes changes between the calls.
<P>
<DD><DL>
<DT><B>指定者：</B><DD>类 <CODE>org.apache.hadoop.fs.FileSystem</CODE> 中的 <CODE>listStatus</CODE></DL>
</DD>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="listLocatedStatus(org.apache.hadoop.fs.Path, org.apache.hadoop.fs.PathFilter)"><!-- --></A><H3>
listLocatedStatus</H3>
<PRE>
protected org.apache.hadoop.fs.RemoteIterator&lt;org.apache.hadoop.fs.LocatedFileStatus&gt; <B>listLocatedStatus</B>(org.apache.hadoop.fs.Path&nbsp;p,
                                                                                                        org.apache.hadoop.fs.PathFilter&nbsp;filter)
                                                                                                 throws java.io.IOException</PRE>
<DL>
<DD><DL>
<DT><B>覆盖：</B><DD>类 <CODE>org.apache.hadoop.fs.FileSystem</CODE> 中的 <CODE>listLocatedStatus</CODE></DL>
</DD>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="mkdir(org.apache.hadoop.fs.Path, org.apache.hadoop.fs.permission.FsPermission)"><!-- --></A><H3>
mkdir</H3>
<PRE>
public boolean <B>mkdir</B>(org.apache.hadoop.fs.Path&nbsp;f,
                     org.apache.hadoop.fs.permission.FsPermission&nbsp;permission)
              throws java.io.IOException</PRE>
<DL>
<DD>Create a directory with given name and permission, only when
 parent directory exists.
<P>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="mkdirs(org.apache.hadoop.fs.Path, org.apache.hadoop.fs.permission.FsPermission)"><!-- --></A><H3>
mkdirs</H3>
<PRE>
public boolean <B>mkdirs</B>(org.apache.hadoop.fs.Path&nbsp;f,
                      org.apache.hadoop.fs.permission.FsPermission&nbsp;permission)
               throws java.io.IOException</PRE>
<DL>
<DD><DL>
<DT><B>指定者：</B><DD>类 <CODE>org.apache.hadoop.fs.FileSystem</CODE> 中的 <CODE>mkdirs</CODE></DL>
</DD>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="primitiveMkdir(org.apache.hadoop.fs.Path, org.apache.hadoop.fs.permission.FsPermission)"><!-- --></A><H3>
primitiveMkdir</H3>
<PRE>
protected boolean <B>primitiveMkdir</B>(org.apache.hadoop.fs.Path&nbsp;f,
                                 org.apache.hadoop.fs.permission.FsPermission&nbsp;absolutePermission)
                          throws java.io.IOException</PRE>
<DL>
<DD><DL>
<DT><B>覆盖：</B><DD>类 <CODE>org.apache.hadoop.fs.FileSystem</CODE> 中的 <CODE>primitiveMkdir</CODE></DL>
</DD>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="close()"><!-- --></A><H3>
close</H3>
<PRE>
public void <B>close</B>()
           throws java.io.IOException</PRE>
<DL>
<DD>
<P>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE>java.io.Closeable</CODE> 中的 <CODE>close</CODE><DT><B>覆盖：</B><DD>类 <CODE>org.apache.hadoop.fs.FileSystem</CODE> 中的 <CODE>close</CODE></DL>
</DD>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="toString()"><!-- --></A><H3>
toString</H3>
<PRE>
public java.lang.String <B>toString</B>()</PRE>
<DL>
<DD><DL>
<DT><B>覆盖：</B><DD>类 <CODE>java.lang.Object</CODE> 中的 <CODE>toString</CODE></DL>
</DD>
<DD><DL>
</DL>
</DD>
</DL>
<HR>

<A NAME="getClient()"><!-- --></A><H3>
getClient</H3>
<PRE>
public <A HREF="../../../../org/apache/hadoop/hdfs/DFSClient.html" title="org.apache.hadoop.hdfs 中的类">DFSClient</A> <B>getClient</B>()</PRE>
<DL>
<DD><DL>
</DL>
</DD>
</DL>
<HR>

<A NAME="getStatus(org.apache.hadoop.fs.Path)"><!-- --></A><H3>
getStatus</H3>
<PRE>
public org.apache.hadoop.fs.FsStatus <B>getStatus</B>(org.apache.hadoop.fs.Path&nbsp;p)
                                        throws java.io.IOException</PRE>
<DL>
<DD>
<P>
<DD><DL>
<DT><B>覆盖：</B><DD>类 <CODE>org.apache.hadoop.fs.FileSystem</CODE> 中的 <CODE>getStatus</CODE></DL>
</DD>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="getDiskStatus()"><!-- --></A><H3>
getDiskStatus</H3>
<PRE>
<FONT SIZE="-1">@Deprecated
</FONT>public <A HREF="../../../../org/apache/hadoop/hdfs/DistributedFileSystem.DiskStatus.html" title="org.apache.hadoop.hdfs 中的类">DistributedFileSystem.DiskStatus</A> <B>getDiskStatus</B>()
                                               throws java.io.IOException</PRE>
<DL>
<DD><B>已过时。</B>&nbsp;<I>Use <CODE>FileSystem.getStatus()</CODE> 
 instead</I>
<P>
<DD>Return the disk usage of the filesystem, including total capacity,
 used space, and remaining space
<P>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="getRawCapacity()"><!-- --></A><H3>
getRawCapacity</H3>
<PRE>
<FONT SIZE="-1">@Deprecated
</FONT>public long <B>getRawCapacity</B>()
                    throws java.io.IOException</PRE>
<DL>
<DD><B>已过时。</B>&nbsp;<I>Use <CODE>FileSystem.getStatus()</CODE> 
 instead</I>
<P>
<DD>Return the total raw capacity of the filesystem, disregarding
 replication.
<P>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="getRawUsed()"><!-- --></A><H3>
getRawUsed</H3>
<PRE>
<FONT SIZE="-1">@Deprecated
</FONT>public long <B>getRawUsed</B>()
                throws java.io.IOException</PRE>
<DL>
<DD><B>已过时。</B>&nbsp;<I>Use <CODE>FileSystem.getStatus()</CODE> 
 instead</I>
<P>
<DD>Return the total raw used space in the filesystem, disregarding
 replication.
<P>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="getMissingBlocksCount()"><!-- --></A><H3>
getMissingBlocksCount</H3>
<PRE>
public long <B>getMissingBlocksCount</B>()
                           throws java.io.IOException</PRE>
<DL>
<DD>Returns count of blocks with no good replicas left. Normally should be
 zero.
<P>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="getUnderReplicatedBlocksCount()"><!-- --></A><H3>
getUnderReplicatedBlocksCount</H3>
<PRE>
public long <B>getUnderReplicatedBlocksCount</B>()
                                   throws java.io.IOException</PRE>
<DL>
<DD>Returns count of blocks with one of more replica missing.
<P>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="getCorruptBlocksCount()"><!-- --></A><H3>
getCorruptBlocksCount</H3>
<PRE>
public long <B>getCorruptBlocksCount</B>()
                           throws java.io.IOException</PRE>
<DL>
<DD>Returns count of blocks with at least one replica marked corrupt.
<P>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="getDataNodeStats()"><!-- --></A><H3>
getDataNodeStats</H3>
<PRE>
public <A HREF="../../../../org/apache/hadoop/hdfs/protocol/DatanodeInfo.html" title="org.apache.hadoop.hdfs.protocol 中的类">DatanodeInfo</A>[] <B>getDataNodeStats</B>()
                                throws java.io.IOException</PRE>
<DL>
<DD>Return statistics for each datanode.
<P>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="setSafeMode(org.apache.hadoop.hdfs.protocol.FSConstants.SafeModeAction)"><!-- --></A><H3>
setSafeMode</H3>
<PRE>
public boolean <B>setSafeMode</B>(<A HREF="../../../../org/apache/hadoop/hdfs/protocol/FSConstants.SafeModeAction.html" title="org.apache.hadoop.hdfs.protocol 中的枚举">FSConstants.SafeModeAction</A>&nbsp;action)
                    throws java.io.IOException</PRE>
<DL>
<DD>Enter, leave or get safe mode.
<P>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE><DT><B>另请参见：</B><DD><A HREF="../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html#setSafeMode(org.apache.hadoop.hdfs.protocol.FSConstants.SafeModeAction)"><CODE>ClientProtocol.setSafeMode(
    FSConstants.SafeModeAction)</CODE></A></DL>
</DD>
</DL>
<HR>

<A NAME="saveNamespace()"><!-- --></A><H3>
saveNamespace</H3>
<PRE>
public void <B>saveNamespace</B>()
                   throws org.apache.hadoop.security.AccessControlException,
                          java.io.IOException</PRE>
<DL>
<DD>Save namespace image.
<P>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>org.apache.hadoop.security.AccessControlException</CODE>
<DD><CODE>java.io.IOException</CODE><DT><B>另请参见：</B><DD><A HREF="../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html#saveNamespace()"><CODE>ClientProtocol.saveNamespace()</CODE></A></DL>
</DD>
</DL>
<HR>

<A NAME="restoreFailedStorage(java.lang.String)"><!-- --></A><H3>
restoreFailedStorage</H3>
<PRE>
public boolean <B>restoreFailedStorage</B>(java.lang.String&nbsp;arg)
                             throws org.apache.hadoop.security.AccessControlException</PRE>
<DL>
<DD>enable/disable/check restoreFaileStorage
<P>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>org.apache.hadoop.security.AccessControlException</CODE><DT><B>另请参见：</B><DD><A HREF="../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html#restoreFailedStorage(java.lang.String)"><CODE>ClientProtocol.restoreFailedStorage(String arg)</CODE></A></DL>
</DD>
</DL>
<HR>

<A NAME="refreshNodes()"><!-- --></A><H3>
refreshNodes</H3>
<PRE>
public void <B>refreshNodes</B>()
                  throws java.io.IOException</PRE>
<DL>
<DD>Refreshes the list of hosts and excluded hosts from the configured 
 files.
<P>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="finalizeUpgrade()"><!-- --></A><H3>
finalizeUpgrade</H3>
<PRE>
public void <B>finalizeUpgrade</B>()
                     throws java.io.IOException</PRE>
<DL>
<DD>Finalize previously upgraded files system state.
<P>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="distributedUpgradeProgress(org.apache.hadoop.hdfs.protocol.FSConstants.UpgradeAction)"><!-- --></A><H3>
distributedUpgradeProgress</H3>
<PRE>
public <A HREF="../../../../org/apache/hadoop/hdfs/server/common/UpgradeStatusReport.html" title="org.apache.hadoop.hdfs.server.common 中的类">UpgradeStatusReport</A> <B>distributedUpgradeProgress</B>(<A HREF="../../../../org/apache/hadoop/hdfs/protocol/FSConstants.UpgradeAction.html" title="org.apache.hadoop.hdfs.protocol 中的枚举">FSConstants.UpgradeAction</A>&nbsp;action)
                                               throws java.io.IOException</PRE>
<DL>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="metaSave(java.lang.String)"><!-- --></A><H3>
metaSave</H3>
<PRE>
public void <B>metaSave</B>(java.lang.String&nbsp;pathname)
              throws java.io.IOException</PRE>
<DL>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="getServerDefaults()"><!-- --></A><H3>
getServerDefaults</H3>
<PRE>
public org.apache.hadoop.fs.FsServerDefaults <B>getServerDefaults</B>()
                                                        throws java.io.IOException</PRE>
<DL>
<DD>
<P>
<DD><DL>
<DT><B>覆盖：</B><DD>类 <CODE>org.apache.hadoop.fs.FileSystem</CODE> 中的 <CODE>getServerDefaults</CODE></DL>
</DD>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="reportChecksumFailure(org.apache.hadoop.fs.Path, org.apache.hadoop.fs.FSDataInputStream, long, org.apache.hadoop.fs.FSDataInputStream, long)"><!-- --></A><H3>
reportChecksumFailure</H3>
<PRE>
public boolean <B>reportChecksumFailure</B>(org.apache.hadoop.fs.Path&nbsp;f,
                                     org.apache.hadoop.fs.FSDataInputStream&nbsp;in,
                                     long&nbsp;inPos,
                                     org.apache.hadoop.fs.FSDataInputStream&nbsp;sums,
                                     long&nbsp;sumsPos)</PRE>
<DL>
<DD>We need to find the blocks that didn't match.  Likely only one 
 is corrupt but we will report both to the namenode.  In the future,
 we can consider figuring out exactly which block is corrupt.
<P>
<DD><DL>
</DL>
</DD>
</DL>
<HR>

<A NAME="getFileStatus(org.apache.hadoop.fs.Path)"><!-- --></A><H3>
getFileStatus</H3>
<PRE>
public org.apache.hadoop.fs.FileStatus <B>getFileStatus</B>(org.apache.hadoop.fs.Path&nbsp;f)
                                              throws java.io.IOException</PRE>
<DL>
<DD>Returns the stat information about the file.
<P>
<DD><DL>
<DT><B>指定者：</B><DD>类 <CODE>org.apache.hadoop.fs.FileSystem</CODE> 中的 <CODE>getFileStatus</CODE></DL>
</DD>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>java.io.FileNotFoundException</CODE> - if the file does not exist.
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="getFileChecksum(org.apache.hadoop.fs.Path)"><!-- --></A><H3>
getFileChecksum</H3>
<PRE>
public org.apache.hadoop.fs.MD5MD5CRC32FileChecksum <B>getFileChecksum</B>(org.apache.hadoop.fs.Path&nbsp;f)
                                                             throws java.io.IOException</PRE>
<DL>
<DD>
<P>
<DD><DL>
<DT><B>覆盖：</B><DD>类 <CODE>org.apache.hadoop.fs.FileSystem</CODE> 中的 <CODE>getFileChecksum</CODE></DL>
</DD>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="setPermission(org.apache.hadoop.fs.Path, org.apache.hadoop.fs.permission.FsPermission)"><!-- --></A><H3>
setPermission</H3>
<PRE>
public void <B>setPermission</B>(org.apache.hadoop.fs.Path&nbsp;p,
                          org.apache.hadoop.fs.permission.FsPermission&nbsp;permission)
                   throws java.io.IOException</PRE>
<DL>
<DD>
<P>
<DD><DL>
<DT><B>覆盖：</B><DD>类 <CODE>org.apache.hadoop.fs.FileSystem</CODE> 中的 <CODE>setPermission</CODE></DL>
</DD>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="setOwner(org.apache.hadoop.fs.Path, java.lang.String, java.lang.String)"><!-- --></A><H3>
setOwner</H3>
<PRE>
public void <B>setOwner</B>(org.apache.hadoop.fs.Path&nbsp;p,
                     java.lang.String&nbsp;username,
                     java.lang.String&nbsp;groupname)
              throws java.io.IOException</PRE>
<DL>
<DD>
<P>
<DD><DL>
<DT><B>覆盖：</B><DD>类 <CODE>org.apache.hadoop.fs.FileSystem</CODE> 中的 <CODE>setOwner</CODE></DL>
</DD>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="setTimes(org.apache.hadoop.fs.Path, long, long)"><!-- --></A><H3>
setTimes</H3>
<PRE>
public void <B>setTimes</B>(org.apache.hadoop.fs.Path&nbsp;p,
                     long&nbsp;mtime,
                     long&nbsp;atime)
              throws java.io.IOException</PRE>
<DL>
<DD>
<P>
<DD><DL>
<DT><B>覆盖：</B><DD>类 <CODE>org.apache.hadoop.fs.FileSystem</CODE> 中的 <CODE>setTimes</CODE></DL>
</DD>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="getDefaultPort()"><!-- --></A><H3>
getDefaultPort</H3>
<PRE>
protected int <B>getDefaultPort</B>()</PRE>
<DL>
<DD><DL>
<DT><B>覆盖：</B><DD>类 <CODE>org.apache.hadoop.fs.FileSystem</CODE> 中的 <CODE>getDefaultPort</CODE></DL>
</DD>
<DD><DL>
</DL>
</DD>
</DL>
<HR>

<A NAME="getDelegationToken(java.lang.String)"><!-- --></A><H3>
getDelegationToken</H3>
<PRE>
public org.apache.hadoop.security.token.Token&lt;<A HREF="../../../../org/apache/hadoop/hdfs/security/token/delegation/DelegationTokenIdentifier.html" title="org.apache.hadoop.hdfs.security.token.delegation 中的类">DelegationTokenIdentifier</A>&gt; <B>getDelegationToken</B>(java.lang.String&nbsp;renewer)
                                                                                     throws java.io.IOException</PRE>
<DL>
<DD><DL>
<DT><B>覆盖：</B><DD>类 <CODE>org.apache.hadoop.fs.FileSystem</CODE> 中的 <CODE>getDelegationToken</CODE></DL>
</DD>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="getDelegationToken(org.apache.hadoop.io.Text)"><!-- --></A><H3>
getDelegationToken</H3>
<PRE>
<FONT SIZE="-1">@Deprecated
</FONT>public org.apache.hadoop.security.token.Token&lt;<A HREF="../../../../org/apache/hadoop/hdfs/security/token/delegation/DelegationTokenIdentifier.html" title="org.apache.hadoop.hdfs.security.token.delegation 中的类">DelegationTokenIdentifier</A>&gt; <B>getDelegationToken</B>(org.apache.hadoop.io.Text&nbsp;renewer)
                                                                                     throws java.io.IOException</PRE>
<DL>
<DD><B>已过时。</B>&nbsp;<I>use <A HREF="../../../../org/apache/hadoop/hdfs/DistributedFileSystem.html#getDelegationToken(java.lang.String)"><CODE>getDelegationToken(String)</CODE></A></I>
<P>
<DD>Get a valid Delegation Token.
<P>
<DD><DL>
<DT><B>参数：</B><DD><CODE>renewer</CODE> - Name of the designated renewer for the token
<DT><B>返回：</B><DD>Token<DelegationTokenIdentifier>
<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="renewDelegationToken(org.apache.hadoop.security.token.Token)"><!-- --></A><H3>
renewDelegationToken</H3>
<PRE>
public long <B>renewDelegationToken</B>(org.apache.hadoop.security.token.Token&lt;<A HREF="../../../../org/apache/hadoop/hdfs/security/token/delegation/DelegationTokenIdentifier.html" title="org.apache.hadoop.hdfs.security.token.delegation 中的类">DelegationTokenIdentifier</A>&gt;&nbsp;token)
                          throws org.apache.hadoop.security.token.SecretManager.InvalidToken,
                                 java.io.IOException</PRE>
<DL>
<DD>Renew an existing delegation token.
<P>
<DD><DL>
<DT><B>参数：</B><DD><CODE>token</CODE> - delegation token obtained earlier
<DT><B>返回：</B><DD>the new expiration time
<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE>
<DD><CODE>org.apache.hadoop.security.token.SecretManager.InvalidToken</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="cancelDelegationToken(org.apache.hadoop.security.token.Token)"><!-- --></A><H3>
cancelDelegationToken</H3>
<PRE>
public void <B>cancelDelegationToken</B>(org.apache.hadoop.security.token.Token&lt;<A HREF="../../../../org/apache/hadoop/hdfs/security/token/delegation/DelegationTokenIdentifier.html" title="org.apache.hadoop.hdfs.security.token.delegation 中的类">DelegationTokenIdentifier</A>&gt;&nbsp;token)
                           throws java.io.IOException</PRE>
<DL>
<DD>Cancel an existing delegation token.
<P>
<DD><DL>
<DT><B>参数：</B><DD><CODE>token</CODE> - delegation token
<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<!-- ========= END OF CLASS DATA ========= -->
<HR>


<!-- ======= START OF BOTTOM NAVBAR ====== -->
<A NAME="navbar_bottom"><!-- --></A>
<A HREF="#skip-navbar_bottom" title="跳过导航链接"></A>
<TABLE BORDER="0" WIDTH="100%" CELLPADDING="1" CELLSPACING="0" SUMMARY="">
<TR>
<TD COLSPAN=2 BGCOLOR="#EEEEFF" CLASS="NavBarCell1">
<A NAME="navbar_bottom_firstrow"><!-- --></A>
<TABLE BORDER="0" CELLPADDING="0" CELLSPACING="3" SUMMARY="">
  <TR ALIGN="center" VALIGN="top">
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="../../../../overview-summary.html"><FONT CLASS="NavBarFont1"><B>概述</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="package-summary.html"><FONT CLASS="NavBarFont1"><B>软件包</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#FFFFFF" CLASS="NavBarCell1Rev"> &nbsp;<FONT CLASS="NavBarFont1Rev"><B>类</B></FONT>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="class-use/DistributedFileSystem.html"><FONT CLASS="NavBarFont1"><B>使用</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="package-tree.html"><FONT CLASS="NavBarFont1"><B>树</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="../../../../deprecated-list.html"><FONT CLASS="NavBarFont1"><B>已过时</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="../../../../index-all.html"><FONT CLASS="NavBarFont1"><B>索引</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="../../../../help-doc.html"><FONT CLASS="NavBarFont1"><B>帮助</B></FONT></A>&nbsp;</TD>
  </TR>
</TABLE>
</TD>
<TD ALIGN="right" VALIGN="top" ROWSPAN=3><EM>
</EM>
</TD>
</TR>

<TR>
<TD BGCOLOR="white" CLASS="NavBarCell2"><FONT SIZE="-2">
&nbsp;<A HREF="../../../../org/apache/hadoop/hdfs/DFSUtil.ErrorSimulator.html" title="org.apache.hadoop.hdfs 中的类"><B>上一个类</B></A>&nbsp;
&nbsp;<A HREF="../../../../org/apache/hadoop/hdfs/DistributedFileSystem.DiskStatus.html" title="org.apache.hadoop.hdfs 中的类"><B>下一个类</B></A></FONT></TD>
<TD BGCOLOR="white" CLASS="NavBarCell2"><FONT SIZE="-2">
  <A HREF="../../../../index.html?org/apache/hadoop/hdfs/DistributedFileSystem.html" target="_top"><B>框架</B></A>  &nbsp;
&nbsp;<A HREF="DistributedFileSystem.html" target="_top"><B>无框架</B></A>  &nbsp;
&nbsp;<SCRIPT type="text/javascript">
  <!--
  if(window==top) {
    document.writeln('<A HREF="../../../../allclasses-noframe.html"><B>所有类</B></A>');
  }
  //-->
</SCRIPT>
<NOSCRIPT>
  <A HREF="../../../../allclasses-noframe.html"><B>所有类</B></A>
</NOSCRIPT>


</FONT></TD>
</TR>
<TR>
<TD VALIGN="top" CLASS="NavBarCell3"><FONT SIZE="-2">
  摘要：&nbsp;<A HREF="#nested_class_summary">嵌套</A>&nbsp;|&nbsp;<A HREF="#fields_inherited_from_class_org.apache.hadoop.fs.FileSystem">字段</A>&nbsp;|&nbsp;<A HREF="#constructor_summary">构造方法</A>&nbsp;|&nbsp;<A HREF="#method_summary">方法</A></FONT></TD>
<TD VALIGN="top" CLASS="NavBarCell3"><FONT SIZE="-2">
详细信息：&nbsp;字段&nbsp;|&nbsp;<A HREF="#constructor_detail">构造方法</A>&nbsp;|&nbsp;<A HREF="#method_detail">方法</A></FONT></TD>
</TR>
</TABLE>
<A NAME="skip-navbar_bottom"></A>
<!-- ======== END OF BOTTOM NAVBAR ======= -->

<HR>
Copyright &copy; 2009 The Apache Software Foundation
</BODY>
</HTML>
