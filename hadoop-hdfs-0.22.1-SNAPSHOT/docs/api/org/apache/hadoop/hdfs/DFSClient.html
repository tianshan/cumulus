<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<!--NewPage-->
<HTML>
<HEAD>
<!-- Generated by javadoc (build 1.6.0_18) on Sun May 03 20:19:33 CST 2015 -->
<TITLE>
DFSClient (Hadoop-Hdfs 0.22.1-SNAPSHOT API)
</TITLE>

<META NAME="date" CONTENT="2015-05-03">

<LINK REL ="stylesheet" TYPE="text/css" HREF="../../../../stylesheet.css" TITLE="Style">

<SCRIPT type="text/javascript">
function windowTitle()
{
    if (location.href.indexOf('is-external=true') == -1) {
        parent.document.title="DFSClient (Hadoop-Hdfs 0.22.1-SNAPSHOT API)";
    }
}
</SCRIPT>
<NOSCRIPT>
</NOSCRIPT>

</HEAD>

<BODY BGCOLOR="white" onload="windowTitle();">
<HR>


<!-- ========= START OF TOP NAVBAR ======= -->
<A NAME="navbar_top"><!-- --></A>
<A HREF="#skip-navbar_top" title="跳过导航链接"></A>
<TABLE BORDER="0" WIDTH="100%" CELLPADDING="1" CELLSPACING="0" SUMMARY="">
<TR>
<TD COLSPAN=2 BGCOLOR="#EEEEFF" CLASS="NavBarCell1">
<A NAME="navbar_top_firstrow"><!-- --></A>
<TABLE BORDER="0" CELLPADDING="0" CELLSPACING="3" SUMMARY="">
  <TR ALIGN="center" VALIGN="top">
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="../../../../overview-summary.html"><FONT CLASS="NavBarFont1"><B>概述</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="package-summary.html"><FONT CLASS="NavBarFont1"><B>软件包</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#FFFFFF" CLASS="NavBarCell1Rev"> &nbsp;<FONT CLASS="NavBarFont1Rev"><B>类</B></FONT>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="class-use/DFSClient.html"><FONT CLASS="NavBarFont1"><B>使用</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="package-tree.html"><FONT CLASS="NavBarFont1"><B>树</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="../../../../deprecated-list.html"><FONT CLASS="NavBarFont1"><B>已过时</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="../../../../index-all.html"><FONT CLASS="NavBarFont1"><B>索引</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="../../../../help-doc.html"><FONT CLASS="NavBarFont1"><B>帮助</B></FONT></A>&nbsp;</TD>
  </TR>
</TABLE>
</TD>
<TD ALIGN="right" VALIGN="top" ROWSPAN=3><EM>
</EM>
</TD>
</TR>

<TR>
<TD BGCOLOR="white" CLASS="NavBarCell2"><FONT SIZE="-2">
&nbsp;<A HREF="../../../../org/apache/hadoop/hdfs/DeprecatedUTF8.html" title="org.apache.hadoop.hdfs 中的类"><B>上一个类</B></A>&nbsp;
&nbsp;<A HREF="../../../../org/apache/hadoop/hdfs/DFSClient.DFSDataInputStream.html" title="org.apache.hadoop.hdfs 中的类"><B>下一个类</B></A></FONT></TD>
<TD BGCOLOR="white" CLASS="NavBarCell2"><FONT SIZE="-2">
  <A HREF="../../../../index.html?org/apache/hadoop/hdfs/DFSClient.html" target="_top"><B>框架</B></A>  &nbsp;
&nbsp;<A HREF="DFSClient.html" target="_top"><B>无框架</B></A>  &nbsp;
&nbsp;<SCRIPT type="text/javascript">
  <!--
  if(window==top) {
    document.writeln('<A HREF="../../../../allclasses-noframe.html"><B>所有类</B></A>');
  }
  //-->
</SCRIPT>
<NOSCRIPT>
  <A HREF="../../../../allclasses-noframe.html"><B>所有类</B></A>
</NOSCRIPT>


</FONT></TD>
</TR>
<TR>
<TD VALIGN="top" CLASS="NavBarCell3"><FONT SIZE="-2">
  摘要：&nbsp;<A HREF="#nested_class_summary">嵌套</A>&nbsp;|&nbsp;<A HREF="#field_summary">字段</A>&nbsp;|&nbsp;<A HREF="#constructor_summary">构造方法</A>&nbsp;|&nbsp;<A HREF="#method_summary">方法</A></FONT></TD>
<TD VALIGN="top" CLASS="NavBarCell3"><FONT SIZE="-2">
详细信息：&nbsp;<A HREF="#field_detail">字段</A>&nbsp;|&nbsp;<A HREF="#constructor_detail">构造方法</A>&nbsp;|&nbsp;<A HREF="#method_detail">方法</A></FONT></TD>
</TR>
</TABLE>
<A NAME="skip-navbar_top"></A>
<!-- ========= END OF TOP NAVBAR ========= -->

<HR>
<!-- ======== START OF CLASS DATA ======== -->
<H2>
<FONT SIZE="-1">
org.apache.hadoop.hdfs</FONT>
<BR>
类 DFSClient</H2>
<PRE>
java.lang.Object
  <IMG SRC="../../../../resources/inherit.gif" ALT="继承者 "><B>org.apache.hadoop.hdfs.DFSClient</B>
</PRE>
<DL>
<DT><B>所有已实现的接口：</B> <DD>java.io.Closeable, <A HREF="../../../../org/apache/hadoop/hdfs/protocol/FSConstants.html" title="org.apache.hadoop.hdfs.protocol 中的接口">FSConstants</A></DD>
</DL>
<HR>
<DL>
<DT><PRE><FONT SIZE="-1">@InterfaceAudience.Private
</FONT>public class <B>DFSClient</B><DT>extends java.lang.Object<DT>implements <A HREF="../../../../org/apache/hadoop/hdfs/protocol/FSConstants.html" title="org.apache.hadoop.hdfs.protocol 中的接口">FSConstants</A>, java.io.Closeable</DL>
</PRE>

<P>
DFSClient can connect to a Hadoop Filesystem and 
 perform basic file tasks.  It uses the ClientProtocol
 to communicate with a NameNode daemon, and connects 
 directly to DataNodes to read/write block data.

 Hadoop DFS users should obtain an instance of 
 DistributedFileSystem, which uses DFSClient to handle
 filesystem tasks.
<P>

<P>
<HR>

<P>
<!-- ======== NESTED CLASS SUMMARY ======== -->

<A NAME="nested_class_summary"><!-- --></A>
<TABLE BORDER="1" WIDTH="100%" CELLPADDING="3" CELLSPACING="0" SUMMARY="">
<TR BGCOLOR="#CCCCFF" CLASS="TableHeadingColor">
<TH ALIGN="left" COLSPAN="2"><FONT SIZE="+2">
<B>嵌套类摘要</B></FONT></TH>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;class</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/hadoop/hdfs/DFSClient.DFSDataInputStream.html" title="org.apache.hadoop.hdfs 中的类">DFSClient.DFSDataInputStream</A></B></CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The Hdfs implementation of <CODE>FSDataInputStream</CODE></TD>
</TR>
</TABLE>
&nbsp;<A NAME="nested_classes_inherited_from_class_org.apache.hadoop.hdfs.protocol.FSConstants"><!-- --></A>
<TABLE BORDER="1" WIDTH="100%" CELLPADDING="3" CELLSPACING="0" SUMMARY="">
<TR BGCOLOR="#EEEEFF" CLASS="TableSubHeadingColor">
<TH ALIGN="left"><B>从接口 org.apache.hadoop.hdfs.protocol.<A HREF="../../../../org/apache/hadoop/hdfs/protocol/FSConstants.html" title="org.apache.hadoop.hdfs.protocol 中的接口">FSConstants</A> 继承的嵌套类/接口</B></TH>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD><CODE><A HREF="../../../../org/apache/hadoop/hdfs/protocol/FSConstants.DatanodeReportType.html" title="org.apache.hadoop.hdfs.protocol 中的枚举">FSConstants.DatanodeReportType</A>, <A HREF="../../../../org/apache/hadoop/hdfs/protocol/FSConstants.SafeModeAction.html" title="org.apache.hadoop.hdfs.protocol 中的枚举">FSConstants.SafeModeAction</A>, <A HREF="../../../../org/apache/hadoop/hdfs/protocol/FSConstants.UpgradeAction.html" title="org.apache.hadoop.hdfs.protocol 中的枚举">FSConstants.UpgradeAction</A></CODE></TD>
</TR>
</TABLE>
&nbsp;
<!-- =========== FIELD SUMMARY =========== -->

<A NAME="field_summary"><!-- --></A>
<TABLE BORDER="1" WIDTH="100%" CELLPADDING="3" CELLSPACING="0" SUMMARY="">
<TR BGCOLOR="#CCCCFF" CLASS="TableHeadingColor">
<TH ALIGN="left" COLSPAN="2"><FONT SIZE="+2">
<B>字段摘要</B></FONT></TH>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;org.apache.commons.logging.Log</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/hadoop/hdfs/DFSClient.html#LOG">LOG</A></B></CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;int</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/hadoop/hdfs/DFSClient.html#MAX_BLOCK_ACQUIRE_FAILURES">MAX_BLOCK_ACQUIRE_FAILURES</A></B></CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;long</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/hadoop/hdfs/DFSClient.html#SERVER_DEFAULTS_VALIDITY_PERIOD">SERVER_DEFAULTS_VALIDITY_PERIOD</A></B></CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
</TABLE>
&nbsp;<A NAME="fields_inherited_from_class_org.apache.hadoop.hdfs.protocol.FSConstants"><!-- --></A>
<TABLE BORDER="1" WIDTH="100%" CELLPADDING="3" CELLSPACING="0" SUMMARY="">
<TR BGCOLOR="#EEEEFF" CLASS="TableSubHeadingColor">
<TH ALIGN="left"><B>从接口 org.apache.hadoop.hdfs.protocol.<A HREF="../../../../org/apache/hadoop/hdfs/protocol/FSConstants.html" title="org.apache.hadoop.hdfs.protocol 中的接口">FSConstants</A> 继承的字段</B></TH>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD><CODE><A HREF="../../../../org/apache/hadoop/hdfs/protocol/FSConstants.html#BLOCK_INVALIDATE_CHUNK">BLOCK_INVALIDATE_CHUNK</A>, <A HREF="../../../../org/apache/hadoop/hdfs/protocol/FSConstants.html#BLOCKREPORT_INITIAL_DELAY">BLOCKREPORT_INITIAL_DELAY</A>, <A HREF="../../../../org/apache/hadoop/hdfs/protocol/FSConstants.html#BLOCKREPORT_INTERVAL">BLOCKREPORT_INTERVAL</A>, <A HREF="../../../../org/apache/hadoop/hdfs/protocol/FSConstants.html#BUFFER_SIZE">BUFFER_SIZE</A>, <A HREF="../../../../org/apache/hadoop/hdfs/protocol/FSConstants.html#DEFAULT_BLOCK_SIZE">DEFAULT_BLOCK_SIZE</A>, <A HREF="../../../../org/apache/hadoop/hdfs/protocol/FSConstants.html#DEFAULT_BYTES_PER_CHECKSUM">DEFAULT_BYTES_PER_CHECKSUM</A>, <A HREF="../../../../org/apache/hadoop/hdfs/protocol/FSConstants.html#DEFAULT_DATA_SOCKET_SIZE">DEFAULT_DATA_SOCKET_SIZE</A>, <A HREF="../../../../org/apache/hadoop/hdfs/protocol/FSConstants.html#DEFAULT_FILE_BUFFER_SIZE">DEFAULT_FILE_BUFFER_SIZE</A>, <A HREF="../../../../org/apache/hadoop/hdfs/protocol/FSConstants.html#DEFAULT_REPLICATION_FACTOR">DEFAULT_REPLICATION_FACTOR</A>, <A HREF="../../../../org/apache/hadoop/hdfs/protocol/FSConstants.html#DEFAULT_WRITE_PACKET_SIZE">DEFAULT_WRITE_PACKET_SIZE</A>, <A HREF="../../../../org/apache/hadoop/hdfs/protocol/FSConstants.html#HDFS_URI_SCHEME">HDFS_URI_SCHEME</A>, <A HREF="../../../../org/apache/hadoop/hdfs/protocol/FSConstants.html#HEARTBEAT_INTERVAL">HEARTBEAT_INTERVAL</A>, <A HREF="../../../../org/apache/hadoop/hdfs/protocol/FSConstants.html#LAYOUT_VERSION">LAYOUT_VERSION</A>, <A HREF="../../../../org/apache/hadoop/hdfs/protocol/FSConstants.html#LEASE_HARDLIMIT_PERIOD">LEASE_HARDLIMIT_PERIOD</A>, <A HREF="../../../../org/apache/hadoop/hdfs/protocol/FSConstants.html#LEASE_RECOVER_PERIOD">LEASE_RECOVER_PERIOD</A>, <A HREF="../../../../org/apache/hadoop/hdfs/protocol/FSConstants.html#LEASE_SOFTLIMIT_PERIOD">LEASE_SOFTLIMIT_PERIOD</A>, <A HREF="../../../../org/apache/hadoop/hdfs/protocol/FSConstants.html#MAX_PATH_DEPTH">MAX_PATH_DEPTH</A>, <A HREF="../../../../org/apache/hadoop/hdfs/protocol/FSConstants.html#MAX_PATH_LENGTH">MAX_PATH_LENGTH</A>, <A HREF="../../../../org/apache/hadoop/hdfs/protocol/FSConstants.html#MIN_BLOCKS_FOR_WRITE">MIN_BLOCKS_FOR_WRITE</A>, <A HREF="../../../../org/apache/hadoop/hdfs/protocol/FSConstants.html#QUOTA_DONT_SET">QUOTA_DONT_SET</A>, <A HREF="../../../../org/apache/hadoop/hdfs/protocol/FSConstants.html#QUOTA_RESET">QUOTA_RESET</A>, <A HREF="../../../../org/apache/hadoop/hdfs/protocol/FSConstants.html#SIZE_OF_INTEGER">SIZE_OF_INTEGER</A>, <A HREF="../../../../org/apache/hadoop/hdfs/protocol/FSConstants.html#SMALL_BUFFER_SIZE">SMALL_BUFFER_SIZE</A></CODE></TD>
</TR>
</TABLE>
&nbsp;
<!-- ======== CONSTRUCTOR SUMMARY ======== -->

<A NAME="constructor_summary"><!-- --></A>
<TABLE BORDER="1" WIDTH="100%" CELLPADDING="3" CELLSPACING="0" SUMMARY="">
<TR BGCOLOR="#CCCCFF" CLASS="TableHeadingColor">
<TH ALIGN="left" COLSPAN="2"><FONT SIZE="+2">
<B>构造方法摘要</B></FONT></TH>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD><CODE><B><A HREF="../../../../org/apache/hadoop/hdfs/DFSClient.html#DFSClient(org.apache.hadoop.conf.Configuration)">DFSClient</A></B>(org.apache.hadoop.conf.Configuration&nbsp;conf)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<B>已过时。</B>&nbsp;<I>Deprecated at 0.21</I></TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD><CODE><B><A HREF="../../../../org/apache/hadoop/hdfs/DFSClient.html#DFSClient(java.net.InetSocketAddress, org.apache.hadoop.conf.Configuration)">DFSClient</A></B>(java.net.InetSocketAddress&nbsp;nameNodeAddr,
          org.apache.hadoop.conf.Configuration&nbsp;conf)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Same as this(nameNodeAddr, conf, null);</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD><CODE><B><A HREF="../../../../org/apache/hadoop/hdfs/DFSClient.html#DFSClient(java.net.InetSocketAddress, org.apache.hadoop.conf.Configuration, org.apache.hadoop.fs.FileSystem.Statistics)">DFSClient</A></B>(java.net.InetSocketAddress&nbsp;nameNodeAddr,
          org.apache.hadoop.conf.Configuration&nbsp;conf,
          org.apache.hadoop.fs.FileSystem.Statistics&nbsp;stats)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Same as this(nameNodeAddr, null, conf, stats);</TD>
</TR>
</TABLE>
&nbsp;
<!-- ========== METHOD SUMMARY =========== -->

<A NAME="method_summary"><!-- --></A>
<TABLE BORDER="1" WIDTH="100%" CELLPADDING="3" CELLSPACING="0" SUMMARY="">
<TR BGCOLOR="#CCCCFF" CLASS="TableHeadingColor">
<TH ALIGN="left" COLSPAN="2"><FONT SIZE="+2">
<B>方法摘要</B></FONT></TH>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;void</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/hadoop/hdfs/DFSClient.html#cancelDelegationToken(org.apache.hadoop.security.token.Token)">cancelDelegationToken</A></B>(org.apache.hadoop.security.token.Token&lt;<A HREF="../../../../org/apache/hadoop/hdfs/security/token/delegation/DelegationTokenIdentifier.html" title="org.apache.hadoop.hdfs.security.token.delegation 中的类">DelegationTokenIdentifier</A>&gt;&nbsp;token)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;void</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/hadoop/hdfs/DFSClient.html#close()">close</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Close the file system, abandoning all of the leases and files being
 created and close connections to the namenode.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;void</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/hadoop/hdfs/DFSClient.html#concat(java.lang.String, java.lang.String[])">concat</A></B>(java.lang.String&nbsp;trg,
       java.lang.String[]&nbsp;srcs)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Move blocks from src to trg and delete src
 See <A HREF="../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html#concat(java.lang.String, java.lang.String[])"><CODE>ClientProtocol.concat(String, String [])</CODE></A>.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;java.io.OutputStream</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/hadoop/hdfs/DFSClient.html#create(java.lang.String, boolean)">create</A></B>(java.lang.String&nbsp;src,
       boolean&nbsp;overwrite)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Call <A HREF="../../../../org/apache/hadoop/hdfs/DFSClient.html#create(java.lang.String, boolean, short, long, org.apache.hadoop.util.Progressable)"><CODE>create(String, boolean, short, long, Progressable)</CODE></A> with
 default <code>replication</code> and <code>blockSize<code> and null <code>
 progress</code>.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;java.io.OutputStream</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/hadoop/hdfs/DFSClient.html#create(java.lang.String, boolean, org.apache.hadoop.util.Progressable)">create</A></B>(java.lang.String&nbsp;src,
       boolean&nbsp;overwrite,
       org.apache.hadoop.util.Progressable&nbsp;progress)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Call <A HREF="../../../../org/apache/hadoop/hdfs/DFSClient.html#create(java.lang.String, boolean, short, long, org.apache.hadoop.util.Progressable)"><CODE>create(String, boolean, short, long, Progressable)</CODE></A> with
 default <code>replication</code> and <code>blockSize<code>.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;java.io.OutputStream</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/hadoop/hdfs/DFSClient.html#create(java.lang.String, boolean, short, long)">create</A></B>(java.lang.String&nbsp;src,
       boolean&nbsp;overwrite,
       short&nbsp;replication,
       long&nbsp;blockSize)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Call <A HREF="../../../../org/apache/hadoop/hdfs/DFSClient.html#create(java.lang.String, boolean, short, long, org.apache.hadoop.util.Progressable)"><CODE>create(String, boolean, short, long, Progressable)</CODE></A> with
 null <code>progress</code>.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;java.io.OutputStream</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/hadoop/hdfs/DFSClient.html#create(java.lang.String, boolean, short, long, org.apache.hadoop.util.Progressable)">create</A></B>(java.lang.String&nbsp;src,
       boolean&nbsp;overwrite,
       short&nbsp;replication,
       long&nbsp;blockSize,
       org.apache.hadoop.util.Progressable&nbsp;progress)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Call <A HREF="../../../../org/apache/hadoop/hdfs/DFSClient.html#create(java.lang.String, boolean, short, long, org.apache.hadoop.util.Progressable, int)"><CODE>create(String, boolean, short, long, Progressable, int)</CODE></A>
 with default bufferSize.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;java.io.OutputStream</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/hadoop/hdfs/DFSClient.html#create(java.lang.String, boolean, short, long, org.apache.hadoop.util.Progressable, int)">create</A></B>(java.lang.String&nbsp;src,
       boolean&nbsp;overwrite,
       short&nbsp;replication,
       long&nbsp;blockSize,
       org.apache.hadoop.util.Progressable&nbsp;progress,
       int&nbsp;buffersize)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Call <A HREF="../../../../org/apache/hadoop/hdfs/DFSClient.html#create(java.lang.String, org.apache.hadoop.fs.permission.FsPermission, java.util.EnumSet, short, long, org.apache.hadoop.util.Progressable, int)"><CODE>create(String, FsPermission, EnumSet, short, long, 
 Progressable, int)</CODE></A> with default <code>permission</code>
 <CODE>FsPermission.getDefault()</CODE>.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;java.io.OutputStream</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/hadoop/hdfs/DFSClient.html#create(java.lang.String, org.apache.hadoop.fs.permission.FsPermission, java.util.EnumSet, boolean, short, long, org.apache.hadoop.util.Progressable, int)">create</A></B>(java.lang.String&nbsp;src,
       org.apache.hadoop.fs.permission.FsPermission&nbsp;permission,
       java.util.EnumSet&lt;org.apache.hadoop.fs.CreateFlag&gt;&nbsp;flag,
       boolean&nbsp;createParent,
       short&nbsp;replication,
       long&nbsp;blockSize,
       org.apache.hadoop.util.Progressable&nbsp;progress,
       int&nbsp;buffersize)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Create a new dfs file with the specified block replication 
 with write-progress reporting and return an output stream for writing
 into the file.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;java.io.OutputStream</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/hadoop/hdfs/DFSClient.html#create(java.lang.String, org.apache.hadoop.fs.permission.FsPermission, java.util.EnumSet, short, long, org.apache.hadoop.util.Progressable, int)">create</A></B>(java.lang.String&nbsp;src,
       org.apache.hadoop.fs.permission.FsPermission&nbsp;permission,
       java.util.EnumSet&lt;org.apache.hadoop.fs.CreateFlag&gt;&nbsp;flag,
       short&nbsp;replication,
       long&nbsp;blockSize,
       org.apache.hadoop.util.Progressable&nbsp;progress,
       int&nbsp;buffersize)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Call <A HREF="../../../../org/apache/hadoop/hdfs/DFSClient.html#create(java.lang.String, org.apache.hadoop.fs.permission.FsPermission, java.util.EnumSet, boolean, short, long, org.apache.hadoop.util.Progressable, int)"><CODE>create(String, FsPermission, EnumSet, boolean, short, 
 long, Progressable, int)</CODE></A> with <code>createParent</code> set to true.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;java.io.OutputStream</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/hadoop/hdfs/DFSClient.html#create(java.lang.String, long, org.apache.hadoop.fs.permission.FsPermission, java.util.EnumSet, boolean, org.apache.hadoop.util.Progressable, int)">create</A></B>(java.lang.String&nbsp;src,
       long&nbsp;fileSize,
       org.apache.hadoop.fs.permission.FsPermission&nbsp;permission,
       java.util.EnumSet&lt;org.apache.hadoop.fs.CreateFlag&gt;&nbsp;flag,
       boolean&nbsp;createParent,
       org.apache.hadoop.util.Progressable&nbsp;progress,
       int&nbsp;buffersize)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;java.io.OutputStream</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/hadoop/hdfs/DFSClient.html#create(java.lang.String, long, org.apache.hadoop.fs.permission.FsPermission, java.util.EnumSet, org.apache.hadoop.util.Progressable, int)">create</A></B>(java.lang.String&nbsp;src,
       long&nbsp;fileSize,
       org.apache.hadoop.fs.permission.FsPermission&nbsp;permission,
       java.util.EnumSet&lt;org.apache.hadoop.fs.CreateFlag&gt;&nbsp;flag,
       org.apache.hadoop.util.Progressable&nbsp;progress,
       int&nbsp;buffersize)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的接口">ClientProtocol</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/hadoop/hdfs/DFSClient.html#createNamenode(org.apache.hadoop.conf.Configuration)">createNamenode</A></B>(org.apache.hadoop.conf.Configuration&nbsp;conf)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The locking hierarchy is to first acquire lock on DFSClient object, followed by 
 lock on leasechecker, followed by lock on an individual DFSOutputStream.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;<A HREF="../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的接口">ClientProtocol</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/hadoop/hdfs/DFSClient.html#createNamenode(java.net.InetSocketAddress, org.apache.hadoop.conf.Configuration)">createNamenode</A></B>(java.net.InetSocketAddress&nbsp;nameNodeAddr,
               org.apache.hadoop.conf.Configuration&nbsp;conf)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;void</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/hadoop/hdfs/DFSClient.html#createSymlink(java.lang.String, java.lang.String, boolean)">createSymlink</A></B>(java.lang.String&nbsp;target,
              java.lang.String&nbsp;link,
              boolean&nbsp;createParent)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Creates a symbolic link.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;<A HREF="../../../../org/apache/hadoop/hdfs/protocol/DatanodeInfo.html" title="org.apache.hadoop.hdfs.protocol 中的类">DatanodeInfo</A>[]</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/hadoop/hdfs/DFSClient.html#datanodeReport(org.apache.hadoop.hdfs.protocol.FSConstants.DatanodeReportType)">datanodeReport</A></B>(<A HREF="../../../../org/apache/hadoop/hdfs/protocol/FSConstants.DatanodeReportType.html" title="org.apache.hadoop.hdfs.protocol 中的枚举">FSConstants.DatanodeReportType</A>&nbsp;type)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;boolean</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/hadoop/hdfs/DFSClient.html#delete(java.lang.String)">delete</A></B>(java.lang.String&nbsp;src)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<B>已过时。</B>&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;boolean</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/hadoop/hdfs/DFSClient.html#delete(java.lang.String, boolean)">delete</A></B>(java.lang.String&nbsp;src,
       boolean&nbsp;recursive)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;delete file or directory.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;<A HREF="../../../../org/apache/hadoop/hdfs/server/common/UpgradeStatusReport.html" title="org.apache.hadoop.hdfs.server.common 中的类">UpgradeStatusReport</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/hadoop/hdfs/DFSClient.html#distributedUpgradeProgress(org.apache.hadoop.hdfs.protocol.FSConstants.UpgradeAction)">distributedUpgradeProgress</A></B>(<A HREF="../../../../org/apache/hadoop/hdfs/protocol/FSConstants.UpgradeAction.html" title="org.apache.hadoop.hdfs.protocol 中的枚举">FSConstants.UpgradeAction</A>&nbsp;action)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;boolean</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/hadoop/hdfs/DFSClient.html#exists(java.lang.String)">exists</A></B>(java.lang.String&nbsp;src)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Implemented using getFileInfo(src)</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;void</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/hadoop/hdfs/DFSClient.html#finalizeUpgrade()">finalizeUpgrade</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;org.apache.hadoop.fs.BlockLocation[]</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/hadoop/hdfs/DFSClient.html#getBlockLocations(java.lang.String, long, long)">getBlockLocations</A></B>(java.lang.String&nbsp;src,
                  long&nbsp;start,
                  long&nbsp;length)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Get block location info about file
 
 getBlockLocations() returns a list of hostnames that store 
 data for a specific file region.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;long</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/hadoop/hdfs/DFSClient.html#getBlockSize(java.lang.String)">getBlockSize</A></B>(java.lang.String&nbsp;f)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;long</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/hadoop/hdfs/DFSClient.html#getCorruptBlocksCount()">getCorruptBlocksCount</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Returns count of blocks with at least one replica marked corrupt.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;long</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/hadoop/hdfs/DFSClient.html#getDefaultBlockSize()">getDefaultBlockSize</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Get the default block size for this cluster</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;short</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/hadoop/hdfs/DFSClient.html#getDefaultReplication()">getDefaultReplication</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;org.apache.hadoop.security.token.Token&lt;<A HREF="../../../../org/apache/hadoop/hdfs/security/token/delegation/DelegationTokenIdentifier.html" title="org.apache.hadoop.hdfs.security.token.delegation 中的类">DelegationTokenIdentifier</A>&gt;</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/hadoop/hdfs/DFSClient.html#getDelegationToken(org.apache.hadoop.io.Text)">getDelegationToken</A></B>(org.apache.hadoop.io.Text&nbsp;renewer)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;org.apache.hadoop.fs.FsStatus</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/hadoop/hdfs/DFSClient.html#getDiskStatus()">getDiskStatus</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;org.apache.hadoop.fs.MD5MD5CRC32FileChecksum</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/hadoop/hdfs/DFSClient.html#getFileChecksum(java.lang.String)">getFileChecksum</A></B>(java.lang.String&nbsp;src)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Get the checksum of a file.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;org.apache.hadoop.fs.MD5MD5CRC32FileChecksum</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/hadoop/hdfs/DFSClient.html#getFileChecksum(java.lang.String, org.apache.hadoop.hdfs.protocol.ClientProtocol, javax.net.SocketFactory, int)">getFileChecksum</A></B>(java.lang.String&nbsp;src,
                <A HREF="../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的接口">ClientProtocol</A>&nbsp;namenode,
                javax.net.SocketFactory&nbsp;socketFactory,
                int&nbsp;socketTimeout)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Get the checksum of a file.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;<A HREF="../../../../org/apache/hadoop/hdfs/protocol/HdfsFileStatus.html" title="org.apache.hadoop.hdfs.protocol 中的类">HdfsFileStatus</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/hadoop/hdfs/DFSClient.html#getFileInfo(java.lang.String)">getFileInfo</A></B>(java.lang.String&nbsp;src)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Get the file info for a specific file or directory.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;<A HREF="../../../../org/apache/hadoop/hdfs/protocol/HdfsFileStatus.html" title="org.apache.hadoop.hdfs.protocol 中的类">HdfsFileStatus</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/hadoop/hdfs/DFSClient.html#getFileLinkInfo(java.lang.String)">getFileLinkInfo</A></B>(java.lang.String&nbsp;src)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Get the file info for a specific file or directory.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;java.lang.String</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/hadoop/hdfs/DFSClient.html#getLinkTarget(java.lang.String)">getLinkTarget</A></B>(java.lang.String&nbsp;path)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Resolve the *first* symlink, if any, in the path.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;long</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/hadoop/hdfs/DFSClient.html#getMissingBlocksCount()">getMissingBlocksCount</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Returns count of blocks with no good replicas left.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;<A HREF="../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的接口">ClientProtocol</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/hadoop/hdfs/DFSClient.html#getNamenode()">getNamenode</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Get the namenode associated with this DFSClient object</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;org.apache.hadoop.fs.FsServerDefaults</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/hadoop/hdfs/DFSClient.html#getServerDefaults()">getServerDefaults</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Get server default values for a number of configuration params.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;long</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/hadoop/hdfs/DFSClient.html#getUnderReplicatedBlocksCount()">getUnderReplicatedBlocksCount</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Returns count of blocks with one of more replica missing.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;<A HREF="../../../../org/apache/hadoop/hdfs/protocol/DirectoryListing.html" title="org.apache.hadoop.hdfs.protocol 中的类">DirectoryListing</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/hadoop/hdfs/DFSClient.html#listPaths(java.lang.String, byte[])">listPaths</A></B>(java.lang.String&nbsp;src,
          byte[]&nbsp;startAfter)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Get a partial listing of the indicated directory
 No block locations need to be fetched</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;<A HREF="../../../../org/apache/hadoop/hdfs/protocol/DirectoryListing.html" title="org.apache.hadoop.hdfs.protocol 中的类">DirectoryListing</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/hadoop/hdfs/DFSClient.html#listPaths(java.lang.String, byte[], boolean)">listPaths</A></B>(java.lang.String&nbsp;src,
          byte[]&nbsp;startAfter,
          boolean&nbsp;needLocation)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Get a partial listing of the indicated directory

 Recommend to use HdfsFileStatus.EMPTY_NAME as startAfter
 if the application wants to fetch a listing starting from
 the first entry in the directory</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;void</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/hadoop/hdfs/DFSClient.html#metaSave(java.lang.String)">metaSave</A></B>(java.lang.String&nbsp;pathname)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Dumps DFS data structures into specified file.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;boolean</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/hadoop/hdfs/DFSClient.html#mkdirs(java.lang.String)">mkdirs</A></B>(java.lang.String&nbsp;src)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<B>已过时。</B>&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;boolean</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/hadoop/hdfs/DFSClient.html#mkdirs(java.lang.String, org.apache.hadoop.fs.permission.FsPermission, boolean)">mkdirs</A></B>(java.lang.String&nbsp;src,
       org.apache.hadoop.fs.permission.FsPermission&nbsp;permission,
       boolean&nbsp;createParent)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Create a directory (or hierarchy of directories) with the given
 name and permission.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;<A HREF="../../../../org/apache/hadoop/hdfs/DFSInputStream.html" title="org.apache.hadoop.hdfs 中的类">DFSInputStream</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/hadoop/hdfs/DFSClient.html#open(java.lang.String)">open</A></B>(java.lang.String&nbsp;src)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;<A HREF="../../../../org/apache/hadoop/hdfs/DFSInputStream.html" title="org.apache.hadoop.hdfs 中的类">DFSInputStream</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/hadoop/hdfs/DFSClient.html#open(java.lang.String, int, boolean)">open</A></B>(java.lang.String&nbsp;src,
     int&nbsp;buffersize,
     boolean&nbsp;verifyChecksum)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Create an input stream that obtains a nodelist from the
 namenode, and then reads from all the right places.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;<A HREF="../../../../org/apache/hadoop/hdfs/DFSInputStream.html" title="org.apache.hadoop.hdfs 中的类">DFSInputStream</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/hadoop/hdfs/DFSClient.html#open(java.lang.String, int, boolean, org.apache.hadoop.fs.FileSystem.Statistics)">open</A></B>(java.lang.String&nbsp;src,
     int&nbsp;buffersize,
     boolean&nbsp;verifyChecksum,
     org.apache.hadoop.fs.FileSystem.Statistics&nbsp;stats)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<B>已过时。</B>&nbsp;<I>Use <A HREF="../../../../org/apache/hadoop/hdfs/DFSClient.html#open(java.lang.String, int, boolean)"><CODE>open(String, int, boolean)</CODE></A> instead.</I></TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;java.io.OutputStream</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/hadoop/hdfs/DFSClient.html#primitiveCreate(java.lang.String, org.apache.hadoop.fs.permission.FsPermission, java.util.EnumSet, boolean, short, long, org.apache.hadoop.util.Progressable, int, int)">primitiveCreate</A></B>(java.lang.String&nbsp;src,
                org.apache.hadoop.fs.permission.FsPermission&nbsp;absPermission,
                java.util.EnumSet&lt;org.apache.hadoop.fs.CreateFlag&gt;&nbsp;flag,
                boolean&nbsp;createParent,
                short&nbsp;replication,
                long&nbsp;blockSize,
                org.apache.hadoop.util.Progressable&nbsp;progress,
                int&nbsp;buffersize,
                int&nbsp;bytesPerChecksum)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Same as {<A HREF="../../../../org/apache/hadoop/hdfs/DFSClient.html#create(java.lang.String, org.apache.hadoop.fs.permission.FsPermission, java.util.EnumSet, short, long, org.apache.hadoop.util.Progressable, int)"><CODE>create(String, FsPermission, EnumSet, short, long,
  Progressable, int)</CODE></A> except that the permission
   is absolute (ie has already been masked with umask.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;boolean</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/hadoop/hdfs/DFSClient.html#primitiveMkdir(java.lang.String, org.apache.hadoop.fs.permission.FsPermission)">primitiveMkdir</A></B>(java.lang.String&nbsp;src,
               org.apache.hadoop.fs.permission.FsPermission&nbsp;absPermission)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Same {<A HREF="../../../../org/apache/hadoop/hdfs/DFSClient.html#mkdirs(java.lang.String, org.apache.hadoop.fs.permission.FsPermission, boolean)"><CODE>mkdirs(String, FsPermission, boolean)</CODE></A> except
 that the permissions has already been masked against umask.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;void</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/hadoop/hdfs/DFSClient.html#refreshNodes()">refreshNodes</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Refresh the hosts and exclude files.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;boolean</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/hadoop/hdfs/DFSClient.html#rename(java.lang.String, java.lang.String)">rename</A></B>(java.lang.String&nbsp;src,
       java.lang.String&nbsp;dst)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<B>已过时。</B>&nbsp;<I>Use <A HREF="../../../../org/apache/hadoop/hdfs/DFSClient.html#rename(java.lang.String, java.lang.String, org.apache.hadoop.fs.Options.Rename...)"><CODE>rename(String, String, Options.Rename...)</CODE></A> instead.</I></TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;void</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/hadoop/hdfs/DFSClient.html#rename(java.lang.String, java.lang.String, org.apache.hadoop.fs.Options.Rename...)">rename</A></B>(java.lang.String&nbsp;src,
       java.lang.String&nbsp;dst,
       org.apache.hadoop.fs.Options.Rename...&nbsp;options)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Rename file or directory.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;long</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/hadoop/hdfs/DFSClient.html#renewDelegationToken(org.apache.hadoop.security.token.Token)">renewDelegationToken</A></B>(org.apache.hadoop.security.token.Token&lt;<A HREF="../../../../org/apache/hadoop/hdfs/security/token/delegation/DelegationTokenIdentifier.html" title="org.apache.hadoop.hdfs.security.token.delegation 中的类">DelegationTokenIdentifier</A>&gt;&nbsp;token)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;void</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/hadoop/hdfs/DFSClient.html#reportBadBlocks(org.apache.hadoop.hdfs.protocol.LocatedBlock[])">reportBadBlocks</A></B>(<A HREF="../../../../org/apache/hadoop/hdfs/protocol/LocatedBlock.html" title="org.apache.hadoop.hdfs.protocol 中的类">LocatedBlock</A>[]&nbsp;blocks)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Report corrupt blocks that were discovered by the client.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;void</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/hadoop/hdfs/DFSClient.html#setOwner(java.lang.String, java.lang.String, java.lang.String)">setOwner</A></B>(java.lang.String&nbsp;src,
         java.lang.String&nbsp;username,
         java.lang.String&nbsp;groupname)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Set file or directory owner.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;void</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/hadoop/hdfs/DFSClient.html#setPermission(java.lang.String, org.apache.hadoop.fs.permission.FsPermission)">setPermission</A></B>(java.lang.String&nbsp;src,
              org.apache.hadoop.fs.permission.FsPermission&nbsp;permission)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Set permissions to a file or directory.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;boolean</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/hadoop/hdfs/DFSClient.html#setReplication(java.lang.String, short)">setReplication</A></B>(java.lang.String&nbsp;src,
               short&nbsp;replication)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Set replication for an existing file.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;boolean</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/hadoop/hdfs/DFSClient.html#setSafeMode(org.apache.hadoop.hdfs.protocol.FSConstants.SafeModeAction)">setSafeMode</A></B>(<A HREF="../../../../org/apache/hadoop/hdfs/protocol/FSConstants.SafeModeAction.html" title="org.apache.hadoop.hdfs.protocol 中的枚举">FSConstants.SafeModeAction</A>&nbsp;action)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Enter, leave or get safe mode.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;void</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/hadoop/hdfs/DFSClient.html#setTimes(java.lang.String, long, long)">setTimes</A></B>(java.lang.String&nbsp;src,
         long&nbsp;mtime,
         long&nbsp;atime)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;set the modification and access time of a file</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;java.lang.String</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/hadoop/hdfs/DFSClient.html#stringifyToken(org.apache.hadoop.security.token.Token)">stringifyToken</A></B>(org.apache.hadoop.security.token.Token&lt;<A HREF="../../../../org/apache/hadoop/hdfs/security/token/delegation/DelegationTokenIdentifier.html" title="org.apache.hadoop.hdfs.security.token.delegation 中的类">DelegationTokenIdentifier</A>&gt;&nbsp;token)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;A test method for printing out tokens</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;java.lang.String</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../../org/apache/hadoop/hdfs/DFSClient.html#toString()">toString</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</TD>
</TR>
</TABLE>
&nbsp;<A NAME="methods_inherited_from_class_java.lang.Object"><!-- --></A>
<TABLE BORDER="1" WIDTH="100%" CELLPADDING="3" CELLSPACING="0" SUMMARY="">
<TR BGCOLOR="#EEEEFF" CLASS="TableSubHeadingColor">
<TH ALIGN="left"><B>从类 java.lang.Object 继承的方法</B></TH>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD><CODE>clone, equals, finalize, getClass, hashCode, notify, notifyAll, wait, wait, wait</CODE></TD>
</TR>
</TABLE>
&nbsp;
<P>

<!-- ============ FIELD DETAIL =========== -->

<A NAME="field_detail"><!-- --></A>
<TABLE BORDER="1" WIDTH="100%" CELLPADDING="3" CELLSPACING="0" SUMMARY="">
<TR BGCOLOR="#CCCCFF" CLASS="TableHeadingColor">
<TH ALIGN="left" COLSPAN="1"><FONT SIZE="+2">
<B>字段详细信息</B></FONT></TH>
</TR>
</TABLE>

<A NAME="LOG"><!-- --></A><H3>
LOG</H3>
<PRE>
public static final org.apache.commons.logging.Log <B>LOG</B></PRE>
<DL>
<DL>
</DL>
</DL>
<HR>

<A NAME="SERVER_DEFAULTS_VALIDITY_PERIOD"><!-- --></A><H3>
SERVER_DEFAULTS_VALIDITY_PERIOD</H3>
<PRE>
public static final long <B>SERVER_DEFAULTS_VALIDITY_PERIOD</B></PRE>
<DL>
<DL>
<DT><B>另请参见：</B><DD><A HREF="../../../../constant-values.html#org.apache.hadoop.hdfs.DFSClient.SERVER_DEFAULTS_VALIDITY_PERIOD">常量字段值</A></DL>
</DL>
<HR>

<A NAME="MAX_BLOCK_ACQUIRE_FAILURES"><!-- --></A><H3>
MAX_BLOCK_ACQUIRE_FAILURES</H3>
<PRE>
public static final int <B>MAX_BLOCK_ACQUIRE_FAILURES</B></PRE>
<DL>
<DL>
<DT><B>另请参见：</B><DD><A HREF="../../../../constant-values.html#org.apache.hadoop.hdfs.DFSClient.MAX_BLOCK_ACQUIRE_FAILURES">常量字段值</A></DL>
</DL>

<!-- ========= CONSTRUCTOR DETAIL ======== -->

<A NAME="constructor_detail"><!-- --></A>
<TABLE BORDER="1" WIDTH="100%" CELLPADDING="3" CELLSPACING="0" SUMMARY="">
<TR BGCOLOR="#CCCCFF" CLASS="TableHeadingColor">
<TH ALIGN="left" COLSPAN="1"><FONT SIZE="+2">
<B>构造方法详细信息</B></FONT></TH>
</TR>
</TABLE>

<A NAME="DFSClient(org.apache.hadoop.conf.Configuration)"><!-- --></A><H3>
DFSClient</H3>
<PRE>
<FONT SIZE="-1">@Deprecated
</FONT>public <B>DFSClient</B>(org.apache.hadoop.conf.Configuration&nbsp;conf)
          throws java.io.IOException</PRE>
<DL>
<DD><B>已过时。</B>&nbsp;<I>Deprecated at 0.21</I>
<P>
<DD>Same as this(NameNode.getAddress(conf), conf);
<P>
<DL>

<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE><DT><B>另请参见：</B><DD><A HREF="../../../../org/apache/hadoop/hdfs/DFSClient.html#DFSClient(java.net.InetSocketAddress, org.apache.hadoop.conf.Configuration)"><CODE>DFSClient(InetSocketAddress, Configuration)</CODE></A></DL>
</DL>
<HR>

<A NAME="DFSClient(java.net.InetSocketAddress, org.apache.hadoop.conf.Configuration)"><!-- --></A><H3>
DFSClient</H3>
<PRE>
public <B>DFSClient</B>(java.net.InetSocketAddress&nbsp;nameNodeAddr,
                 org.apache.hadoop.conf.Configuration&nbsp;conf)
          throws java.io.IOException</PRE>
<DL>
<DD>Same as this(nameNodeAddr, conf, null);
<P>
<DL>

<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE><DT><B>另请参见：</B><DD><A HREF="../../../../org/apache/hadoop/hdfs/DFSClient.html#DFSClient(java.net.InetSocketAddress, org.apache.hadoop.conf.Configuration, org.apache.hadoop.fs.FileSystem.Statistics)"><CODE>DFSClient(InetSocketAddress, Configuration, org.apache.hadoop.fs.FileSystem.Statistics)</CODE></A></DL>
</DL>
<HR>

<A NAME="DFSClient(java.net.InetSocketAddress, org.apache.hadoop.conf.Configuration, org.apache.hadoop.fs.FileSystem.Statistics)"><!-- --></A><H3>
DFSClient</H3>
<PRE>
public <B>DFSClient</B>(java.net.InetSocketAddress&nbsp;nameNodeAddr,
                 org.apache.hadoop.conf.Configuration&nbsp;conf,
                 org.apache.hadoop.fs.FileSystem.Statistics&nbsp;stats)
          throws java.io.IOException</PRE>
<DL>
<DD>Same as this(nameNodeAddr, null, conf, stats);
<P>
<DL>

<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE><DT><B>另请参见：</B><DD><A HREF="../../../../org/apache/hadoop/hdfs/DFSClient.html#DFSClient(java.net.InetSocketAddress, org.apache.hadoop.hdfs.protocol.ClientProtocol, org.apache.hadoop.conf.Configuration, org.apache.hadoop.fs.FileSystem.Statistics)"><CODE>DFSClient(InetSocketAddress, ClientProtocol, Configuration, org.apache.hadoop.fs.FileSystem.Statistics)</CODE></A></DL>
</DL>

<!-- ============ METHOD DETAIL ========== -->

<A NAME="method_detail"><!-- --></A>
<TABLE BORDER="1" WIDTH="100%" CELLPADDING="3" CELLSPACING="0" SUMMARY="">
<TR BGCOLOR="#CCCCFF" CLASS="TableHeadingColor">
<TH ALIGN="left" COLSPAN="1"><FONT SIZE="+2">
<B>方法详细信息</B></FONT></TH>
</TR>
</TABLE>

<A NAME="createNamenode(org.apache.hadoop.conf.Configuration)"><!-- --></A><H3>
createNamenode</H3>
<PRE>
public static <A HREF="../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的接口">ClientProtocol</A> <B>createNamenode</B>(org.apache.hadoop.conf.Configuration&nbsp;conf)
                                     throws java.io.IOException</PRE>
<DL>
<DD>The locking hierarchy is to first acquire lock on DFSClient object, followed by 
 lock on leasechecker, followed by lock on an individual DFSOutputStream.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="createNamenode(java.net.InetSocketAddress, org.apache.hadoop.conf.Configuration)"><!-- --></A><H3>
createNamenode</H3>
<PRE>
public static <A HREF="../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的接口">ClientProtocol</A> <B>createNamenode</B>(java.net.InetSocketAddress&nbsp;nameNodeAddr,
                                            org.apache.hadoop.conf.Configuration&nbsp;conf)
                                     throws java.io.IOException</PRE>
<DL>
<DD><DL>
</DL>
</DD>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="close()"><!-- --></A><H3>
close</H3>
<PRE>
public void <B>close</B>()
           throws java.io.IOException</PRE>
<DL>
<DD>Close the file system, abandoning all of the leases and files being
 created and close connections to the namenode.
<P>
<DD><DL>
<DT><B>指定者：</B><DD>接口 <CODE>java.io.Closeable</CODE> 中的 <CODE>close</CODE></DL>
</DD>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="getDefaultBlockSize()"><!-- --></A><H3>
getDefaultBlockSize</H3>
<PRE>
public long <B>getDefaultBlockSize</B>()</PRE>
<DL>
<DD>Get the default block size for this cluster
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>

<DT><B>返回：</B><DD>the default block size in bytes</DL>
</DD>
</DL>
<HR>

<A NAME="getBlockSize(java.lang.String)"><!-- --></A><H3>
getBlockSize</H3>
<PRE>
public long <B>getBlockSize</B>(java.lang.String&nbsp;f)
                  throws java.io.IOException</PRE>
<DL>
<DD><DL>
</DL>
</DD>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE><DT><B>另请参见：</B><DD><A HREF="../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html#getPreferredBlockSize(java.lang.String)"><CODE>ClientProtocol.getPreferredBlockSize(String)</CODE></A></DL>
</DD>
</DL>
<HR>

<A NAME="getServerDefaults()"><!-- --></A><H3>
getServerDefaults</H3>
<PRE>
public org.apache.hadoop.fs.FsServerDefaults <B>getServerDefaults</B>()
                                                        throws java.io.IOException</PRE>
<DL>
<DD>Get server default values for a number of configuration params.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE><DT><B>另请参见：</B><DD><A HREF="../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html#getServerDefaults()"><CODE>ClientProtocol.getServerDefaults()</CODE></A></DL>
</DD>
</DL>
<HR>

<A NAME="stringifyToken(org.apache.hadoop.security.token.Token)"><!-- --></A><H3>
stringifyToken</H3>
<PRE>
public static java.lang.String <B>stringifyToken</B>(org.apache.hadoop.security.token.Token&lt;<A HREF="../../../../org/apache/hadoop/hdfs/security/token/delegation/DelegationTokenIdentifier.html" title="org.apache.hadoop.hdfs.security.token.delegation 中的类">DelegationTokenIdentifier</A>&gt;&nbsp;token)
                                       throws java.io.IOException</PRE>
<DL>
<DD>A test method for printing out tokens
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>参数：</B><DD><CODE>token</CODE> - 
<DT><B>返回：</B><DD>Stringify version of the token
<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="getDelegationToken(org.apache.hadoop.io.Text)"><!-- --></A><H3>
getDelegationToken</H3>
<PRE>
public org.apache.hadoop.security.token.Token&lt;<A HREF="../../../../org/apache/hadoop/hdfs/security/token/delegation/DelegationTokenIdentifier.html" title="org.apache.hadoop.hdfs.security.token.delegation 中的类">DelegationTokenIdentifier</A>&gt; <B>getDelegationToken</B>(org.apache.hadoop.io.Text&nbsp;renewer)
                                                                                     throws java.io.IOException</PRE>
<DL>
<DD><DL>
</DL>
</DD>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE><DT><B>另请参见：</B><DD><A HREF="../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html#getDelegationToken(org.apache.hadoop.io.Text)"><CODE>ClientProtocol.getDelegationToken(Text)</CODE></A></DL>
</DD>
</DL>
<HR>

<A NAME="renewDelegationToken(org.apache.hadoop.security.token.Token)"><!-- --></A><H3>
renewDelegationToken</H3>
<PRE>
public long <B>renewDelegationToken</B>(org.apache.hadoop.security.token.Token&lt;<A HREF="../../../../org/apache/hadoop/hdfs/security/token/delegation/DelegationTokenIdentifier.html" title="org.apache.hadoop.hdfs.security.token.delegation 中的类">DelegationTokenIdentifier</A>&gt;&nbsp;token)
                          throws org.apache.hadoop.security.token.SecretManager.InvalidToken,
                                 java.io.IOException</PRE>
<DL>
<DD><DL>
</DL>
</DD>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>org.apache.hadoop.security.token.SecretManager.InvalidToken</CODE>
<DD><CODE>java.io.IOException</CODE><DT><B>另请参见：</B><DD><A HREF="../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html#renewDelegationToken(org.apache.hadoop.security.token.Token)"><CODE>ClientProtocol.renewDelegationToken(Token)</CODE></A></DL>
</DD>
</DL>
<HR>

<A NAME="cancelDelegationToken(org.apache.hadoop.security.token.Token)"><!-- --></A><H3>
cancelDelegationToken</H3>
<PRE>
public void <B>cancelDelegationToken</B>(org.apache.hadoop.security.token.Token&lt;<A HREF="../../../../org/apache/hadoop/hdfs/security/token/delegation/DelegationTokenIdentifier.html" title="org.apache.hadoop.hdfs.security.token.delegation 中的类">DelegationTokenIdentifier</A>&gt;&nbsp;token)
                           throws org.apache.hadoop.security.token.SecretManager.InvalidToken,
                                  java.io.IOException</PRE>
<DL>
<DD><DL>
</DL>
</DD>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>org.apache.hadoop.security.token.SecretManager.InvalidToken</CODE>
<DD><CODE>java.io.IOException</CODE><DT><B>另请参见：</B><DD><A HREF="../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html#cancelDelegationToken(org.apache.hadoop.security.token.Token)"><CODE>ClientProtocol.cancelDelegationToken(Token)</CODE></A></DL>
</DD>
</DL>
<HR>

<A NAME="reportBadBlocks(org.apache.hadoop.hdfs.protocol.LocatedBlock[])"><!-- --></A><H3>
reportBadBlocks</H3>
<PRE>
public void <B>reportBadBlocks</B>(<A HREF="../../../../org/apache/hadoop/hdfs/protocol/LocatedBlock.html" title="org.apache.hadoop.hdfs.protocol 中的类">LocatedBlock</A>[]&nbsp;blocks)
                     throws java.io.IOException</PRE>
<DL>
<DD>Report corrupt blocks that were discovered by the client.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE><DT><B>另请参见：</B><DD><A HREF="../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html#reportBadBlocks(org.apache.hadoop.hdfs.protocol.LocatedBlock[])"><CODE>ClientProtocol.reportBadBlocks(LocatedBlock[])</CODE></A></DL>
</DD>
</DL>
<HR>

<A NAME="getDefaultReplication()"><!-- --></A><H3>
getDefaultReplication</H3>
<PRE>
public short <B>getDefaultReplication</B>()</PRE>
<DL>
<DD><DL>
</DL>
</DD>
<DD><DL>
</DL>
</DD>
</DL>
<HR>

<A NAME="getBlockLocations(java.lang.String, long, long)"><!-- --></A><H3>
getBlockLocations</H3>
<PRE>
public org.apache.hadoop.fs.BlockLocation[] <B>getBlockLocations</B>(java.lang.String&nbsp;src,
                                                              long&nbsp;start,
                                                              long&nbsp;length)
                                                       throws java.io.IOException,
                                                              org.apache.hadoop.fs.UnresolvedLinkException</PRE>
<DL>
<DD>Get block location info about file
 
 getBlockLocations() returns a list of hostnames that store 
 data for a specific file region.  It returns a set of hostnames
 for every block within the indicated region.

 This function is very useful when writing code that considers
 data-placement when performing operations.  For example, the
 MapReduce system tries to schedule tasks on the same machines
 as the data-block the task processes.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE>
<DD><CODE>org.apache.hadoop.fs.UnresolvedLinkException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="open(java.lang.String)"><!-- --></A><H3>
open</H3>
<PRE>
public <A HREF="../../../../org/apache/hadoop/hdfs/DFSInputStream.html" title="org.apache.hadoop.hdfs 中的类">DFSInputStream</A> <B>open</B>(java.lang.String&nbsp;src)
                    throws java.io.IOException,
                           org.apache.hadoop.fs.UnresolvedLinkException</PRE>
<DL>
<DD><DL>
</DL>
</DD>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE>
<DD><CODE>org.apache.hadoop.fs.UnresolvedLinkException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="open(java.lang.String, int, boolean, org.apache.hadoop.fs.FileSystem.Statistics)"><!-- --></A><H3>
open</H3>
<PRE>
<FONT SIZE="-1">@Deprecated
</FONT>public <A HREF="../../../../org/apache/hadoop/hdfs/DFSInputStream.html" title="org.apache.hadoop.hdfs 中的类">DFSInputStream</A> <B>open</B>(java.lang.String&nbsp;src,
                                      int&nbsp;buffersize,
                                      boolean&nbsp;verifyChecksum,
                                      org.apache.hadoop.fs.FileSystem.Statistics&nbsp;stats)
                    throws java.io.IOException,
                           org.apache.hadoop.fs.UnresolvedLinkException</PRE>
<DL>
<DD><B>已过时。</B>&nbsp;<I>Use <A HREF="../../../../org/apache/hadoop/hdfs/DFSClient.html#open(java.lang.String, int, boolean)"><CODE>open(String, int, boolean)</CODE></A> instead.</I>
<P>
<DD>Create an input stream that obtains a nodelist from the
 namenode, and then reads from all the right places.  Creates
 inner subclass of InputStream that does the right out-of-band
 work.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE>
<DD><CODE>org.apache.hadoop.fs.UnresolvedLinkException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="open(java.lang.String, int, boolean)"><!-- --></A><H3>
open</H3>
<PRE>
public <A HREF="../../../../org/apache/hadoop/hdfs/DFSInputStream.html" title="org.apache.hadoop.hdfs 中的类">DFSInputStream</A> <B>open</B>(java.lang.String&nbsp;src,
                           int&nbsp;buffersize,
                           boolean&nbsp;verifyChecksum)
                    throws java.io.IOException,
                           org.apache.hadoop.fs.UnresolvedLinkException</PRE>
<DL>
<DD>Create an input stream that obtains a nodelist from the
 namenode, and then reads from all the right places.  Creates
 inner subclass of InputStream that does the right out-of-band
 work.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE>
<DD><CODE>org.apache.hadoop.fs.UnresolvedLinkException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="getNamenode()"><!-- --></A><H3>
getNamenode</H3>
<PRE>
public <A HREF="../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的接口">ClientProtocol</A> <B>getNamenode</B>()</PRE>
<DL>
<DD>Get the namenode associated with this DFSClient object
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>

<DT><B>返回：</B><DD>the namenode associated with this DFSClient object</DL>
</DD>
</DL>
<HR>

<A NAME="create(java.lang.String, boolean)"><!-- --></A><H3>
create</H3>
<PRE>
public java.io.OutputStream <B>create</B>(java.lang.String&nbsp;src,
                                   boolean&nbsp;overwrite)
                            throws java.io.IOException</PRE>
<DL>
<DD>Call <A HREF="../../../../org/apache/hadoop/hdfs/DFSClient.html#create(java.lang.String, boolean, short, long, org.apache.hadoop.util.Progressable)"><CODE>create(String, boolean, short, long, Progressable)</CODE></A> with
 default <code>replication</code> and <code>blockSize<code> and null <code>
 progress</code>.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="create(java.lang.String, boolean, org.apache.hadoop.util.Progressable)"><!-- --></A><H3>
create</H3>
<PRE>
public java.io.OutputStream <B>create</B>(java.lang.String&nbsp;src,
                                   boolean&nbsp;overwrite,
                                   org.apache.hadoop.util.Progressable&nbsp;progress)
                            throws java.io.IOException</PRE>
<DL>
<DD>Call <A HREF="../../../../org/apache/hadoop/hdfs/DFSClient.html#create(java.lang.String, boolean, short, long, org.apache.hadoop.util.Progressable)"><CODE>create(String, boolean, short, long, Progressable)</CODE></A> with
 default <code>replication</code> and <code>blockSize<code>.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="create(java.lang.String, boolean, short, long)"><!-- --></A><H3>
create</H3>
<PRE>
public java.io.OutputStream <B>create</B>(java.lang.String&nbsp;src,
                                   boolean&nbsp;overwrite,
                                   short&nbsp;replication,
                                   long&nbsp;blockSize)
                            throws java.io.IOException</PRE>
<DL>
<DD>Call <A HREF="../../../../org/apache/hadoop/hdfs/DFSClient.html#create(java.lang.String, boolean, short, long, org.apache.hadoop.util.Progressable)"><CODE>create(String, boolean, short, long, Progressable)</CODE></A> with
 null <code>progress</code>.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="create(java.lang.String, boolean, short, long, org.apache.hadoop.util.Progressable)"><!-- --></A><H3>
create</H3>
<PRE>
public java.io.OutputStream <B>create</B>(java.lang.String&nbsp;src,
                                   boolean&nbsp;overwrite,
                                   short&nbsp;replication,
                                   long&nbsp;blockSize,
                                   org.apache.hadoop.util.Progressable&nbsp;progress)
                            throws java.io.IOException</PRE>
<DL>
<DD>Call <A HREF="../../../../org/apache/hadoop/hdfs/DFSClient.html#create(java.lang.String, boolean, short, long, org.apache.hadoop.util.Progressable, int)"><CODE>create(String, boolean, short, long, Progressable, int)</CODE></A>
 with default bufferSize.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="create(java.lang.String, boolean, short, long, org.apache.hadoop.util.Progressable, int)"><!-- --></A><H3>
create</H3>
<PRE>
public java.io.OutputStream <B>create</B>(java.lang.String&nbsp;src,
                                   boolean&nbsp;overwrite,
                                   short&nbsp;replication,
                                   long&nbsp;blockSize,
                                   org.apache.hadoop.util.Progressable&nbsp;progress,
                                   int&nbsp;buffersize)
                            throws java.io.IOException</PRE>
<DL>
<DD>Call <A HREF="../../../../org/apache/hadoop/hdfs/DFSClient.html#create(java.lang.String, org.apache.hadoop.fs.permission.FsPermission, java.util.EnumSet, short, long, org.apache.hadoop.util.Progressable, int)"><CODE>create(String, FsPermission, EnumSet, short, long, 
 Progressable, int)</CODE></A> with default <code>permission</code>
 <CODE>FsPermission.getDefault()</CODE>.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>参数：</B><DD><CODE>src</CODE> - File name<DD><CODE>overwrite</CODE> - overwrite an existing file if true<DD><CODE>replication</CODE> - replication factor for the file<DD><CODE>blockSize</CODE> - maximum block size<DD><CODE>progress</CODE> - interface for reporting client progress<DD><CODE>buffersize</CODE> - underlying buffersize
<DT><B>返回：</B><DD>output stream
<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="create(java.lang.String, org.apache.hadoop.fs.permission.FsPermission, java.util.EnumSet, short, long, org.apache.hadoop.util.Progressable, int)"><!-- --></A><H3>
create</H3>
<PRE>
public java.io.OutputStream <B>create</B>(java.lang.String&nbsp;src,
                                   org.apache.hadoop.fs.permission.FsPermission&nbsp;permission,
                                   java.util.EnumSet&lt;org.apache.hadoop.fs.CreateFlag&gt;&nbsp;flag,
                                   short&nbsp;replication,
                                   long&nbsp;blockSize,
                                   org.apache.hadoop.util.Progressable&nbsp;progress,
                                   int&nbsp;buffersize)
                            throws java.io.IOException</PRE>
<DL>
<DD>Call <A HREF="../../../../org/apache/hadoop/hdfs/DFSClient.html#create(java.lang.String, org.apache.hadoop.fs.permission.FsPermission, java.util.EnumSet, boolean, short, long, org.apache.hadoop.util.Progressable, int)"><CODE>create(String, FsPermission, EnumSet, boolean, short, 
 long, Progressable, int)</CODE></A> with <code>createParent</code> set to true.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="create(java.lang.String, long, org.apache.hadoop.fs.permission.FsPermission, java.util.EnumSet, org.apache.hadoop.util.Progressable, int)"><!-- --></A><H3>
create</H3>
<PRE>
public java.io.OutputStream <B>create</B>(java.lang.String&nbsp;src,
                                   long&nbsp;fileSize,
                                   org.apache.hadoop.fs.permission.FsPermission&nbsp;permission,
                                   java.util.EnumSet&lt;org.apache.hadoop.fs.CreateFlag&gt;&nbsp;flag,
                                   org.apache.hadoop.util.Progressable&nbsp;progress,
                                   int&nbsp;buffersize)
                            throws java.io.IOException</PRE>
<DL>
<DD><DL>
</DL>
</DD>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="create(java.lang.String, org.apache.hadoop.fs.permission.FsPermission, java.util.EnumSet, boolean, short, long, org.apache.hadoop.util.Progressable, int)"><!-- --></A><H3>
create</H3>
<PRE>
public java.io.OutputStream <B>create</B>(java.lang.String&nbsp;src,
                                   org.apache.hadoop.fs.permission.FsPermission&nbsp;permission,
                                   java.util.EnumSet&lt;org.apache.hadoop.fs.CreateFlag&gt;&nbsp;flag,
                                   boolean&nbsp;createParent,
                                   short&nbsp;replication,
                                   long&nbsp;blockSize,
                                   org.apache.hadoop.util.Progressable&nbsp;progress,
                                   int&nbsp;buffersize)
                            throws java.io.IOException</PRE>
<DL>
<DD>Create a new dfs file with the specified block replication 
 with write-progress reporting and return an output stream for writing
 into the file.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>参数：</B><DD><CODE>src</CODE> - File name<DD><CODE>permission</CODE> - The permission of the directory being created.
          If null, use default permission <CODE>FsPermission.getDefault()</CODE><DD><CODE>flag</CODE> - indicates create a new file or create/overwrite an
          existing file or append to an existing file<DD><CODE>createParent</CODE> - create missing parent directory if true<DD><CODE>replication</CODE> - block replication<DD><CODE>blockSize</CODE> - maximum block size<DD><CODE>progress</CODE> - interface for reporting client progress<DD><CODE>buffersize</CODE> - underlying buffer size
<DT><B>返回：</B><DD>output stream
<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE><DT><B>另请参见：</B><DD><A HREF="../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html#create(java.lang.String, org.apache.hadoop.fs.permission.FsPermission, java.lang.String, org.apache.hadoop.io.EnumSetWritable, boolean, short, long)"><CODE>for detailed description of exceptions thrown</CODE></A></DL>
</DD>
</DL>
<HR>

<A NAME="create(java.lang.String, long, org.apache.hadoop.fs.permission.FsPermission, java.util.EnumSet, boolean, org.apache.hadoop.util.Progressable, int)"><!-- --></A><H3>
create</H3>
<PRE>
public java.io.OutputStream <B>create</B>(java.lang.String&nbsp;src,
                                   long&nbsp;fileSize,
                                   org.apache.hadoop.fs.permission.FsPermission&nbsp;permission,
                                   java.util.EnumSet&lt;org.apache.hadoop.fs.CreateFlag&gt;&nbsp;flag,
                                   boolean&nbsp;createParent,
                                   org.apache.hadoop.util.Progressable&nbsp;progress,
                                   int&nbsp;buffersize)
                            throws java.io.IOException</PRE>
<DL>
<DD><DL>
</DL>
</DD>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="primitiveCreate(java.lang.String, org.apache.hadoop.fs.permission.FsPermission, java.util.EnumSet, boolean, short, long, org.apache.hadoop.util.Progressable, int, int)"><!-- --></A><H3>
primitiveCreate</H3>
<PRE>
public java.io.OutputStream <B>primitiveCreate</B>(java.lang.String&nbsp;src,
                                            org.apache.hadoop.fs.permission.FsPermission&nbsp;absPermission,
                                            java.util.EnumSet&lt;org.apache.hadoop.fs.CreateFlag&gt;&nbsp;flag,
                                            boolean&nbsp;createParent,
                                            short&nbsp;replication,
                                            long&nbsp;blockSize,
                                            org.apache.hadoop.util.Progressable&nbsp;progress,
                                            int&nbsp;buffersize,
                                            int&nbsp;bytesPerChecksum)
                                     throws java.io.IOException,
                                            org.apache.hadoop.fs.UnresolvedLinkException</PRE>
<DL>
<DD>Same as {<A HREF="../../../../org/apache/hadoop/hdfs/DFSClient.html#create(java.lang.String, org.apache.hadoop.fs.permission.FsPermission, java.util.EnumSet, short, long, org.apache.hadoop.util.Progressable, int)"><CODE>create(String, FsPermission, EnumSet, short, long,
  Progressable, int)</CODE></A> except that the permission
   is absolute (ie has already been masked with umask.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE>
<DD><CODE>org.apache.hadoop.fs.UnresolvedLinkException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="createSymlink(java.lang.String, java.lang.String, boolean)"><!-- --></A><H3>
createSymlink</H3>
<PRE>
public void <B>createSymlink</B>(java.lang.String&nbsp;target,
                          java.lang.String&nbsp;link,
                          boolean&nbsp;createParent)
                   throws java.io.IOException</PRE>
<DL>
<DD>Creates a symbolic link.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE><DT><B>另请参见：</B><DD><A HREF="../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html#createSymlink(java.lang.String, java.lang.String, org.apache.hadoop.fs.permission.FsPermission, boolean)"><CODE>ClientProtocol.createSymlink(String, String,FsPermission, boolean)</CODE></A></DL>
</DD>
</DL>
<HR>

<A NAME="getLinkTarget(java.lang.String)"><!-- --></A><H3>
getLinkTarget</H3>
<PRE>
public java.lang.String <B>getLinkTarget</B>(java.lang.String&nbsp;path)
                               throws java.io.IOException</PRE>
<DL>
<DD>Resolve the *first* symlink, if any, in the path.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE><DT><B>另请参见：</B><DD><A HREF="../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html#getLinkTarget(java.lang.String)"><CODE>ClientProtocol.getLinkTarget(String)</CODE></A></DL>
</DD>
</DL>
<HR>

<A NAME="setReplication(java.lang.String, short)"><!-- --></A><H3>
setReplication</H3>
<PRE>
public boolean <B>setReplication</B>(java.lang.String&nbsp;src,
                              short&nbsp;replication)
                       throws java.io.IOException</PRE>
<DL>
<DD>Set replication for an existing file.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>参数：</B><DD><CODE>src</CODE> - file name<DD><CODE>replication</CODE> - 
<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE><DT><B>另请参见：</B><DD><A HREF="../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html#setReplication(java.lang.String, short)"><CODE>ClientProtocol.setReplication(String, short)</CODE></A></DL>
</DD>
</DL>
<HR>

<A NAME="rename(java.lang.String, java.lang.String)"><!-- --></A><H3>
rename</H3>
<PRE>
<FONT SIZE="-1">@Deprecated
</FONT>public boolean <B>rename</B>(java.lang.String&nbsp;src,
                                 java.lang.String&nbsp;dst)
               throws java.io.IOException</PRE>
<DL>
<DD><B>已过时。</B>&nbsp;<I>Use <A HREF="../../../../org/apache/hadoop/hdfs/DFSClient.html#rename(java.lang.String, java.lang.String, org.apache.hadoop.fs.Options.Rename...)"><CODE>rename(String, String, Options.Rename...)</CODE></A> instead.</I>
<P>
<DD>Rename file or directory.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE><DT><B>另请参见：</B><DD><A HREF="../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html#rename(java.lang.String, java.lang.String)"><CODE>ClientProtocol.rename(String, String)</CODE></A></DL>
</DD>
</DL>
<HR>

<A NAME="concat(java.lang.String, java.lang.String[])"><!-- --></A><H3>
concat</H3>
<PRE>
public void <B>concat</B>(java.lang.String&nbsp;trg,
                   java.lang.String[]&nbsp;srcs)
            throws java.io.IOException</PRE>
<DL>
<DD>Move blocks from src to trg and delete src
 See <A HREF="../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html#concat(java.lang.String, java.lang.String[])"><CODE>ClientProtocol.concat(String, String [])</CODE></A>.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="rename(java.lang.String, java.lang.String, org.apache.hadoop.fs.Options.Rename...)"><!-- --></A><H3>
rename</H3>
<PRE>
public void <B>rename</B>(java.lang.String&nbsp;src,
                   java.lang.String&nbsp;dst,
                   org.apache.hadoop.fs.Options.Rename...&nbsp;options)
            throws java.io.IOException</PRE>
<DL>
<DD>Rename file or directory.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE><DT><B>另请参见：</B><DD><A HREF="../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html#rename(java.lang.String, java.lang.String, org.apache.hadoop.fs.Options.Rename...)"><CODE>ClientProtocol.rename(String, String, Options.Rename...)</CODE></A></DL>
</DD>
</DL>
<HR>

<A NAME="delete(java.lang.String)"><!-- --></A><H3>
delete</H3>
<PRE>
<FONT SIZE="-1">@Deprecated
</FONT>public boolean <B>delete</B>(java.lang.String&nbsp;src)
               throws java.io.IOException</PRE>
<DL>
<DD><B>已过时。</B>&nbsp;
<P>
<DD>Delete file or directory.
 See <A HREF="../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html#delete(java.lang.String)"><CODE>ClientProtocol.delete(String)</CODE></A>.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="delete(java.lang.String, boolean)"><!-- --></A><H3>
delete</H3>
<PRE>
public boolean <B>delete</B>(java.lang.String&nbsp;src,
                      boolean&nbsp;recursive)
               throws java.io.IOException</PRE>
<DL>
<DD>delete file or directory.
 delete contents of the directory if non empty and recursive 
 set to true
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE><DT><B>另请参见：</B><DD><A HREF="../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html#delete(java.lang.String, boolean)"><CODE>ClientProtocol.delete(String, boolean)</CODE></A></DL>
</DD>
</DL>
<HR>

<A NAME="exists(java.lang.String)"><!-- --></A><H3>
exists</H3>
<PRE>
public boolean <B>exists</B>(java.lang.String&nbsp;src)
               throws java.io.IOException</PRE>
<DL>
<DD>Implemented using getFileInfo(src)
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="listPaths(java.lang.String, byte[])"><!-- --></A><H3>
listPaths</H3>
<PRE>
public <A HREF="../../../../org/apache/hadoop/hdfs/protocol/DirectoryListing.html" title="org.apache.hadoop.hdfs.protocol 中的类">DirectoryListing</A> <B>listPaths</B>(java.lang.String&nbsp;src,
                                  byte[]&nbsp;startAfter)
                           throws java.io.IOException</PRE>
<DL>
<DD>Get a partial listing of the indicated directory
 No block locations need to be fetched
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="listPaths(java.lang.String, byte[], boolean)"><!-- --></A><H3>
listPaths</H3>
<PRE>
public <A HREF="../../../../org/apache/hadoop/hdfs/protocol/DirectoryListing.html" title="org.apache.hadoop.hdfs.protocol 中的类">DirectoryListing</A> <B>listPaths</B>(java.lang.String&nbsp;src,
                                  byte[]&nbsp;startAfter,
                                  boolean&nbsp;needLocation)
                           throws java.io.IOException</PRE>
<DL>
<DD>Get a partial listing of the indicated directory

 Recommend to use HdfsFileStatus.EMPTY_NAME as startAfter
 if the application wants to fetch a listing starting from
 the first entry in the directory
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE><DT><B>另请参见：</B><DD><A HREF="../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html#getListing(java.lang.String, byte[], boolean)"><CODE>ClientProtocol.getListing(String, byte[], boolean)</CODE></A></DL>
</DD>
</DL>
<HR>

<A NAME="getFileInfo(java.lang.String)"><!-- --></A><H3>
getFileInfo</H3>
<PRE>
public <A HREF="../../../../org/apache/hadoop/hdfs/protocol/HdfsFileStatus.html" title="org.apache.hadoop.hdfs.protocol 中的类">HdfsFileStatus</A> <B>getFileInfo</B>(java.lang.String&nbsp;src)
                           throws java.io.IOException</PRE>
<DL>
<DD>Get the file info for a specific file or directory.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>参数：</B><DD><CODE>src</CODE> - The string representation of the path to the file
<DT><B>返回：</B><DD>object containing information regarding the file
         or null if file not found
<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE><DT><B>另请参见：</B><DD><A HREF="../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html#getFileInfo(java.lang.String)"><CODE>for description of exceptions</CODE></A></DL>
</DD>
</DL>
<HR>

<A NAME="getFileLinkInfo(java.lang.String)"><!-- --></A><H3>
getFileLinkInfo</H3>
<PRE>
public <A HREF="../../../../org/apache/hadoop/hdfs/protocol/HdfsFileStatus.html" title="org.apache.hadoop.hdfs.protocol 中的类">HdfsFileStatus</A> <B>getFileLinkInfo</B>(java.lang.String&nbsp;src)
                               throws java.io.IOException</PRE>
<DL>
<DD>Get the file info for a specific file or directory. If src
 refers to a symlink then the FileStatus of the link is returned.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>参数：</B><DD><CODE>src</CODE> - path to a file or directory.
 
 For description of exceptions thrown
<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE><DT><B>另请参见：</B><DD><A HREF="../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html#getFileLinkInfo(java.lang.String)"><CODE>ClientProtocol.getFileLinkInfo(String)</CODE></A></DL>
</DD>
</DL>
<HR>

<A NAME="getFileChecksum(java.lang.String)"><!-- --></A><H3>
getFileChecksum</H3>
<PRE>
public org.apache.hadoop.fs.MD5MD5CRC32FileChecksum <B>getFileChecksum</B>(java.lang.String&nbsp;src)
                                                             throws java.io.IOException</PRE>
<DL>
<DD>Get the checksum of a file.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>参数：</B><DD><CODE>src</CODE> - The file path
<DT><B>返回：</B><DD>The checksum
<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE><DT><B>另请参见：</B><DD><A HREF="../../../../org/apache/hadoop/hdfs/DistributedFileSystem.html#getFileChecksum(org.apache.hadoop.fs.Path)"><CODE>DistributedFileSystem.getFileChecksum(Path)</CODE></A></DL>
</DD>
</DL>
<HR>

<A NAME="getFileChecksum(java.lang.String, org.apache.hadoop.hdfs.protocol.ClientProtocol, javax.net.SocketFactory, int)"><!-- --></A><H3>
getFileChecksum</H3>
<PRE>
public static org.apache.hadoop.fs.MD5MD5CRC32FileChecksum <B>getFileChecksum</B>(java.lang.String&nbsp;src,
                                                                           <A HREF="../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的接口">ClientProtocol</A>&nbsp;namenode,
                                                                           javax.net.SocketFactory&nbsp;socketFactory,
                                                                           int&nbsp;socketTimeout)
                                                                    throws java.io.IOException</PRE>
<DL>
<DD>Get the checksum of a file.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>参数：</B><DD><CODE>src</CODE> - The file path
<DT><B>返回：</B><DD>The checksum
<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="setPermission(java.lang.String, org.apache.hadoop.fs.permission.FsPermission)"><!-- --></A><H3>
setPermission</H3>
<PRE>
public void <B>setPermission</B>(java.lang.String&nbsp;src,
                          org.apache.hadoop.fs.permission.FsPermission&nbsp;permission)
                   throws java.io.IOException</PRE>
<DL>
<DD>Set permissions to a file or directory.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>参数：</B><DD><CODE>src</CODE> - path name.<DD><CODE>permission</CODE> - 
<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE><DT><B>另请参见：</B><DD><A HREF="../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html#setPermission(java.lang.String, org.apache.hadoop.fs.permission.FsPermission)"><CODE>ClientProtocol.setPermission(String, FsPermission)</CODE></A></DL>
</DD>
</DL>
<HR>

<A NAME="setOwner(java.lang.String, java.lang.String, java.lang.String)"><!-- --></A><H3>
setOwner</H3>
<PRE>
public void <B>setOwner</B>(java.lang.String&nbsp;src,
                     java.lang.String&nbsp;username,
                     java.lang.String&nbsp;groupname)
              throws java.io.IOException</PRE>
<DL>
<DD>Set file or directory owner.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>参数：</B><DD><CODE>src</CODE> - path name.<DD><CODE>username</CODE> - user id.<DD><CODE>groupname</CODE> - user group.
<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE><DT><B>另请参见：</B><DD><A HREF="../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html#setOwner(java.lang.String, java.lang.String, java.lang.String)"><CODE>ClientProtocol.setOwner(String, String, String)</CODE></A></DL>
</DD>
</DL>
<HR>

<A NAME="getDiskStatus()"><!-- --></A><H3>
getDiskStatus</H3>
<PRE>
public org.apache.hadoop.fs.FsStatus <B>getDiskStatus</B>()
                                            throws java.io.IOException</PRE>
<DL>
<DD><DL>
</DL>
</DD>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE><DT><B>另请参见：</B><DD><A HREF="../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html#getStats()"><CODE>ClientProtocol.getStats()</CODE></A></DL>
</DD>
</DL>
<HR>

<A NAME="getMissingBlocksCount()"><!-- --></A><H3>
getMissingBlocksCount</H3>
<PRE>
public long <B>getMissingBlocksCount</B>()
                           throws java.io.IOException</PRE>
<DL>
<DD>Returns count of blocks with no good replicas left. Normally should be 
 zero.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="getUnderReplicatedBlocksCount()"><!-- --></A><H3>
getUnderReplicatedBlocksCount</H3>
<PRE>
public long <B>getUnderReplicatedBlocksCount</B>()
                                   throws java.io.IOException</PRE>
<DL>
<DD>Returns count of blocks with one of more replica missing.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="getCorruptBlocksCount()"><!-- --></A><H3>
getCorruptBlocksCount</H3>
<PRE>
public long <B>getCorruptBlocksCount</B>()
                           throws java.io.IOException</PRE>
<DL>
<DD>Returns count of blocks with at least one replica marked corrupt.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="datanodeReport(org.apache.hadoop.hdfs.protocol.FSConstants.DatanodeReportType)"><!-- --></A><H3>
datanodeReport</H3>
<PRE>
public <A HREF="../../../../org/apache/hadoop/hdfs/protocol/DatanodeInfo.html" title="org.apache.hadoop.hdfs.protocol 中的类">DatanodeInfo</A>[] <B>datanodeReport</B>(<A HREF="../../../../org/apache/hadoop/hdfs/protocol/FSConstants.DatanodeReportType.html" title="org.apache.hadoop.hdfs.protocol 中的枚举">FSConstants.DatanodeReportType</A>&nbsp;type)
                              throws java.io.IOException</PRE>
<DL>
<DD><DL>
</DL>
</DD>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="setSafeMode(org.apache.hadoop.hdfs.protocol.FSConstants.SafeModeAction)"><!-- --></A><H3>
setSafeMode</H3>
<PRE>
public boolean <B>setSafeMode</B>(<A HREF="../../../../org/apache/hadoop/hdfs/protocol/FSConstants.SafeModeAction.html" title="org.apache.hadoop.hdfs.protocol 中的枚举">FSConstants.SafeModeAction</A>&nbsp;action)
                    throws java.io.IOException</PRE>
<DL>
<DD>Enter, leave or get safe mode.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE><DT><B>另请参见：</B><DD><A HREF="../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html#setSafeMode(org.apache.hadoop.hdfs.protocol.FSConstants.SafeModeAction)"><CODE>ClientProtocol.setSafeMode(FSConstants.SafeModeAction)</CODE></A></DL>
</DD>
</DL>
<HR>

<A NAME="refreshNodes()"><!-- --></A><H3>
refreshNodes</H3>
<PRE>
public void <B>refreshNodes</B>()
                  throws java.io.IOException</PRE>
<DL>
<DD>Refresh the hosts and exclude files.  (Rereads them.)
 See <A HREF="../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html#refreshNodes()"><CODE>ClientProtocol.refreshNodes()</CODE></A> 
 for more details.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE><DT><B>另请参见：</B><DD><A HREF="../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html#refreshNodes()"><CODE>ClientProtocol.refreshNodes()</CODE></A></DL>
</DD>
</DL>
<HR>

<A NAME="metaSave(java.lang.String)"><!-- --></A><H3>
metaSave</H3>
<PRE>
public void <B>metaSave</B>(java.lang.String&nbsp;pathname)
              throws java.io.IOException</PRE>
<DL>
<DD>Dumps DFS data structures into specified file.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE><DT><B>另请参见：</B><DD><A HREF="../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html#metaSave(java.lang.String)"><CODE>ClientProtocol.metaSave(String)</CODE></A></DL>
</DD>
</DL>
<HR>

<A NAME="finalizeUpgrade()"><!-- --></A><H3>
finalizeUpgrade</H3>
<PRE>
public void <B>finalizeUpgrade</B>()
                     throws java.io.IOException</PRE>
<DL>
<DD><DL>
</DL>
</DD>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE><DT><B>另请参见：</B><DD><A HREF="../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html#finalizeUpgrade()"><CODE>ClientProtocol.finalizeUpgrade()</CODE></A></DL>
</DD>
</DL>
<HR>

<A NAME="distributedUpgradeProgress(org.apache.hadoop.hdfs.protocol.FSConstants.UpgradeAction)"><!-- --></A><H3>
distributedUpgradeProgress</H3>
<PRE>
public <A HREF="../../../../org/apache/hadoop/hdfs/server/common/UpgradeStatusReport.html" title="org.apache.hadoop.hdfs.server.common 中的类">UpgradeStatusReport</A> <B>distributedUpgradeProgress</B>(<A HREF="../../../../org/apache/hadoop/hdfs/protocol/FSConstants.UpgradeAction.html" title="org.apache.hadoop.hdfs.protocol 中的枚举">FSConstants.UpgradeAction</A>&nbsp;action)
                                               throws java.io.IOException</PRE>
<DL>
<DD><DL>
</DL>
</DD>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE><DT><B>另请参见：</B><DD><A HREF="../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html#distributedUpgradeProgress(org.apache.hadoop.hdfs.protocol.FSConstants.UpgradeAction)"><CODE>ClientProtocol.distributedUpgradeProgress(FSConstants.UpgradeAction)</CODE></A></DL>
</DD>
</DL>
<HR>

<A NAME="mkdirs(java.lang.String)"><!-- --></A><H3>
mkdirs</H3>
<PRE>
<FONT SIZE="-1">@Deprecated
</FONT>public boolean <B>mkdirs</B>(java.lang.String&nbsp;src)
               throws java.io.IOException</PRE>
<DL>
<DD><B>已过时。</B>&nbsp;
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="mkdirs(java.lang.String, org.apache.hadoop.fs.permission.FsPermission, boolean)"><!-- --></A><H3>
mkdirs</H3>
<PRE>
public boolean <B>mkdirs</B>(java.lang.String&nbsp;src,
                      org.apache.hadoop.fs.permission.FsPermission&nbsp;permission,
                      boolean&nbsp;createParent)
               throws java.io.IOException</PRE>
<DL>
<DD>Create a directory (or hierarchy of directories) with the given
 name and permission.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>
<DT><B>参数：</B><DD><CODE>src</CODE> - The path of the directory being created<DD><CODE>permission</CODE> - The permission of the directory being created.
 If permission == null, use <CODE>FsPermission.getDefault()</CODE>.<DD><CODE>createParent</CODE> - create missing parent directory if true
<DT><B>返回：</B><DD>True if the operation success.
<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE><DT><B>另请参见：</B><DD><A HREF="../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html#mkdirs(java.lang.String, org.apache.hadoop.fs.permission.FsPermission, boolean)"><CODE>ClientProtocol.mkdirs(String, FsPermission, boolean)</CODE></A></DL>
</DD>
</DL>
<HR>

<A NAME="primitiveMkdir(java.lang.String, org.apache.hadoop.fs.permission.FsPermission)"><!-- --></A><H3>
primitiveMkdir</H3>
<PRE>
public boolean <B>primitiveMkdir</B>(java.lang.String&nbsp;src,
                              org.apache.hadoop.fs.permission.FsPermission&nbsp;absPermission)
                       throws java.io.IOException</PRE>
<DL>
<DD>Same {<A HREF="../../../../org/apache/hadoop/hdfs/DFSClient.html#mkdirs(java.lang.String, org.apache.hadoop.fs.permission.FsPermission, boolean)"><CODE>mkdirs(String, FsPermission, boolean)</CODE></A> except
 that the permissions has already been masked against umask.
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE></DL>
</DD>
</DL>
<HR>

<A NAME="setTimes(java.lang.String, long, long)"><!-- --></A><H3>
setTimes</H3>
<PRE>
public void <B>setTimes</B>(java.lang.String&nbsp;src,
                     long&nbsp;mtime,
                     long&nbsp;atime)
              throws java.io.IOException</PRE>
<DL>
<DD>set the modification and access time of a file
<P>
<DD><DL>
</DL>
</DD>
<DD><DL>

<DT><B>抛出：</B>
<DD><CODE>java.io.IOException</CODE><DT><B>另请参见：</B><DD><A HREF="../../../../org/apache/hadoop/hdfs/protocol/ClientProtocol.html#setTimes(java.lang.String, long, long)"><CODE>ClientProtocol.setTimes(String, long, long)</CODE></A></DL>
</DD>
</DL>
<HR>

<A NAME="toString()"><!-- --></A><H3>
toString</H3>
<PRE>
public java.lang.String <B>toString</B>()</PRE>
<DL>
<DD>
<P>
<DD><DL>
<DT><B>覆盖：</B><DD>类 <CODE>java.lang.Object</CODE> 中的 <CODE>toString</CODE></DL>
</DD>
<DD><DL>
</DL>
</DD>
</DL>
<!-- ========= END OF CLASS DATA ========= -->
<HR>


<!-- ======= START OF BOTTOM NAVBAR ====== -->
<A NAME="navbar_bottom"><!-- --></A>
<A HREF="#skip-navbar_bottom" title="跳过导航链接"></A>
<TABLE BORDER="0" WIDTH="100%" CELLPADDING="1" CELLSPACING="0" SUMMARY="">
<TR>
<TD COLSPAN=2 BGCOLOR="#EEEEFF" CLASS="NavBarCell1">
<A NAME="navbar_bottom_firstrow"><!-- --></A>
<TABLE BORDER="0" CELLPADDING="0" CELLSPACING="3" SUMMARY="">
  <TR ALIGN="center" VALIGN="top">
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="../../../../overview-summary.html"><FONT CLASS="NavBarFont1"><B>概述</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="package-summary.html"><FONT CLASS="NavBarFont1"><B>软件包</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#FFFFFF" CLASS="NavBarCell1Rev"> &nbsp;<FONT CLASS="NavBarFont1Rev"><B>类</B></FONT>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="class-use/DFSClient.html"><FONT CLASS="NavBarFont1"><B>使用</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="package-tree.html"><FONT CLASS="NavBarFont1"><B>树</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="../../../../deprecated-list.html"><FONT CLASS="NavBarFont1"><B>已过时</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="../../../../index-all.html"><FONT CLASS="NavBarFont1"><B>索引</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="../../../../help-doc.html"><FONT CLASS="NavBarFont1"><B>帮助</B></FONT></A>&nbsp;</TD>
  </TR>
</TABLE>
</TD>
<TD ALIGN="right" VALIGN="top" ROWSPAN=3><EM>
</EM>
</TD>
</TR>

<TR>
<TD BGCOLOR="white" CLASS="NavBarCell2"><FONT SIZE="-2">
&nbsp;<A HREF="../../../../org/apache/hadoop/hdfs/DeprecatedUTF8.html" title="org.apache.hadoop.hdfs 中的类"><B>上一个类</B></A>&nbsp;
&nbsp;<A HREF="../../../../org/apache/hadoop/hdfs/DFSClient.DFSDataInputStream.html" title="org.apache.hadoop.hdfs 中的类"><B>下一个类</B></A></FONT></TD>
<TD BGCOLOR="white" CLASS="NavBarCell2"><FONT SIZE="-2">
  <A HREF="../../../../index.html?org/apache/hadoop/hdfs/DFSClient.html" target="_top"><B>框架</B></A>  &nbsp;
&nbsp;<A HREF="DFSClient.html" target="_top"><B>无框架</B></A>  &nbsp;
&nbsp;<SCRIPT type="text/javascript">
  <!--
  if(window==top) {
    document.writeln('<A HREF="../../../../allclasses-noframe.html"><B>所有类</B></A>');
  }
  //-->
</SCRIPT>
<NOSCRIPT>
  <A HREF="../../../../allclasses-noframe.html"><B>所有类</B></A>
</NOSCRIPT>


</FONT></TD>
</TR>
<TR>
<TD VALIGN="top" CLASS="NavBarCell3"><FONT SIZE="-2">
  摘要：&nbsp;<A HREF="#nested_class_summary">嵌套</A>&nbsp;|&nbsp;<A HREF="#field_summary">字段</A>&nbsp;|&nbsp;<A HREF="#constructor_summary">构造方法</A>&nbsp;|&nbsp;<A HREF="#method_summary">方法</A></FONT></TD>
<TD VALIGN="top" CLASS="NavBarCell3"><FONT SIZE="-2">
详细信息：&nbsp;<A HREF="#field_detail">字段</A>&nbsp;|&nbsp;<A HREF="#constructor_detail">构造方法</A>&nbsp;|&nbsp;<A HREF="#method_detail">方法</A></FONT></TD>
</TR>
</TABLE>
<A NAME="skip-navbar_bottom"></A>
<!-- ======== END OF BOTTOM NAVBAR ======= -->

<HR>
Copyright &copy; 2009 The Apache Software Foundation
</BODY>
</HTML>
