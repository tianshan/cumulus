<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<!--NewPage-->
<HTML>
<HEAD>
<!-- Generated by javadoc (build 1.6.0_18) on Sun May 03 20:19:36 CST 2015 -->
<TITLE>
索引 (Hadoop-Hdfs 0.22.1-SNAPSHOT API)
</TITLE>

<META NAME="date" CONTENT="2015-05-03">

<LINK REL ="stylesheet" TYPE="text/css" HREF="./stylesheet.css" TITLE="Style">

<SCRIPT type="text/javascript">
function windowTitle()
{
    if (location.href.indexOf('is-external=true') == -1) {
        parent.document.title="索引 (Hadoop-Hdfs 0.22.1-SNAPSHOT API)";
    }
}
</SCRIPT>
<NOSCRIPT>
</NOSCRIPT>

</HEAD>

<BODY BGCOLOR="white" onload="windowTitle();">
<HR>


<!-- ========= START OF TOP NAVBAR ======= -->
<A NAME="navbar_top"><!-- --></A>
<A HREF="#skip-navbar_top" title="跳过导航链接"></A>
<TABLE BORDER="0" WIDTH="100%" CELLPADDING="1" CELLSPACING="0" SUMMARY="">
<TR>
<TD COLSPAN=2 BGCOLOR="#EEEEFF" CLASS="NavBarCell1">
<A NAME="navbar_top_firstrow"><!-- --></A>
<TABLE BORDER="0" CELLPADDING="0" CELLSPACING="3" SUMMARY="">
  <TR ALIGN="center" VALIGN="top">
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="./overview-summary.html"><FONT CLASS="NavBarFont1"><B>概述</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <FONT CLASS="NavBarFont1">软件包</FONT>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <FONT CLASS="NavBarFont1">类</FONT>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <FONT CLASS="NavBarFont1">使用</FONT>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="./overview-tree.html"><FONT CLASS="NavBarFont1"><B>树</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="./deprecated-list.html"><FONT CLASS="NavBarFont1"><B>已过时</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#FFFFFF" CLASS="NavBarCell1Rev"> &nbsp;<FONT CLASS="NavBarFont1Rev"><B>索引</B></FONT>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="./help-doc.html"><FONT CLASS="NavBarFont1"><B>帮助</B></FONT></A>&nbsp;</TD>
  </TR>
</TABLE>
</TD>
<TD ALIGN="right" VALIGN="top" ROWSPAN=3><EM>
</EM>
</TD>
</TR>

<TR>
<TD BGCOLOR="white" CLASS="NavBarCell2"><FONT SIZE="-2">
&nbsp;上一个&nbsp;
&nbsp;下一个</FONT></TD>
<TD BGCOLOR="white" CLASS="NavBarCell2"><FONT SIZE="-2">
  <A HREF="./index.html?index-all.html" target="_top"><B>框架</B></A>  &nbsp;
&nbsp;<A HREF="index-all.html" target="_top"><B>无框架</B></A>  &nbsp;
&nbsp;<SCRIPT type="text/javascript">
  <!--
  if(window==top) {
    document.writeln('<A HREF="./allclasses-noframe.html"><B>所有类</B></A>');
  }
  //-->
</SCRIPT>
<NOSCRIPT>
  <A HREF="./allclasses-noframe.html"><B>所有类</B></A>
</NOSCRIPT>


</FONT></TD>
</TR>
</TABLE>
<A NAME="skip-navbar_top"></A>
<!-- ========= END OF TOP NAVBAR ========= -->

<A HREF="#_A_">A</A> <A HREF="#_B_">B</A> <A HREF="#_C_">C</A> <A HREF="#_D_">D</A> <A HREF="#_E_">E</A> <A HREF="#_F_">F</A> <A HREF="#_G_">G</A> <A HREF="#_H_">H</A> <A HREF="#_I_">I</A> <A HREF="#_J_">J</A> <A HREF="#_K_">K</A> <A HREF="#_L_">L</A> <A HREF="#_M_">M</A> <A HREF="#_N_">N</A> <A HREF="#_O_">O</A> <A HREF="#_P_">P</A> <A HREF="#_Q_">Q</A> <A HREF="#_R_">R</A> <A HREF="#_S_">S</A> <A HREF="#_T_">T</A> <A HREF="#_U_">U</A> <A HREF="#_V_">V</A> <A HREF="#_W_">W</A> <A HREF="#_X_">X</A> <A HREF="#___">_</A> <HR>
<A NAME="_A_"><!-- --></A><H2>
<B>A</B></H2>
<DL>
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/ClientProtocol.html#abandonBlock(org.apache.hadoop.hdfs.protocol.Block, java.lang.String, java.lang.String)"><B>abandonBlock(Block, String, String)</B></A> - 
接口 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/ClientProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的接口">ClientProtocol</A> 中的方法
<DD>The client can give up on a blcok by calling abandonBlock().
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#abandonBlock(org.apache.hadoop.hdfs.protocol.Block, java.lang.String, java.lang.String)"><B>abandonBlock(Block, String, String)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FSNamesystem</A> 中的方法
<DD>The client would like to let go of the given block
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html#abandonBlock(org.apache.hadoop.hdfs.protocol.Block, java.lang.String, java.lang.String)"><B>abandonBlock(Block, String, String)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">NameNode</A> 中的方法
<DD>The client needs to give up on the block.
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/NamenodeProtocol.html#ACT_CHECKPOINT"><B>ACT_CHECKPOINT</B></A> - 
接口 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/NamenodeProtocol.html" title="org.apache.hadoop.hdfs.server.protocol 中的接口">NamenodeProtocol</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/NamenodeProtocol.html#ACT_SHUTDOWN"><B>ACT_SHUTDOWN</B></A> - 
接口 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/NamenodeProtocol.html" title="org.apache.hadoop.hdfs.server.protocol 中的接口">NamenodeProtocol</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/NamenodeProtocol.html#ACT_UNKNOWN"><B>ACT_UNKNOWN</B></A> - 
接口 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/NamenodeProtocol.html" title="org.apache.hadoop.hdfs.server.protocol 中的接口">NamenodeProtocol</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeCPUStator.html#activate()"><B>activate()</B></A> - 
类 org.apache.hadoop.hdfs.server.monitor.<A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeCPUStator.html" title="org.apache.hadoop.hdfs.server.monitor 中的类">ServernodeCPUStator</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeIOStator.html#activate()"><B>activate()</B></A> - 
类 org.apache.hadoop.hdfs.server.monitor.<A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeIOStator.html" title="org.apache.hadoop.hdfs.server.monitor 中的类">ServernodeIOStator</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeMEMStator.html#activate()"><B>activate()</B></A> - 
类 org.apache.hadoop.hdfs.server.monitor.<A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeMEMStator.html" title="org.apache.hadoop.hdfs.server.monitor 中的类">ServernodeMEMStator</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeNETStator.html#activate()"><B>activate()</B></A> - 
类 org.apache.hadoop.hdfs.server.monitor.<A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeNETStator.html" title="org.apache.hadoop.hdfs.server.monitor 中的类">ServernodeNETStator</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeStator.html#activate()"><B>activate()</B></A> - 
类 org.apache.hadoop.hdfs.server.monitor.<A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeStator.html" title="org.apache.hadoop.hdfs.server.monitor 中的类">ServernodeStator</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/BlockRecoveryCommand.html#add(org.apache.hadoop.hdfs.server.protocol.BlockRecoveryCommand.RecoveringBlock)"><B>add(BlockRecoveryCommand.RecoveringBlock)</B></A> - 
类 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/BlockRecoveryCommand.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">BlockRecoveryCommand</A> 中的方法
<DD>Add recovering block to the command.
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/ClientProtocol.html#addBlock(java.lang.String, java.lang.String, org.apache.hadoop.hdfs.protocol.Block, org.apache.hadoop.hdfs.protocol.DatanodeInfo[])"><B>addBlock(String, String, Block, DatanodeInfo[])</B></A> - 
接口 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/ClientProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的接口">ClientProtocol</A> 中的方法
<DD>A client that wants to write an additional block to the 
 indicated filename (which must currently be open for writing)
 should call addBlock().
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html#addBlock(java.lang.String, java.lang.String, org.apache.hadoop.hdfs.protocol.Block, org.apache.hadoop.hdfs.protocol.DatanodeInfo[])"><B>addBlock(String, String, Block, DatanodeInfo[])</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">NameNode</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/security/token/delegation/DelegationTokenSecretManager.html#addPersistedDelegationToken(org.apache.hadoop.hdfs.security.token.delegation.DelegationTokenIdentifier, long)"><B>addPersistedDelegationToken(DelegationTokenIdentifier, long)</B></A> - 
类 org.apache.hadoop.hdfs.security.token.delegation.<A HREF="./org/apache/hadoop/hdfs/security/token/delegation/DelegationTokenSecretManager.html" title="org.apache.hadoop.hdfs.security.token.delegation 中的类">DelegationTokenSecretManager</A> 中的方法
<DD>This method is intended to be used only while reading edit logs.
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/Storage.html#addStorageDir(org.apache.hadoop.hdfs.server.common.Storage.StorageDirectory)"><B>addStorageDir(Storage.StorageDirectory)</B></A> - 
类 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/Storage.html" title="org.apache.hadoop.hdfs.server.common 中的类">Storage</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/JspHelper.html#addTableFooter(javax.servlet.jsp.JspWriter)"><B>addTableFooter(JspWriter)</B></A> - 
类 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/JspHelper.html" title="org.apache.hadoop.hdfs.server.common 中的类">JspHelper</A> 中的静态方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/JspHelper.html#addTableHeader(javax.servlet.jsp.JspWriter)"><B>addTableHeader(JspWriter)</B></A> - 
类 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/JspHelper.html" title="org.apache.hadoop.hdfs.server.common 中的类">JspHelper</A> 中的静态方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/JspHelper.html#addTableRow(javax.servlet.jsp.JspWriter, java.lang.String[])"><B>addTableRow(JspWriter, String[])</B></A> - 
类 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/JspHelper.html" title="org.apache.hadoop.hdfs.server.common 中的类">JspHelper</A> 中的静态方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/JspHelper.html#addTableRow(javax.servlet.jsp.JspWriter, java.lang.String[], int)"><B>addTableRow(JspWriter, String[], int)</B></A> - 
类 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/JspHelper.html" title="org.apache.hadoop.hdfs.server.common 中的类">JspHelper</A> 中的静态方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/CorruptReplicasMap.html#addToCorruptReplicasMap(org.apache.hadoop.hdfs.protocol.Block, org.apache.hadoop.hdfs.server.namenode.DatanodeDescriptor)"><B>addToCorruptReplicasMap(Block, DatanodeDescriptor)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/CorruptReplicasMap.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">CorruptReplicasMap</A> 中的方法
<DD>Mark the block belonging to datanode as corrupt.
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDataset.html#adjustCrcChannelPosition(org.apache.hadoop.hdfs.protocol.Block, org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface.BlockWriteStreams, int)"><B>adjustCrcChannelPosition(Block, FSDatasetInterface.BlockWriteStreams, int)</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDataset.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">FSDataset</A> 中的方法
<DD>Sets the offset in the meta file so that the
 last checksum will be overwritten.
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.html#adjustCrcChannelPosition(org.apache.hadoop.hdfs.protocol.Block, org.apache.hadoop.hdfs.server.datanode.FSDatasetInterface.BlockWriteStreams, int)"><B>adjustCrcChannelPosition(Block, FSDatasetInterface.BlockWriteStreams, int)</B></A> - 
接口 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.html" title="org.apache.hadoop.hdfs.server.datanode 中的接口">FSDatasetInterface</A> 中的方法
<DD>Sets the file pointer of the checksum stream so that the last checksum
 will be overwritten
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeInfo.html#adminState"><B>adminState</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeInfo.html" title="org.apache.hadoop.hdfs.protocol 中的类">DatanodeInfo</A> 中的变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/balancer/Balancer.html#ALREADY_RUNNING"><B>ALREADY_RUNNING</B></A> - 
类 org.apache.hadoop.hdfs.server.balancer.<A HREF="./org/apache/hadoop/hdfs/server/balancer/Balancer.html" title="org.apache.hadoop.hdfs.server.balancer 中的类">Balancer</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/AlreadyBeingCreatedException.html" title="org.apache.hadoop.hdfs.protocol 中的类"><B>AlreadyBeingCreatedException</B></A> - <A HREF="./org/apache/hadoop/hdfs/protocol/package-summary.html">org.apache.hadoop.hdfs.protocol</A> 中的 异常<DD>The exception that happens when you ask to create a file that already
 is being created, but is not closed yet.<DT><A HREF="./org/apache/hadoop/hdfs/protocol/AlreadyBeingCreatedException.html#AlreadyBeingCreatedException(java.lang.String)"><B>AlreadyBeingCreatedException(String)</B></A> - 
异常 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/AlreadyBeingCreatedException.html" title="org.apache.hadoop.hdfs.protocol 中的类">AlreadyBeingCreatedException</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/Storage.StorageDirectory.html#analyzeStorage(org.apache.hadoop.hdfs.server.common.HdfsConstants.StartupOption)"><B>analyzeStorage(HdfsConstants.StartupOption)</B></A> - 
类 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/Storage.StorageDirectory.html" title="org.apache.hadoop.hdfs.server.common 中的类">Storage.StorageDirectory</A> 中的方法
<DD>Check consistency of the storage directory
<DT><A HREF="./org/apache/hadoop/hdfs/DistributedFileSystem.html#append(org.apache.hadoop.fs.Path, int, org.apache.hadoop.util.Progressable)"><B>append(Path, int, Progressable)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DistributedFileSystem.html" title="org.apache.hadoop.hdfs 中的类">DistributedFileSystem</A> 中的方法
<DD>This optional operation is not yet supported.
<DT><A HREF="./org/apache/hadoop/hdfs/HftpFileSystem.html#append(org.apache.hadoop.fs.Path, int, org.apache.hadoop.util.Progressable)"><B>append(Path, int, Progressable)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/HftpFileSystem.html" title="org.apache.hadoop.hdfs 中的类">HftpFileSystem</A> 中的方法
<DD>This optional operation is not yet supported.
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/ClientProtocol.html#append(java.lang.String, java.lang.String)"><B>append(String, String)</B></A> - 
接口 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/ClientProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的接口">ClientProtocol</A> 中的方法
<DD>Append to the end of the file.
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDataset.html#append(org.apache.hadoop.hdfs.protocol.Block, long, long)"><B>append(Block, long, long)</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDataset.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">FSDataset</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.html#append(org.apache.hadoop.hdfs.protocol.Block, long, long)"><B>append(Block, long, long)</B></A> - 
接口 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.html" title="org.apache.hadoop.hdfs.server.datanode 中的接口">FSDatasetInterface</A> 中的方法
<DD>Append to a finalized replica and returns the meta info of the replica
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html#append(java.lang.String, java.lang.String)"><B>append(String, String)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">NameNode</A> 中的方法
<DD>Append to the end of the file.
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#auditLog"><B>auditLog</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FSNamesystem</A> 中的静态变量
<DD>Logger for audit events, noting successful FSNamesystem operations.
<DT><A HREF="./org/apache/hadoop/hdfs/DFSInputStream.html#available()"><B>available()</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSInputStream.html" title="org.apache.hadoop.hdfs 中的类">DFSInputStream</A> 中的方法
<DD>Return the size of the remaining available bytes
 if the size is less than or equal to <CODE>Integer.MAX_VALUE</CODE>,
 otherwise, return <CODE>Integer.MAX_VALUE</CODE>.
</DL>
<HR>
<A NAME="_B_"><!-- --></A><H2>
<B>B</B></H2>
<DL>
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/BackupNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类"><B>BackupNode</B></A> - <A HREF="./org/apache/hadoop/hdfs/server/namenode/package-summary.html">org.apache.hadoop.hdfs.server.namenode</A> 中的 类<DD>BackupNode.<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/BackupStorage.html" title="org.apache.hadoop.hdfs.server.namenode 中的类"><B>BackupStorage</B></A> - <A HREF="./org/apache/hadoop/hdfs/server/namenode/package-summary.html">org.apache.hadoop.hdfs.server.namenode</A> 中的 类<DD>&nbsp;<DT><A HREF="./org/apache/hadoop/hdfs/server/balancer/Balancer.html" title="org.apache.hadoop.hdfs.server.balancer 中的类"><B>Balancer</B></A> - <A HREF="./org/apache/hadoop/hdfs/server/balancer/package-summary.html">org.apache.hadoop.hdfs.server.balancer</A> 中的 类<DD>The balancer is a tool that balances disk space usage on an HDFS cluster
 when some datanodes become full or when new empty nodes join the cluster.<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/DataNode.html#beginRCRecovery(org.apache.hadoop.hdfs.protocol.DatanodeInfo, org.apache.hadoop.hdfs.protocol.Block[], byte[])"><B>beginRCRecovery(DatanodeInfo, Block[], byte[])</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/DataNode.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">DataNode</A> 中的方法
<DD>new comer inform a helper node to start rc in RC(regenerating code)recovery work. created at 2041-4-17. modified
 at 2014-4-24
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/InterDatanodeProtocol.html#beginRCRecovery(org.apache.hadoop.hdfs.protocol.DatanodeInfo, org.apache.hadoop.hdfs.protocol.Block[], byte[])"><B>beginRCRecovery(DatanodeInfo, Block[], byte[])</B></A> - 
接口 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/InterDatanodeProtocol.html" title="org.apache.hadoop.hdfs.server.protocol 中的接口">InterDatanodeProtocol</A> 中的方法
<DD>new comer inform a helper node to start rc in RC(regenerating
 code)recovery work. created at 2041-4-17. modified at 2014-4-24
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/JspHelper.html#bestNode(org.apache.hadoop.hdfs.protocol.LocatedBlocks)"><B>bestNode(LocatedBlocks)</B></A> - 
类 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/JspHelper.html" title="org.apache.hadoop.hdfs.server.common 中的类">JspHelper</A> 中的静态方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/JspHelper.html#bestNode(org.apache.hadoop.hdfs.protocol.LocatedBlock)"><B>bestNode(LocatedBlock)</B></A> - 
类 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/JspHelper.html" title="org.apache.hadoop.hdfs.server.common 中的类">JspHelper</A> 中的静态方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/JspHelper.html#bestNode(org.apache.hadoop.hdfs.protocol.DatanodeInfo[], boolean)"><B>bestNode(DatanodeInfo[], boolean)</B></A> - 
类 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/JspHelper.html" title="org.apache.hadoop.hdfs.server.common 中的类">JspHelper</A> 中的静态方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/Block.html" title="org.apache.hadoop.hdfs.protocol 中的类"><B>Block</B></A> - <A HREF="./org/apache/hadoop/hdfs/protocol/package-summary.html">org.apache.hadoop.hdfs.protocol</A> 中的 类<DD>A Block is a Hadoop FS primitive, identified by a 
 long.<DT><A HREF="./org/apache/hadoop/hdfs/protocol/Block.html#Block()"><B>Block()</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/Block.html" title="org.apache.hadoop.hdfs.protocol 中的类">Block</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/Block.html#Block(long, long, long)"><B>Block(long, long, long)</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/Block.html" title="org.apache.hadoop.hdfs.protocol 中的类">Block</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/Block.html#Block(long)"><B>Block(long)</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/Block.html" title="org.apache.hadoop.hdfs.protocol 中的类">Block</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/Block.html#Block(org.apache.hadoop.hdfs.protocol.Block)"><B>Block(Block)</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/Block.html" title="org.apache.hadoop.hdfs.protocol 中的类">Block</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/Block.html#Block(java.io.File, long, long)"><B>Block(File, long, long)</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/Block.html" title="org.apache.hadoop.hdfs.protocol 中的类">Block</A> 的构造方法
<DD>Find the blockid from the given filename
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/DatanodeDescriptor.BlockTargetPair.html#block"><B>block</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/DatanodeDescriptor.BlockTargetPair.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">DatanodeDescriptor.BlockTargetPair</A> 中的变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/Block.html#BLOCK_FILE_PREFIX"><B>BLOCK_FILE_PREFIX</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/Block.html" title="org.apache.hadoop.hdfs.protocol 中的类">Block</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/FSConstants.html#BLOCK_INVALIDATE_CHUNK"><B>BLOCK_INVALIDATE_CHUNK</B></A> - 
接口 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/FSConstants.html" title="org.apache.hadoop.hdfs.protocol 中的接口">FSConstants</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/metrics/DataNodeMetrics.html#blockChecksumOp"><B>blockChecksumOp</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.metrics.<A HREF="./org/apache/hadoop/hdfs/server/datanode/metrics/DataNodeMetrics.html" title="org.apache.hadoop.hdfs.server.datanode.metrics 中的类">DataNodeMetrics</A> 中的变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/BlockCommand.html" title="org.apache.hadoop.hdfs.server.protocol 中的类"><B>BlockCommand</B></A> - <A HREF="./org/apache/hadoop/hdfs/server/protocol/package-summary.html">org.apache.hadoop.hdfs.server.protocol</A> 中的 类<DD>A BlockCommand is an instruction to a datanode 
 regarding some blocks under its control.<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/BlockCommand.html#BlockCommand()"><B>BlockCommand()</B></A> - 
类 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/BlockCommand.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">BlockCommand</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/BlockCommand.html#BlockCommand(int, java.util.List)"><B>BlockCommand(int, List&lt;DatanodeDescriptor.BlockTargetPair&gt;)</B></A> - 
类 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/BlockCommand.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">BlockCommand</A> 的构造方法
<DD>Create BlockCommand for transferring blocks to another datanode
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/BlockCommand.html#BlockCommand(int, org.apache.hadoop.hdfs.protocol.Block[])"><B>BlockCommand(int, Block[])</B></A> - 
类 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/BlockCommand.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">BlockCommand</A> 的构造方法
<DD>Create BlockCommand for the given action
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/Block.html#blockFilePattern"><B>blockFilePattern</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/Block.html" title="org.apache.hadoop.hdfs.protocol 中的类">Block</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/security/token/block/BlockKey.html" title="org.apache.hadoop.hdfs.security.token.block 中的类"><B>BlockKey</B></A> - <A HREF="./org/apache/hadoop/hdfs/security/token/block/package-summary.html">org.apache.hadoop.hdfs.security.token.block</A> 中的 类<DD>Key used for generating and verifying block tokens<DT><A HREF="./org/apache/hadoop/hdfs/security/token/block/BlockKey.html#BlockKey()"><B>BlockKey()</B></A> - 
类 org.apache.hadoop.hdfs.security.token.block.<A HREF="./org/apache/hadoop/hdfs/security/token/block/BlockKey.html" title="org.apache.hadoop.hdfs.security.token.block 中的类">BlockKey</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/security/token/block/BlockKey.html#BlockKey(int, long, javax.crypto.SecretKey)"><B>BlockKey(int, long, SecretKey)</B></A> - 
类 org.apache.hadoop.hdfs.security.token.block.<A HREF="./org/apache/hadoop/hdfs/security/token/block/BlockKey.html" title="org.apache.hadoop.hdfs.security.token.block 中的类">BlockKey</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/BlockListAsLongs.html" title="org.apache.hadoop.hdfs.protocol 中的类"><B>BlockListAsLongs</B></A> - <A HREF="./org/apache/hadoop/hdfs/protocol/package-summary.html">org.apache.hadoop.hdfs.protocol</A> 中的 类<DD>This class provides an interface for accessing list of blocks that
 has been implemented as long[].<DT><A HREF="./org/apache/hadoop/hdfs/protocol/BlockListAsLongs.html#BlockListAsLongs(java.util.List, java.util.List)"><B>BlockListAsLongs(List&lt;? extends Block&gt;, List&lt;ReplicaInfo&gt;)</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/BlockListAsLongs.html" title="org.apache.hadoop.hdfs.protocol 中的类">BlockListAsLongs</A> 的构造方法
<DD>Create block report from finalized and under construction lists of blocks.
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/BlockListAsLongs.html#BlockListAsLongs()"><B>BlockListAsLongs()</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/BlockListAsLongs.html" title="org.apache.hadoop.hdfs.protocol 中的类">BlockListAsLongs</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/BlockListAsLongs.html#BlockListAsLongs(long[])"><B>BlockListAsLongs(long[])</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/BlockListAsLongs.html" title="org.apache.hadoop.hdfs.protocol 中的类">BlockListAsLongs</A> 的构造方法
<DD>Constructor
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/BlockListAsLongs.BlockReportIterator.html" title="org.apache.hadoop.hdfs.protocol 中的类"><B>BlockListAsLongs.BlockReportIterator</B></A> - <A HREF="./org/apache/hadoop/hdfs/protocol/package-summary.html">org.apache.hadoop.hdfs.protocol</A> 中的 类<DD>Iterates over blocks in the block report.<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/BlockManager.html" title="org.apache.hadoop.hdfs.server.namenode 中的类"><B>BlockManager</B></A> - <A HREF="./org/apache/hadoop/hdfs/server/namenode/package-summary.html">org.apache.hadoop.hdfs.server.namenode</A> 中的 类<DD>Keeps information related to the blocks stored in the Hadoop cluster.<DT><A HREF="./org/apache/hadoop/hdfs/BlockMissingException.html" title="org.apache.hadoop.hdfs 中的类"><B>BlockMissingException</B></A> - <A HREF="./org/apache/hadoop/hdfs/package-summary.html">org.apache.hadoop.hdfs</A> 中的 异常<DD>This exception is thrown when a read encounters a block that has no locations
 associated with it.<DT><A HREF="./org/apache/hadoop/hdfs/BlockMissingException.html#BlockMissingException(java.lang.String, java.lang.String, long)"><B>BlockMissingException(String, String, long)</B></A> - 
异常 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/BlockMissingException.html" title="org.apache.hadoop.hdfs 中的类">BlockMissingException</A> 的构造方法
<DD>An exception that indicates that file was corrupted.
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/BlockPlacementPolicy.html" title="org.apache.hadoop.hdfs.server.namenode 中的类"><B>BlockPlacementPolicy</B></A> - <A HREF="./org/apache/hadoop/hdfs/server/namenode/package-summary.html">org.apache.hadoop.hdfs.server.namenode</A> 中的 类<DD>This interface is used for choosing the desired number of targets
 for placing block replicas.<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/BlockPlacementPolicy.html#BlockPlacementPolicy()"><B>BlockPlacementPolicy()</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/BlockPlacementPolicy.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">BlockPlacementPolicy</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/BlockPlacementPolicy.NotEnoughReplicasException.html" title="org.apache.hadoop.hdfs.server.namenode 中的类"><B>BlockPlacementPolicy.NotEnoughReplicasException</B></A> - <A HREF="./org/apache/hadoop/hdfs/server/namenode/package-summary.html">org.apache.hadoop.hdfs.server.namenode</A> 中的 异常<DD>&nbsp;<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/BlockPlacementPolicyDefault.html" title="org.apache.hadoop.hdfs.server.namenode 中的类"><B>BlockPlacementPolicyDefault</B></A> - <A HREF="./org/apache/hadoop/hdfs/server/namenode/package-summary.html">org.apache.hadoop.hdfs.server.namenode</A> 中的 类<DD>The class is responsible for choosing the desired number of targets
 for placing block replicas.<DT><A HREF="./org/apache/hadoop/hdfs/BlockReader.html" title="org.apache.hadoop.hdfs 中的类"><B>BlockReader</B></A> - <A HREF="./org/apache/hadoop/hdfs/package-summary.html">org.apache.hadoop.hdfs</A> 中的 类<DD>This is a wrapper around connection to datanode
 and understands checksum, offset etc.<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#blockReceived(org.apache.hadoop.hdfs.protocol.DatanodeID, org.apache.hadoop.hdfs.protocol.Block, java.lang.String)"><B>blockReceived(DatanodeID, Block, String)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FSNamesystem</A> 中的方法
<DD>The given node is reporting that it received a certain block.
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html#blockReceived(org.apache.hadoop.hdfs.server.protocol.DatanodeRegistration, org.apache.hadoop.hdfs.protocol.Block[], java.lang.String[])"><B>blockReceived(DatanodeRegistration, Block[], String[])</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">NameNode</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/DatanodeProtocol.html#blockReceived(org.apache.hadoop.hdfs.server.protocol.DatanodeRegistration, org.apache.hadoop.hdfs.protocol.Block[], java.lang.String[])"><B>blockReceived(DatanodeRegistration, Block[], String[])</B></A> - 
接口 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/DatanodeProtocol.html" title="org.apache.hadoop.hdfs.server.protocol 中的接口">DatanodeProtocol</A> 中的方法
<DD>blockReceived() allows the DataNode to tell the NameNode about
 recently-received block data, with a hint for pereferred replica
 to be deleted when there is any excessive blocks.
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/BlockRecoveryCommand.html" title="org.apache.hadoop.hdfs.server.protocol 中的类"><B>BlockRecoveryCommand</B></A> - <A HREF="./org/apache/hadoop/hdfs/server/protocol/package-summary.html">org.apache.hadoop.hdfs.server.protocol</A> 中的 类<DD>BlockRecoveryCommand is an instruction to a data-node to recover
 the specified blocks.<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/BlockRecoveryCommand.html#BlockRecoveryCommand()"><B>BlockRecoveryCommand()</B></A> - 
类 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/BlockRecoveryCommand.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">BlockRecoveryCommand</A> 的构造方法
<DD>Create empty BlockRecoveryCommand.
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/BlockRecoveryCommand.html#BlockRecoveryCommand(int)"><B>BlockRecoveryCommand(int)</B></A> - 
类 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/BlockRecoveryCommand.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">BlockRecoveryCommand</A> 的构造方法
<DD>Create BlockRecoveryCommand with
 the specified capacity for recovering blocks.
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/BlockRecoveryCommand.RecoveringBlock.html" title="org.apache.hadoop.hdfs.server.protocol 中的类"><B>BlockRecoveryCommand.RecoveringBlock</B></A> - <A HREF="./org/apache/hadoop/hdfs/server/protocol/package-summary.html">org.apache.hadoop.hdfs.server.protocol</A> 中的 类<DD>This is a block with locations from which it should be recovered
 and the new generation stamp, which the block will have after 
 successful recovery.<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/BlockRecoveryCommand.RecoveringBlock.html#BlockRecoveryCommand.RecoveringBlock()"><B>BlockRecoveryCommand.RecoveringBlock()</B></A> - 
类 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/BlockRecoveryCommand.RecoveringBlock.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">BlockRecoveryCommand.RecoveringBlock</A> 的构造方法
<DD>Create empty RecoveringBlock.
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/BlockRecoveryCommand.RecoveringBlock.html#BlockRecoveryCommand.RecoveringBlock(org.apache.hadoop.hdfs.protocol.Block, org.apache.hadoop.hdfs.protocol.DatanodeInfo[], long)"><B>BlockRecoveryCommand.RecoveringBlock(Block, DatanodeInfo[], long)</B></A> - 
类 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/BlockRecoveryCommand.RecoveringBlock.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">BlockRecoveryCommand.RecoveringBlock</A> 的构造方法
<DD>Create RecoveringBlock.
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/metrics/NameNodeMetrics.html#blockReport"><B>blockReport</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.metrics.<A HREF="./org/apache/hadoop/hdfs/server/namenode/metrics/NameNodeMetrics.html" title="org.apache.hadoop.hdfs.server.namenode.metrics 中的类">NameNodeMetrics</A> 中的变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html#blockReport(org.apache.hadoop.hdfs.server.protocol.DatanodeRegistration, long[])"><B>blockReport(DatanodeRegistration, long[])</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">NameNode</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/DatanodeProtocol.html#blockReport(org.apache.hadoop.hdfs.server.protocol.DatanodeRegistration, long[])"><B>blockReport(DatanodeRegistration, long[])</B></A> - 
接口 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/DatanodeProtocol.html" title="org.apache.hadoop.hdfs.server.protocol 中的接口">DatanodeProtocol</A> 中的方法
<DD>blockReport() tells the NameNode about all the locally-stored blocks.
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/FSConstants.html#BLOCKREPORT_INITIAL_DELAY"><B>BLOCKREPORT_INITIAL_DELAY</B></A> - 
接口 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/FSConstants.html" title="org.apache.hadoop.hdfs.protocol 中的接口">FSConstants</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/FSConstants.html#BLOCKREPORT_INTERVAL"><B>BLOCKREPORT_INTERVAL</B></A> - 
接口 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/FSConstants.html" title="org.apache.hadoop.hdfs.protocol 中的接口">FSConstants</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/metrics/DataNodeMetrics.html#blockReports"><B>blockReports</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.metrics.<A HREF="./org/apache/hadoop/hdfs/server/datanode/metrics/DataNodeMetrics.html" title="org.apache.hadoop.hdfs.server.datanode.metrics 中的类">DataNodeMetrics</A> 中的变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/DataNode.html#blockScanner"><B>blockScanner</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/DataNode.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">DataNode</A> 中的变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/DataNode.html#blockScannerThread"><B>blockScannerThread</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/DataNode.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">DataNode</A> 中的变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/metrics/DataNodeMetrics.html#blocksRead"><B>blocksRead</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.metrics.<A HREF="./org/apache/hadoop/hdfs/server/datanode/metrics/DataNodeMetrics.html" title="org.apache.hadoop.hdfs.server.datanode.metrics 中的类">DataNodeMetrics</A> 中的变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/metrics/DataNodeMetrics.html#blocksRemoved"><B>blocksRemoved</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.metrics.<A HREF="./org/apache/hadoop/hdfs/server/datanode/metrics/DataNodeMetrics.html" title="org.apache.hadoop.hdfs.server.datanode.metrics 中的类">DataNodeMetrics</A> 中的变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/metrics/DataNodeMetrics.html#blocksReplicated"><B>blocksReplicated</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.metrics.<A HREF="./org/apache/hadoop/hdfs/server/datanode/metrics/DataNodeMetrics.html" title="org.apache.hadoop.hdfs.server.datanode.metrics 中的类">DataNodeMetrics</A> 中的变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/metrics/DataNodeMetrics.html#blocksVerified"><B>blocksVerified</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.metrics.<A HREF="./org/apache/hadoop/hdfs/server/datanode/metrics/DataNodeMetrics.html" title="org.apache.hadoop.hdfs.server.datanode.metrics 中的类">DataNodeMetrics</A> 中的变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/BlocksWithLocations.html" title="org.apache.hadoop.hdfs.server.protocol 中的类"><B>BlocksWithLocations</B></A> - <A HREF="./org/apache/hadoop/hdfs/server/protocol/package-summary.html">org.apache.hadoop.hdfs.server.protocol</A> 中的 类<DD>A class to implement an array of BlockLocations
  It provide efficient customized serialization/deserialization methods
  in stead of using the default array (de)serialization provided by RPC<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/BlocksWithLocations.html#BlocksWithLocations(org.apache.hadoop.hdfs.server.protocol.BlocksWithLocations.BlockWithLocations[])"><B>BlocksWithLocations(BlocksWithLocations.BlockWithLocations[])</B></A> - 
类 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/BlocksWithLocations.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">BlocksWithLocations</A> 的构造方法
<DD>Constructor with one parameter
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/BlocksWithLocations.BlockWithLocations.html" title="org.apache.hadoop.hdfs.server.protocol 中的类"><B>BlocksWithLocations.BlockWithLocations</B></A> - <A HREF="./org/apache/hadoop/hdfs/server/protocol/package-summary.html">org.apache.hadoop.hdfs.server.protocol</A> 中的 类<DD>A class to keep track of a block and its locations<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/BlocksWithLocations.BlockWithLocations.html#BlocksWithLocations.BlockWithLocations()"><B>BlocksWithLocations.BlockWithLocations()</B></A> - 
类 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/BlocksWithLocations.BlockWithLocations.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">BlocksWithLocations.BlockWithLocations</A> 的构造方法
<DD>default constructor
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/BlocksWithLocations.BlockWithLocations.html#BlocksWithLocations.BlockWithLocations(org.apache.hadoop.hdfs.protocol.Block, java.lang.String[])"><B>BlocksWithLocations.BlockWithLocations(Block, String[])</B></A> - 
类 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/BlocksWithLocations.BlockWithLocations.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">BlocksWithLocations.BlockWithLocations</A> 的构造方法
<DD>constructor
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/metrics/DataNodeMetrics.html#blocksWritten"><B>blocksWritten</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.metrics.<A HREF="./org/apache/hadoop/hdfs/server/datanode/metrics/DataNodeMetrics.html" title="org.apache.hadoop.hdfs.server.datanode.metrics 中的类">DataNodeMetrics</A> 中的变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/security/token/block/BlockTokenIdentifier.html" title="org.apache.hadoop.hdfs.security.token.block 中的类"><B>BlockTokenIdentifier</B></A> - <A HREF="./org/apache/hadoop/hdfs/security/token/block/package-summary.html">org.apache.hadoop.hdfs.security.token.block</A> 中的 类<DD>&nbsp;<DT><A HREF="./org/apache/hadoop/hdfs/security/token/block/BlockTokenIdentifier.html#BlockTokenIdentifier()"><B>BlockTokenIdentifier()</B></A> - 
类 org.apache.hadoop.hdfs.security.token.block.<A HREF="./org/apache/hadoop/hdfs/security/token/block/BlockTokenIdentifier.html" title="org.apache.hadoop.hdfs.security.token.block 中的类">BlockTokenIdentifier</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/security/token/block/BlockTokenIdentifier.html#BlockTokenIdentifier(java.lang.String, long, java.util.EnumSet)"><B>BlockTokenIdentifier(String, long, EnumSet&lt;BlockTokenSecretManager.AccessMode&gt;)</B></A> - 
类 org.apache.hadoop.hdfs.security.token.block.<A HREF="./org/apache/hadoop/hdfs/security/token/block/BlockTokenIdentifier.html" title="org.apache.hadoop.hdfs.security.token.block 中的类">BlockTokenIdentifier</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/security/token/block/BlockTokenSecretManager.html" title="org.apache.hadoop.hdfs.security.token.block 中的类"><B>BlockTokenSecretManager</B></A> - <A HREF="./org/apache/hadoop/hdfs/security/token/block/package-summary.html">org.apache.hadoop.hdfs.security.token.block</A> 中的 类<DD>BlockTokenSecretManager can be instantiated in 2 modes, master mode and slave
 mode.<DT><A HREF="./org/apache/hadoop/hdfs/security/token/block/BlockTokenSecretManager.html#BlockTokenSecretManager(boolean, long, long)"><B>BlockTokenSecretManager(boolean, long, long)</B></A> - 
类 org.apache.hadoop.hdfs.security.token.block.<A HREF="./org/apache/hadoop/hdfs/security/token/block/BlockTokenSecretManager.html" title="org.apache.hadoop.hdfs.security.token.block 中的类">BlockTokenSecretManager</A> 的构造方法
<DD>Constructor
<DT><A HREF="./org/apache/hadoop/hdfs/security/token/block/BlockTokenSecretManager.AccessMode.html" title="org.apache.hadoop.hdfs.security.token.block 中的枚举"><B>BlockTokenSecretManager.AccessMode</B></A> - <A HREF="./org/apache/hadoop/hdfs/security/token/block/package-summary.html">org.apache.hadoop.hdfs.security.token.block</A> 中的 枚举<DD>&nbsp;<DT><A HREF="./org/apache/hadoop/hdfs/security/token/block/BlockTokenSelector.html" title="org.apache.hadoop.hdfs.security.token.block 中的类"><B>BlockTokenSelector</B></A> - <A HREF="./org/apache/hadoop/hdfs/security/token/block/package-summary.html">org.apache.hadoop.hdfs.security.token.block</A> 中的 类<DD>A block token selector for HDFS<DT><A HREF="./org/apache/hadoop/hdfs/security/token/block/BlockTokenSelector.html#BlockTokenSelector()"><B>BlockTokenSelector()</B></A> - 
类 org.apache.hadoop.hdfs.security.token.block.<A HREF="./org/apache/hadoop/hdfs/security/token/block/BlockTokenSelector.html" title="org.apache.hadoop.hdfs.security.token.block 中的类">BlockTokenSelector</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/metrics/DataNodeMetrics.html#blockVerificationFailures"><B>blockVerificationFailures</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.metrics.<A HREF="./org/apache/hadoop/hdfs/server/datanode/metrics/DataNodeMetrics.html" title="org.apache.hadoop.hdfs.server.datanode.metrics 中的类">DataNodeMetrics</A> 中的变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/UpgradeManager.html#broadcastCommand"><B>broadcastCommand</B></A> - 
类 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/UpgradeManager.html" title="org.apache.hadoop.hdfs.server.common 中的类">UpgradeManager</A> 中的变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/FSConstants.html#BUFFER_SIZE"><B>BUFFER_SIZE</B></A> - 
接口 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/FSConstants.html" title="org.apache.hadoop.hdfs.protocol 中的接口">FSConstants</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/BufferData.html" title="org.apache.hadoop.hdfs.server.namenode 中的类"><B>BufferData</B></A> - <A HREF="./org/apache/hadoop/hdfs/server/namenode/package-summary.html">org.apache.hadoop.hdfs.server.namenode</A> 中的 类<DD>&nbsp;<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/BufferData.html#BufferData(org.apache.hadoop.hdfs.server.namenode.INodeFile, byte[])"><B>BufferData(INodeFile, byte[])</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/BufferData.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">BufferData</A> 的构造方法
<DD>new constructor
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/BufferData.html#BufferData(org.apache.hadoop.hdfs.server.namenode.INodeFile)"><B>BufferData(INodeFile)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/BufferData.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">BufferData</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FSImage.html#bufferStorage"><B>bufferStorage</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/FSImage.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FSImage</A> 中的变量
<DD>added by tony
<DT><A HREF="./org/apache/hadoop/hdfs/tools/offlineImageViewer/OfflineImageViewer.html#buildOptions()"><B>buildOptions()</B></A> - 
类 org.apache.hadoop.hdfs.tools.offlineImageViewer.<A HREF="./org/apache/hadoop/hdfs/tools/offlineImageViewer/OfflineImageViewer.html" title="org.apache.hadoop.hdfs.tools.offlineImageViewer 中的类">OfflineImageViewer</A> 中的静态方法
<DD>Build command-line options and descriptions
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/ListPathsServlet.html#buildRoot(javax.servlet.http.HttpServletRequest, org.znerd.xmlenc.XMLOutputter)"><B>buildRoot(HttpServletRequest, XMLOutputter)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/ListPathsServlet.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">ListPathsServlet</A> 中的方法
<DD>Build a map from the query string, setting values and defaults.
<DT><A HREF="./org/apache/hadoop/hdfs/util/ByteArray.html" title="org.apache.hadoop.hdfs.util 中的类"><B>ByteArray</B></A> - <A HREF="./org/apache/hadoop/hdfs/util/package-summary.html">org.apache.hadoop.hdfs.util</A> 中的 类<DD>Wrapper for byte[] to use byte[] as key in HashMap<DT><A HREF="./org/apache/hadoop/hdfs/util/ByteArray.html#ByteArray(byte[])"><B>ByteArray(byte[])</B></A> - 
类 org.apache.hadoop.hdfs.util.<A HREF="./org/apache/hadoop/hdfs/util/ByteArray.html" title="org.apache.hadoop.hdfs.util 中的类">ByteArray</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSUtil.html#byteArray2String(byte[][])"><B>byteArray2String(byte[][])</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSUtil.html" title="org.apache.hadoop.hdfs 中的类">DFSUtil</A> 中的静态方法
<DD>Given a list of path components returns a path as a UTF8 String
<DT><A HREF="./org/apache/hadoop/hdfs/DFSUtil.html#bytes2byteArray(byte[], byte)"><B>bytes2byteArray(byte[], byte)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSUtil.html" title="org.apache.hadoop.hdfs 中的类">DFSUtil</A> 中的静态方法
<DD>Splits the array of bytes into array of arrays of bytes
 on byte separator
<DT><A HREF="./org/apache/hadoop/hdfs/DFSUtil.html#bytes2byteArray(byte[], int, byte)"><B>bytes2byteArray(byte[], int, byte)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSUtil.html" title="org.apache.hadoop.hdfs 中的类">DFSUtil</A> 中的静态方法
<DD>Splits first len bytes in bytes to array of arrays of bytes
 on byte separator
<DT><A HREF="./org/apache/hadoop/hdfs/DFSUtil.html#bytes2String(byte[])"><B>bytes2String(byte[])</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSUtil.html" title="org.apache.hadoop.hdfs 中的类">DFSUtil</A> 中的静态方法
<DD>Converts a byte array to a string using UTF8 encoding.
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/metrics/DataNodeMetrics.html#bytesRead"><B>bytesRead</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.metrics.<A HREF="./org/apache/hadoop/hdfs/server/datanode/metrics/DataNodeMetrics.html" title="org.apache.hadoop.hdfs.server.datanode.metrics 中的类">DataNodeMetrics</A> 中的变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/metrics/DataNodeMetrics.html#bytesWritten"><B>bytesWritten</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.metrics.<A HREF="./org/apache/hadoop/hdfs/server/datanode/metrics/DataNodeMetrics.html" title="org.apache.hadoop.hdfs.server.datanode.metrics 中的类">DataNodeMetrics</A> 中的变量
<DD>&nbsp;
</DL>
<HR>
<A NAME="_C_"><!-- --></A><H2>
<B>C</B></H2>
<DL>
<DT><A HREF="./org/apache/hadoop/hdfs/DFSClient.html#cancelDelegationToken(org.apache.hadoop.security.token.Token)"><B>cancelDelegationToken(Token&lt;DelegationTokenIdentifier&gt;)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSClient.html" title="org.apache.hadoop.hdfs 中的类">DFSClient</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DistributedFileSystem.html#cancelDelegationToken(org.apache.hadoop.security.token.Token)"><B>cancelDelegationToken(Token&lt;DelegationTokenIdentifier&gt;)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DistributedFileSystem.html" title="org.apache.hadoop.hdfs 中的类">DistributedFileSystem</A> 中的方法
<DD>Cancel an existing delegation token.
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/ClientProtocol.html#cancelDelegationToken(org.apache.hadoop.security.token.Token)"><B>cancelDelegationToken(Token&lt;DelegationTokenIdentifier&gt;)</B></A> - 
接口 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/ClientProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的接口">ClientProtocol</A> 中的方法
<DD>Cancel an existing delegation token.
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#cancelDelegationToken(org.apache.hadoop.security.token.Token)"><B>cancelDelegationToken(Token&lt;DelegationTokenIdentifier&gt;)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FSNamesystem</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html#cancelDelegationToken(org.apache.hadoop.security.token.Token)"><B>cancelDelegationToken(Token&lt;DelegationTokenIdentifier&gt;)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">NameNode</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/tools/DelegationTokenFetcher.html#cancelDelegationToken(java.lang.String, org.apache.hadoop.security.token.Token)"><B>cancelDelegationToken(String, Token&lt;DelegationTokenIdentifier&gt;)</B></A> - 
类 org.apache.hadoop.hdfs.tools.<A HREF="./org/apache/hadoop/hdfs/tools/DelegationTokenFetcher.html" title="org.apache.hadoop.hdfs.tools 中的类">DelegationTokenFetcher</A> 中的静态方法
<DD>Cancel a Delegation Token.
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/CancelDelegationTokenServlet.html" title="org.apache.hadoop.hdfs.server.namenode 中的类"><B>CancelDelegationTokenServlet</B></A> - <A HREF="./org/apache/hadoop/hdfs/server/namenode/package-summary.html">org.apache.hadoop.hdfs.server.namenode</A> 中的 类<DD>Cancel delegation tokens over http for use in hftp.<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/CancelDelegationTokenServlet.html#CancelDelegationTokenServlet()"><B>CancelDelegationTokenServlet()</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/CancelDelegationTokenServlet.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">CancelDelegationTokenServlet</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeInfo.html#capacity"><B>capacity</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeInfo.html" title="org.apache.hadoop.hdfs.protocol 中的类">DatanodeInfo</A> 中的变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/HeaderBuffer.html#change(org.apache.hadoop.hdfs.server.namenode.INodeFile, org.apache.hadoop.hdfs.server.namenode.INodeFile)"><B>change(INodeFile, INodeFile)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/HeaderBuffer.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">HeaderBuffer</A> 中的方法
<DD>replace the oldFile in buffer
<DT><A HREF="./org/apache/hadoop/hdfs/security/token/block/BlockTokenSecretManager.html#checkAccess(org.apache.hadoop.hdfs.security.token.block.BlockTokenIdentifier, java.lang.String, org.apache.hadoop.hdfs.protocol.Block, org.apache.hadoop.hdfs.security.token.block.BlockTokenSecretManager.AccessMode)"><B>checkAccess(BlockTokenIdentifier, String, Block, BlockTokenSecretManager.AccessMode)</B></A> - 
类 org.apache.hadoop.hdfs.security.token.block.<A HREF="./org/apache/hadoop/hdfs/security/token/block/BlockTokenSecretManager.html" title="org.apache.hadoop.hdfs.security.token.block 中的类">BlockTokenSecretManager</A> 中的方法
<DD>Check if access should be allowed. userID is not checked if null.
<DT><A HREF="./org/apache/hadoop/hdfs/security/token/block/BlockTokenSecretManager.html#checkAccess(org.apache.hadoop.security.token.Token, java.lang.String, org.apache.hadoop.hdfs.protocol.Block, org.apache.hadoop.hdfs.security.token.block.BlockTokenSecretManager.AccessMode)"><B>checkAccess(Token&lt;BlockTokenIdentifier&gt;, String, Block, BlockTokenSecretManager.AccessMode)</B></A> - 
类 org.apache.hadoop.hdfs.security.token.block.<A HREF="./org/apache/hadoop/hdfs/security/token/block/BlockTokenSecretManager.html" title="org.apache.hadoop.hdfs.security.token.block 中的类">BlockTokenSecretManager</A> 中的方法
<DD>Check if access should be allowed. userID is not checked if null
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDataset.html#checkAndUpdate(long, java.io.File, java.io.File, org.apache.hadoop.hdfs.server.datanode.FSDataset.FSVolume)"><B>checkAndUpdate(long, File, File, FSDataset.FSVolume)</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDataset.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">FSDataset</A> 中的方法
<DD>Reconcile the difference between blocks on the disk and blocks in
 volumeMap

 Check the given block for inconsistencies.
<DT><A HREF="./org/apache/hadoop/hdfs/HsftpFileSystem.DummyTrustManager.html#checkClientTrusted(java.security.cert.X509Certificate[], java.lang.String)"><B>checkClientTrusted(X509Certificate[], String)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/HsftpFileSystem.DummyTrustManager.html" title="org.apache.hadoop.hdfs 中的类">HsftpFileSystem.DummyTrustManager</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDataset.html#checkDataDir()"><B>checkDataDir()</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDataset.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">FSDataset</A> 中的方法
<DD>check if a data directory is healthy
 if some volumes failed - make sure to remove all the blocks that belong
 to these volumes
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.html#checkDataDir()"><B>checkDataDir()</B></A> - 
接口 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.html" title="org.apache.hadoop.hdfs.server.datanode 中的接口">FSDatasetInterface</A> 中的方法
<DD>Check if all the data directories are healthy
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/DataNode.html#checkDiskError(java.lang.Exception)"><B>checkDiskError(Exception)</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/DataNode.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">DataNode</A> 中的方法
<DD>Check if there is no space in disk
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/DataNode.html#checkDiskError()"><B>checkDiskError()</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/DataNode.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">DataNode</A> 中的方法
<DD>Check if there is a disk failure and if so, handle the error
<DT><A HREF="./org/apache/hadoop/hdfs/DistributedFileSystem.html#checkPath(org.apache.hadoop.fs.Path)"><B>checkPath(Path)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DistributedFileSystem.html" title="org.apache.hadoop.hdfs 中的类">DistributedFileSystem</A> 中的方法
<DD>Permit paths which explicitly specify the default port.
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/CheckpointCommand.html" title="org.apache.hadoop.hdfs.server.protocol 中的类"><B>CheckpointCommand</B></A> - <A HREF="./org/apache/hadoop/hdfs/server/protocol/package-summary.html">org.apache.hadoop.hdfs.server.protocol</A> 中的 类<DD>Checkpoint command.<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/CheckpointCommand.html#CheckpointCommand()"><B>CheckpointCommand()</B></A> - 
类 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/CheckpointCommand.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">CheckpointCommand</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/CheckpointCommand.html#CheckpointCommand(org.apache.hadoop.hdfs.server.namenode.CheckpointSignature, boolean, boolean)"><B>CheckpointCommand(CheckpointSignature, boolean, boolean)</B></A> - 
类 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/CheckpointCommand.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">CheckpointCommand</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/CheckpointSignature.html" title="org.apache.hadoop.hdfs.server.namenode 中的类"><B>CheckpointSignature</B></A> - <A HREF="./org/apache/hadoop/hdfs/server/namenode/package-summary.html">org.apache.hadoop.hdfs.server.namenode</A> 中的 类<DD>A unique signature intended to identify checkpoint transactions.<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/CheckpointSignature.html#CheckpointSignature()"><B>CheckpointSignature()</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/CheckpointSignature.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">CheckpointSignature</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FSImage.html#checkpointTime"><B>checkpointTime</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/FSImage.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FSImage</A> 中的变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/HsftpFileSystem.DummyTrustManager.html#checkServerTrusted(java.security.cert.X509Certificate[], java.lang.String)"><B>checkServerTrusted(X509Certificate[], String)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/HsftpFileSystem.DummyTrustManager.html" title="org.apache.hadoop.hdfs 中的类">HsftpFileSystem.DummyTrustManager</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/Storage.html#checkVersionUpgradable(int)"><B>checkVersionUpgradable(int)</B></A> - 
类 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/Storage.html" title="org.apache.hadoop.hdfs.server.common 中的类">Storage</A> 中的静态方法
<DD>Checks if the upgrade from the given old version is supported.
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/CodingMatrix.html#chooseMatrix(long)"><B>chooseMatrix(long)</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/CodingMatrix.html" title="org.apache.hadoop.hdfs.protocol 中的类">CodingMatrix</A> 中的静态方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/BlockPlacementPolicy.html#chooseRandom(java.lang.String, int, org.apache.hadoop.hdfs.server.namenode.DatanodeDescriptor, java.util.List, java.util.HashMap, long)"><B>chooseRandom(String, int, DatanodeDescriptor, List&lt;DatanodeDescriptor&gt;, HashMap&lt;Node, Node&gt;, long)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/BlockPlacementPolicy.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">BlockPlacementPolicy</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/BlockPlacementPolicyDefault.html#chooseRandom(java.lang.String, int, org.apache.hadoop.hdfs.server.namenode.DatanodeDescriptor, java.util.List, java.util.HashMap, long)"><B>chooseRandom(String, int, DatanodeDescriptor, List&lt;DatanodeDescriptor&gt;, HashMap&lt;Node, Node&gt;, long)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/BlockPlacementPolicyDefault.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">BlockPlacementPolicyDefault</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/BlockPlacementPolicy.html#chooseReplicaToDelete(org.apache.hadoop.hdfs.server.namenode.FSInodeInfo, org.apache.hadoop.hdfs.protocol.Block, short, java.util.Collection, java.util.Collection)"><B>chooseReplicaToDelete(FSInodeInfo, Block, short, Collection&lt;DatanodeDescriptor&gt;, Collection&lt;DatanodeDescriptor&gt;)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/BlockPlacementPolicy.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">BlockPlacementPolicy</A> 中的方法
<DD>Decide whether deleting the specified replica of the block still makes 
 the block conform to the configured block placement policy.
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/BlockPlacementPolicyDefault.html#chooseReplicaToDelete(org.apache.hadoop.hdfs.server.namenode.FSInodeInfo, org.apache.hadoop.hdfs.protocol.Block, short, java.util.Collection, java.util.Collection)"><B>chooseReplicaToDelete(FSInodeInfo, Block, short, Collection&lt;DatanodeDescriptor&gt;, Collection&lt;DatanodeDescriptor&gt;)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/BlockPlacementPolicyDefault.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">BlockPlacementPolicyDefault</A> 中的方法
<DD>Decide whether deleting the specified replica of the block still makes 
 the block conform to the configured block placement policy.
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/BlockPlacementPolicyDefault.html#chooseTarget(java.lang.String, int, org.apache.hadoop.hdfs.server.namenode.DatanodeDescriptor, java.util.List, long)"><B>chooseTarget(String, int, DatanodeDescriptor, List&lt;DatanodeDescriptor&gt;, long)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/BlockPlacementPolicyDefault.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">BlockPlacementPolicyDefault</A> 中的方法
<DD>choose <i>numOfReplicas</i> data nodes for <i>writer</i> 
 to re-replicate a block with size <i>blocksize</i> 
 If not, return as many as we can.
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/BlockPlacementPolicyDefault.html#chooseTarget(java.lang.String, int, org.apache.hadoop.hdfs.server.namenode.DatanodeDescriptor, java.util.List, java.util.HashMap, long)"><B>chooseTarget(String, int, DatanodeDescriptor, List&lt;DatanodeDescriptor&gt;, HashMap&lt;Node, Node&gt;, long)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/BlockPlacementPolicyDefault.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">BlockPlacementPolicyDefault</A> 中的方法
<DD>choose <i>numOfReplicas</i> data nodes for <i>writer</i> 
 to re-replicate a block with size <i>blocksize</i> 
 If not, return as many as we can.
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/BlockPlacementPolicyDefault.html#chooseTarget(org.apache.hadoop.hdfs.server.namenode.FSInodeInfo, int, org.apache.hadoop.hdfs.server.namenode.DatanodeDescriptor, java.util.List, long)"><B>chooseTarget(FSInodeInfo, int, DatanodeDescriptor, List&lt;DatanodeDescriptor&gt;, long)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/BlockPlacementPolicyDefault.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">BlockPlacementPolicyDefault</A> 中的方法
<DD>
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FSImage.html#ckptState"><B>ckptState</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/FSImage.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FSImage</A> 中的变量
<DD>Can fs-image be rolled?
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/Storage.StorageDirectory.html#clearDirectory()"><B>clearDirectory()</B></A> - 
类 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/Storage.StorageDirectory.html" title="org.apache.hadoop.hdfs.server.common 中的类">Storage.StorageDirectory</A> 中的方法
<DD>Clear and re-create storage directory.
<DT><A HREF="./org/apache/hadoop/hdfs/DFSUtil.ErrorSimulator.html#clearErrorSimulation(int)"><B>clearErrorSimulation(int)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSUtil.ErrorSimulator.html" title="org.apache.hadoop.hdfs 中的类">DFSUtil.ErrorSimulator</A> 中的静态方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/ClientDatanodeProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的接口"><B>ClientDatanodeProtocol</B></A> - <A HREF="./org/apache/hadoop/hdfs/protocol/package-summary.html">org.apache.hadoop.hdfs.protocol</A> 中的 接口<DD>An client-datanode protocol for block recovery<DT><A HREF="./org/apache/hadoop/hdfs/protocol/ClientProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的接口"><B>ClientProtocol</B></A> - <A HREF="./org/apache/hadoop/hdfs/protocol/package-summary.html">org.apache.hadoop.hdfs.protocol</A> 中的 接口<DD>ClientProtocol is used by user code via 
 <A HREF="./org/apache/hadoop/hdfs/DistributedFileSystem.html" title="org.apache.hadoop.hdfs 中的类"><CODE>DistributedFileSystem</CODE></A> class to communicate 
 with the NameNode.<DT><A HREF="./org/apache/hadoop/hdfs/BlockReader.html#close()"><B>close()</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/BlockReader.html" title="org.apache.hadoop.hdfs 中的类">BlockReader</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSClient.html#close()"><B>close()</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSClient.html" title="org.apache.hadoop.hdfs 中的类">DFSClient</A> 中的方法
<DD>Close the file system, abandoning all of the leases and files being
 created and close connections to the namenode.
<DT><A HREF="./org/apache/hadoop/hdfs/DFSInputStream.html#close()"><B>close()</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSInputStream.html" title="org.apache.hadoop.hdfs 中的类">DFSInputStream</A> 中的方法
<DD>Close it down!
<DT><A HREF="./org/apache/hadoop/hdfs/DistributedFileSystem.html#close()"><B>close()</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DistributedFileSystem.html" title="org.apache.hadoop.hdfs 中的类">DistributedFileSystem</A> 中的方法
<DD>
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.BlockInputStreams.html#close()"><B>close()</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.BlockInputStreams.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">FSDatasetInterface.BlockInputStreams</A> 中的方法
<DD>
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#close()"><B>close()</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FSNamesystem</A> 中的方法
<DD>Close down this file system manager.
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/CodingMatrix.html#code(byte, byte, byte)"><B>code(byte, byte, byte)</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/CodingMatrix.html" title="org.apache.hadoop.hdfs.protocol 中的类">CodingMatrix</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.Op.html#code"><B>code</B></A> - 
枚举 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.Op.html" title="org.apache.hadoop.hdfs.protocol 中的枚举">DataTransferProtocol.Op</A> 中的变量
<DD>The code for this operation.
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/RegeneratingCodeMatrix.html#code(byte, byte, byte)"><B>code(byte, byte, byte)</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/RegeneratingCodeMatrix.html" title="org.apache.hadoop.hdfs.protocol 中的类">RegeneratingCodeMatrix</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/RSCoderProtocol.html#code(byte, byte, byte)"><B>code(byte, byte, byte)</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/RSCoderProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的类">RSCoderProtocol</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/XORCoderProtocol.html#code(byte, byte, byte)"><B>code(byte, byte, byte)</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/XORCoderProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的类">XORCoderProtocol</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/CodingMatrix.html" title="org.apache.hadoop.hdfs.protocol 中的类"><B>CodingMatrix</B></A> - <A HREF="./org/apache/hadoop/hdfs/protocol/package-summary.html">org.apache.hadoop.hdfs.protocol</A> 中的 类<DD>&nbsp;<DT><A HREF="./org/apache/hadoop/hdfs/protocol/CodingMatrix.html#CodingMatrix()"><B>CodingMatrix()</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/CodingMatrix.html" title="org.apache.hadoop.hdfs.protocol 中的类">CodingMatrix</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/CodingMatrix.html#CodingMatrix(org.apache.hadoop.hdfs.protocol.CodingMatrix)"><B>CodingMatrix(CodingMatrix)</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/CodingMatrix.html" title="org.apache.hadoop.hdfs.protocol 中的类">CodingMatrix</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/CodingMatrix.html#CodingMatrix(byte, byte)"><B>CodingMatrix(byte, byte)</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/CodingMatrix.html" title="org.apache.hadoop.hdfs.protocol 中的类">CodingMatrix</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html#commitBlockSynchronization(org.apache.hadoop.hdfs.protocol.Block, long, long, boolean, boolean, org.apache.hadoop.hdfs.protocol.DatanodeID[])"><B>commitBlockSynchronization(Block, long, long, boolean, boolean, DatanodeID[])</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">NameNode</A> 中的方法
<DD>Commit block synchronization in lease recovery
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/DatanodeProtocol.html#commitBlockSynchronization(org.apache.hadoop.hdfs.protocol.Block, long, long, boolean, boolean, org.apache.hadoop.hdfs.protocol.DatanodeID[])"><B>commitBlockSynchronization(Block, long, long, boolean, boolean, DatanodeID[])</B></A> - 
接口 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/DatanodeProtocol.html" title="org.apache.hadoop.hdfs.server.protocol 中的接口">DatanodeProtocol</A> 中的方法
<DD>Commit block synchronization in lease recovery
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/Block.html#compareTo(org.apache.hadoop.hdfs.protocol.Block)"><B>compareTo(Block)</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/Block.html" title="org.apache.hadoop.hdfs.protocol 中的类">Block</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeID.html#compareTo(org.apache.hadoop.hdfs.protocol.DatanodeID)"><B>compareTo(DatanodeID)</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeID.html" title="org.apache.hadoop.hdfs.protocol 中的类">DatanodeID</A> 中的方法
<DD>Comparable.
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/GenerationStamp.html#compareTo(org.apache.hadoop.hdfs.server.common.GenerationStamp)"><B>compareTo(GenerationStamp)</B></A> - 
类 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/GenerationStamp.html" title="org.apache.hadoop.hdfs.server.common 中的类">GenerationStamp</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/UpgradeObject.html#compareTo(org.apache.hadoop.hdfs.server.common.Upgradeable)"><B>compareTo(Upgradeable)</B></A> - 
类 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/UpgradeObject.html" title="org.apache.hadoop.hdfs.server.common 中的类">UpgradeObject</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/CheckpointSignature.html#compareTo(org.apache.hadoop.hdfs.server.namenode.CheckpointSignature)"><B>compareTo(CheckpointSignature)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/CheckpointSignature.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">CheckpointSignature</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/ClientProtocol.html#complete(java.lang.String, java.lang.String, org.apache.hadoop.hdfs.protocol.Block[])"><B>complete(String, String, Block[])</B></A> - 
接口 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/ClientProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的接口">ClientProtocol</A> 中的方法
<DD>modified by Vither Chien, we dont need the param lastblock, we 
 complete the file instead.
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html#complete(java.lang.String, java.lang.String, org.apache.hadoop.hdfs.protocol.Block[])"><B>complete(String, String, Block[])</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">NameNode</A> 中的方法
<DD>modified by Vither Chien, we dont need the param lastblock, we 
 complete the file instead.
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#completeFile(java.lang.String, java.lang.String, org.apache.hadoop.hdfs.protocol.Block[])"><B>completeFile(String, String, Block[])</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FSNamesystem</A> 中的方法
<DD>Complete in-progress write to the given file.
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/Upgradeable.html#completeUpgrade()"><B>completeUpgrade()</B></A> - 
接口 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/Upgradeable.html" title="org.apache.hadoop.hdfs.server.common 中的接口">Upgradeable</A> 中的方法
<DD>Complete upgrade.
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/UpgradeManager.html#completeUpgrade()"><B>completeUpgrade()</B></A> - 
类 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/UpgradeManager.html" title="org.apache.hadoop.hdfs.server.common 中的类">UpgradeManager</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/UpgradeObjectDatanode.html#completeUpgrade()"><B>completeUpgrade()</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/UpgradeObjectDatanode.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">UpgradeObjectDatanode</A> 中的方法
<DD>Complete upgrade and return a status complete command for broadcasting.
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#computeDatanodeWork()"><B>computeDatanodeWork()</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FSNamesystem</A> 中的方法
<DD>Compute block replication and block invalidation work 
 that can be scheduled on data-nodes.
<DT><A HREF="./org/apache/hadoop/hdfs/DFSClient.html#concat(java.lang.String, java.lang.String[])"><B>concat(String, String[])</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSClient.html" title="org.apache.hadoop.hdfs 中的类">DFSClient</A> 中的方法
<DD>Move blocks from src to trg and delete src
 See <A HREF="./org/apache/hadoop/hdfs/protocol/ClientProtocol.html#concat(java.lang.String, java.lang.String[])"><CODE>ClientProtocol.concat(String, String [])</CODE></A>.
<DT><A HREF="./org/apache/hadoop/hdfs/DistributedFileSystem.html#concat(org.apache.hadoop.fs.Path, org.apache.hadoop.fs.Path[])"><B>concat(Path, Path[])</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DistributedFileSystem.html" title="org.apache.hadoop.hdfs 中的类">DistributedFileSystem</A> 中的方法
<DD>THIS IS DFS only operations, it is not part of FileSystem
 move blocks from srcs to trg
 and delete srcs afterwards
 all blocks should be the same size
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/ClientProtocol.html#concat(java.lang.String, java.lang.String[])"><B>concat(String, String[])</B></A> - 
接口 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/ClientProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的接口">ClientProtocol</A> 中的方法
<DD>Moves blocks from srcs to trg and delete srcs
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#concat(java.lang.String, java.lang.String[])"><B>concat(String, String[])</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FSNamesystem</A> 中的方法
<DD>Moves all the blocks from srcs and appends them to trg
 To avoid rollbacks we will verify validitity of ALL of the args
 before we start actual move.
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html#concat(java.lang.String, java.lang.String[])"><B>concat(String, String[])</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">NameNode</A> 中的方法
<DD>Moves blocks from srcs to trg and delete srcs
<DT><A HREF="./org/apache/hadoop/hdfs/util/GSet.html#contains(K)"><B>contains(K)</B></A> - 
接口 org.apache.hadoop.hdfs.util.<A HREF="./org/apache/hadoop/hdfs/util/GSet.html" title="org.apache.hadoop.hdfs.util 中的接口">GSet</A> 中的方法
<DD>Does this set contain an element corresponding to the given key?
<DT><A HREF="./org/apache/hadoop/hdfs/util/GSetByHashMap.html#contains(K)"><B>contains(K)</B></A> - 
类 org.apache.hadoop.hdfs.util.<A HREF="./org/apache/hadoop/hdfs/util/GSetByHashMap.html" title="org.apache.hadoop.hdfs.util 中的类">GSetByHashMap</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/util/LightWeightGSet.html#contains(K)"><B>contains(K)</B></A> - 
类 org.apache.hadoop.hdfs.util.<A HREF="./org/apache/hadoop/hdfs/util/LightWeightGSet.html" title="org.apache.hadoop.hdfs.util 中的类">LightWeightGSet</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/StreamFile.html#CONTENT_LENGTH"><B>CONTENT_LENGTH</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/StreamFile.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">StreamFile</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/ContentSummaryServlet.html" title="org.apache.hadoop.hdfs.server.namenode 中的类"><B>ContentSummaryServlet</B></A> - <A HREF="./org/apache/hadoop/hdfs/server/namenode/package-summary.html">org.apache.hadoop.hdfs.server.namenode</A> 中的 类<DD>Servlets for file checksum<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/ContentSummaryServlet.html#ContentSummaryServlet()"><B>ContentSummaryServlet()</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/ContentSummaryServlet.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">ContentSummaryServlet</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/metrics/DataNodeMetrics.html#copyBlockOp"><B>copyBlockOp</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.metrics.<A HREF="./org/apache/hadoop/hdfs/server/datanode/metrics/DataNodeMetrics.html" title="org.apache.hadoop.hdfs.server.datanode.metrics 中的类">DataNodeMetrics</A> 中的变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NamenodeFsck.html#CORRUPT_STATUS"><B>CORRUPT_STATUS</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/NamenodeFsck.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">NamenodeFsck</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/CorruptReplicasMap.html" title="org.apache.hadoop.hdfs.server.namenode 中的类"><B>CorruptReplicasMap</B></A> - <A HREF="./org/apache/hadoop/hdfs/server/namenode/package-summary.html">org.apache.hadoop.hdfs.server.namenode</A> 中的 类<DD>Stores information about all corrupt blocks in the File System.<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/CorruptReplicasMap.html#CorruptReplicasMap()"><B>CorruptReplicasMap()</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/CorruptReplicasMap.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">CorruptReplicasMap</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/QuotaExceededException.html#count"><B>count</B></A> - 
异常 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/QuotaExceededException.html" title="org.apache.hadoop.hdfs.protocol 中的类">QuotaExceededException</A> 中的变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/LeaseManager.html#countLease()"><B>countLease()</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/LeaseManager.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">LeaseManager</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeInfo.html#cpuStatus"><B>cpuStatus</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeInfo.html" title="org.apache.hadoop.hdfs.protocol 中的类">DatanodeInfo</A> 中的变量
<DD>add by xianyu
<DT><A HREF="./org/apache/hadoop/hdfs/DFSClient.html#create(java.lang.String, boolean)"><B>create(String, boolean)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSClient.html" title="org.apache.hadoop.hdfs 中的类">DFSClient</A> 中的方法
<DD>Call <A HREF="./org/apache/hadoop/hdfs/DFSClient.html#create(java.lang.String, boolean, short, long, org.apache.hadoop.util.Progressable)"><CODE>DFSClient.create(String, boolean, short, long, Progressable)</CODE></A> with
 default <code>replication</code> and <code>blockSize<code> and null <code>
 progress</code>.
<DT><A HREF="./org/apache/hadoop/hdfs/DFSClient.html#create(java.lang.String, boolean, org.apache.hadoop.util.Progressable)"><B>create(String, boolean, Progressable)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSClient.html" title="org.apache.hadoop.hdfs 中的类">DFSClient</A> 中的方法
<DD>Call <A HREF="./org/apache/hadoop/hdfs/DFSClient.html#create(java.lang.String, boolean, short, long, org.apache.hadoop.util.Progressable)"><CODE>DFSClient.create(String, boolean, short, long, Progressable)</CODE></A> with
 default <code>replication</code> and <code>blockSize<code>.
<DT><A HREF="./org/apache/hadoop/hdfs/DFSClient.html#create(java.lang.String, boolean, short, long)"><B>create(String, boolean, short, long)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSClient.html" title="org.apache.hadoop.hdfs 中的类">DFSClient</A> 中的方法
<DD>Call <A HREF="./org/apache/hadoop/hdfs/DFSClient.html#create(java.lang.String, boolean, short, long, org.apache.hadoop.util.Progressable)"><CODE>DFSClient.create(String, boolean, short, long, Progressable)</CODE></A> with
 null <code>progress</code>.
<DT><A HREF="./org/apache/hadoop/hdfs/DFSClient.html#create(java.lang.String, boolean, short, long, org.apache.hadoop.util.Progressable)"><B>create(String, boolean, short, long, Progressable)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSClient.html" title="org.apache.hadoop.hdfs 中的类">DFSClient</A> 中的方法
<DD>Call <A HREF="./org/apache/hadoop/hdfs/DFSClient.html#create(java.lang.String, boolean, short, long, org.apache.hadoop.util.Progressable, int)"><CODE>DFSClient.create(String, boolean, short, long, Progressable, int)</CODE></A>
 with default bufferSize.
<DT><A HREF="./org/apache/hadoop/hdfs/DFSClient.html#create(java.lang.String, boolean, short, long, org.apache.hadoop.util.Progressable, int)"><B>create(String, boolean, short, long, Progressable, int)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSClient.html" title="org.apache.hadoop.hdfs 中的类">DFSClient</A> 中的方法
<DD>Call <A HREF="./org/apache/hadoop/hdfs/DFSClient.html#create(java.lang.String, org.apache.hadoop.fs.permission.FsPermission, java.util.EnumSet, short, long, org.apache.hadoop.util.Progressable, int)"><CODE>DFSClient.create(String, FsPermission, EnumSet, short, long, 
 Progressable, int)</CODE></A> with default <code>permission</code>
 <CODE>FsPermission.getDefault()</CODE>.
<DT><A HREF="./org/apache/hadoop/hdfs/DFSClient.html#create(java.lang.String, org.apache.hadoop.fs.permission.FsPermission, java.util.EnumSet, short, long, org.apache.hadoop.util.Progressable, int)"><B>create(String, FsPermission, EnumSet&lt;CreateFlag&gt;, short, long, Progressable, int)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSClient.html" title="org.apache.hadoop.hdfs 中的类">DFSClient</A> 中的方法
<DD>Call <A HREF="./org/apache/hadoop/hdfs/DFSClient.html#create(java.lang.String, org.apache.hadoop.fs.permission.FsPermission, java.util.EnumSet, boolean, short, long, org.apache.hadoop.util.Progressable, int)"><CODE>DFSClient.create(String, FsPermission, EnumSet, boolean, short, 
 long, Progressable, int)</CODE></A> with <code>createParent</code> set to true.
<DT><A HREF="./org/apache/hadoop/hdfs/DFSClient.html#create(java.lang.String, long, org.apache.hadoop.fs.permission.FsPermission, java.util.EnumSet, org.apache.hadoop.util.Progressable, int)"><B>create(String, long, FsPermission, EnumSet&lt;CreateFlag&gt;, Progressable, int)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSClient.html" title="org.apache.hadoop.hdfs 中的类">DFSClient</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSClient.html#create(java.lang.String, org.apache.hadoop.fs.permission.FsPermission, java.util.EnumSet, boolean, short, long, org.apache.hadoop.util.Progressable, int)"><B>create(String, FsPermission, EnumSet&lt;CreateFlag&gt;, boolean, short, long, Progressable, int)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSClient.html" title="org.apache.hadoop.hdfs 中的类">DFSClient</A> 中的方法
<DD>Create a new dfs file with the specified block replication 
 with write-progress reporting and return an output stream for writing
 into the file.
<DT><A HREF="./org/apache/hadoop/hdfs/DFSClient.html#create(java.lang.String, long, org.apache.hadoop.fs.permission.FsPermission, java.util.EnumSet, boolean, org.apache.hadoop.util.Progressable, int)"><B>create(String, long, FsPermission, EnumSet&lt;CreateFlag&gt;, boolean, Progressable, int)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSClient.html" title="org.apache.hadoop.hdfs 中的类">DFSClient</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DistributedFileSystem.html#create(org.apache.hadoop.fs.Path, org.apache.hadoop.fs.permission.FsPermission, boolean, int, short, long, org.apache.hadoop.util.Progressable)"><B>create(Path, FsPermission, boolean, int, short, long, Progressable)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DistributedFileSystem.html" title="org.apache.hadoop.hdfs 中的类">DistributedFileSystem</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DistributedFileSystem.html#create(org.apache.hadoop.fs.Path, long, org.apache.hadoop.fs.permission.FsPermission, boolean, int, org.apache.hadoop.util.Progressable)"><B>create(Path, long, FsPermission, boolean, int, Progressable)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DistributedFileSystem.html" title="org.apache.hadoop.hdfs 中的类">DistributedFileSystem</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/HftpFileSystem.html#create(org.apache.hadoop.fs.Path, org.apache.hadoop.fs.permission.FsPermission, boolean, int, short, long, org.apache.hadoop.util.Progressable)"><B>create(Path, FsPermission, boolean, int, short, long, Progressable)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/HftpFileSystem.html" title="org.apache.hadoop.hdfs 中的类">HftpFileSystem</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/HftpFileSystem.html#create(org.apache.hadoop.fs.Path, long, org.apache.hadoop.fs.permission.FsPermission, boolean, int, org.apache.hadoop.util.Progressable)"><B>create(Path, long, FsPermission, boolean, int, Progressable)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/HftpFileSystem.html" title="org.apache.hadoop.hdfs 中的类">HftpFileSystem</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/ClientProtocol.html#create(java.lang.String, org.apache.hadoop.fs.permission.FsPermission, java.lang.String, org.apache.hadoop.io.EnumSetWritable, boolean, short, long)"><B>create(String, FsPermission, String, EnumSetWritable&lt;CreateFlag&gt;, boolean, short, long)</B></A> - 
接口 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/ClientProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的接口">ClientProtocol</A> 中的方法
<DD>Create a new file entry in the namespace.
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/ClientProtocol.html#create(java.lang.String, long, long, org.apache.hadoop.fs.permission.FsPermission, java.lang.String, org.apache.hadoop.io.EnumSetWritable, boolean)"><B>create(String, long, long, FsPermission, String, EnumSetWritable&lt;CreateFlag&gt;, boolean)</B></A> - 
接口 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/ClientProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的接口">ClientProtocol</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html#create(java.lang.String, org.apache.hadoop.fs.permission.FsPermission, java.lang.String, org.apache.hadoop.io.EnumSetWritable, boolean, short, long)"><B>create(String, FsPermission, String, EnumSetWritable&lt;CreateFlag&gt;, boolean, short, long)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">NameNode</A> 中的方法
<DD>Create a new file entry in the namespace.
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html#create(java.lang.String, long, long, org.apache.hadoop.fs.permission.FsPermission, java.lang.String, org.apache.hadoop.io.EnumSetWritable, boolean)"><B>create(String, long, long, FsPermission, String, EnumSetWritable&lt;CreateFlag&gt;, boolean)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">NameNode</A> 中的方法
<DD>
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/DataNode.html#createDataNode(java.lang.String[], org.apache.hadoop.conf.Configuration)"><B>createDataNode(String[], Configuration)</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/DataNode.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">DataNode</A> 中的静态方法
<DD>Instantiate & Start a single datanode daemon and wait for it to finish.
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/DataNode.html#createDataNode(java.lang.String[], org.apache.hadoop.conf.Configuration, org.apache.hadoop.hdfs.server.datanode.SecureDataNodeStarter.SecureResources)"><B>createDataNode(String[], Configuration, SecureDataNodeStarter.SecureResources)</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/DataNode.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">DataNode</A> 中的静态方法
<DD>Instantiate & Start a single datanode daemon and wait for it to finish.
<DT><A HREF="./org/apache/hadoop/hdfs/security/token/block/BlockTokenSecretManager.html#createIdentifier()"><B>createIdentifier()</B></A> - 
类 org.apache.hadoop.hdfs.security.token.block.<A HREF="./org/apache/hadoop/hdfs/security/token/block/BlockTokenSecretManager.html" title="org.apache.hadoop.hdfs.security.token.block 中的类">BlockTokenSecretManager</A> 中的方法
<DD>Create an empty block token identifier
<DT><A HREF="./org/apache/hadoop/hdfs/security/token/delegation/DelegationTokenSecretManager.html#createIdentifier()"><B>createIdentifier()</B></A> - 
类 org.apache.hadoop.hdfs.security.token.delegation.<A HREF="./org/apache/hadoop/hdfs/security/token/delegation/DelegationTokenSecretManager.html" title="org.apache.hadoop.hdfs.security.token.delegation 中的类">DelegationTokenSecretManager</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/DataNode.html#createInterDataNodeProtocolProxy(org.apache.hadoop.hdfs.protocol.DatanodeID, org.apache.hadoop.conf.Configuration, int)"><B>createInterDataNodeProtocolProxy(DatanodeID, Configuration, int)</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/DataNode.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">DataNode</A> 中的静态方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/fs/Hdfs.html#createInternal(org.apache.hadoop.fs.Path, java.util.EnumSet, org.apache.hadoop.fs.permission.FsPermission, int, short, long, org.apache.hadoop.util.Progressable, int, boolean)"><B>createInternal(Path, EnumSet&lt;CreateFlag&gt;, FsPermission, int, short, long, Progressable, int, boolean)</B></A> - 
类 org.apache.hadoop.fs.<A HREF="./org/apache/hadoop/fs/Hdfs.html" title="org.apache.hadoop.fs 中的类">Hdfs</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSClient.html#createNamenode(org.apache.hadoop.conf.Configuration)"><B>createNamenode(Configuration)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSClient.html" title="org.apache.hadoop.hdfs 中的类">DFSClient</A> 中的静态方法
<DD>The locking hierarchy is to first acquire lock on DFSClient object, followed by 
 lock on leasechecker, followed by lock on an individual DFSOutputStream.
<DT><A HREF="./org/apache/hadoop/hdfs/DFSClient.html#createNamenode(java.net.InetSocketAddress, org.apache.hadoop.conf.Configuration)"><B>createNamenode(InetSocketAddress, Configuration)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSClient.html" title="org.apache.hadoop.hdfs 中的类">DFSClient</A> 中的静态方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html#createNameNode(java.lang.String[], org.apache.hadoop.conf.Configuration)"><B>createNameNode(String[], Configuration)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">NameNode</A> 中的静态方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DistributedFileSystem.html#createNonRecursive(org.apache.hadoop.fs.Path, org.apache.hadoop.fs.permission.FsPermission, java.util.EnumSet, int, short, long, org.apache.hadoop.util.Progressable)"><B>createNonRecursive(Path, FsPermission, EnumSet&lt;CreateFlag&gt;, int, short, long, Progressable)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DistributedFileSystem.html" title="org.apache.hadoop.hdfs 中的类">DistributedFileSystem</A> 中的方法
<DD>Same as create(), except fails if parent directory doesn't already exist.
<DT><A HREF="./org/apache/hadoop/hdfs/security/token/block/BlockTokenSecretManager.html#createPassword(org.apache.hadoop.hdfs.security.token.block.BlockTokenIdentifier)"><B>createPassword(BlockTokenIdentifier)</B></A> - 
类 org.apache.hadoop.hdfs.security.token.block.<A HREF="./org/apache/hadoop/hdfs/security/token/block/BlockTokenSecretManager.html" title="org.apache.hadoop.hdfs.security.token.block 中的类">BlockTokenSecretManager</A> 中的方法
<DD>Create a new password/secret for the given block token identifier.
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDataset.html#createRbw(org.apache.hadoop.hdfs.protocol.Block)"><B>createRbw(Block)</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDataset.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">FSDataset</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.html#createRbw(org.apache.hadoop.hdfs.protocol.Block)"><B>createRbw(Block)</B></A> - 
接口 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.html" title="org.apache.hadoop.hdfs.server.datanode 中的接口">FSDatasetInterface</A> 中的方法
<DD>Creates a RBW replica and returns the meta info of the replica
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/DataNode.html#createSocketAddr(java.lang.String)"><B>createSocketAddr(String)</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/DataNode.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">DataNode</A> 中的静态方法
<DD><B>已过时。</B>&nbsp;
<DT><A HREF="./org/apache/hadoop/fs/Hdfs.html#createSymlink(org.apache.hadoop.fs.Path, org.apache.hadoop.fs.Path, boolean)"><B>createSymlink(Path, Path, boolean)</B></A> - 
类 org.apache.hadoop.fs.<A HREF="./org/apache/hadoop/fs/Hdfs.html" title="org.apache.hadoop.fs 中的类">Hdfs</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSClient.html#createSymlink(java.lang.String, java.lang.String, boolean)"><B>createSymlink(String, String, boolean)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSClient.html" title="org.apache.hadoop.hdfs 中的类">DFSClient</A> 中的方法
<DD>Creates a symbolic link.
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/ClientProtocol.html#createSymlink(java.lang.String, java.lang.String, org.apache.hadoop.fs.permission.FsPermission, boolean)"><B>createSymlink(String, String, FsPermission, boolean)</B></A> - 
接口 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/ClientProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的接口">ClientProtocol</A> 中的方法
<DD>Create symlink to a file or directory.
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#createSymlink(java.lang.String, java.lang.String, org.apache.hadoop.fs.permission.PermissionStatus, boolean)"><B>createSymlink(String, String, PermissionStatus, boolean)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FSNamesystem</A> 中的方法
<DD>Create a symbolic link.
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html#createSymlink(java.lang.String, java.lang.String, org.apache.hadoop.fs.permission.FsPermission, boolean)"><B>createSymlink(String, String, FsPermission, boolean)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">NameNode</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDataset.html#createTemporary(org.apache.hadoop.hdfs.protocol.Block)"><B>createTemporary(Block)</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDataset.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">FSDataset</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.html#createTemporary(org.apache.hadoop.hdfs.protocol.Block)"><B>createTemporary(Block)</B></A> - 
接口 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.html" title="org.apache.hadoop.hdfs.server.datanode 中的接口">FSDatasetInterface</A> 中的方法
<DD>Creates a temporary replica and returns the meta information of the replica
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/JspHelper.html#createTitle(javax.servlet.jsp.JspWriter, javax.servlet.http.HttpServletRequest, java.lang.String)"><B>createTitle(JspWriter, HttpServletRequest, String)</B></A> - 
类 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/JspHelper.html" title="org.apache.hadoop.hdfs.server.common 中的类">JspHelper</A> 中的静态方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FileDataServlet.html#createUri(java.lang.String, org.apache.hadoop.hdfs.protocol.HdfsFileStatus, org.apache.hadoop.security.UserGroupInformation, org.apache.hadoop.hdfs.protocol.ClientProtocol, javax.servlet.http.HttpServletRequest, java.lang.String)"><B>createUri(String, HdfsFileStatus, UserGroupInformation, ClientProtocol, HttpServletRequest, String)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/FileDataServlet.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FileDataServlet</A> 中的方法
<DD>Create a redirection URI
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/StorageInfo.html#cTime"><B>cTime</B></A> - 
类 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/StorageInfo.html" title="org.apache.hadoop.hdfs.server.common 中的类">StorageInfo</A> 中的变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/CumulusRecoveryCommand.html" title="org.apache.hadoop.hdfs.server.protocol 中的类"><B>CumulusRecoveryCommand</B></A> - <A HREF="./org/apache/hadoop/hdfs/server/protocol/package-summary.html">org.apache.hadoop.hdfs.server.protocol</A> 中的 类<DD>command to guide datanode recoverying block<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/CumulusRecoveryCommand.html#CumulusRecoveryCommand()"><B>CumulusRecoveryCommand()</B></A> - 
类 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/CumulusRecoveryCommand.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">CumulusRecoveryCommand</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/CumulusRecoveryCommand.html#CumulusRecoveryCommand(int, byte, byte, org.apache.hadoop.hdfs.protocol.CodingMatrix, java.util.List)"><B>CumulusRecoveryCommand(int, byte, byte, CodingMatrix, List&lt;DatanodeDescriptor.BlockTargetPair&gt;)</B></A> - 
类 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/CumulusRecoveryCommand.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">CumulusRecoveryCommand</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/JspHelper.html#CURRENT_CONF"><B>CURRENT_CONF</B></A> - 
类 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/JspHelper.html" title="org.apache.hadoop.hdfs.server.common 中的类">JspHelper</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/UpgradeManager.html#currentUpgrades"><B>currentUpgrades</B></A> - 
类 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/UpgradeManager.html" title="org.apache.hadoop.hdfs.server.common 中的类">UpgradeManager</A> 中的变量
<DD>&nbsp;
</DL>
<HR>
<A NAME="_D_"><!-- --></A><H2>
<B>D</B></H2>
<DL>
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/DataNode.html#data"><B>data</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/DataNode.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">DataNode</A> 中的变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.html#DATA_TRANSFER_VERSION"><B>DATA_TRANSFER_VERSION</B></A> - 
接口 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的接口">DataTransferProtocol</A> 中的静态变量
<DD>Version for data transfers between clients and datanodes
 This should change when serialization of DatanodeInfo, not just
 when protocol changes.
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/DataNode.html" title="org.apache.hadoop.hdfs.server.datanode 中的类"><B>DataNode</B></A> - <A HREF="./org/apache/hadoop/hdfs/server/datanode/package-summary.html">org.apache.hadoop.hdfs.server.datanode</A> 中的 类<DD>DataNode is a class (and program) that stores a set of
 blocks for a DFS deployment.<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/DataNode.RCRecoveryThreadTarget.html" title="org.apache.hadoop.hdfs.server.datanode 中的类"><B>DataNode.RCRecoveryThreadTarget</B></A> - <A HREF="./org/apache/hadoop/hdfs/server/datanode/package-summary.html">org.apache.hadoop.hdfs.server.datanode</A> 中的 类<DD>rc(regenerating code)recovery thread target, changed on basis of CumulusRecovery. created at 2014-4-17. modified
 at 2014-4-24,2014-4-25.<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/DataNode.RCRecoveryThreadTarget.html#DataNode.RCRecoveryThreadTarget(byte, org.apache.hadoop.hdfs.protocol.LocatedBlock[], org.apache.hadoop.hdfs.protocol.CodingMatrix)"><B>DataNode.RCRecoveryThreadTarget(byte, LocatedBlock[], CodingMatrix)</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/DataNode.RCRecoveryThreadTarget.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">DataNode.RCRecoveryThreadTarget</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/metrics/DataNodeActivityMBean.html" title="org.apache.hadoop.hdfs.server.datanode.metrics 中的类"><B>DataNodeActivityMBean</B></A> - <A HREF="./org/apache/hadoop/hdfs/server/datanode/metrics/package-summary.html">org.apache.hadoop.hdfs.server.datanode.metrics</A> 中的 类<DD>This is the JMX MBean for reporting the DataNode Activity.<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/metrics/DataNodeActivityMBean.html#DataNodeActivityMBean(org.apache.hadoop.metrics.util.MetricsRegistry, java.lang.String)"><B>DataNodeActivityMBean(MetricsRegistry, String)</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.metrics.<A HREF="./org/apache/hadoop/hdfs/server/datanode/metrics/DataNodeActivityMBean.html" title="org.apache.hadoop.hdfs.server.datanode.metrics 中的类">DataNodeActivityMBean</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/DatanodeCommand.html" title="org.apache.hadoop.hdfs.server.protocol 中的类"><B>DatanodeCommand</B></A> - <A HREF="./org/apache/hadoop/hdfs/server/protocol/package-summary.html">org.apache.hadoop.hdfs.server.protocol</A> 中的 类<DD>Base class for data-node command.<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/DatanodeCommand.html#DatanodeCommand()"><B>DatanodeCommand()</B></A> - 
类 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/DatanodeCommand.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">DatanodeCommand</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/DatanodeDescriptor.html" title="org.apache.hadoop.hdfs.server.namenode 中的类"><B>DatanodeDescriptor</B></A> - <A HREF="./org/apache/hadoop/hdfs/server/namenode/package-summary.html">org.apache.hadoop.hdfs.server.namenode</A> 中的 类<DD>DatanodeDescriptor tracks stats on a given DataNode, such as
 available storage capacity, last update time, etc., and maintains a
 set of blocks stored on the datanode.<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/DatanodeDescriptor.html#DatanodeDescriptor()"><B>DatanodeDescriptor()</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/DatanodeDescriptor.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">DatanodeDescriptor</A> 的构造方法
<DD>Default constructor
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/DatanodeDescriptor.html#DatanodeDescriptor(org.apache.hadoop.hdfs.protocol.DatanodeID)"><B>DatanodeDescriptor(DatanodeID)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/DatanodeDescriptor.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">DatanodeDescriptor</A> 的构造方法
<DD>DatanodeDescriptor constructor
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/DatanodeDescriptor.html#DatanodeDescriptor(org.apache.hadoop.hdfs.protocol.DatanodeID, java.lang.String)"><B>DatanodeDescriptor(DatanodeID, String)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/DatanodeDescriptor.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">DatanodeDescriptor</A> 的构造方法
<DD>DatanodeDescriptor constructor
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/DatanodeDescriptor.html#DatanodeDescriptor(org.apache.hadoop.hdfs.protocol.DatanodeID, java.lang.String, java.lang.String)"><B>DatanodeDescriptor(DatanodeID, String, String)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/DatanodeDescriptor.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">DatanodeDescriptor</A> 的构造方法
<DD>DatanodeDescriptor constructor
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/DatanodeDescriptor.html#DatanodeDescriptor(org.apache.hadoop.hdfs.protocol.DatanodeID, long, long, long, org.apache.hadoop.hdfs.server.monitor.ServernodeCPUStatus, org.apache.hadoop.hdfs.server.monitor.ServernodeMEMStatus, org.apache.hadoop.hdfs.server.monitor.ServernodeNETStatus[], org.apache.hadoop.hdfs.server.monitor.ServernodeIOStatus[], int, int)"><B>DatanodeDescriptor(DatanodeID, long, long, long, ServernodeCPUStatus, ServernodeMEMStatus, ServernodeNETStatus[], ServernodeIOStatus[], int, int)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/DatanodeDescriptor.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">DatanodeDescriptor</A> 的构造方法
<DD>DatanodeDescriptor constructor
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/DatanodeDescriptor.html#DatanodeDescriptor(org.apache.hadoop.hdfs.protocol.DatanodeID, java.lang.String, java.lang.String, long, long, long, org.apache.hadoop.hdfs.server.monitor.ServernodeCPUStatus, org.apache.hadoop.hdfs.server.monitor.ServernodeMEMStatus, org.apache.hadoop.hdfs.server.monitor.ServernodeNETStatus[], org.apache.hadoop.hdfs.server.monitor.ServernodeIOStatus[], int, int)"><B>DatanodeDescriptor(DatanodeID, String, String, long, long, long, ServernodeCPUStatus, ServernodeMEMStatus, ServernodeNETStatus[], ServernodeIOStatus[], int, int)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/DatanodeDescriptor.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">DatanodeDescriptor</A> 的构造方法
<DD>DatanodeDescriptor constructor
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/DatanodeDescriptor.BlockTargetPair.html" title="org.apache.hadoop.hdfs.server.namenode 中的类"><B>DatanodeDescriptor.BlockTargetPair</B></A> - <A HREF="./org/apache/hadoop/hdfs/server/namenode/package-summary.html">org.apache.hadoop.hdfs.server.namenode</A> 中的 类<DD>Block and targets pair<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeID.html" title="org.apache.hadoop.hdfs.protocol 中的类"><B>DatanodeID</B></A> - <A HREF="./org/apache/hadoop/hdfs/protocol/package-summary.html">org.apache.hadoop.hdfs.protocol</A> 中的 类<DD>DatanodeID is composed of the data node 
 name (hostname:portNumber) and the data storage ID, 
 which it currently represents.<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeID.html#DatanodeID()"><B>DatanodeID()</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeID.html" title="org.apache.hadoop.hdfs.protocol 中的类">DatanodeID</A> 的构造方法
<DD>Equivalent to DatanodeID("").
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeID.html#DatanodeID(java.lang.String)"><B>DatanodeID(String)</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeID.html" title="org.apache.hadoop.hdfs.protocol 中的类">DatanodeID</A> 的构造方法
<DD>Equivalent to DatanodeID(nodeName, "", -1, -1).
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeID.html#DatanodeID(org.apache.hadoop.hdfs.protocol.DatanodeID)"><B>DatanodeID(DatanodeID)</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeID.html" title="org.apache.hadoop.hdfs.protocol 中的类">DatanodeID</A> 的构造方法
<DD>DatanodeID copy constructor
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeID.html#DatanodeID(java.lang.String, java.lang.String, int, int)"><B>DatanodeID(String, String, int, int)</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeID.html" title="org.apache.hadoop.hdfs.protocol 中的类">DatanodeID</A> 的构造方法
<DD>Create DatanodeID
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeInfo.html" title="org.apache.hadoop.hdfs.protocol 中的类"><B>DatanodeInfo</B></A> - <A HREF="./org/apache/hadoop/hdfs/protocol/package-summary.html">org.apache.hadoop.hdfs.protocol</A> 中的 类<DD>DatanodeInfo represents the status of a DataNode.<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeInfo.html#DatanodeInfo()"><B>DatanodeInfo()</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeInfo.html" title="org.apache.hadoop.hdfs.protocol 中的类">DatanodeInfo</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeInfo.html#DatanodeInfo(org.apache.hadoop.hdfs.protocol.DatanodeInfo)"><B>DatanodeInfo(DatanodeInfo)</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeInfo.html" title="org.apache.hadoop.hdfs.protocol 中的类">DatanodeInfo</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeInfo.html#DatanodeInfo(org.apache.hadoop.hdfs.protocol.DatanodeID)"><B>DatanodeInfo(DatanodeID)</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeInfo.html" title="org.apache.hadoop.hdfs.protocol 中的类">DatanodeInfo</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeInfo.html#DatanodeInfo(org.apache.hadoop.hdfs.protocol.DatanodeID, java.lang.String, java.lang.String)"><B>DatanodeInfo(DatanodeID, String, String)</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeInfo.html" title="org.apache.hadoop.hdfs.protocol 中的类">DatanodeInfo</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeInfo.AdminStates.html" title="org.apache.hadoop.hdfs.protocol 中的枚举"><B>DatanodeInfo.AdminStates</B></A> - <A HREF="./org/apache/hadoop/hdfs/protocol/package-summary.html">org.apache.hadoop.hdfs.protocol</A> 中的 枚举<DD>&nbsp;<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/DatanodeJspHelper.html" title="org.apache.hadoop.hdfs.server.datanode 中的类"><B>DatanodeJspHelper</B></A> - <A HREF="./org/apache/hadoop/hdfs/server/datanode/package-summary.html">org.apache.hadoop.hdfs.server.datanode</A> 中的 类<DD>&nbsp;<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/DatanodeJspHelper.html#DatanodeJspHelper()"><B>DatanodeJspHelper()</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/DatanodeJspHelper.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">DatanodeJspHelper</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/metrics/DataNodeMetrics.html" title="org.apache.hadoop.hdfs.server.datanode.metrics 中的类"><B>DataNodeMetrics</B></A> - <A HREF="./org/apache/hadoop/hdfs/server/datanode/metrics/package-summary.html">org.apache.hadoop.hdfs.server.datanode.metrics</A> 中的 类<DD>This class is for maintaining  the various DataNode statistics
 and publishing them through the metrics interfaces.<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/metrics/DataNodeMetrics.html#DataNodeMetrics(org.apache.hadoop.conf.Configuration, java.lang.String)"><B>DataNodeMetrics(Configuration, String)</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.metrics.<A HREF="./org/apache/hadoop/hdfs/server/datanode/metrics/DataNodeMetrics.html" title="org.apache.hadoop.hdfs.server.datanode.metrics 中的类">DataNodeMetrics</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/DatanodeMonitorServlet.html" title="org.apache.hadoop.hdfs.server.datanode 中的类"><B>DatanodeMonitorServlet</B></A> - <A HREF="./org/apache/hadoop/hdfs/server/datanode/package-summary.html">org.apache.hadoop.hdfs.server.datanode</A> 中的 类<DD>&nbsp;<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/DatanodeMonitorServlet.html#DatanodeMonitorServlet()"><B>DatanodeMonitorServlet()</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/DatanodeMonitorServlet.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">DatanodeMonitorServlet</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/DataNodeMXBean.html" title="org.apache.hadoop.hdfs.server.datanode 中的接口"><B>DataNodeMXBean</B></A> - <A HREF="./org/apache/hadoop/hdfs/server/datanode/package-summary.html">org.apache.hadoop.hdfs.server.datanode</A> 中的 接口<DD>This is the JMX management interface for data node information<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/DatanodeProtocol.html" title="org.apache.hadoop.hdfs.server.protocol 中的接口"><B>DatanodeProtocol</B></A> - <A HREF="./org/apache/hadoop/hdfs/server/protocol/package-summary.html">org.apache.hadoop.hdfs.server.protocol</A> 中的 接口<DD>Protocol that a DFS datanode uses to communicate with the NameNode.<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/DatanodeRegistration.html" title="org.apache.hadoop.hdfs.server.protocol 中的类"><B>DatanodeRegistration</B></A> - <A HREF="./org/apache/hadoop/hdfs/server/protocol/package-summary.html">org.apache.hadoop.hdfs.server.protocol</A> 中的 类<DD>DatanodeRegistration class contains all information the name-node needs
 to identify and verify a data-node when it contacts the name-node.<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/DatanodeRegistration.html#DatanodeRegistration()"><B>DatanodeRegistration()</B></A> - 
类 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/DatanodeRegistration.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">DatanodeRegistration</A> 的构造方法
<DD>Default constructor.
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/DatanodeRegistration.html#DatanodeRegistration(java.lang.String)"><B>DatanodeRegistration(String)</B></A> - 
类 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/DatanodeRegistration.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">DatanodeRegistration</A> 的构造方法
<DD>Create DatanodeRegistration
<DT><A HREF="./org/apache/hadoop/hdfs/DFSClient.html#datanodeReport(org.apache.hadoop.hdfs.protocol.FSConstants.DatanodeReportType)"><B>datanodeReport(FSConstants.DatanodeReportType)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSClient.html" title="org.apache.hadoop.hdfs 中的类">DFSClient</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#datanodeReport(org.apache.hadoop.hdfs.protocol.FSConstants.DatanodeReportType)"><B>datanodeReport(FSConstants.DatanodeReportType)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FSNamesystem</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DataPool.html" title="org.apache.hadoop.hdfs 中的类"><B>DataPool</B></A> - <A HREF="./org/apache/hadoop/hdfs/package-summary.html">org.apache.hadoop.hdfs</A> 中的 类<DD>&nbsp;<DT><A HREF="./org/apache/hadoop/hdfs/DataPool.html#DataPool(org.apache.hadoop.hdfs.BlockReader, int, int)"><B>DataPool(BlockReader, int, int)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DataPool.html" title="org.apache.hadoop.hdfs 中的类">DataPool</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/DataStorage.html" title="org.apache.hadoop.hdfs.server.datanode 中的类"><B>DataStorage</B></A> - <A HREF="./org/apache/hadoop/hdfs/server/datanode/package-summary.html">org.apache.hadoop.hdfs.server.datanode</A> 中的 类<DD>Data storage information file.<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/DataStorage.html#DataStorage(org.apache.hadoop.hdfs.server.common.StorageInfo, java.lang.String)"><B>DataStorage(StorageInfo, String)</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/DataStorage.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">DataStorage</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的接口"><B>DataTransferProtocol</B></A> - <A HREF="./org/apache/hadoop/hdfs/protocol/package-summary.html">org.apache.hadoop.hdfs.protocol</A> 中的 接口<DD>Transfer data to/from datanode using a streaming protocol.<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.BlockConstructionStage.html" title="org.apache.hadoop.hdfs.protocol 中的枚举"><B>DataTransferProtocol.BlockConstructionStage</B></A> - <A HREF="./org/apache/hadoop/hdfs/protocol/package-summary.html">org.apache.hadoop.hdfs.protocol</A> 中的 枚举<DD>&nbsp;<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.Op.html" title="org.apache.hadoop.hdfs.protocol 中的枚举"><B>DataTransferProtocol.Op</B></A> - <A HREF="./org/apache/hadoop/hdfs/protocol/package-summary.html">org.apache.hadoop.hdfs.protocol</A> 中的 枚举<DD>Operation<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.PacketHeader.html" title="org.apache.hadoop.hdfs.protocol 中的类"><B>DataTransferProtocol.PacketHeader</B></A> - <A HREF="./org/apache/hadoop/hdfs/protocol/package-summary.html">org.apache.hadoop.hdfs.protocol</A> 中的 类<DD>Header data for each packet that goes through the read/write pipelines.<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.PacketHeader.html#DataTransferProtocol.PacketHeader()"><B>DataTransferProtocol.PacketHeader()</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.PacketHeader.html" title="org.apache.hadoop.hdfs.protocol 中的类">DataTransferProtocol.PacketHeader</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.PacketHeader.html#DataTransferProtocol.PacketHeader(int, long, long, boolean, int)"><B>DataTransferProtocol.PacketHeader(int, long, long, boolean, int)</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.PacketHeader.html" title="org.apache.hadoop.hdfs.protocol 中的类">DataTransferProtocol.PacketHeader</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.PipelineAck.html" title="org.apache.hadoop.hdfs.protocol 中的类"><B>DataTransferProtocol.PipelineAck</B></A> - <A HREF="./org/apache/hadoop/hdfs/protocol/package-summary.html">org.apache.hadoop.hdfs.protocol</A> 中的 类<DD>reply<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.PipelineAck.html#DataTransferProtocol.PipelineAck()"><B>DataTransferProtocol.PipelineAck()</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.PipelineAck.html" title="org.apache.hadoop.hdfs.protocol 中的类">DataTransferProtocol.PipelineAck</A> 的构造方法
<DD>default constructor
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.PipelineAck.html#DataTransferProtocol.PipelineAck(long, org.apache.hadoop.hdfs.protocol.DataTransferProtocol.Status[])"><B>DataTransferProtocol.PipelineAck(long, DataTransferProtocol.Status[])</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.PipelineAck.html" title="org.apache.hadoop.hdfs.protocol 中的类">DataTransferProtocol.PipelineAck</A> 的构造方法
<DD>Constructor
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.Receiver.html" title="org.apache.hadoop.hdfs.protocol 中的类"><B>DataTransferProtocol.Receiver</B></A> - <A HREF="./org/apache/hadoop/hdfs/protocol/package-summary.html">org.apache.hadoop.hdfs.protocol</A> 中的 类<DD>Receiver<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.Receiver.html#DataTransferProtocol.Receiver()"><B>DataTransferProtocol.Receiver()</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.Receiver.html" title="org.apache.hadoop.hdfs.protocol 中的类">DataTransferProtocol.Receiver</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.Sender.html" title="org.apache.hadoop.hdfs.protocol 中的类"><B>DataTransferProtocol.Sender</B></A> - <A HREF="./org/apache/hadoop/hdfs/protocol/package-summary.html">org.apache.hadoop.hdfs.protocol</A> 中的 类<DD>Sender<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.Sender.html#DataTransferProtocol.Sender()"><B>DataTransferProtocol.Sender()</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.Sender.html" title="org.apache.hadoop.hdfs.protocol 中的类">DataTransferProtocol.Sender</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.Status.html" title="org.apache.hadoop.hdfs.protocol 中的枚举"><B>DataTransferProtocol.Status</B></A> - <A HREF="./org/apache/hadoop/hdfs/protocol/package-summary.html">org.apache.hadoop.hdfs.protocol</A> 中的 枚举<DD>Status<DT><A HREF="./org/apache/hadoop/hdfs/util/DataTransferThrottler.html" title="org.apache.hadoop.hdfs.util 中的类"><B>DataTransferThrottler</B></A> - <A HREF="./org/apache/hadoop/hdfs/util/package-summary.html">org.apache.hadoop.hdfs.util</A> 中的 类<DD>a class to throttle the data transfers.<DT><A HREF="./org/apache/hadoop/hdfs/util/DataTransferThrottler.html#DataTransferThrottler(long)"><B>DataTransferThrottler(long)</B></A> - 
类 org.apache.hadoop.hdfs.util.<A HREF="./org/apache/hadoop/hdfs/util/DataTransferThrottler.html" title="org.apache.hadoop.hdfs.util 中的类">DataTransferThrottler</A> 的构造方法
<DD>Constructor
<DT><A HREF="./org/apache/hadoop/hdfs/util/DataTransferThrottler.html#DataTransferThrottler(long, long)"><B>DataTransferThrottler(long, long)</B></A> - 
类 org.apache.hadoop.hdfs.util.<A HREF="./org/apache/hadoop/hdfs/util/DataTransferThrottler.html" title="org.apache.hadoop.hdfs.util 中的类">DataTransferThrottler</A> 的构造方法
<DD>Constructor
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/CodingMatrix.html#decoder(short[][], byte[][], int[], int, byte[])"><B>decoder(short[][], byte[][], int[], int, byte[])</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/CodingMatrix.html" title="org.apache.hadoop.hdfs.protocol 中的类">CodingMatrix</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/RegeneratingCodeMatrix.html#decoder(short[][], byte[][], int[], int, byte[])"><B>decoder(short[][], byte[][], int[], int, byte[])</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/RegeneratingCodeMatrix.html" title="org.apache.hadoop.hdfs.protocol 中的类">RegeneratingCodeMatrix</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/RSCoderProtocol.html#decoder(short[][], byte[][], int[], int, byte[])"><B>decoder(short[][], byte[][], int[], int, byte[])</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/RSCoderProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的类">RSCoderProtocol</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/XORCoderProtocol.html#decoder(short[][], byte[][], int[], int, byte[])"><B>decoder(short[][], byte[][], int[], int, byte[])</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/XORCoderProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的类">XORCoderProtocol</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/FSConstants.html#DEFAULT_BLOCK_SIZE"><B>DEFAULT_BLOCK_SIZE</B></A> - 
接口 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/FSConstants.html" title="org.apache.hadoop.hdfs.protocol 中的接口">FSConstants</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/FSConstants.html#DEFAULT_BYTES_PER_CHECKSUM"><B>DEFAULT_BYTES_PER_CHECKSUM</B></A> - 
接口 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/FSConstants.html" title="org.apache.hadoop.hdfs.protocol 中的接口">FSConstants</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/FSConstants.html#DEFAULT_DATA_SOCKET_SIZE"><B>DEFAULT_DATA_SOCKET_SIZE</B></A> - 
接口 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/FSConstants.html" title="org.apache.hadoop.hdfs.protocol 中的接口">FSConstants</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/FSConstants.html#DEFAULT_FILE_BUFFER_SIZE"><B>DEFAULT_FILE_BUFFER_SIZE</B></A> - 
接口 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/FSConstants.html" title="org.apache.hadoop.hdfs.protocol 中的接口">FSConstants</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/BlockManager.html#DEFAULT_INITIAL_MAP_CAPACITY"><B>DEFAULT_INITIAL_MAP_CAPACITY</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/BlockManager.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">BlockManager</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/BlockManager.html#DEFAULT_MAP_LOAD_FACTOR"><B>DEFAULT_MAP_LOAD_FACTOR</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/BlockManager.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">BlockManager</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/BlockManager.html#DEFAULT_MAX_CORRUPT_FILES_RETURNED"><B>DEFAULT_MAX_CORRUPT_FILES_RETURNED</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/BlockManager.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">BlockManager</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html#DEFAULT_PORT"><B>DEFAULT_PORT</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">NameNode</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/FSConstants.html#DEFAULT_REPLICATION_FACTOR"><B>DEFAULT_REPLICATION_FACTOR</B></A> - 
接口 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/FSConstants.html" title="org.apache.hadoop.hdfs.protocol 中的接口">FSConstants</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/FSConstants.html#DEFAULT_WRITE_PACKET_SIZE"><B>DEFAULT_WRITE_PACKET_SIZE</B></A> - 
接口 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/FSConstants.html" title="org.apache.hadoop.hdfs.protocol 中的接口">FSConstants</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/JspHelper.html#DELEGATION_PARAMETER_NAME"><B>DELEGATION_PARAMETER_NAME</B></A> - 
类 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/JspHelper.html" title="org.apache.hadoop.hdfs.server.common 中的类">JspHelper</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/tools/DelegationTokenFetcher.html" title="org.apache.hadoop.hdfs.tools 中的类"><B>DelegationTokenFetcher</B></A> - <A HREF="./org/apache/hadoop/hdfs/tools/package-summary.html">org.apache.hadoop.hdfs.tools</A> 中的 类<DD>Fetch a DelegationToken from the current Namenode and store it in the
 specified file.<DT><A HREF="./org/apache/hadoop/hdfs/tools/DelegationTokenFetcher.html#DelegationTokenFetcher()"><B>DelegationTokenFetcher()</B></A> - 
类 org.apache.hadoop.hdfs.tools.<A HREF="./org/apache/hadoop/hdfs/tools/DelegationTokenFetcher.html" title="org.apache.hadoop.hdfs.tools 中的类">DelegationTokenFetcher</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/security/token/delegation/DelegationTokenIdentifier.html" title="org.apache.hadoop.hdfs.security.token.delegation 中的类"><B>DelegationTokenIdentifier</B></A> - <A HREF="./org/apache/hadoop/hdfs/security/token/delegation/package-summary.html">org.apache.hadoop.hdfs.security.token.delegation</A> 中的 类<DD>A delegation token identifier that is specific to HDFS.<DT><A HREF="./org/apache/hadoop/hdfs/security/token/delegation/DelegationTokenIdentifier.html#DelegationTokenIdentifier()"><B>DelegationTokenIdentifier()</B></A> - 
类 org.apache.hadoop.hdfs.security.token.delegation.<A HREF="./org/apache/hadoop/hdfs/security/token/delegation/DelegationTokenIdentifier.html" title="org.apache.hadoop.hdfs.security.token.delegation 中的类">DelegationTokenIdentifier</A> 的构造方法
<DD>Create an empty delegation token identifier for reading into.
<DT><A HREF="./org/apache/hadoop/hdfs/security/token/delegation/DelegationTokenIdentifier.html#DelegationTokenIdentifier(org.apache.hadoop.io.Text, org.apache.hadoop.io.Text, org.apache.hadoop.io.Text)"><B>DelegationTokenIdentifier(Text, Text, Text)</B></A> - 
类 org.apache.hadoop.hdfs.security.token.delegation.<A HREF="./org/apache/hadoop/hdfs/security/token/delegation/DelegationTokenIdentifier.html" title="org.apache.hadoop.hdfs.security.token.delegation 中的类">DelegationTokenIdentifier</A> 的构造方法
<DD>Create a new delegation token identifier
<DT><A HREF="./org/apache/hadoop/hdfs/security/token/delegation/DelegationTokenSecretManager.html" title="org.apache.hadoop.hdfs.security.token.delegation 中的类"><B>DelegationTokenSecretManager</B></A> - <A HREF="./org/apache/hadoop/hdfs/security/token/delegation/package-summary.html">org.apache.hadoop.hdfs.security.token.delegation</A> 中的 类<DD>A HDFS specific delegation token secret manager.<DT><A HREF="./org/apache/hadoop/hdfs/security/token/delegation/DelegationTokenSecretManager.html#DelegationTokenSecretManager(long, long, long, long, org.apache.hadoop.hdfs.server.namenode.FSNamesystem)"><B>DelegationTokenSecretManager(long, long, long, long, FSNamesystem)</B></A> - 
类 org.apache.hadoop.hdfs.security.token.delegation.<A HREF="./org/apache/hadoop/hdfs/security/token/delegation/DelegationTokenSecretManager.html" title="org.apache.hadoop.hdfs.security.token.delegation 中的类">DelegationTokenSecretManager</A> 的构造方法
<DD>Create a secret manager
<DT><A HREF="./org/apache/hadoop/hdfs/security/token/delegation/DelegationTokenSelector.html" title="org.apache.hadoop.hdfs.security.token.delegation 中的类"><B>DelegationTokenSelector</B></A> - <A HREF="./org/apache/hadoop/hdfs/security/token/delegation/package-summary.html">org.apache.hadoop.hdfs.security.token.delegation</A> 中的 类<DD>A delegation token that is specialized for HDFS<DT><A HREF="./org/apache/hadoop/hdfs/security/token/delegation/DelegationTokenSelector.html#DelegationTokenSelector()"><B>DelegationTokenSelector()</B></A> - 
类 org.apache.hadoop.hdfs.security.token.delegation.<A HREF="./org/apache/hadoop/hdfs/security/token/delegation/DelegationTokenSelector.html" title="org.apache.hadoop.hdfs.security.token.delegation 中的类">DelegationTokenSelector</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/fs/Hdfs.html#delete(org.apache.hadoop.fs.Path, boolean)"><B>delete(Path, boolean)</B></A> - 
类 org.apache.hadoop.fs.<A HREF="./org/apache/hadoop/fs/Hdfs.html" title="org.apache.hadoop.fs 中的类">Hdfs</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSClient.html#delete(java.lang.String)"><B>delete(String)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSClient.html" title="org.apache.hadoop.hdfs 中的类">DFSClient</A> 中的方法
<DD><B>已过时。</B>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSClient.html#delete(java.lang.String, boolean)"><B>delete(String, boolean)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSClient.html" title="org.apache.hadoop.hdfs 中的类">DFSClient</A> 中的方法
<DD>delete file or directory.
<DT><A HREF="./org/apache/hadoop/hdfs/DistributedFileSystem.html#delete(org.apache.hadoop.fs.Path, boolean)"><B>delete(Path, boolean)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DistributedFileSystem.html" title="org.apache.hadoop.hdfs 中的类">DistributedFileSystem</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/HftpFileSystem.html#delete(org.apache.hadoop.fs.Path, boolean)"><B>delete(Path, boolean)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/HftpFileSystem.html" title="org.apache.hadoop.hdfs 中的类">HftpFileSystem</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/ClientProtocol.html#delete(java.lang.String)"><B>delete(String)</B></A> - 
接口 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/ClientProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的接口">ClientProtocol</A> 中的方法
<DD><B>已过时。</B>&nbsp;<I>use <A HREF="./org/apache/hadoop/hdfs/protocol/ClientProtocol.html#delete(java.lang.String, boolean)"><CODE>ClientProtocol.delete(String, boolean)</CODE></A> istead.</I>
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/ClientProtocol.html#delete(java.lang.String, boolean)"><B>delete(String, boolean)</B></A> - 
接口 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/ClientProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的接口">ClientProtocol</A> 中的方法
<DD>Delete the given file or directory from the file system.
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#delete(java.lang.String, boolean)"><B>delete(String, boolean)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FSNamesystem</A> 中的方法
<DD>Remove the indicated file from namespace.
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html#delete(java.lang.String)"><B>delete(String)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">NameNode</A> 中的方法
<DD><B>已过时。</B>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html#delete(java.lang.String, boolean)"><B>delete(String, boolean)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">NameNode</A> 中的方法
<DD>Delete the given file or directory from the file system.
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/Storage.html#deleteDir(java.io.File)"><B>deleteDir(File)</B></A> - 
类 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/Storage.html" title="org.apache.hadoop.hdfs.server.common 中的类">Storage</A> 中的静态方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DeprecatedUTF8.html" title="org.apache.hadoop.hdfs 中的类"><B>DeprecatedUTF8</B></A> - <A HREF="./org/apache/hadoop/hdfs/package-summary.html">org.apache.hadoop.hdfs</A> 中的 类<DD>A simple wrapper around <CODE>UTF8</CODE>.<DT><A HREF="./org/apache/hadoop/hdfs/DeprecatedUTF8.html#DeprecatedUTF8()"><B>DeprecatedUTF8()</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DeprecatedUTF8.html" title="org.apache.hadoop.hdfs 中的类">DeprecatedUTF8</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DeprecatedUTF8.html#DeprecatedUTF8(java.lang.String)"><B>DeprecatedUTF8(String)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DeprecatedUTF8.html" title="org.apache.hadoop.hdfs 中的类">DeprecatedUTF8</A> 的构造方法
<DD>Construct from a given string.
<DT><A HREF="./org/apache/hadoop/hdfs/DeprecatedUTF8.html#DeprecatedUTF8(org.apache.hadoop.hdfs.DeprecatedUTF8)"><B>DeprecatedUTF8(DeprecatedUTF8)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DeprecatedUTF8.html" title="org.apache.hadoop.hdfs 中的类">DeprecatedUTF8</A> 的构造方法
<DD>Construct from a given string.
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/SecureDataNodeStarter.html#destroy()"><B>destroy()</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/SecureDataNodeStarter.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">SecureDataNodeStarter</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/HftpFileSystem.html#df"><B>df</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/HftpFileSystem.html" title="org.apache.hadoop.hdfs 中的类">HftpFileSystem</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/ListPathsServlet.html#df"><B>df</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/ListPathsServlet.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">ListPathsServlet</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_ADMIN"><B>DFS_ADMIN</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_BALANCER_MOVEDWINWIDTH_DEFAULT"><B>DFS_BALANCER_MOVEDWINWIDTH_DEFAULT</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_BALANCER_MOVEDWINWIDTH_KEY"><B>DFS_BALANCER_MOVEDWINWIDTH_KEY</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_BLOCK_ACCESS_KEY_UPDATE_INTERVAL_DEFAULT"><B>DFS_BLOCK_ACCESS_KEY_UPDATE_INTERVAL_DEFAULT</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_BLOCK_ACCESS_KEY_UPDATE_INTERVAL_KEY"><B>DFS_BLOCK_ACCESS_KEY_UPDATE_INTERVAL_KEY</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_BLOCK_ACCESS_TOKEN_ENABLE_DEFAULT"><B>DFS_BLOCK_ACCESS_TOKEN_ENABLE_DEFAULT</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_BLOCK_ACCESS_TOKEN_ENABLE_KEY"><B>DFS_BLOCK_ACCESS_TOKEN_ENABLE_KEY</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_BLOCK_ACCESS_TOKEN_LIFETIME_DEFAULT"><B>DFS_BLOCK_ACCESS_TOKEN_LIFETIME_DEFAULT</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_BLOCK_ACCESS_TOKEN_LIFETIME_KEY"><B>DFS_BLOCK_ACCESS_TOKEN_LIFETIME_KEY</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_BLOCK_SIZE_DEFAULT"><B>DFS_BLOCK_SIZE_DEFAULT</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_BLOCK_SIZE_KEY"><B>DFS_BLOCK_SIZE_KEY</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_BLOCKREPORT_INITIAL_DELAY_DEFAULT"><B>DFS_BLOCKREPORT_INITIAL_DELAY_DEFAULT</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_BLOCKREPORT_INITIAL_DELAY_KEY"><B>DFS_BLOCKREPORT_INITIAL_DELAY_KEY</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_BLOCKREPORT_INTERVAL_MSEC_DEFAULT"><B>DFS_BLOCKREPORT_INTERVAL_MSEC_DEFAULT</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_BLOCKREPORT_INTERVAL_MSEC_KEY"><B>DFS_BLOCKREPORT_INTERVAL_MSEC_KEY</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_BYTES_PER_CHECKSUM_DEFAULT"><B>DFS_BYTES_PER_CHECKSUM_DEFAULT</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_BYTES_PER_CHECKSUM_KEY"><B>DFS_BYTES_PER_CHECKSUM_KEY</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_CLIENT_BLOCK_WRITE_LOCATEFOLLOWINGBLOCK_RETRIES_DEFAULT"><B>DFS_CLIENT_BLOCK_WRITE_LOCATEFOLLOWINGBLOCK_RETRIES_DEFAULT</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_CLIENT_BLOCK_WRITE_LOCATEFOLLOWINGBLOCK_RETRIES_KEY"><B>DFS_CLIENT_BLOCK_WRITE_LOCATEFOLLOWINGBLOCK_RETRIES_KEY</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_CLIENT_BLOCK_WRITE_RETRIES_DEFAULT"><B>DFS_CLIENT_BLOCK_WRITE_RETRIES_DEFAULT</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_CLIENT_BLOCK_WRITE_RETRIES_KEY"><B>DFS_CLIENT_BLOCK_WRITE_RETRIES_KEY</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_CLIENT_CACHED_CONN_RETRY_DEFAULT"><B>DFS_CLIENT_CACHED_CONN_RETRY_DEFAULT</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_CLIENT_CACHED_CONN_RETRY_KEY"><B>DFS_CLIENT_CACHED_CONN_RETRY_KEY</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_CLIENT_HTTPS_KEYSTORE_RESOURCE_DEFAULT"><B>DFS_CLIENT_HTTPS_KEYSTORE_RESOURCE_DEFAULT</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_CLIENT_HTTPS_KEYSTORE_RESOURCE_KEY"><B>DFS_CLIENT_HTTPS_KEYSTORE_RESOURCE_KEY</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_CLIENT_HTTPS_NEED_AUTH_DEFAULT"><B>DFS_CLIENT_HTTPS_NEED_AUTH_DEFAULT</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_CLIENT_HTTPS_NEED_AUTH_KEY"><B>DFS_CLIENT_HTTPS_NEED_AUTH_KEY</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_CLIENT_MAX_BLOCK_ACQUIRE_FAILURES_DEFAULT"><B>DFS_CLIENT_MAX_BLOCK_ACQUIRE_FAILURES_DEFAULT</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_CLIENT_MAX_BLOCK_ACQUIRE_FAILURES_KEY"><B>DFS_CLIENT_MAX_BLOCK_ACQUIRE_FAILURES_KEY</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_CLIENT_READ_PREFETCH_SIZE_KEY"><B>DFS_CLIENT_READ_PREFETCH_SIZE_KEY</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_CLIENT_RETRY_WINDOW_BASE"><B>DFS_CLIENT_RETRY_WINDOW_BASE</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_CLIENT_SOCKET_CACHE_CAPACITY_DEFAULT"><B>DFS_CLIENT_SOCKET_CACHE_CAPACITY_DEFAULT</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_CLIENT_SOCKET_CACHE_CAPACITY_KEY"><B>DFS_CLIENT_SOCKET_CACHE_CAPACITY_KEY</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_CLIENT_SOCKET_TIMEOUT_KEY"><B>DFS_CLIENT_SOCKET_TIMEOUT_KEY</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_CLIENT_WRITE_PACKET_SIZE_DEFAULT"><B>DFS_CLIENT_WRITE_PACKET_SIZE_DEFAULT</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_CLIENT_WRITE_PACKET_SIZE_KEY"><B>DFS_CLIENT_WRITE_PACKET_SIZE_KEY</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_DATANODE_ADDRESS_DEFAULT"><B>DFS_DATANODE_ADDRESS_DEFAULT</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_DATANODE_ADDRESS_KEY"><B>DFS_DATANODE_ADDRESS_KEY</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_DATANODE_BALANCE_BANDWIDTHPERSEC_DEFAULT"><B>DFS_DATANODE_BALANCE_BANDWIDTHPERSEC_DEFAULT</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_DATANODE_BALANCE_BANDWIDTHPERSEC_KEY"><B>DFS_DATANODE_BALANCE_BANDWIDTHPERSEC_KEY</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_DATANODE_DATA_DIR_KEY"><B>DFS_DATANODE_DATA_DIR_KEY</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_DATANODE_DATA_DIR_PERMISSION_DEFAULT"><B>DFS_DATANODE_DATA_DIR_PERMISSION_DEFAULT</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_DATANODE_DATA_DIR_PERMISSION_KEY"><B>DFS_DATANODE_DATA_DIR_PERMISSION_KEY</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_DATANODE_DIRECTORYSCAN_INTERVAL_DEFAULT"><B>DFS_DATANODE_DIRECTORYSCAN_INTERVAL_DEFAULT</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_DATANODE_DIRECTORYSCAN_INTERVAL_KEY"><B>DFS_DATANODE_DIRECTORYSCAN_INTERVAL_KEY</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_DATANODE_DIRECTORYSCAN_THREADS_DEFAULT"><B>DFS_DATANODE_DIRECTORYSCAN_THREADS_DEFAULT</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_DATANODE_DIRECTORYSCAN_THREADS_KEY"><B>DFS_DATANODE_DIRECTORYSCAN_THREADS_KEY</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_DATANODE_DNS_INTERFACE_DEFAULT"><B>DFS_DATANODE_DNS_INTERFACE_DEFAULT</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_DATANODE_DNS_INTERFACE_KEY"><B>DFS_DATANODE_DNS_INTERFACE_KEY</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_DATANODE_DNS_NAMESERVER_DEFAULT"><B>DFS_DATANODE_DNS_NAMESERVER_DEFAULT</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_DATANODE_DNS_NAMESERVER_KEY"><B>DFS_DATANODE_DNS_NAMESERVER_KEY</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_DATANODE_DU_RESERVED_DEFAULT"><B>DFS_DATANODE_DU_RESERVED_DEFAULT</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_DATANODE_DU_RESERVED_KEY"><B>DFS_DATANODE_DU_RESERVED_KEY</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_DATANODE_FAILED_VOLUMES_TOLERATED_DEFAULT"><B>DFS_DATANODE_FAILED_VOLUMES_TOLERATED_DEFAULT</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_DATANODE_FAILED_VOLUMES_TOLERATED_KEY"><B>DFS_DATANODE_FAILED_VOLUMES_TOLERATED_KEY</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_DATANODE_HANDLER_COUNT_DEFAULT"><B>DFS_DATANODE_HANDLER_COUNT_DEFAULT</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_DATANODE_HANDLER_COUNT_KEY"><B>DFS_DATANODE_HANDLER_COUNT_KEY</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_DATANODE_HOST_NAME_KEY"><B>DFS_DATANODE_HOST_NAME_KEY</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_DATANODE_HTTP_ADDRESS_DEFAULT"><B>DFS_DATANODE_HTTP_ADDRESS_DEFAULT</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_DATANODE_HTTP_ADDRESS_KEY"><B>DFS_DATANODE_HTTP_ADDRESS_KEY</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_DATANODE_HTTPS_ADDRESS_DEFAULT"><B>DFS_DATANODE_HTTPS_ADDRESS_DEFAULT</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_DATANODE_HTTPS_ADDRESS_KEY"><B>DFS_DATANODE_HTTPS_ADDRESS_KEY</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_DATANODE_IPC_ADDRESS_DEFAULT"><B>DFS_DATANODE_IPC_ADDRESS_DEFAULT</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_DATANODE_IPC_ADDRESS_KEY"><B>DFS_DATANODE_IPC_ADDRESS_KEY</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_DATANODE_KEYTAB_FILE_KEY"><B>DFS_DATANODE_KEYTAB_FILE_KEY</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_DATANODE_MAX_RECEIVER_THREADS_DEFAULT"><B>DFS_DATANODE_MAX_RECEIVER_THREADS_DEFAULT</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_DATANODE_MAX_RECEIVER_THREADS_KEY"><B>DFS_DATANODE_MAX_RECEIVER_THREADS_KEY</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_DATANODE_NUMBLOCKS_DEFAULT"><B>DFS_DATANODE_NUMBLOCKS_DEFAULT</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_DATANODE_NUMBLOCKS_KEY"><B>DFS_DATANODE_NUMBLOCKS_KEY</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_DATANODE_PLUGINS_KEY"><B>DFS_DATANODE_PLUGINS_KEY</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_DATANODE_SCAN_PERIOD_HOURS_DEFAULT"><B>DFS_DATANODE_SCAN_PERIOD_HOURS_DEFAULT</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_DATANODE_SCAN_PERIOD_HOURS_KEY"><B>DFS_DATANODE_SCAN_PERIOD_HOURS_KEY</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_DATANODE_SIMULATEDDATASTORAGE_CAPACITY_DEFAULT"><B>DFS_DATANODE_SIMULATEDDATASTORAGE_CAPACITY_DEFAULT</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_DATANODE_SIMULATEDDATASTORAGE_CAPACITY_KEY"><B>DFS_DATANODE_SIMULATEDDATASTORAGE_CAPACITY_KEY</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_DATANODE_SIMULATEDDATASTORAGE_DEFAULT"><B>DFS_DATANODE_SIMULATEDDATASTORAGE_DEFAULT</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_DATANODE_SIMULATEDDATASTORAGE_KEY"><B>DFS_DATANODE_SIMULATEDDATASTORAGE_KEY</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_DATANODE_SOCKET_REUSE_KEEPALIVE_DEFAULT"><B>DFS_DATANODE_SOCKET_REUSE_KEEPALIVE_DEFAULT</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_DATANODE_SOCKET_REUSE_KEEPALIVE_KEY"><B>DFS_DATANODE_SOCKET_REUSE_KEEPALIVE_KEY</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_DATANODE_SOCKET_WRITE_TIMEOUT_KEY"><B>DFS_DATANODE_SOCKET_WRITE_TIMEOUT_KEY</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_DATANODE_STARTUP_KEY"><B>DFS_DATANODE_STARTUP_KEY</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_DATANODE_STORAGEID_KEY"><B>DFS_DATANODE_STORAGEID_KEY</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_DATANODE_TRANSFERTO_ALLOWED_DEFAULT"><B>DFS_DATANODE_TRANSFERTO_ALLOWED_DEFAULT</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_DATANODE_TRANSFERTO_ALLOWED_KEY"><B>DFS_DATANODE_TRANSFERTO_ALLOWED_KEY</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_DATANODE_USER_NAME_KEY"><B>DFS_DATANODE_USER_NAME_KEY</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_DEFAULT_CHUNK_VIEW_SIZE_DEFAULT"><B>DFS_DEFAULT_CHUNK_VIEW_SIZE_DEFAULT</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_DEFAULT_CHUNK_VIEW_SIZE_KEY"><B>DFS_DEFAULT_CHUNK_VIEW_SIZE_KEY</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_DF_INTERVAL_DEFAULT"><B>DFS_DF_INTERVAL_DEFAULT</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_DF_INTERVAL_KEY"><B>DFS_DF_INTERVAL_KEY</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_HEARTBEAT_INTERVAL_DEFAULT"><B>DFS_HEARTBEAT_INTERVAL_DEFAULT</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_HEARTBEAT_INTERVAL_KEY"><B>DFS_HEARTBEAT_INTERVAL_KEY</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_HTTPS_ENABLE_DEFAULT"><B>DFS_HTTPS_ENABLE_DEFAULT</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_HTTPS_ENABLE_KEY"><B>DFS_HTTPS_ENABLE_KEY</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_IMAGE_COMPRESS_DEFAULT"><B>DFS_IMAGE_COMPRESS_DEFAULT</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_IMAGE_COMPRESS_KEY"><B>DFS_IMAGE_COMPRESS_KEY</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_IMAGE_COMPRESSION_CODEC_DEFAULT"><B>DFS_IMAGE_COMPRESSION_CODEC_DEFAULT</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_IMAGE_COMPRESSION_CODEC_KEY"><B>DFS_IMAGE_COMPRESSION_CODEC_KEY</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_IMAGE_TRANSFER_RATE_DEFAULT"><B>DFS_IMAGE_TRANSFER_RATE_DEFAULT</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_IMAGE_TRANSFER_RATE_KEY"><B>DFS_IMAGE_TRANSFER_RATE_KEY</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_LIST_LIMIT"><B>DFS_LIST_LIMIT</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_LIST_LIMIT_DEFAULT"><B>DFS_LIST_LIMIT_DEFAULT</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_METRICS_SESSION_ID_KEY"><B>DFS_METRICS_SESSION_ID_KEY</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_NAMENODE_ACCESSTIME_PRECISION_DEFAULT"><B>DFS_NAMENODE_ACCESSTIME_PRECISION_DEFAULT</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_NAMENODE_ACCESSTIME_PRECISION_KEY"><B>DFS_NAMENODE_ACCESSTIME_PRECISION_KEY</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_NAMENODE_BACKUP_ADDRESS_DEFAULT"><B>DFS_NAMENODE_BACKUP_ADDRESS_DEFAULT</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_NAMENODE_BACKUP_ADDRESS_KEY"><B>DFS_NAMENODE_BACKUP_ADDRESS_KEY</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_NAMENODE_BACKUP_HTTP_ADDRESS_DEFAULT"><B>DFS_NAMENODE_BACKUP_HTTP_ADDRESS_DEFAULT</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_NAMENODE_BACKUP_HTTP_ADDRESS_KEY"><B>DFS_NAMENODE_BACKUP_HTTP_ADDRESS_KEY</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_NAMENODE_BACKUP_SERVICE_RPC_ADDRESS_KEY"><B>DFS_NAMENODE_BACKUP_SERVICE_RPC_ADDRESS_KEY</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_NAMENODE_CHECKPOINT_DIR_KEY"><B>DFS_NAMENODE_CHECKPOINT_DIR_KEY</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_NAMENODE_CHECKPOINT_EDITS_DIR_KEY"><B>DFS_NAMENODE_CHECKPOINT_EDITS_DIR_KEY</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_NAMENODE_CHECKPOINT_PERIOD_DEFAULT"><B>DFS_NAMENODE_CHECKPOINT_PERIOD_DEFAULT</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_NAMENODE_CHECKPOINT_PERIOD_KEY"><B>DFS_NAMENODE_CHECKPOINT_PERIOD_KEY</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_NAMENODE_CHECKPOINT_SIZE_DEFAULT"><B>DFS_NAMENODE_CHECKPOINT_SIZE_DEFAULT</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_NAMENODE_CHECKPOINT_SIZE_KEY"><B>DFS_NAMENODE_CHECKPOINT_SIZE_KEY</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_NAMENODE_DECOMMISSION_INTERVAL_DEFAULT"><B>DFS_NAMENODE_DECOMMISSION_INTERVAL_DEFAULT</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_NAMENODE_DECOMMISSION_INTERVAL_KEY"><B>DFS_NAMENODE_DECOMMISSION_INTERVAL_KEY</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_NAMENODE_DECOMMISSION_NODES_PER_INTERVAL_DEFAULT"><B>DFS_NAMENODE_DECOMMISSION_NODES_PER_INTERVAL_DEFAULT</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_NAMENODE_DECOMMISSION_NODES_PER_INTERVAL_KEY"><B>DFS_NAMENODE_DECOMMISSION_NODES_PER_INTERVAL_KEY</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_NAMENODE_DELEGATION_KEY_UPDATE_INTERVAL_DEFAULT"><B>DFS_NAMENODE_DELEGATION_KEY_UPDATE_INTERVAL_DEFAULT</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_NAMENODE_DELEGATION_KEY_UPDATE_INTERVAL_KEY"><B>DFS_NAMENODE_DELEGATION_KEY_UPDATE_INTERVAL_KEY</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_NAMENODE_DELEGATION_TOKEN_MAX_LIFETIME_DEFAULT"><B>DFS_NAMENODE_DELEGATION_TOKEN_MAX_LIFETIME_DEFAULT</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_NAMENODE_DELEGATION_TOKEN_MAX_LIFETIME_KEY"><B>DFS_NAMENODE_DELEGATION_TOKEN_MAX_LIFETIME_KEY</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_NAMENODE_DELEGATION_TOKEN_RENEW_INTERVAL_DEFAULT"><B>DFS_NAMENODE_DELEGATION_TOKEN_RENEW_INTERVAL_DEFAULT</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_NAMENODE_DELEGATION_TOKEN_RENEW_INTERVAL_KEY"><B>DFS_NAMENODE_DELEGATION_TOKEN_RENEW_INTERVAL_KEY</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_NAMENODE_EDITS_DIR_KEY"><B>DFS_NAMENODE_EDITS_DIR_KEY</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_NAMENODE_HANDLER_COUNT_DEFAULT"><B>DFS_NAMENODE_HANDLER_COUNT_DEFAULT</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_NAMENODE_HANDLER_COUNT_KEY"><B>DFS_NAMENODE_HANDLER_COUNT_KEY</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_NAMENODE_HEARTBEAT_RECHECK_INTERVAL_DEFAULT"><B>DFS_NAMENODE_HEARTBEAT_RECHECK_INTERVAL_DEFAULT</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_NAMENODE_HEARTBEAT_RECHECK_INTERVAL_KEY"><B>DFS_NAMENODE_HEARTBEAT_RECHECK_INTERVAL_KEY</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_NAMENODE_HOSTS_EXCLUDE_KEY"><B>DFS_NAMENODE_HOSTS_EXCLUDE_KEY</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_NAMENODE_HOSTS_KEY"><B>DFS_NAMENODE_HOSTS_KEY</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_NAMENODE_HTTP_ADDRESS_DEFAULT"><B>DFS_NAMENODE_HTTP_ADDRESS_DEFAULT</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_NAMENODE_HTTP_ADDRESS_KEY"><B>DFS_NAMENODE_HTTP_ADDRESS_KEY</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_NAMENODE_HTTPS_ADDRESS_DEFAULT"><B>DFS_NAMENODE_HTTPS_ADDRESS_DEFAULT</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_NAMENODE_HTTPS_ADDRESS_KEY"><B>DFS_NAMENODE_HTTPS_ADDRESS_KEY</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_NAMENODE_KEYTAB_FILE_KEY"><B>DFS_NAMENODE_KEYTAB_FILE_KEY</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_NAMENODE_KRB_HTTPS_USER_NAME_KEY"><B>DFS_NAMENODE_KRB_HTTPS_USER_NAME_KEY</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_NAMENODE_MAX_OBJECTS_DEFAULT"><B>DFS_NAMENODE_MAX_OBJECTS_DEFAULT</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_NAMENODE_MAX_OBJECTS_KEY"><B>DFS_NAMENODE_MAX_OBJECTS_KEY</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_NAMENODE_NAME_CACHE_THRESHOLD_DEFAULT"><B>DFS_NAMENODE_NAME_CACHE_THRESHOLD_DEFAULT</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_NAMENODE_NAME_CACHE_THRESHOLD_KEY"><B>DFS_NAMENODE_NAME_CACHE_THRESHOLD_KEY</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_NAMENODE_NAME_DIR_KEY"><B>DFS_NAMENODE_NAME_DIR_KEY</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_NAMENODE_NAME_DIR_RESTORE_DEFAULT"><B>DFS_NAMENODE_NAME_DIR_RESTORE_DEFAULT</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_NAMENODE_NAME_DIR_RESTORE_KEY"><B>DFS_NAMENODE_NAME_DIR_RESTORE_KEY</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_NAMENODE_PLUGINS_KEY"><B>DFS_NAMENODE_PLUGINS_KEY</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_NAMENODE_REPLICATION_CONSIDERLOAD_DEFAULT"><B>DFS_NAMENODE_REPLICATION_CONSIDERLOAD_DEFAULT</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_NAMENODE_REPLICATION_CONSIDERLOAD_KEY"><B>DFS_NAMENODE_REPLICATION_CONSIDERLOAD_KEY</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_NAMENODE_REPLICATION_INTERVAL_DEFAULT"><B>DFS_NAMENODE_REPLICATION_INTERVAL_DEFAULT</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_NAMENODE_REPLICATION_INTERVAL_KEY"><B>DFS_NAMENODE_REPLICATION_INTERVAL_KEY</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_NAMENODE_REPLICATION_MAX_STREAMS_DEFAULT"><B>DFS_NAMENODE_REPLICATION_MAX_STREAMS_DEFAULT</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_NAMENODE_REPLICATION_MAX_STREAMS_KEY"><B>DFS_NAMENODE_REPLICATION_MAX_STREAMS_KEY</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_NAMENODE_REPLICATION_MIN_DEFAULT"><B>DFS_NAMENODE_REPLICATION_MIN_DEFAULT</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_NAMENODE_REPLICATION_MIN_KEY"><B>DFS_NAMENODE_REPLICATION_MIN_KEY</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_NAMENODE_REPLICATION_PENDING_TIMEOUT_SEC_DEFAULT"><B>DFS_NAMENODE_REPLICATION_PENDING_TIMEOUT_SEC_DEFAULT</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_NAMENODE_REPLICATION_PENDING_TIMEOUT_SEC_KEY"><B>DFS_NAMENODE_REPLICATION_PENDING_TIMEOUT_SEC_KEY</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_NAMENODE_SAFEMODE_EXTENSION_DEFAULT"><B>DFS_NAMENODE_SAFEMODE_EXTENSION_DEFAULT</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_NAMENODE_SAFEMODE_EXTENSION_KEY"><B>DFS_NAMENODE_SAFEMODE_EXTENSION_KEY</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_NAMENODE_SAFEMODE_MIN_DATANODES_DEFAULT"><B>DFS_NAMENODE_SAFEMODE_MIN_DATANODES_DEFAULT</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_NAMENODE_SAFEMODE_MIN_DATANODES_KEY"><B>DFS_NAMENODE_SAFEMODE_MIN_DATANODES_KEY</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_NAMENODE_SAFEMODE_THRESHOLD_PCT_DEFAULT"><B>DFS_NAMENODE_SAFEMODE_THRESHOLD_PCT_DEFAULT</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_NAMENODE_SAFEMODE_THRESHOLD_PCT_KEY"><B>DFS_NAMENODE_SAFEMODE_THRESHOLD_PCT_KEY</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_NAMENODE_SECONDARY_HTTP_ADDRESS_DEFAULT"><B>DFS_NAMENODE_SECONDARY_HTTP_ADDRESS_DEFAULT</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_NAMENODE_SECONDARY_HTTP_ADDRESS_KEY"><B>DFS_NAMENODE_SECONDARY_HTTP_ADDRESS_KEY</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_NAMENODE_SERVICE_HANDLER_COUNT_DEFAULT"><B>DFS_NAMENODE_SERVICE_HANDLER_COUNT_DEFAULT</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_NAMENODE_SERVICE_HANDLER_COUNT_KEY"><B>DFS_NAMENODE_SERVICE_HANDLER_COUNT_KEY</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_NAMENODE_SERVICE_RPC_ADDRESS_KEY"><B>DFS_NAMENODE_SERVICE_RPC_ADDRESS_KEY</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_NAMENODE_STARTUP_KEY"><B>DFS_NAMENODE_STARTUP_KEY</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_NAMENODE_SUPPORT_ALLOW_FORMAT_DEFAULT"><B>DFS_NAMENODE_SUPPORT_ALLOW_FORMAT_DEFAULT</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_NAMENODE_SUPPORT_ALLOW_FORMAT_KEY"><B>DFS_NAMENODE_SUPPORT_ALLOW_FORMAT_KEY</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_NAMENODE_UPGRADE_PERMISSION_DEFAULT"><B>DFS_NAMENODE_UPGRADE_PERMISSION_DEFAULT</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_NAMENODE_UPGRADE_PERMISSION_KEY"><B>DFS_NAMENODE_UPGRADE_PERMISSION_KEY</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_NAMENODE_USER_NAME_KEY"><B>DFS_NAMENODE_USER_NAME_KEY</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_PERMISSIONS_ENABLED_DEFAULT"><B>DFS_PERMISSIONS_ENABLED_DEFAULT</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_PERMISSIONS_ENABLED_KEY"><B>DFS_PERMISSIONS_ENABLED_KEY</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_PERMISSIONS_SUPERUSERGROUP_DEFAULT"><B>DFS_PERMISSIONS_SUPERUSERGROUP_DEFAULT</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_PERMISSIONS_SUPERUSERGROUP_KEY"><B>DFS_PERMISSIONS_SUPERUSERGROUP_KEY</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_REPLICATION_DEFAULT"><B>DFS_REPLICATION_DEFAULT</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_REPLICATION_KEY"><B>DFS_REPLICATION_KEY</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_REPLICATION_MAX_DEFAULT"><B>DFS_REPLICATION_MAX_DEFAULT</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_REPLICATION_MAX_KEY"><B>DFS_REPLICATION_MAX_KEY</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY"><B>DFS_SECONDARY_NAMENODE_KEYTAB_FILE_KEY</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_SECONDARY_NAMENODE_KRB_HTTPS_USER_NAME_KEY"><B>DFS_SECONDARY_NAMENODE_KRB_HTTPS_USER_NAME_KEY</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_SECONDARY_NAMENODE_USER_NAME_KEY"><B>DFS_SECONDARY_NAMENODE_USER_NAME_KEY</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_SERVER_HTTPS_KEYSTORE_RESOURCE_DEFAULT"><B>DFS_SERVER_HTTPS_KEYSTORE_RESOURCE_DEFAULT</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_SERVER_HTTPS_KEYSTORE_RESOURCE_KEY"><B>DFS_SERVER_HTTPS_KEYSTORE_RESOURCE_KEY</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_STREAM_BUFFER_SIZE_DEFAULT"><B>DFS_STREAM_BUFFER_SIZE_DEFAULT</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_STREAM_BUFFER_SIZE_KEY"><B>DFS_STREAM_BUFFER_SIZE_KEY</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_SUPPORT_APPEND_DEFAULT"><B>DFS_SUPPORT_APPEND_DEFAULT</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_SUPPORT_APPEND_KEY"><B>DFS_SUPPORT_APPEND_KEY</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFS_WEB_UGI_KEY"><B>DFS_WEB_UGI_KEY</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/tools/DFSAdmin.html" title="org.apache.hadoop.hdfs.tools 中的类"><B>DFSAdmin</B></A> - <A HREF="./org/apache/hadoop/hdfs/tools/package-summary.html">org.apache.hadoop.hdfs.tools</A> 中的 类<DD>This class provides some DFS administrative access.<DT><A HREF="./org/apache/hadoop/hdfs/tools/DFSAdmin.html#DFSAdmin()"><B>DFSAdmin()</B></A> - 
类 org.apache.hadoop.hdfs.tools.<A HREF="./org/apache/hadoop/hdfs/tools/DFSAdmin.html" title="org.apache.hadoop.hdfs.tools 中的类">DFSAdmin</A> 的构造方法
<DD>Construct a DFSAdmin object.
<DT><A HREF="./org/apache/hadoop/hdfs/tools/DFSAdmin.html#DFSAdmin(org.apache.hadoop.conf.Configuration)"><B>DFSAdmin(Configuration)</B></A> - 
类 org.apache.hadoop.hdfs.tools.<A HREF="./org/apache/hadoop/hdfs/tools/DFSAdmin.html" title="org.apache.hadoop.hdfs.tools 中的类">DFSAdmin</A> 的构造方法
<DD>Construct a DFSAdmin object.
<DT><A HREF="./org/apache/hadoop/hdfs/tools/DFSck.html" title="org.apache.hadoop.hdfs.tools 中的类"><B>DFSck</B></A> - <A HREF="./org/apache/hadoop/hdfs/tools/package-summary.html">org.apache.hadoop.hdfs.tools</A> 中的 类<DD>This class provides rudimentary checking of DFS volumes for errors and
 sub-optimal conditions.<DT><A HREF="./org/apache/hadoop/hdfs/tools/DFSck.html#DFSck(org.apache.hadoop.conf.Configuration)"><B>DFSck(Configuration)</B></A> - 
类 org.apache.hadoop.hdfs.tools.<A HREF="./org/apache/hadoop/hdfs/tools/DFSck.html" title="org.apache.hadoop.hdfs.tools 中的类">DFSck</A> 的构造方法
<DD>Filesystem checker.
<DT><A HREF="./org/apache/hadoop/hdfs/tools/DFSck.html#DFSck(org.apache.hadoop.conf.Configuration, java.io.PrintStream)"><B>DFSck(Configuration, PrintStream)</B></A> - 
类 org.apache.hadoop.hdfs.tools.<A HREF="./org/apache/hadoop/hdfs/tools/DFSck.html" title="org.apache.hadoop.hdfs.tools 中的类">DFSck</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSClient.html" title="org.apache.hadoop.hdfs 中的类"><B>DFSClient</B></A> - <A HREF="./org/apache/hadoop/hdfs/package-summary.html">org.apache.hadoop.hdfs</A> 中的 类<DD>DFSClient can connect to a Hadoop Filesystem and 
 perform basic file tasks.<DT><A HREF="./org/apache/hadoop/hdfs/DFSClient.html#DFSClient(org.apache.hadoop.conf.Configuration)"><B>DFSClient(Configuration)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSClient.html" title="org.apache.hadoop.hdfs 中的类">DFSClient</A> 的构造方法
<DD><B>已过时。</B>&nbsp;<I>Deprecated at 0.21</I>
<DT><A HREF="./org/apache/hadoop/hdfs/DFSClient.html#DFSClient(java.net.InetSocketAddress, org.apache.hadoop.conf.Configuration)"><B>DFSClient(InetSocketAddress, Configuration)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSClient.html" title="org.apache.hadoop.hdfs 中的类">DFSClient</A> 的构造方法
<DD>Same as this(nameNodeAddr, conf, null);
<DT><A HREF="./org/apache/hadoop/hdfs/DFSClient.html#DFSClient(java.net.InetSocketAddress, org.apache.hadoop.conf.Configuration, org.apache.hadoop.fs.FileSystem.Statistics)"><B>DFSClient(InetSocketAddress, Configuration, FileSystem.Statistics)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSClient.html" title="org.apache.hadoop.hdfs 中的类">DFSClient</A> 的构造方法
<DD>Same as this(nameNodeAddr, null, conf, stats);
<DT><A HREF="./org/apache/hadoop/hdfs/DFSClient.DFSDataInputStream.html" title="org.apache.hadoop.hdfs 中的类"><B>DFSClient.DFSDataInputStream</B></A> - <A HREF="./org/apache/hadoop/hdfs/package-summary.html">org.apache.hadoop.hdfs</A> 中的 类<DD>The Hdfs implementation of <CODE>FSDataInputStream</CODE><DT><A HREF="./org/apache/hadoop/hdfs/DFSClient.DFSDataInputStream.html#DFSClient.DFSDataInputStream(org.apache.hadoop.hdfs.DFSInputStream)"><B>DFSClient.DFSDataInputStream(DFSInputStream)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSClient.DFSDataInputStream.html" title="org.apache.hadoop.hdfs 中的类">DFSClient.DFSDataInputStream</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类"><B>DFSConfigKeys</B></A> - <A HREF="./org/apache/hadoop/hdfs/package-summary.html">org.apache.hadoop.hdfs</A> 中的 类<DD>This class contains constants for configuration keys used
 in hdfs.<DT><A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html#DFSConfigKeys()"><B>DFSConfigKeys()</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSConfigKeys.html" title="org.apache.hadoop.hdfs 中的类">DFSConfigKeys</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSInputStream.html" title="org.apache.hadoop.hdfs 中的类"><B>DFSInputStream</B></A> - <A HREF="./org/apache/hadoop/hdfs/package-summary.html">org.apache.hadoop.hdfs</A> 中的 类<DD>DFSInputStream provides bytes from a named file.<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#DFSNodesStatus(java.util.ArrayList, java.util.ArrayList)"><B>DFSNodesStatus(ArrayList&lt;DatanodeDescriptor&gt;, ArrayList&lt;DatanodeDescriptor&gt;)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FSNamesystem</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeInfo.html#dfsUsed"><B>dfsUsed</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeInfo.html" title="org.apache.hadoop.hdfs.protocol 中的类">DatanodeInfo</A> 中的变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSUtil.html" title="org.apache.hadoop.hdfs 中的类"><B>DFSUtil</B></A> - <A HREF="./org/apache/hadoop/hdfs/package-summary.html">org.apache.hadoop.hdfs</A> 中的 类<DD>&nbsp;<DT><A HREF="./org/apache/hadoop/hdfs/DFSUtil.html#DFSUtil()"><B>DFSUtil()</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSUtil.html" title="org.apache.hadoop.hdfs 中的类">DFSUtil</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSUtil.ErrorSimulator.html" title="org.apache.hadoop.hdfs 中的类"><B>DFSUtil.ErrorSimulator</B></A> - <A HREF="./org/apache/hadoop/hdfs/package-summary.html">org.apache.hadoop.hdfs</A> 中的 类<DD>Utility class to facilitate junit test error simulation.<DT><A HREF="./org/apache/hadoop/hdfs/DFSUtil.ErrorSimulator.html#DFSUtil.ErrorSimulator()"><B>DFSUtil.ErrorSimulator()</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSUtil.ErrorSimulator.html" title="org.apache.hadoop.hdfs 中的类">DFSUtil.ErrorSimulator</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#dir"><B>dir</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FSNamesystem</A> 中的变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DirectoryListing.html" title="org.apache.hadoop.hdfs.protocol 中的类"><B>DirectoryListing</B></A> - <A HREF="./org/apache/hadoop/hdfs/protocol/package-summary.html">org.apache.hadoop.hdfs.protocol</A> 中的 类<DD>This class defines a partial listing of a directory to support
 iterative directory listing.<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DirectoryListing.html#DirectoryListing()"><B>DirectoryListing()</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DirectoryListing.html" title="org.apache.hadoop.hdfs.protocol 中的类">DirectoryListing</A> 的构造方法
<DD>default constructor
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DirectoryListing.html#DirectoryListing(org.apache.hadoop.hdfs.protocol.HdfsFileStatus[], int)"><B>DirectoryListing(HdfsFileStatus[], int)</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DirectoryListing.html" title="org.apache.hadoop.hdfs.protocol 中的类">DirectoryListing</A> 的构造方法
<DD>constructor
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/DirectoryScanner.html" title="org.apache.hadoop.hdfs.server.datanode 中的类"><B>DirectoryScanner</B></A> - <A HREF="./org/apache/hadoop/hdfs/server/datanode/package-summary.html">org.apache.hadoop.hdfs.server.datanode</A> 中的 类<DD>Periodically scans the data directories for block and block metadata files.<DT><A HREF="./org/apache/hadoop/hdfs/server/common/Storage.html#dirIterator()"><B>dirIterator()</B></A> - 
类 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/Storage.html" title="org.apache.hadoop.hdfs.server.common 中的类">Storage</A> 中的方法
<DD>Return default iterator
 This iterator returns all entries in storageDirs
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/Storage.html#dirIterator(org.apache.hadoop.hdfs.server.common.Storage.StorageDirType)"><B>dirIterator(Storage.StorageDirType)</B></A> - 
类 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/Storage.html" title="org.apache.hadoop.hdfs.server.common 中的类">Storage</A> 中的方法
<DD>Return iterator based on Storage Directory Type
 This iterator selects entries in storageDirs of type dirType and returns
 them via the Iterator
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/DisallowedDatanodeException.html" title="org.apache.hadoop.hdfs.server.protocol 中的类"><B>DisallowedDatanodeException</B></A> - <A HREF="./org/apache/hadoop/hdfs/server/protocol/package-summary.html">org.apache.hadoop.hdfs.server.protocol</A> 中的 异常<DD>This exception is thrown when a datanode tries to register or communicate
 with the namenode when it does not appear on the list of included nodes, 
 or has been specifically excluded.<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/DisallowedDatanodeException.html#DisallowedDatanodeException(org.apache.hadoop.hdfs.protocol.DatanodeID)"><B>DisallowedDatanodeException(DatanodeID)</B></A> - 
异常 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/DisallowedDatanodeException.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">DisallowedDatanodeException</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/DatanodeProtocol.html#DISK_ERROR"><B>DISK_ERROR</B></A> - 
接口 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/DatanodeProtocol.html" title="org.apache.hadoop.hdfs.server.protocol 中的接口">DatanodeProtocol</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DistributedFileSystem.html" title="org.apache.hadoop.hdfs 中的类"><B>DistributedFileSystem</B></A> - <A HREF="./org/apache/hadoop/hdfs/package-summary.html">org.apache.hadoop.hdfs</A> 中的 类<DD>Implementation of the abstract FileSystem for the DFS system.<DT><A HREF="./org/apache/hadoop/hdfs/DistributedFileSystem.html#DistributedFileSystem()"><B>DistributedFileSystem()</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DistributedFileSystem.html" title="org.apache.hadoop.hdfs 中的类">DistributedFileSystem</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DistributedFileSystem.html#DistributedFileSystem(java.net.InetSocketAddress, org.apache.hadoop.conf.Configuration)"><B>DistributedFileSystem(InetSocketAddress, Configuration)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DistributedFileSystem.html" title="org.apache.hadoop.hdfs 中的类">DistributedFileSystem</A> 的构造方法
<DD><B>已过时。</B>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DistributedFileSystem.DiskStatus.html" title="org.apache.hadoop.hdfs 中的类"><B>DistributedFileSystem.DiskStatus</B></A> - <A HREF="./org/apache/hadoop/hdfs/package-summary.html">org.apache.hadoop.hdfs</A> 中的 类<DD><B>已过时。</B>&nbsp;<I>Use <CODE>FsStatus</CODE> instead</I><DT><A HREF="./org/apache/hadoop/hdfs/DistributedFileSystem.DiskStatus.html#DistributedFileSystem.DiskStatus(org.apache.hadoop.fs.FsStatus)"><B>DistributedFileSystem.DiskStatus(FsStatus)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DistributedFileSystem.DiskStatus.html" title="org.apache.hadoop.hdfs 中的类">DistributedFileSystem.DiskStatus</A> 的构造方法
<DD><B>已过时。</B>&nbsp;&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DistributedFileSystem.DiskStatus.html#DistributedFileSystem.DiskStatus(long, long, long)"><B>DistributedFileSystem.DiskStatus(long, long, long)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DistributedFileSystem.DiskStatus.html" title="org.apache.hadoop.hdfs 中的类">DistributedFileSystem.DiskStatus</A> 的构造方法
<DD><B>已过时。</B>&nbsp;&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSClient.html#distributedUpgradeProgress(org.apache.hadoop.hdfs.protocol.FSConstants.UpgradeAction)"><B>distributedUpgradeProgress(FSConstants.UpgradeAction)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSClient.html" title="org.apache.hadoop.hdfs 中的类">DFSClient</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DistributedFileSystem.html#distributedUpgradeProgress(org.apache.hadoop.hdfs.protocol.FSConstants.UpgradeAction)"><B>distributedUpgradeProgress(FSConstants.UpgradeAction)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DistributedFileSystem.html" title="org.apache.hadoop.hdfs 中的类">DistributedFileSystem</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/ClientProtocol.html#distributedUpgradeProgress(org.apache.hadoop.hdfs.protocol.FSConstants.UpgradeAction)"><B>distributedUpgradeProgress(FSConstants.UpgradeAction)</B></A> - 
接口 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/ClientProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的接口">ClientProtocol</A> 中的方法
<DD>Report distributed upgrade progress or force current upgrade to proceed.
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html#distributedUpgradeProgress(org.apache.hadoop.hdfs.protocol.FSConstants.UpgradeAction)"><B>distributedUpgradeProgress(FSConstants.UpgradeAction)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">NameNode</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/RSCoderProtocol.html#div"><B>div</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/RSCoderProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的类">RSCoderProtocol</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/DataNode.html#DN_CLIENTTRACE_FORMAT"><B>DN_CLIENTTRACE_FORMAT</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/DataNode.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">DataNode</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/HdfsConstants.html#DN_KEEPALIVE_TIMEOUT"><B>DN_KEEPALIVE_TIMEOUT</B></A> - 
接口 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/HdfsConstants.html" title="org.apache.hadoop.hdfs.server.common 中的接口">HdfsConstants</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/DatanodeProtocol.html#DNA_ACCESSKEYUPDATE"><B>DNA_ACCESSKEYUPDATE</B></A> - 
接口 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/DatanodeProtocol.html" title="org.apache.hadoop.hdfs.server.protocol 中的接口">DatanodeProtocol</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/DatanodeProtocol.html#DNA_CUMULUS_RECOVERY"><B>DNA_CUMULUS_RECOVERY</B></A> - 
接口 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/DatanodeProtocol.html" title="org.apache.hadoop.hdfs.server.protocol 中的接口">DatanodeProtocol</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/DatanodeProtocol.html#DNA_FINALIZE"><B>DNA_FINALIZE</B></A> - 
接口 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/DatanodeProtocol.html" title="org.apache.hadoop.hdfs.server.protocol 中的接口">DatanodeProtocol</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/DatanodeProtocol.html#DNA_INVALIDATE"><B>DNA_INVALIDATE</B></A> - 
接口 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/DatanodeProtocol.html" title="org.apache.hadoop.hdfs.server.protocol 中的接口">DatanodeProtocol</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/DatanodeProtocol.html#DNA_RC_RECOVERY"><B>DNA_RC_RECOVERY</B></A> - 
接口 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/DatanodeProtocol.html" title="org.apache.hadoop.hdfs.server.protocol 中的接口">DatanodeProtocol</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/DatanodeProtocol.html#DNA_RECOVERBLOCK"><B>DNA_RECOVERBLOCK</B></A> - 
接口 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/DatanodeProtocol.html" title="org.apache.hadoop.hdfs.server.protocol 中的接口">DatanodeProtocol</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/DatanodeProtocol.html#DNA_REGISTER"><B>DNA_REGISTER</B></A> - 
接口 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/DatanodeProtocol.html" title="org.apache.hadoop.hdfs.server.protocol 中的接口">DatanodeProtocol</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/DatanodeProtocol.html#DNA_SHUTDOWN"><B>DNA_SHUTDOWN</B></A> - 
接口 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/DatanodeProtocol.html" title="org.apache.hadoop.hdfs.server.protocol 中的接口">DatanodeProtocol</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/DatanodeProtocol.html#DNA_TRANSFER"><B>DNA_TRANSFER</B></A> - 
接口 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/DatanodeProtocol.html" title="org.apache.hadoop.hdfs.server.protocol 中的接口">DatanodeProtocol</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/DatanodeProtocol.html#DNA_UNKNOWN"><B>DNA_UNKNOWN</B></A> - 
接口 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/DatanodeProtocol.html" title="org.apache.hadoop.hdfs.server.protocol 中的接口">DatanodeProtocol</A> 中的静态变量
<DD>Determines actions that data node should perform 
 when receiving a datanode command.
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/DataNode.html#dnRegistration"><B>dnRegistration</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/DataNode.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">DataNode</A> 中的变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/DataNode.html#dnStator"><B>dnStator</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/DataNode.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">DataNode</A> 中的变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/DatanodeMonitorServlet.html#doGet(javax.servlet.http.HttpServletRequest, javax.servlet.http.HttpServletResponse)"><B>doGet(HttpServletRequest, HttpServletResponse)</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/DatanodeMonitorServlet.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">DatanodeMonitorServlet</A> 中的方法
<DD>Service a GET request as described below.
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/CancelDelegationTokenServlet.html#doGet(javax.servlet.http.HttpServletRequest, javax.servlet.http.HttpServletResponse)"><B>doGet(HttpServletRequest, HttpServletResponse)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/CancelDelegationTokenServlet.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">CancelDelegationTokenServlet</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/ContentSummaryServlet.html#doGet(javax.servlet.http.HttpServletRequest, javax.servlet.http.HttpServletResponse)"><B>doGet(HttpServletRequest, HttpServletResponse)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/ContentSummaryServlet.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">ContentSummaryServlet</A> 中的方法
<DD>
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FileChecksumServlets.GetServlet.html#doGet(javax.servlet.http.HttpServletRequest, javax.servlet.http.HttpServletResponse)"><B>doGet(HttpServletRequest, HttpServletResponse)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/FileChecksumServlets.GetServlet.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FileChecksumServlets.GetServlet</A> 中的方法
<DD>
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FileChecksumServlets.RedirectServlet.html#doGet(javax.servlet.http.HttpServletRequest, javax.servlet.http.HttpServletResponse)"><B>doGet(HttpServletRequest, HttpServletResponse)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/FileChecksumServlets.RedirectServlet.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FileChecksumServlets.RedirectServlet</A> 中的方法
<DD>
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FileDataServlet.html#doGet(javax.servlet.http.HttpServletRequest, javax.servlet.http.HttpServletResponse)"><B>doGet(HttpServletRequest, HttpServletResponse)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/FileDataServlet.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FileDataServlet</A> 中的方法
<DD>Service a GET request as described below.
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FsckServlet.html#doGet(javax.servlet.http.HttpServletRequest, javax.servlet.http.HttpServletResponse)"><B>doGet(HttpServletRequest, HttpServletResponse)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/FsckServlet.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FsckServlet</A> 中的方法
<DD>Handle fsck request
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/GetDelegationTokenServlet.html#doGet(javax.servlet.http.HttpServletRequest, javax.servlet.http.HttpServletResponse)"><B>doGet(HttpServletRequest, HttpServletResponse)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/GetDelegationTokenServlet.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">GetDelegationTokenServlet</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/GetImageServlet.html#doGet(javax.servlet.http.HttpServletRequest, javax.servlet.http.HttpServletResponse)"><B>doGet(HttpServletRequest, HttpServletResponse)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/GetImageServlet.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">GetImageServlet</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/ListPathsServlet.html#doGet(javax.servlet.http.HttpServletRequest, javax.servlet.http.HttpServletResponse)"><B>doGet(HttpServletRequest, HttpServletResponse)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/ListPathsServlet.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">ListPathsServlet</A> 中的方法
<DD>Service a GET request as described below.
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/MonitorServlet.html#doGet(javax.servlet.http.HttpServletRequest, javax.servlet.http.HttpServletResponse)"><B>doGet(HttpServletRequest, HttpServletResponse)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/MonitorServlet.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">MonitorServlet</A> 中的方法
<DD>Service a GET request as described below.
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/RenewDelegationTokenServlet.html#doGet(javax.servlet.http.HttpServletRequest, javax.servlet.http.HttpServletResponse)"><B>doGet(HttpServletRequest, HttpServletResponse)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/RenewDelegationTokenServlet.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">RenewDelegationTokenServlet</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/StreamFile.html#doGet(javax.servlet.http.HttpServletRequest, javax.servlet.http.HttpServletResponse)"><B>doGet(HttpServletRequest, HttpServletResponse)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/StreamFile.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">StreamFile</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/Storage.StorageDirectory.html#doRecover(org.apache.hadoop.hdfs.server.common.Storage.StorageState)"><B>doRecover(Storage.StorageState)</B></A> - 
类 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/Storage.StorageDirectory.html" title="org.apache.hadoop.hdfs.server.common 中的类">Storage.StorageDirectory</A> 中的方法
<DD>Complete or recover storage state from previously failed transition.
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/metrics/DataNodeMetrics.html#doUpdates(org.apache.hadoop.metrics.MetricsContext)"><B>doUpdates(MetricsContext)</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.metrics.<A HREF="./org/apache/hadoop/hdfs/server/datanode/metrics/DataNodeMetrics.html" title="org.apache.hadoop.hdfs.server.datanode.metrics 中的类">DataNodeMetrics</A> 中的方法
<DD>Since this object is a registered updater, this method will be called
 periodically, e.g. every 5 seconds.
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/metrics/FSNamesystemMetrics.html#doUpdates(org.apache.hadoop.metrics.MetricsContext)"><B>doUpdates(MetricsContext)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.metrics.<A HREF="./org/apache/hadoop/hdfs/server/namenode/metrics/FSNamesystemMetrics.html" title="org.apache.hadoop.hdfs.server.namenode.metrics 中的类">FSNamesystemMetrics</A> 中的方法
<DD>Since this object is a registered updater, this method will be called
 periodically, e.g. every 5 seconds.
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/metrics/NameNodeMetrics.html#doUpdates(org.apache.hadoop.metrics.MetricsContext)"><B>doUpdates(MetricsContext)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.metrics.<A HREF="./org/apache/hadoop/hdfs/server/namenode/metrics/NameNodeMetrics.html" title="org.apache.hadoop.hdfs.server.namenode.metrics 中的类">NameNodeMetrics</A> 中的方法
<DD>Since this object is a registered updater, this method will be called
 periodically, e.g. every 5 seconds.
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/UpgradeObjectDatanode.html#doUpgrade()"><B>doUpgrade()</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/UpgradeObjectDatanode.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">UpgradeObjectDatanode</A> 中的方法
<DD>Specifies how the upgrade is performed.
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/SecondaryNameNode.html#doWork()"><B>doWork()</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/SecondaryNameNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">SecondaryNameNode</A> 中的方法
<DD><B>已过时。</B>&nbsp;&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DSQuotaExceededException.html" title="org.apache.hadoop.hdfs.protocol 中的类"><B>DSQuotaExceededException</B></A> - <A HREF="./org/apache/hadoop/hdfs/protocol/package-summary.html">org.apache.hadoop.hdfs.protocol</A> 中的 异常<DD>&nbsp;<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DSQuotaExceededException.html#DSQuotaExceededException()"><B>DSQuotaExceededException()</B></A> - 
异常 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DSQuotaExceededException.html" title="org.apache.hadoop.hdfs.protocol 中的类">DSQuotaExceededException</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DSQuotaExceededException.html#DSQuotaExceededException(java.lang.String)"><B>DSQuotaExceededException(String)</B></A> - 
异常 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DSQuotaExceededException.html" title="org.apache.hadoop.hdfs.protocol 中的类">DSQuotaExceededException</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DSQuotaExceededException.html#DSQuotaExceededException(long, long)"><B>DSQuotaExceededException(long, long)</B></A> - 
异常 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DSQuotaExceededException.html" title="org.apache.hadoop.hdfs.protocol 中的类">DSQuotaExceededException</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/security/token/block/ExportedBlockKeys.html#DUMMY_KEYS"><B>DUMMY_KEYS</B></A> - 
类 org.apache.hadoop.hdfs.security.token.block.<A HREF="./org/apache/hadoop/hdfs/security/token/block/ExportedBlockKeys.html" title="org.apache.hadoop.hdfs.security.token.block 中的类">ExportedBlockKeys</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/security/token/block/BlockTokenSecretManager.html#DUMMY_TOKEN"><B>DUMMY_TOKEN</B></A> - 
类 org.apache.hadoop.hdfs.security.token.block.<A HREF="./org/apache/hadoop/hdfs/security/token/block/BlockTokenSecretManager.html" title="org.apache.hadoop.hdfs.security.token.block 中的类">BlockTokenSecretManager</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeInfo.html#dumpDatanode()"><B>dumpDatanode()</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeInfo.html" title="org.apache.hadoop.hdfs.protocol 中的类">DatanodeInfo</A> 中的方法
<DD>A formatted string for printing the status of the DataNode.
</DL>
<HR>
<A NAME="_E_"><!-- --></A><H2>
<B>E</B></H2>
<DL>
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FSImage.html#editLog"><B>editLog</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/FSImage.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FSImage</A> 中的变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeID.html#EMPTY_ARRAY"><B>EMPTY_ARRAY</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeID.html" title="org.apache.hadoop.hdfs.protocol 中的类">DatanodeID</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/DataNode.html#EMPTY_DEL_HINT"><B>EMPTY_DEL_HINT</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/DataNode.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">DataNode</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/HdfsFileStatus.html#EMPTY_NAME"><B>EMPTY_NAME</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/HdfsFileStatus.html" title="org.apache.hadoop.hdfs.protocol 中的类">HdfsFileStatus</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/BackupNode.html#endCheckpoint(org.apache.hadoop.hdfs.server.protocol.NamenodeRegistration, org.apache.hadoop.hdfs.server.namenode.CheckpointSignature)"><B>endCheckpoint(NamenodeRegistration, CheckpointSignature)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/BackupNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">BackupNode</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html#endCheckpoint(org.apache.hadoop.hdfs.server.protocol.NamenodeRegistration, org.apache.hadoop.hdfs.server.namenode.CheckpointSignature)"><B>endCheckpoint(NamenodeRegistration, CheckpointSignature)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">NameNode</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/NamenodeProtocol.html#endCheckpoint(org.apache.hadoop.hdfs.server.protocol.NamenodeRegistration, org.apache.hadoop.hdfs.server.namenode.CheckpointSignature)"><B>endCheckpoint(NamenodeRegistration, CheckpointSignature)</B></A> - 
接口 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/NamenodeProtocol.html" title="org.apache.hadoop.hdfs.server.protocol 中的接口">NamenodeProtocol</A> 中的方法
<DD>A request to the active name-node to finalize
 previously started checkpoint.
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/DataNode.html#endRCRecovery(org.apache.hadoop.hdfs.protocol.Block)"><B>endRCRecovery(Block)</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/DataNode.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">DataNode</A> 中的方法
<DD>new comer inform a helper node to end rc in RC(regenerating code)recovery work. created at 2041-4-24
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/InterDatanodeProtocol.html#endRCRecovery(org.apache.hadoop.hdfs.protocol.Block)"><B>endRCRecovery(Block)</B></A> - 
接口 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/InterDatanodeProtocol.html" title="org.apache.hadoop.hdfs.server.protocol 中的接口">InterDatanodeProtocol</A> 中的方法
<DD>added at 2014-4-24
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/Block.html#equals(java.lang.Object)"><B>equals(Object)</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/Block.html" title="org.apache.hadoop.hdfs.protocol 中的类">Block</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeID.html#equals(java.lang.Object)"><B>equals(Object)</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeID.html" title="org.apache.hadoop.hdfs.protocol 中的类">DatanodeID</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeInfo.html#equals(java.lang.Object)"><B>equals(Object)</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeInfo.html" title="org.apache.hadoop.hdfs.protocol 中的类">DatanodeInfo</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.PacketHeader.html#equals(java.lang.Object)"><B>equals(Object)</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.PacketHeader.html" title="org.apache.hadoop.hdfs.protocol 中的类">DataTransferProtocol.PacketHeader</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/security/token/block/BlockTokenIdentifier.html#equals(java.lang.Object)"><B>equals(Object)</B></A> - 
类 org.apache.hadoop.hdfs.security.token.block.<A HREF="./org/apache/hadoop/hdfs/security/token/block/BlockTokenIdentifier.html" title="org.apache.hadoop.hdfs.security.token.block 中的类">BlockTokenIdentifier</A> 中的方法
<DD>
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/GenerationStamp.html#equals(java.lang.Object)"><B>equals(Object)</B></A> - 
类 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/GenerationStamp.html" title="org.apache.hadoop.hdfs.server.common 中的类">GenerationStamp</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/UpgradeObject.html#equals(java.lang.Object)"><B>equals(Object)</B></A> - 
类 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/UpgradeObject.html" title="org.apache.hadoop.hdfs.server.common 中的类">UpgradeObject</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/CheckpointSignature.html#equals(java.lang.Object)"><B>equals(Object)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/CheckpointSignature.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">CheckpointSignature</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/DatanodeDescriptor.html#equals(java.lang.Object)"><B>equals(Object)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/DatanodeDescriptor.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">DatanodeDescriptor</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/DatanodeRegistration.html#equals(java.lang.Object)"><B>equals(Object)</B></A> - 
类 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/DatanodeRegistration.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">DatanodeRegistration</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/ReplicaRecoveryInfo.html#equals(java.lang.Object)"><B>equals(Object)</B></A> - 
类 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/ReplicaRecoveryInfo.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">ReplicaRecoveryInfo</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/util/ByteArray.html#equals(java.lang.Object)"><B>equals(Object)</B></A> - 
类 org.apache.hadoop.hdfs.util.<A HREF="./org/apache/hadoop/hdfs/util/ByteArray.html" title="org.apache.hadoop.hdfs.util 中的类">ByteArray</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DataPool.html#error"><B>error</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DataPool.html" title="org.apache.hadoop.hdfs 中的类">DataPool</A> 中的变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html#errorReport(org.apache.hadoop.hdfs.server.protocol.NamenodeRegistration, int, java.lang.String)"><B>errorReport(NamenodeRegistration, int, String)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">NameNode</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html#errorReport(org.apache.hadoop.hdfs.server.protocol.DatanodeRegistration, int, java.lang.String)"><B>errorReport(DatanodeRegistration, int, String)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">NameNode</A> 中的方法
<DD>Handle an error report from a datanode.
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/DatanodeProtocol.html#errorReport(org.apache.hadoop.hdfs.server.protocol.DatanodeRegistration, int, java.lang.String)"><B>errorReport(DatanodeRegistration, int, String)</B></A> - 
接口 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/DatanodeProtocol.html" title="org.apache.hadoop.hdfs.server.protocol 中的接口">DatanodeProtocol</A> 中的方法
<DD>errorReport() tells the NameNode about something that has gone
 awry.
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/NamenodeProtocol.html#errorReport(org.apache.hadoop.hdfs.server.protocol.NamenodeRegistration, int, java.lang.String)"><B>errorReport(NamenodeRegistration, int, String)</B></A> - 
接口 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/NamenodeProtocol.html" title="org.apache.hadoop.hdfs.server.protocol 中的接口">NamenodeProtocol</A> 中的方法
<DD>Report to the active name-node an error occurred on a subordinate node.
<DT><A HREF="./org/apache/hadoop/hdfs/DFSClient.html#exists(java.lang.String)"><B>exists(String)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSClient.html" title="org.apache.hadoop.hdfs 中的类">DFSClient</A> 中的方法
<DD>Implemented using getFileInfo(src)
<DT><A HREF="./org/apache/hadoop/hdfs/security/token/block/ExportedBlockKeys.html" title="org.apache.hadoop.hdfs.security.token.block 中的类"><B>ExportedBlockKeys</B></A> - <A HREF="./org/apache/hadoop/hdfs/security/token/block/package-summary.html">org.apache.hadoop.hdfs.security.token.block</A> 中的 类<DD>Object for passing block keys<DT><A HREF="./org/apache/hadoop/hdfs/security/token/block/ExportedBlockKeys.html#ExportedBlockKeys()"><B>ExportedBlockKeys()</B></A> - 
类 org.apache.hadoop.hdfs.security.token.block.<A HREF="./org/apache/hadoop/hdfs/security/token/block/ExportedBlockKeys.html" title="org.apache.hadoop.hdfs.security.token.block 中的类">ExportedBlockKeys</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/DatanodeRegistration.html#exportedKeys"><B>exportedKeys</B></A> - 
类 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/DatanodeRegistration.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">DatanodeRegistration</A> 中的变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/security/token/block/BlockTokenSecretManager.html#exportKeys()"><B>exportKeys()</B></A> - 
类 org.apache.hadoop.hdfs.security.token.block.<A HREF="./org/apache/hadoop/hdfs/security/token/block/BlockTokenSecretManager.html" title="org.apache.hadoop.hdfs.security.token.block 中的类">BlockTokenSecretManager</A> 中的方法
<DD>Export block keys, only to be used in master mode
</DL>
<HR>
<A NAME="_F_"><!-- --></A><H2>
<B>F</B></H2>
<DL>
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NamenodeFsck.html#FAILURE_STATUS"><B>FAILURE_STATUS</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/NamenodeFsck.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">NamenodeFsck</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/NamenodeProtocol.html#FATAL"><B>FATAL</B></A> - 
接口 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/NamenodeProtocol.html" title="org.apache.hadoop.hdfs.server.protocol 中的接口">NamenodeProtocol</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/DatanodeProtocol.html#FATAL_DISK_ERROR"><B>FATAL_DISK_ERROR</B></A> - 
接口 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/DatanodeProtocol.html" title="org.apache.hadoop.hdfs.server.protocol 中的接口">DatanodeProtocol</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/Util.html#fileAsURI(java.io.File)"><B>fileAsURI(File)</B></A> - 
类 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/Util.html" title="org.apache.hadoop.hdfs.server.common 中的类">Util</A> 中的静态方法
<DD>Converts the passed File to a URI.
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FileChecksumServlets.html" title="org.apache.hadoop.hdfs.server.namenode 中的类"><B>FileChecksumServlets</B></A> - <A HREF="./org/apache/hadoop/hdfs/server/namenode/package-summary.html">org.apache.hadoop.hdfs.server.namenode</A> 中的 类<DD>Servlets for file checksum<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FileChecksumServlets.html#FileChecksumServlets()"><B>FileChecksumServlets()</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/FileChecksumServlets.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FileChecksumServlets</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FileChecksumServlets.GetServlet.html" title="org.apache.hadoop.hdfs.server.namenode 中的类"><B>FileChecksumServlets.GetServlet</B></A> - <A HREF="./org/apache/hadoop/hdfs/server/namenode/package-summary.html">org.apache.hadoop.hdfs.server.namenode</A> 中的 类<DD>Get FileChecksum<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FileChecksumServlets.GetServlet.html#FileChecksumServlets.GetServlet()"><B>FileChecksumServlets.GetServlet()</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/FileChecksumServlets.GetServlet.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FileChecksumServlets.GetServlet</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FileChecksumServlets.RedirectServlet.html" title="org.apache.hadoop.hdfs.server.namenode 中的类"><B>FileChecksumServlets.RedirectServlet</B></A> - <A HREF="./org/apache/hadoop/hdfs/server/namenode/package-summary.html">org.apache.hadoop.hdfs.server.namenode</A> 中的 类<DD>Redirect file checksum queries to an appropriate datanode.<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FileChecksumServlets.RedirectServlet.html#FileChecksumServlets.RedirectServlet()"><B>FileChecksumServlets.RedirectServlet()</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/FileChecksumServlets.RedirectServlet.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FileChecksumServlets.RedirectServlet</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FileDataServlet.html" title="org.apache.hadoop.hdfs.server.namenode 中的类"><B>FileDataServlet</B></A> - <A HREF="./org/apache/hadoop/hdfs/server/namenode/package-summary.html">org.apache.hadoop.hdfs.server.namenode</A> 中的 类<DD>Redirect queries about the hosted filesystem to an appropriate datanode.<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FileDataServlet.html#FileDataServlet()"><B>FileDataServlet()</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/FileDataServlet.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FileDataServlet</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/Block.html#filename2id(java.lang.String)"><B>filename2id(String)</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/Block.html" title="org.apache.hadoop.hdfs.protocol 中的类">Block</A> 中的静态方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/DatanodeCommand.html#FINALIZE"><B>FINALIZE</B></A> - 
类 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/DatanodeCommand.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">DatanodeCommand</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDataset.html#finalizeBlock(org.apache.hadoop.hdfs.protocol.Block)"><B>finalizeBlock(Block)</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDataset.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">FSDataset</A> 中的方法
<DD>Complete the block write!
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.html#finalizeBlock(org.apache.hadoop.hdfs.protocol.Block)"><B>finalizeBlock(Block)</B></A> - 
接口 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.html" title="org.apache.hadoop.hdfs.server.datanode 中的接口">FSDatasetInterface</A> 中的方法
<DD>Finalizes the block previously opened for writing using writeToBlock.
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/UpgradeStatusReport.html#finalized"><B>finalized</B></A> - 
类 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/UpgradeStatusReport.html" title="org.apache.hadoop.hdfs.server.common 中的类">UpgradeStatusReport</A> 中的变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSClient.html#finalizeUpgrade()"><B>finalizeUpgrade()</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSClient.html" title="org.apache.hadoop.hdfs 中的类">DFSClient</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DistributedFileSystem.html#finalizeUpgrade()"><B>finalizeUpgrade()</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DistributedFileSystem.html" title="org.apache.hadoop.hdfs 中的类">DistributedFileSystem</A> 中的方法
<DD>Finalize previously upgraded files system state.
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/ClientProtocol.html#finalizeUpgrade()"><B>finalizeUpgrade()</B></A> - 
接口 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/ClientProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的接口">ClientProtocol</A> 中的方法
<DD>Finalize previous upgrade.
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html#finalizeUpgrade()"><B>finalizeUpgrade()</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">NameNode</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/tools/DFSAdmin.html#finalizeUpgrade()"><B>finalizeUpgrade()</B></A> - 
类 org.apache.hadoop.hdfs.tools.<A HREF="./org/apache/hadoop/hdfs/tools/DFSAdmin.html" title="org.apache.hadoop.hdfs.tools 中的类">DFSAdmin</A> 中的方法
<DD>Command to ask the namenode to finalize previously performed upgrade.
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/LocatedBlocks.html#findBlock(long)"><B>findBlock(long)</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/LocatedBlocks.html" title="org.apache.hadoop.hdfs.protocol 中的类">LocatedBlocks</A> 中的方法
<DD>Find block containing specified offset.
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDataset.html#findBlockFile(long)"><B>findBlockFile(long)</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDataset.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">FSDataset</A> 中的方法
<DD>Return the block file for the given ID
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/GenerationStamp.html#FIRST_VALID_STAMP"><B>FIRST_VALID_STAMP</B></A> - 
类 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/GenerationStamp.html" title="org.apache.hadoop.hdfs.server.common 中的类">GenerationStamp</A> 中的静态变量
<DD>The first valid generation stamp.
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NamenodeFsck.html#FIXING_DELETE"><B>FIXING_DELETE</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/NamenodeFsck.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">NamenodeFsck</A> 中的静态变量
<DD>Delete corrupted files.
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NamenodeFsck.html#FIXING_MOVE"><B>FIXING_MOVE</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/NamenodeFsck.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">NamenodeFsck</A> 中的静态变量
<DD>Move corrupted files to /lost+found .
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NamenodeFsck.html#FIXING_NONE"><B>FIXING_NONE</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/NamenodeFsck.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">NamenodeFsck</A> 中的静态变量
<DD>Don't attempt any fixing .
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/UpgradeObjectNamenode.html#forceProceed()"><B>forceProceed()</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/UpgradeObjectNamenode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">UpgradeObjectNamenode</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FSImage.html#format()"><B>format()</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/FSImage.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FSImage</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html#format(org.apache.hadoop.conf.Configuration)"><B>format(Configuration)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">NameNode</A> 中的静态方法
<DD>Format a new filesystem.
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NamenodeFsck.html#fsck()"><B>fsck()</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/NamenodeFsck.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">NamenodeFsck</A> 中的方法
<DD>Check files on DFS, starting from the indicated path.
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FsckServlet.html" title="org.apache.hadoop.hdfs.server.namenode 中的类"><B>FsckServlet</B></A> - <A HREF="./org/apache/hadoop/hdfs/server/namenode/package-summary.html">org.apache.hadoop.hdfs.server.namenode</A> 中的 类<DD>This class is used in Namesystem's web server to do fsck on namenode.<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FsckServlet.html#FsckServlet()"><B>FsckServlet()</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/FsckServlet.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FsckServlet</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FSClusterStats.html" title="org.apache.hadoop.hdfs.server.namenode 中的接口"><B>FSClusterStats</B></A> - <A HREF="./org/apache/hadoop/hdfs/server/namenode/package-summary.html">org.apache.hadoop.hdfs.server.namenode</A> 中的 接口<DD>This interface is used for retrieving the load related statistics of 
 the cluster.<DT><A HREF="./org/apache/hadoop/hdfs/protocol/FSConstants.html" title="org.apache.hadoop.hdfs.protocol 中的接口"><B>FSConstants</B></A> - <A HREF="./org/apache/hadoop/hdfs/protocol/package-summary.html">org.apache.hadoop.hdfs.protocol</A> 中的 接口<DD>Some handy constants<DT><A HREF="./org/apache/hadoop/hdfs/protocol/FSConstants.DatanodeReportType.html" title="org.apache.hadoop.hdfs.protocol 中的枚举"><B>FSConstants.DatanodeReportType</B></A> - <A HREF="./org/apache/hadoop/hdfs/protocol/package-summary.html">org.apache.hadoop.hdfs.protocol</A> 中的 枚举<DD>&nbsp;<DT><A HREF="./org/apache/hadoop/hdfs/protocol/FSConstants.SafeModeAction.html" title="org.apache.hadoop.hdfs.protocol 中的枚举"><B>FSConstants.SafeModeAction</B></A> - <A HREF="./org/apache/hadoop/hdfs/protocol/package-summary.html">org.apache.hadoop.hdfs.protocol</A> 中的 枚举<DD>&nbsp;<DT><A HREF="./org/apache/hadoop/hdfs/protocol/FSConstants.UpgradeAction.html" title="org.apache.hadoop.hdfs.protocol 中的枚举"><B>FSConstants.UpgradeAction</B></A> - <A HREF="./org/apache/hadoop/hdfs/protocol/package-summary.html">org.apache.hadoop.hdfs.protocol</A> 中的 枚举<DD>Distributed upgrade actions:
 
 1.<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDataset.html" title="org.apache.hadoop.hdfs.server.datanode 中的类"><B>FSDataset</B></A> - <A HREF="./org/apache/hadoop/hdfs/server/datanode/package-summary.html">org.apache.hadoop.hdfs.server.datanode</A> 中的 类<DD>FSDataset manages a set of data blocks.<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDataset.html#FSDataset(org.apache.hadoop.hdfs.server.datanode.DataStorage, org.apache.hadoop.conf.Configuration)"><B>FSDataset(DataStorage, Configuration)</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDataset.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">FSDataset</A> 的构造方法
<DD>An FSDataset has a directory where it loads its data files.
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.html" title="org.apache.hadoop.hdfs.server.datanode 中的接口"><B>FSDatasetInterface</B></A> - <A HREF="./org/apache/hadoop/hdfs/server/datanode/package-summary.html">org.apache.hadoop.hdfs.server.datanode</A> 中的 接口<DD>This is an interface for the underlying storage that stores blocks for
 a data node.<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.BlockInputStreams.html" title="org.apache.hadoop.hdfs.server.datanode 中的类"><B>FSDatasetInterface.BlockInputStreams</B></A> - <A HREF="./org/apache/hadoop/hdfs/server/datanode/package-summary.html">org.apache.hadoop.hdfs.server.datanode</A> 中的 类<DD>This class contains the input streams for the data and checksum
 of a block<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.BlockWriteStreams.html" title="org.apache.hadoop.hdfs.server.datanode 中的类"><B>FSDatasetInterface.BlockWriteStreams</B></A> - <A HREF="./org/apache/hadoop/hdfs/server/datanode/package-summary.html">org.apache.hadoop.hdfs.server.datanode</A> 中的 类<DD>This class contains the output streams for the data and checksum
 of a block<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.MetaDataInputStream.html" title="org.apache.hadoop.hdfs.server.datanode 中的类"><B>FSDatasetInterface.MetaDataInputStream</B></A> - <A HREF="./org/apache/hadoop/hdfs/server/datanode/package-summary.html">org.apache.hadoop.hdfs.server.datanode</A> 中的 类<DD>This class provides the input stream and length of the metadata
 of a block<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/metrics/FSDatasetMBean.html" title="org.apache.hadoop.hdfs.server.datanode.metrics 中的接口"><B>FSDatasetMBean</B></A> - <A HREF="./org/apache/hadoop/hdfs/server/datanode/metrics/package-summary.html">org.apache.hadoop.hdfs.server.datanode.metrics</A> 中的 接口<DD>This Interface defines the methods to get the status of a the FSDataset of
 a data node.<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FSEditLog.html" title="org.apache.hadoop.hdfs.server.namenode 中的类"><B>FSEditLog</B></A> - <A HREF="./org/apache/hadoop/hdfs/server/namenode/package-summary.html">org.apache.hadoop.hdfs.server.namenode</A> 中的 类<DD>FSEditLog maintains a log of the namespace modifications.<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FSEditLogLoader.html" title="org.apache.hadoop.hdfs.server.namenode 中的类"><B>FSEditLogLoader</B></A> - <A HREF="./org/apache/hadoop/hdfs/server/namenode/package-summary.html">org.apache.hadoop.hdfs.server.namenode</A> 中的 类<DD>&nbsp;<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FSEditLogLoader.html#FSEditLogLoader(org.apache.hadoop.hdfs.server.namenode.FSNamesystem)"><B>FSEditLogLoader(FSNamesystem)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/FSEditLogLoader.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FSEditLogLoader</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FSImage.html" title="org.apache.hadoop.hdfs.server.namenode 中的类"><B>FSImage</B></A> - <A HREF="./org/apache/hadoop/hdfs/server/namenode/package-summary.html">org.apache.hadoop.hdfs.server.namenode</A> 中的 类<DD>FSImage handles checkpointing and logging of the namespace edits.<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FSImage.html#FSImage(org.apache.hadoop.hdfs.server.common.StorageInfo)"><B>FSImage(StorageInfo)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/FSImage.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FSImage</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/metrics/NameNodeMetrics.html#fsImageLoadTime"><B>fsImageLoadTime</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.metrics.<A HREF="./org/apache/hadoop/hdfs/server/namenode/metrics/NameNodeMetrics.html" title="org.apache.hadoop.hdfs.server.namenode.metrics 中的类">NameNodeMetrics</A> 中的变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FSImageSerialization.html" title="org.apache.hadoop.hdfs.server.namenode 中的类"><B>FSImageSerialization</B></A> - <A HREF="./org/apache/hadoop/hdfs/server/namenode/package-summary.html">org.apache.hadoop.hdfs.server.namenode</A> 中的 类<DD>Static utility functions for serializing various pieces of data in the correct
 format for the FSImage file.<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FSInodeInfo.html" title="org.apache.hadoop.hdfs.server.namenode 中的接口"><B>FSInodeInfo</B></A> - <A HREF="./org/apache/hadoop/hdfs/server/namenode/package-summary.html">org.apache.hadoop.hdfs.server.namenode</A> 中的 接口<DD>This interface is used used the pluggable block placement policy
 to expose a few characteristics of an Inode.<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html" title="org.apache.hadoop.hdfs.server.namenode 中的类"><B>FSNamesystem</B></A> - <A HREF="./org/apache/hadoop/hdfs/server/namenode/package-summary.html">org.apache.hadoop.hdfs.server.namenode</A> 中的 类<DD>FSNamesystem does the actual bookkeeping work for the
 DataNode.<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/metrics/FSNamesystemMBean.html" title="org.apache.hadoop.hdfs.server.namenode.metrics 中的接口"><B>FSNamesystemMBean</B></A> - <A HREF="./org/apache/hadoop/hdfs/server/namenode/metrics/package-summary.html">org.apache.hadoop.hdfs.server.namenode.metrics</A> 中的 接口<DD>This Interface defines the methods to get the status of a the FSNamesystem of
 a name node.<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/metrics/FSNamesystemMetrics.html" title="org.apache.hadoop.hdfs.server.namenode.metrics 中的类"><B>FSNamesystemMetrics</B></A> - <A HREF="./org/apache/hadoop/hdfs/server/namenode/metrics/package-summary.html">org.apache.hadoop.hdfs.server.namenode.metrics</A> 中的 类<DD>This class is for maintaining  the various FSNamesystem status metrics
 and publishing them through the metrics interfaces.<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/metrics/FSNamesystemMetrics.html#FSNamesystemMetrics(org.apache.hadoop.hdfs.server.namenode.FSNamesystem, org.apache.hadoop.conf.Configuration)"><B>FSNamesystemMetrics(FSNamesystem, Configuration)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.metrics.<A HREF="./org/apache/hadoop/hdfs/server/namenode/metrics/FSNamesystemMetrics.html" title="org.apache.hadoop.hdfs.server.namenode.metrics 中的类">FSNamesystemMetrics</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/ClientProtocol.html#fsync(java.lang.String, java.lang.String)"><B>fsync(String, String)</B></A> - 
接口 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/ClientProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的接口">ClientProtocol</A> 中的方法
<DD>Write all metadata for this file into persistent storage.
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html#fsync(java.lang.String, java.lang.String)"><B>fsync(String, String)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">NameNode</A> 中的方法
<DD>Write all metadata for this file into persistent storage.
</DL>
<HR>
<A NAME="_G_"><!-- --></A><H2>
<B>G</B></H2>
<DL>
<DT><A HREF="./org/apache/hadoop/hdfs/security/token/block/BlockTokenSecretManager.html#generateToken(org.apache.hadoop.hdfs.protocol.Block, java.util.EnumSet)"><B>generateToken(Block, EnumSet&lt;BlockTokenSecretManager.AccessMode&gt;)</B></A> - 
类 org.apache.hadoop.hdfs.security.token.block.<A HREF="./org/apache/hadoop/hdfs/security/token/block/BlockTokenSecretManager.html" title="org.apache.hadoop.hdfs.security.token.block 中的类">BlockTokenSecretManager</A> 中的方法
<DD>Generate an block token for current user
<DT><A HREF="./org/apache/hadoop/hdfs/security/token/block/BlockTokenSecretManager.html#generateToken(java.lang.String, org.apache.hadoop.hdfs.protocol.Block, java.util.EnumSet)"><B>generateToken(String, Block, EnumSet&lt;BlockTokenSecretManager.AccessMode&gt;)</B></A> - 
类 org.apache.hadoop.hdfs.security.token.block.<A HREF="./org/apache/hadoop/hdfs/security/token/block/BlockTokenSecretManager.html" title="org.apache.hadoop.hdfs.security.token.block 中的类">BlockTokenSecretManager</A> 中的方法
<DD>Generate a block token for a specified user
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/GenerationStamp.html" title="org.apache.hadoop.hdfs.server.common 中的类"><B>GenerationStamp</B></A> - <A HREF="./org/apache/hadoop/hdfs/server/common/package-summary.html">org.apache.hadoop.hdfs.server.common</A> 中的 类<DD>A GenerationStamp is a Hadoop FS primitive, identified by a long.<DT><A HREF="./org/apache/hadoop/hdfs/server/common/GenerationStamp.html#GenerationStamp()"><B>GenerationStamp()</B></A> - 
类 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/GenerationStamp.html" title="org.apache.hadoop.hdfs.server.common 中的类">GenerationStamp</A> 的构造方法
<DD>Create a new instance, initialized to FIRST_VALID_STAMP.
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/LocatedBlocks.html#get(int)"><B>get(int)</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/LocatedBlocks.html" title="org.apache.hadoop.hdfs.protocol 中的类">LocatedBlocks</A> 中的方法
<DD>Get located block.
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/HeaderBuffer.html#get(org.apache.hadoop.hdfs.server.namenode.INode)"><B>get(INode)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/HeaderBuffer.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">HeaderBuffer</A> 中的方法
<DD>get the BufferData with the filepath,if not exist in the entries,
 find from the bufferStorage file.
<DT><A HREF="./org/apache/hadoop/hdfs/util/GSet.html#get(K)"><B>get(K)</B></A> - 
接口 org.apache.hadoop.hdfs.util.<A HREF="./org/apache/hadoop/hdfs/util/GSet.html" title="org.apache.hadoop.hdfs.util 中的接口">GSet</A> 中的方法
<DD>Return the stored element which is equal to the given key.
<DT><A HREF="./org/apache/hadoop/hdfs/util/GSetByHashMap.html#get(K)"><B>get(K)</B></A> - 
类 org.apache.hadoop.hdfs.util.<A HREF="./org/apache/hadoop/hdfs/util/GSetByHashMap.html" title="org.apache.hadoop.hdfs.util 中的类">GSetByHashMap</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/util/LightWeightGSet.html#get(K)"><B>get(K)</B></A> - 
类 org.apache.hadoop.hdfs.util.<A HREF="./org/apache/hadoop/hdfs/util/LightWeightGSet.html" title="org.apache.hadoop.hdfs.util 中的类">LightWeightGSet</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/ClientProtocol.html#GET_STATS_CAPACITY_IDX"><B>GET_STATS_CAPACITY_IDX</B></A> - 
接口 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/ClientProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的接口">ClientProtocol</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/ClientProtocol.html#GET_STATS_CORRUPT_BLOCKS_IDX"><B>GET_STATS_CORRUPT_BLOCKS_IDX</B></A> - 
接口 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/ClientProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的接口">ClientProtocol</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/ClientProtocol.html#GET_STATS_MISSING_BLOCKS_IDX"><B>GET_STATS_MISSING_BLOCKS_IDX</B></A> - 
接口 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/ClientProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的接口">ClientProtocol</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/ClientProtocol.html#GET_STATS_REMAINING_IDX"><B>GET_STATS_REMAINING_IDX</B></A> - 
接口 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/ClientProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的接口">ClientProtocol</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/ClientProtocol.html#GET_STATS_UNDER_REPLICATED_IDX"><B>GET_STATS_UNDER_REPLICATED_IDX</B></A> - 
接口 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/ClientProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的接口">ClientProtocol</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/ClientProtocol.html#GET_STATS_USED_IDX"><B>GET_STATS_USED_IDX</B></A> - 
接口 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/ClientProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的接口">ClientProtocol</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/CodingMatrix.html#getA()"><B>getA()</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/CodingMatrix.html" title="org.apache.hadoop.hdfs.protocol 中的类">CodingMatrix</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/RegeneratingCodeMatrix.html#getA()"><B>getA()</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/RegeneratingCodeMatrix.html" title="org.apache.hadoop.hdfs.protocol 中的类">RegeneratingCodeMatrix</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/HsftpFileSystem.DummyTrustManager.html#getAcceptedIssuers()"><B>getAcceptedIssuers()</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/HsftpFileSystem.DummyTrustManager.html" title="org.apache.hadoop.hdfs 中的类">HsftpFileSystem.DummyTrustManager</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/security/token/block/BlockTokenIdentifier.html#getAccessModes()"><B>getAccessModes()</B></A> - 
类 org.apache.hadoop.hdfs.security.token.block.<A HREF="./org/apache/hadoop/hdfs/security/token/block/BlockTokenIdentifier.html" title="org.apache.hadoop.hdfs.security.token.block 中的类">BlockTokenIdentifier</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/HdfsFileStatus.html#getAccessTime()"><B>getAccessTime()</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/HdfsFileStatus.html" title="org.apache.hadoop.hdfs.protocol 中的类">HdfsFileStatus</A> 中的方法
<DD>Get the access time of the file.
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/ServerCommand.html#getAction()"><B>getAction()</B></A> - 
类 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/ServerCommand.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">ServerCommand</A> 中的方法
<DD>Get server command action.
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#getAdditionalBlock(java.lang.String, java.lang.String, org.apache.hadoop.hdfs.protocol.Block, java.util.HashMap)"><B>getAdditionalBlock(String, String, Block, HashMap&lt;Node, Node&gt;)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FSNamesystem</A> 中的方法
<DD>The client would like to obtain an additional block for the indicated
 filename (which is being written-to).
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#getAdditionalBlock(boolean, java.lang.String, java.lang.String, org.apache.hadoop.hdfs.protocol.Block, java.util.HashMap)"><B>getAdditionalBlock(boolean, String, String, Block, HashMap&lt;Node, Node&gt;)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FSNamesystem</A> 中的方法
<DD>This method is a overload one of getAdditionalBlock(...).
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html#getAddress(java.lang.String)"><B>getAddress(String)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">NameNode</A> 中的静态方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html#getAddress(org.apache.hadoop.conf.Configuration)"><B>getAddress(Configuration)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">NameNode</A> 中的静态方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/DatanodeRegistration.html#getAddress()"><B>getAddress()</B></A> - 
类 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/DatanodeRegistration.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">DatanodeRegistration</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/NamenodeRegistration.html#getAddress()"><B>getAddress()</B></A> - 
类 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/NamenodeRegistration.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">NamenodeRegistration</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/NodeRegistration.html#getAddress()"><B>getAddress()</B></A> - 
接口 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/NodeRegistration.html" title="org.apache.hadoop.hdfs.server.protocol 中的接口">NodeRegistration</A> 中的方法
<DD>Get address of the server node.
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/ClientProtocol.html#getAllBlocksLocations(java.lang.String)"><B>getAllBlocksLocations(String)</B></A> - 
接口 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/ClientProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的接口">ClientProtocol</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html#getAllBlocksLocations(java.lang.String)"><B>getAllBlocksLocations(String)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">NameNode</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#getAllBlocksLocationsInternal(java.lang.String)"><B>getAllBlocksLocationsInternal(String)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FSNamesystem</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/security/token/block/ExportedBlockKeys.html#getAllKeys()"><B>getAllKeys()</B></A> - 
类 org.apache.hadoop.hdfs.security.token.block.<A HREF="./org/apache/hadoop/hdfs/security/token/block/ExportedBlockKeys.html" title="org.apache.hadoop.hdfs.security.token.block 中的类">ExportedBlockKeys</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeCPUStatus.html#getAvgCPURate()"><B>getAvgCPURate()</B></A> - 
类 org.apache.hadoop.hdfs.server.monitor.<A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeCPUStatus.html" title="org.apache.hadoop.hdfs.server.monitor 中的类">ServernodeCPUStatus</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeIOStatus.html#getAvgIORate()"><B>getAvgIORate()</B></A> - 
类 org.apache.hadoop.hdfs.server.monitor.<A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeIOStatus.html" title="org.apache.hadoop.hdfs.server.monitor 中的类">ServernodeIOStatus</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeMEMStatus.html#getAvgMEMRate()"><B>getAvgMEMRate()</B></A> - 
类 org.apache.hadoop.hdfs.server.monitor.<A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeMEMStatus.html" title="org.apache.hadoop.hdfs.server.monitor 中的类">ServernodeMEMStatus</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeNETStatus.html#getAvgNETRxRate()"><B>getAvgNETRxRate()</B></A> - 
类 org.apache.hadoop.hdfs.server.monitor.<A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeNETStatus.html" title="org.apache.hadoop.hdfs.server.monitor 中的类">ServernodeNETStatus</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeNETStatus.html#getAvgNETTxRate()"><B>getAvgNETTxRate()</B></A> - 
类 org.apache.hadoop.hdfs.server.monitor.<A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeNETStatus.html" title="org.apache.hadoop.hdfs.server.monitor 中的类">ServernodeNETStatus</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/CodingMatrix.html#getB()"><B>getB()</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/CodingMatrix.html" title="org.apache.hadoop.hdfs.protocol 中的类">CodingMatrix</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/RegeneratingCodeMatrix.html#getB()"><B>getB()</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/RegeneratingCodeMatrix.html" title="org.apache.hadoop.hdfs.protocol 中的类">RegeneratingCodeMatrix</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeNETStatus.html#getBandwidth()"><B>getBandwidth()</B></A> - 
类 org.apache.hadoop.hdfs.server.monitor.<A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeNETStatus.html" title="org.apache.hadoop.hdfs.server.monitor 中的类">ServernodeNETStatus</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/util/DataTransferThrottler.html#getBandwidth()"><B>getBandwidth()</B></A> - 
类 org.apache.hadoop.hdfs.util.<A HREF="./org/apache/hadoop/hdfs/util/DataTransferThrottler.html" title="org.apache.hadoop.hdfs.util 中的类">DataTransferThrottler</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/LocatedBlock.html#getBlock()"><B>getBlock()</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/LocatedBlock.html" title="org.apache.hadoop.hdfs.protocol 中的类">LocatedBlock</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/BlocksWithLocations.BlockWithLocations.html#getBlock()"><B>getBlock()</B></A> - 
类 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/BlocksWithLocations.BlockWithLocations.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">BlocksWithLocations.BlockWithLocations</A> 中的方法
<DD>get the block
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#getBlockCapacity()"><B>getBlockCapacity()</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FSNamesystem</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDataset.html#getBlockFile(org.apache.hadoop.hdfs.protocol.Block)"><B>getBlockFile(Block)</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDataset.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">FSDataset</A> 中的方法
<DD>Get File name for a given block.
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/BlockListAsLongs.html#getBlockGenStamp(int)"><B>getBlockGenStamp(int)</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/BlockListAsLongs.html" title="org.apache.hadoop.hdfs.protocol 中的类">BlockListAsLongs</A> 中的方法
<DD><B>已过时。</B>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/Block.html#getBlockId(java.lang.String)"><B>getBlockId(String)</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/Block.html" title="org.apache.hadoop.hdfs.protocol 中的类">Block</A> 中的静态方法
<DD>Get the blockId from the name of the metafile name
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/Block.html#getBlockId()"><B>getBlockId()</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/Block.html" title="org.apache.hadoop.hdfs.protocol 中的类">Block</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/BlockListAsLongs.html#getBlockId(int)"><B>getBlockId(int)</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/BlockListAsLongs.html" title="org.apache.hadoop.hdfs.protocol 中的类">BlockListAsLongs</A> 中的方法
<DD><B>已过时。</B>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/security/token/block/BlockTokenIdentifier.html#getBlockId()"><B>getBlockId()</B></A> - 
类 org.apache.hadoop.hdfs.security.token.block.<A HREF="./org/apache/hadoop/hdfs/security/token/block/BlockTokenIdentifier.html" title="org.apache.hadoop.hdfs.security.token.block 中的类">BlockTokenIdentifier</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/Replica.html#getBlockId()"><B>getBlockId()</B></A> - 
接口 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/Replica.html" title="org.apache.hadoop.hdfs.server.datanode 中的接口">Replica</A> 中的方法
<DD>Get the block ID
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDataset.html#getBlockInputStream(org.apache.hadoop.hdfs.protocol.Block)"><B>getBlockInputStream(Block)</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDataset.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">FSDataset</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDataset.html#getBlockInputStream(org.apache.hadoop.hdfs.protocol.Block, long)"><B>getBlockInputStream(Block, long)</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDataset.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">FSDataset</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.html#getBlockInputStream(org.apache.hadoop.hdfs.protocol.Block)"><B>getBlockInputStream(Block)</B></A> - 
接口 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.html" title="org.apache.hadoop.hdfs.server.datanode 中的接口">FSDatasetInterface</A> 中的方法
<DD>Returns an input stream to read the contents of the specified block
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.html#getBlockInputStream(org.apache.hadoop.hdfs.protocol.Block, long)"><B>getBlockInputStream(Block, long)</B></A> - 
接口 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.html" title="org.apache.hadoop.hdfs.server.datanode 中的接口">FSDatasetInterface</A> 中的方法
<DD>Returns an input stream at specified offset of the specified block
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html#getBlockKeys()"><B>getBlockKeys()</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">NameNode</A> 中的方法
<DD>Get the current block keys
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/NamenodeProtocol.html#getBlockKeys()"><B>getBlockKeys()</B></A> - 
接口 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/NamenodeProtocol.html" title="org.apache.hadoop.hdfs.server.protocol 中的接口">NamenodeProtocol</A> 中的方法
<DD>Get the current block keys
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/BlockListAsLongs.html#getBlockLen(int)"><B>getBlockLen(int)</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/BlockListAsLongs.html" title="org.apache.hadoop.hdfs.protocol 中的类">BlockListAsLongs</A> 中的方法
<DD><B>已过时。</B>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/BlockListAsLongs.html#getBlockListAsLongs()"><B>getBlockListAsLongs()</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/BlockListAsLongs.html" title="org.apache.hadoop.hdfs.protocol 中的类">BlockListAsLongs</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSClient.html#getBlockLocations(java.lang.String, long, long)"><B>getBlockLocations(String, long, long)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSClient.html" title="org.apache.hadoop.hdfs 中的类">DFSClient</A> 中的方法
<DD>Get block location info about file
 
 getBlockLocations() returns a list of hostnames that store 
 data for a specific file region.
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/ClientProtocol.html#getBlockLocations(java.lang.String, long, long)"><B>getBlockLocations(String, long, long)</B></A> - 
接口 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/ClientProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的接口">ClientProtocol</A> 中的方法
<DD>Get locations of the blocks of the specified file within the specified range.
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/HdfsLocatedFileStatus.html#getBlockLocations()"><B>getBlockLocations()</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/HdfsLocatedFileStatus.html" title="org.apache.hadoop.hdfs.protocol 中的类">HdfsLocatedFileStatus</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html#getBlockLocations(java.lang.String, long, long)"><B>getBlockLocations(String, long, long)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">NameNode</A> 中的方法
<DD>Get locations of the blocks of the specified file within the specified range.
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/Block.html#getBlockName()"><B>getBlockName()</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/Block.html" title="org.apache.hadoop.hdfs.protocol 中的类">Block</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSInputStream.html#getBlockReader(java.net.InetSocketAddress, java.lang.String, org.apache.hadoop.hdfs.protocol.Block, org.apache.hadoop.security.token.Token, long, long, int, boolean, java.lang.String)"><B>getBlockReader(InetSocketAddress, String, Block, Token&lt;BlockTokenIdentifier&gt;, long, long, int, boolean, String)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSInputStream.html" title="org.apache.hadoop.hdfs 中的类">DFSInputStream</A> 中的方法
<DD>Retrieve a BlockReader suitable for reading.
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDataset.html#getBlockReport()"><B>getBlockReport()</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDataset.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">FSDataset</A> 中的方法
<DD>Generates a block report from the in-memory block map.
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.html#getBlockReport()"><B>getBlockReport()</B></A> - 
接口 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.html" title="org.apache.hadoop.hdfs.server.datanode 中的接口">FSDatasetInterface</A> 中的方法
<DD>Returns the block report - the full list of blocks stored
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/BlockListAsLongs.html#getBlockReportIterator()"><B>getBlockReportIterator()</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/BlockListAsLongs.html" title="org.apache.hadoop.hdfs.protocol 中的类">BlockListAsLongs</A> 中的方法
<DD>Returns <A HREF="./org/apache/hadoop/hdfs/protocol/BlockListAsLongs.BlockReportIterator.html" title="org.apache.hadoop.hdfs.protocol 中的类"><CODE>BlockListAsLongs.BlockReportIterator</CODE></A>.
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/BackupNode.html#getBlocks(org.apache.hadoop.hdfs.protocol.DatanodeInfo, long)"><B>getBlocks(DatanodeInfo, long)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/BackupNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">BackupNode</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html#getBlocks(org.apache.hadoop.hdfs.protocol.DatanodeInfo, long)"><B>getBlocks(DatanodeInfo, long)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">NameNode</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/BlockCommand.html#getBlocks()"><B>getBlocks()</B></A> - 
类 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/BlockCommand.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">BlockCommand</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/BlocksWithLocations.html#getBlocks()"><B>getBlocks()</B></A> - 
类 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/BlocksWithLocations.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">BlocksWithLocations</A> 中的方法
<DD>getter
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/NamenodeProtocol.html#getBlocks(org.apache.hadoop.hdfs.protocol.DatanodeInfo, long)"><B>getBlocks(DatanodeInfo, long)</B></A> - 
接口 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/NamenodeProtocol.html" title="org.apache.hadoop.hdfs.server.protocol 中的接口">NamenodeProtocol</A> 中的方法
<DD>Get a list of blocks belonging to <code>datanode</code>
 whose total size equals <code>size</code>.
<DT><A HREF="./org/apache/hadoop/hdfs/DFSClient.html#getBlockSize(java.lang.String)"><B>getBlockSize(String)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSClient.html" title="org.apache.hadoop.hdfs 中的类">DFSClient</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/HdfsFileStatus.html#getBlockSize()"><B>getBlockSize()</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/HdfsFileStatus.html" title="org.apache.hadoop.hdfs.protocol 中的类">HdfsFileStatus</A> 中的方法
<DD>Get the block size of the file.
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/LocatedBlock.html#getBlockSize()"><B>getBlockSize()</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/LocatedBlock.html" title="org.apache.hadoop.hdfs.protocol 中的类">LocatedBlock</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/DatanodeDescriptor.html#getBlocksScheduled()"><B>getBlocksScheduled()</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/DatanodeDescriptor.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">DatanodeDescriptor</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#getBlocksTotal()"><B>getBlocksTotal()</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FSNamesystem</A> 中的方法
<DD>Get the total number of blocks in the system.
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/metrics/FSNamesystemMBean.html#getBlocksTotal()"><B>getBlocksTotal()</B></A> - 
接口 org.apache.hadoop.hdfs.server.namenode.metrics.<A HREF="./org/apache/hadoop/hdfs/server/namenode/metrics/FSNamesystemMBean.html" title="org.apache.hadoop.hdfs.server.namenode.metrics 中的接口">FSNamesystemMBean</A> 中的方法
<DD>Number of allocated blocks in the system
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/LocatedBlock.html#getBlockToken()"><B>getBlockToken()</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/LocatedBlock.html" title="org.apache.hadoop.hdfs.protocol 中的类">LocatedBlock</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/UpgradeManager.html#getBroadcastCommand()"><B>getBroadcastCommand()</B></A> - 
类 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/UpgradeManager.html" title="org.apache.hadoop.hdfs.server.common 中的类">UpgradeManager</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FSImage.html#getBufferStorage()"><B>getBufferStorage()</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/FSImage.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FSImage</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/Storage.html#getBuildVersion()"><B>getBuildVersion()</B></A> - 
类 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/Storage.html" title="org.apache.hadoop.hdfs.server.common 中的类">Storage</A> 中的静态方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/NamespaceInfo.html#getBuildVersion()"><B>getBuildVersion()</B></A> - 
类 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/NamespaceInfo.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">NamespaceInfo</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/security/token/block/BlockTokenIdentifier.html#getBytes()"><B>getBytes()</B></A> - 
类 org.apache.hadoop.hdfs.security.token.block.<A HREF="./org/apache/hadoop/hdfs/security/token/block/BlockTokenIdentifier.html" title="org.apache.hadoop.hdfs.security.token.block 中的类">BlockTokenIdentifier</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/util/ByteArray.html#getBytes()"><B>getBytes()</B></A> - 
类 org.apache.hadoop.hdfs.util.<A HREF="./org/apache/hadoop/hdfs/util/ByteArray.html" title="org.apache.hadoop.hdfs.util 中的类">ByteArray</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/Replica.html#getBytesOnDisk()"><B>getBytesOnDisk()</B></A> - 
接口 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/Replica.html" title="org.apache.hadoop.hdfs.server.datanode 中的接口">Replica</A> 中的方法
<DD>Get the number of bytes that have written to disk
<DT><A HREF="./org/apache/hadoop/hdfs/HftpFileSystem.html#getCanonicalServiceName()"><B>getCanonicalServiceName()</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/HftpFileSystem.html" title="org.apache.hadoop.hdfs 中的类">HftpFileSystem</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeInfo.html#getCapacity()"><B>getCapacity()</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeInfo.html" title="org.apache.hadoop.hdfs.protocol 中的类">DatanodeInfo</A> 中的方法
<DD>The raw capacity.
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDataset.html#getCapacity()"><B>getCapacity()</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDataset.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">FSDataset</A> 中的方法
<DD>Return total capacity, used and unused
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/metrics/FSDatasetMBean.html#getCapacity()"><B>getCapacity()</B></A> - 
接口 org.apache.hadoop.hdfs.server.datanode.metrics.<A HREF="./org/apache/hadoop/hdfs/server/datanode/metrics/FSDatasetMBean.html" title="org.apache.hadoop.hdfs.server.datanode.metrics 中的接口">FSDatasetMBean</A> 中的方法
<DD>Returns total capacity (in bytes) of storage (used and unused)
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#getCapacityRemaining()"><B>getCapacityRemaining()</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FSNamesystem</A> 中的方法
<DD>Total non-used raw bytes.
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/metrics/FSNamesystemMBean.html#getCapacityRemaining()"><B>getCapacityRemaining()</B></A> - 
接口 org.apache.hadoop.hdfs.server.namenode.metrics.<A HREF="./org/apache/hadoop/hdfs/server/namenode/metrics/FSNamesystemMBean.html" title="org.apache.hadoop.hdfs.server.namenode.metrics 中的接口">FSNamesystemMBean</A> 中的方法
<DD>Free (unused) storage capacity
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#getCapacityRemainingPercent()"><B>getCapacityRemainingPercent()</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FSNamesystem</A> 中的方法
<DD>Total remaining space by data nodes as percentage of total capacity
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#getCapacityTotal()"><B>getCapacityTotal()</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FSNamesystem</A> 中的方法
<DD>Total raw bytes including non-dfs used space.
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/metrics/FSNamesystemMBean.html#getCapacityTotal()"><B>getCapacityTotal()</B></A> - 
接口 org.apache.hadoop.hdfs.server.namenode.metrics.<A HREF="./org/apache/hadoop/hdfs/server/namenode/metrics/FSNamesystemMBean.html" title="org.apache.hadoop.hdfs.server.namenode.metrics 中的接口">FSNamesystemMBean</A> 中的方法
<DD>Total storage capacity
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#getCapacityUsed()"><B>getCapacityUsed()</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FSNamesystem</A> 中的方法
<DD>Total used space by data nodes
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/metrics/FSNamesystemMBean.html#getCapacityUsed()"><B>getCapacityUsed()</B></A> - 
接口 org.apache.hadoop.hdfs.server.namenode.metrics.<A HREF="./org/apache/hadoop/hdfs/server/namenode/metrics/FSNamesystemMBean.html" title="org.apache.hadoop.hdfs.server.namenode.metrics 中的接口">FSNamesystemMBean</A> 中的方法
<DD>Used storage capacity
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#getCapacityUsedNonDFS()"><B>getCapacityUsedNonDFS()</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FSNamesystem</A> 中的方法
<DD>Total used space by data nodes for non DFS purposes such
 as storing temporary files on the local file system
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#getCapacityUsedPercent()"><B>getCapacityUsedPercent()</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FSNamesystem</A> 中的方法
<DD>Total used space by data nodes as percentage of total capacity
<DT><A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeNETStatus.html#getCardname()"><B>getCardname()</B></A> - 
类 org.apache.hadoop.hdfs.server.monitor.<A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeNETStatus.html" title="org.apache.hadoop.hdfs.server.monitor 中的类">ServernodeNETStatus</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/NamenodeRegistration.html#getCheckpointTime()"><B>getCheckpointTime()</B></A> - 
类 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/NamenodeRegistration.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">NamenodeRegistration</A> 中的方法
<DD>Get the age of the image.
<DT><A HREF="./org/apache/hadoop/hdfs/BlockReader.html#getChunkPosition(long)"><B>getChunkPosition(long)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/BlockReader.html" title="org.apache.hadoop.hdfs 中的类">BlockReader</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DistributedFileSystem.html#getClient()"><B>getClient()</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DistributedFileSystem.html" title="org.apache.hadoop.hdfs 中的类">DistributedFileSystem</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/CodingMatrix.html#getCodingFactorList(int)"><B>getCodingFactorList(int)</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/CodingMatrix.html" title="org.apache.hadoop.hdfs.protocol 中的类">CodingMatrix</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/ClientProtocol.html#getCodingMatrix(java.lang.String)"><B>getCodingMatrix(String)</B></A> - 
接口 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/ClientProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的接口">ClientProtocol</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/CodingMatrix.html#getCodingmatrix()"><B>getCodingmatrix()</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/CodingMatrix.html" title="org.apache.hadoop.hdfs.protocol 中的类">CodingMatrix</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#getCodingMatrix(java.lang.String)"><B>getCodingMatrix(String)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FSNamesystem</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html#getCodingMatrix(java.lang.String)"><B>getCodingMatrix(String)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">NameNode</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/CodingMatrix.html#getColumn()"><B>getColumn()</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/CodingMatrix.html" title="org.apache.hadoop.hdfs.protocol 中的类">CodingMatrix</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/balancer/Balancer.html#getConf()"><B>getConf()</B></A> - 
类 org.apache.hadoop.hdfs.server.balancer.<A HREF="./org/apache/hadoop/hdfs/server/balancer/Balancer.html" title="org.apache.hadoop.hdfs.server.balancer 中的类">Balancer</A> 中的方法
<DD>return this balancer's configuration
<DT><A HREF="./org/apache/hadoop/hdfs/DistributedFileSystem.html#getContentSummary(org.apache.hadoop.fs.Path)"><B>getContentSummary(Path)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DistributedFileSystem.html" title="org.apache.hadoop.hdfs 中的类">DistributedFileSystem</A> 中的方法
<DD>
<DT><A HREF="./org/apache/hadoop/hdfs/HftpFileSystem.html#getContentSummary(org.apache.hadoop.fs.Path)"><B>getContentSummary(Path)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/HftpFileSystem.html" title="org.apache.hadoop.hdfs 中的类">HftpFileSystem</A> 中的方法
<DD>
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/ClientProtocol.html#getContentSummary(java.lang.String)"><B>getContentSummary(String)</B></A> - 
接口 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/ClientProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的接口">ClientProtocol</A> 中的方法
<DD>Get <CODE>ContentSummary</CODE> rooted at the specified directory.
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html#getContentSummary(java.lang.String)"><B>getContentSummary(String)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">NameNode</A> 中的方法
<DD>Get <CODE>ContentSummary</CODE> rooted at the specified directory.
<DT><A HREF="./org/apache/hadoop/hdfs/DFSClient.html#getCorruptBlocksCount()"><B>getCorruptBlocksCount()</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSClient.html" title="org.apache.hadoop.hdfs 中的类">DFSClient</A> 中的方法
<DD>Returns count of blocks with at least one replica marked corrupt.
<DT><A HREF="./org/apache/hadoop/hdfs/DistributedFileSystem.html#getCorruptBlocksCount()"><B>getCorruptBlocksCount()</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DistributedFileSystem.html" title="org.apache.hadoop.hdfs 中的类">DistributedFileSystem</A> 中的方法
<DD>Returns count of blocks with at least one replica marked corrupt.
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#getCorruptReplicaBlocks()"><B>getCorruptReplicaBlocks()</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FSNamesystem</A> 中的方法
<DD>Returns number of blocks with corrupt replicas
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeInfo.html#getCPUStatus()"><B>getCPUStatus()</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeInfo.html" title="org.apache.hadoop.hdfs.protocol 中的类">DatanodeInfo</A> 中的方法
<DD>get the cpu status of datanode
<DT><A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeStator.html#getCPUStatus()"><B>getCPUStatus()</B></A> - 
类 org.apache.hadoop.hdfs.server.monitor.<A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeStator.html" title="org.apache.hadoop.hdfs.server.monitor 中的类">ServernodeStator</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/StorageInfo.html#getCTime()"><B>getCTime()</B></A> - 
类 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/StorageInfo.html" title="org.apache.hadoop.hdfs.server.common 中的类">StorageInfo</A> 中的方法
<DD>Creation time of the file system state.
<DT><A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeCPUStatus.html#getCurCPURate()"><B>getCurCPURate()</B></A> - 
类 org.apache.hadoop.hdfs.server.monitor.<A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeCPUStatus.html" title="org.apache.hadoop.hdfs.server.monitor 中的类">ServernodeCPUStatus</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeIOStatus.html#getCurIORate()"><B>getCurIORate()</B></A> - 
类 org.apache.hadoop.hdfs.server.monitor.<A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeIOStatus.html" title="org.apache.hadoop.hdfs.server.monitor 中的类">ServernodeIOStatus</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeMEMStatus.html#getCurMEMRate()"><B>getCurMEMRate()</B></A> - 
类 org.apache.hadoop.hdfs.server.monitor.<A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeMEMStatus.html" title="org.apache.hadoop.hdfs.server.monitor 中的类">ServernodeMEMStatus</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeNETStatus.html#getCurNETRxRate()"><B>getCurNETRxRate()</B></A> - 
类 org.apache.hadoop.hdfs.server.monitor.<A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeNETStatus.html" title="org.apache.hadoop.hdfs.server.monitor 中的类">ServernodeNETStatus</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeNETStatus.html#getCurNETTxRate()"><B>getCurNETTxRate()</B></A> - 
类 org.apache.hadoop.hdfs.server.monitor.<A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeNETStatus.html" title="org.apache.hadoop.hdfs.server.monitor 中的类">ServernodeNETStatus</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSClient.DFSDataInputStream.html#getCurrentBlock()"><B>getCurrentBlock()</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSClient.DFSDataInputStream.html" title="org.apache.hadoop.hdfs 中的类">DFSClient.DFSDataInputStream</A> 中的方法
<DD>Returns the block containing the target position.
<DT><A HREF="./org/apache/hadoop/hdfs/DFSInputStream.html#getCurrentBlock()"><B>getCurrentBlock()</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSInputStream.html" title="org.apache.hadoop.hdfs 中的类">DFSInputStream</A> 中的方法
<DD>Returns the block containing the target position.
<DT><A HREF="./org/apache/hadoop/hdfs/DFSClient.DFSDataInputStream.html#getCurrentDatanode()"><B>getCurrentDatanode()</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSClient.DFSDataInputStream.html" title="org.apache.hadoop.hdfs 中的类">DFSClient.DFSDataInputStream</A> 中的方法
<DD>Returns the datanode from which the stream is currently reading.
<DT><A HREF="./org/apache/hadoop/hdfs/DFSInputStream.html#getCurrentDatanode()"><B>getCurrentDatanode()</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSInputStream.html" title="org.apache.hadoop.hdfs 中的类">DFSInputStream</A> 中的方法
<DD>Returns the datanode from which the stream is currently reading.
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/Storage.StorageDirectory.html#getCurrentDir()"><B>getCurrentDir()</B></A> - 
类 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/Storage.StorageDirectory.html" title="org.apache.hadoop.hdfs.server.common 中的类">Storage.StorageDirectory</A> 中的方法
<DD>Directory <code>current</code> contains latest files defining
 the file system meta-data.
<DT><A HREF="./org/apache/hadoop/hdfs/security/token/block/ExportedBlockKeys.html#getCurrentKey()"><B>getCurrentKey()</B></A> - 
类 org.apache.hadoop.hdfs.security.token.block.<A HREF="./org/apache/hadoop/hdfs/security/token/block/ExportedBlockKeys.html" title="org.apache.hadoop.hdfs.security.token.block 中的类">ExportedBlockKeys</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/LayoutVersion.html#getCurrentLayoutVersion()"><B>getCurrentLayoutVersion()</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/LayoutVersion.html" title="org.apache.hadoop.hdfs.protocol 中的类">LayoutVersion</A> 中的静态方法
<DD>Get the current layout version
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/BlockListAsLongs.BlockReportIterator.html#getCurrentReplicaState()"><B>getCurrentReplicaState()</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/BlockListAsLongs.BlockReportIterator.html" title="org.apache.hadoop.hdfs.protocol 中的类">BlockListAsLongs.BlockReportIterator</A> 中的方法
<DD>Get the state of the current replica.
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/UpgradeCommand.html#getCurrentStatus()"><B>getCurrentStatus()</B></A> - 
类 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/UpgradeCommand.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">UpgradeCommand</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/CodingMatrix.html#getD()"><B>getD()</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/CodingMatrix.html" title="org.apache.hadoop.hdfs.protocol 中的类">CodingMatrix</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/RegeneratingCodeMatrix.html#getD()"><B>getD()</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/RegeneratingCodeMatrix.html" title="org.apache.hadoop.hdfs.protocol 中的类">RegeneratingCodeMatrix</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DataPool.html#getData(byte[], int)"><B>getData(byte[], int)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DataPool.html" title="org.apache.hadoop.hdfs 中的类">DataPool</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.PacketHeader.html#getDataLen()"><B>getDataLen()</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.PacketHeader.html" title="org.apache.hadoop.hdfs.protocol 中的类">DataTransferProtocol.PacketHeader</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/DataNode.html#getDataNode()"><B>getDataNode()</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/DataNode.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">DataNode</A> 中的静态方法
<DD>Return the DataNode object
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/UpgradeObjectDatanode.html#getDatanode()"><B>getDatanode()</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/UpgradeObjectDatanode.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">UpgradeObjectDatanode</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#getDatanode(org.apache.hadoop.hdfs.protocol.DatanodeID)"><B>getDatanode(DatanodeID)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FSNamesystem</A> 中的方法
<DD>Get data node by storage ID.
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#getDataNodeInfo(java.lang.String)"><B>getDataNodeInfo(String)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FSNamesystem</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/DataNode.html#getDatanodeRegistration()"><B>getDatanodeRegistration()</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/DataNode.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">DataNode</A> 中的方法
<DD>Return DatanodeRegistration
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/ClientProtocol.html#getDatanodeReport(org.apache.hadoop.hdfs.protocol.FSConstants.DatanodeReportType)"><B>getDatanodeReport(FSConstants.DatanodeReportType)</B></A> - 
接口 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/ClientProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的接口">ClientProtocol</A> 中的方法
<DD>Get a report on the system's current datanodes.
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeInfo.html#getDatanodeReport()"><B>getDatanodeReport()</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeInfo.html" title="org.apache.hadoop.hdfs.protocol 中的类">DatanodeInfo</A> 中的方法
<DD>A formatted string for reporting the status of the DataNode.
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html#getDatanodeReport(org.apache.hadoop.hdfs.protocol.FSConstants.DatanodeReportType)"><B>getDatanodeReport(FSConstants.DatanodeReportType)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">NameNode</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/BlocksWithLocations.BlockWithLocations.html#getDatanodes()"><B>getDatanodes()</B></A> - 
类 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/BlocksWithLocations.BlockWithLocations.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">BlocksWithLocations.BlockWithLocations</A> 中的方法
<DD>get the block's locations
<DT><A HREF="./org/apache/hadoop/hdfs/DistributedFileSystem.html#getDataNodeStats()"><B>getDataNodeStats()</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DistributedFileSystem.html" title="org.apache.hadoop.hdfs 中的类">DistributedFileSystem</A> 中的方法
<DD>Return statistics for each datanode.
<DT><A HREF="./org/apache/hadoop/hdfs/HftpFileSystem.html#getDateFormat()"><B>getDateFormat()</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/HftpFileSystem.html" title="org.apache.hadoop.hdfs 中的类">HftpFileSystem</A> 中的静态方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#getDeadDataNodesStorageID()"><B>getDeadDataNodesStorageID()</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FSNamesystem</A> 中的方法
<DD>get the storageID of the datanodes who is/are dead
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#getDeadNodes()"><B>getDeadNodes()</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FSNamesystem</A> 中的方法
<DD>Returned information is a JSON representation of map with host name as the
 key and value is a map of dead node attribute keys to its values
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNodeMXBean.html#getDeadNodes()"><B>getDeadNodes()</B></A> - 
接口 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNodeMXBean.html" title="org.apache.hadoop.hdfs.server.namenode 中的接口">NameNodeMXBean</A> 中的方法
<DD>Gets the dead node information of the cluster.
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#getDecommissioningNodes()"><B>getDecommissioningNodes()</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FSNamesystem</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#getDecommissioningNodesStorageID()"><B>getDecommissioningNodesStorageID()</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FSNamesystem</A> 中的方法
<DD>get the storageID of the datanodes who is/are decommissioning
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#getDecomNodes()"><B>getDecomNodes()</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FSNamesystem</A> 中的方法
<DD>Returned information is a JSON representation of map with host name as the
 key and value is a map of decomisioning node attribute keys to its values
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNodeMXBean.html#getDecomNodes()"><B>getDecomNodes()</B></A> - 
接口 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNodeMXBean.html" title="org.apache.hadoop.hdfs.server.namenode 中的接口">NameNodeMXBean</A> 中的方法
<DD>Gets the decommissioning node information of the cluster.
<DT><A HREF="./org/apache/hadoop/hdfs/DFSClient.html#getDefaultBlockSize()"><B>getDefaultBlockSize()</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSClient.html" title="org.apache.hadoop.hdfs 中的类">DFSClient</A> 中的方法
<DD>Get the default block size for this cluster
<DT><A HREF="./org/apache/hadoop/hdfs/DistributedFileSystem.html#getDefaultBlockSize()"><B>getDefaultBlockSize()</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DistributedFileSystem.html" title="org.apache.hadoop.hdfs 中的类">DistributedFileSystem</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DistributedFileSystem.html#getDefaultPort()"><B>getDefaultPort()</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DistributedFileSystem.html" title="org.apache.hadoop.hdfs 中的类">DistributedFileSystem</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/HftpFileSystem.html#getDefaultPort()"><B>getDefaultPort()</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/HftpFileSystem.html" title="org.apache.hadoop.hdfs 中的类">HftpFileSystem</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSClient.html#getDefaultReplication()"><B>getDefaultReplication()</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSClient.html" title="org.apache.hadoop.hdfs 中的类">DFSClient</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DistributedFileSystem.html#getDefaultReplication()"><B>getDefaultReplication()</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DistributedFileSystem.html" title="org.apache.hadoop.hdfs 中的类">DistributedFileSystem</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/JspHelper.html#getDefaultWebUser(org.apache.hadoop.conf.Configuration)"><B>getDefaultWebUser(Configuration)</B></A> - 
类 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/JspHelper.html" title="org.apache.hadoop.hdfs.server.common 中的类">JspHelper</A> 中的静态方法
<DD>If security is turned off, what is the default web user?
<DT><A HREF="./org/apache/hadoop/hdfs/DFSClient.html#getDelegationToken(org.apache.hadoop.io.Text)"><B>getDelegationToken(Text)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSClient.html" title="org.apache.hadoop.hdfs 中的类">DFSClient</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DistributedFileSystem.html#getDelegationToken(java.lang.String)"><B>getDelegationToken(String)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DistributedFileSystem.html" title="org.apache.hadoop.hdfs 中的类">DistributedFileSystem</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DistributedFileSystem.html#getDelegationToken(org.apache.hadoop.io.Text)"><B>getDelegationToken(Text)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DistributedFileSystem.html" title="org.apache.hadoop.hdfs 中的类">DistributedFileSystem</A> 中的方法
<DD><B>已过时。</B>&nbsp;<I>use <A HREF="./org/apache/hadoop/hdfs/DistributedFileSystem.html#getDelegationToken(java.lang.String)"><CODE>DistributedFileSystem.getDelegationToken(String)</CODE></A></I>
<DT><A HREF="./org/apache/hadoop/hdfs/HftpFileSystem.html#getDelegationToken(java.lang.String)"><B>getDelegationToken(String)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/HftpFileSystem.html" title="org.apache.hadoop.hdfs 中的类">HftpFileSystem</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/ClientProtocol.html#getDelegationToken(org.apache.hadoop.io.Text)"><B>getDelegationToken(Text)</B></A> - 
接口 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/ClientProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的接口">ClientProtocol</A> 中的方法
<DD>Get a valid Delegation Token.
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#getDelegationToken(org.apache.hadoop.io.Text)"><B>getDelegationToken(Text)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FSNamesystem</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html#getDelegationToken(org.apache.hadoop.io.Text)"><B>getDelegationToken(Text)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">NameNode</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#getDelegationTokenSecretManager()"><B>getDelegationTokenSecretManager()</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FSNamesystem</A> 中的方法
<DD>Returns the DelegationTokenSecretManager instance in the namesystem.
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/GetDelegationTokenServlet.html" title="org.apache.hadoop.hdfs.server.namenode 中的类"><B>GetDelegationTokenServlet</B></A> - <A HREF="./org/apache/hadoop/hdfs/server/namenode/package-summary.html">org.apache.hadoop.hdfs.server.namenode</A> 中的 类<DD>Serve delegation tokens over http for use in hftp.<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/GetDelegationTokenServlet.html#GetDelegationTokenServlet()"><B>GetDelegationTokenServlet()</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/GetDelegationTokenServlet.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">GetDelegationTokenServlet</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/JspHelper.html#getDelegationTokenUrlParam(java.lang.String)"><B>getDelegationTokenUrlParam(String)</B></A> - 
类 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/JspHelper.html" title="org.apache.hadoop.hdfs.server.common 中的类">JspHelper</A> 中的静态方法
<DD>Returns the url parameter for the given token string.
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/Upgradeable.html#getDescription()"><B>getDescription()</B></A> - 
接口 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/Upgradeable.html" title="org.apache.hadoop.hdfs.server.common 中的接口">Upgradeable</A> 中的方法
<DD>Description of the upgrade object for displaying.
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/UpgradeObject.html#getDescription()"><B>getDescription()</B></A> - 
类 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/UpgradeObject.html" title="org.apache.hadoop.hdfs.server.common 中的类">UpgradeObject</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/StreamFile.html#getDFSClient(javax.servlet.http.HttpServletRequest)"><B>getDFSClient(HttpServletRequest)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/StreamFile.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">StreamFile</A> 中的方法
<DD>getting a client for connecting to dfs
<DT><A HREF="./org/apache/hadoop/hdfs/DistributedFileSystem.DiskStatus.html#getDfsUsed()"><B>getDfsUsed()</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DistributedFileSystem.DiskStatus.html" title="org.apache.hadoop.hdfs 中的类">DistributedFileSystem.DiskStatus</A> 中的方法
<DD><B>已过时。</B>&nbsp;&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeInfo.html#getDfsUsed()"><B>getDfsUsed()</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeInfo.html" title="org.apache.hadoop.hdfs.protocol 中的类">DatanodeInfo</A> 中的方法
<DD>The used space by the data node.
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDataset.html#getDfsUsed()"><B>getDfsUsed()</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDataset.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">FSDataset</A> 中的方法
<DD>Return the total space used by dfs datanode
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/metrics/FSDatasetMBean.html#getDfsUsed()"><B>getDfsUsed()</B></A> - 
接口 org.apache.hadoop.hdfs.server.datanode.metrics.<A HREF="./org/apache/hadoop/hdfs/server/datanode/metrics/FSDatasetMBean.html" title="org.apache.hadoop.hdfs.server.datanode.metrics 中的接口">FSDatasetMBean</A> 中的方法
<DD>Returns the total space (in bytes) used by dfs datanode
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeInfo.html#getDfsUsedPercent()"><B>getDfsUsedPercent()</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeInfo.html" title="org.apache.hadoop.hdfs.protocol 中的类">DatanodeInfo</A> 中的方法
<DD>The used space by the data node as percentage of present capacity
<DT><A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeIOStatus.html#getDiskname()"><B>getDiskname()</B></A> - 
类 org.apache.hadoop.hdfs.server.monitor.<A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeIOStatus.html" title="org.apache.hadoop.hdfs.server.monitor 中的类">ServernodeIOStatus</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSClient.html#getDiskStatus()"><B>getDiskStatus()</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSClient.html" title="org.apache.hadoop.hdfs 中的类">DFSClient</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DistributedFileSystem.html#getDiskStatus()"><B>getDiskStatus()</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DistributedFileSystem.html" title="org.apache.hadoop.hdfs 中的类">DistributedFileSystem</A> 中的方法
<DD><B>已过时。</B>&nbsp;<I>Use <CODE>FileSystem.getStatus()</CODE> 
 instead</I>
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/UpgradeManager.html#getDistributedUpgrades()"><B>getDistributedUpgrades()</B></A> - 
类 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/UpgradeManager.html" title="org.apache.hadoop.hdfs.server.common 中的类">UpgradeManager</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/UpgradeObjectCollection.html#getDistributedUpgrades(int, org.apache.hadoop.hdfs.server.common.HdfsConstants.NodeType)"><B>getDistributedUpgrades(int, HdfsConstants.NodeType)</B></A> - 
类 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/UpgradeObjectCollection.html" title="org.apache.hadoop.hdfs.server.common 中的类">UpgradeObjectCollection</A> 中的静态方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/NamespaceInfo.html#getDistributedUpgradeVersion()"><B>getDistributedUpgradeVersion()</B></A> - 
类 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/NamespaceInfo.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">NamespaceInfo</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/tools/DelegationTokenFetcher.html#getDTfromRemote(java.lang.String, java.lang.String)"><B>getDTfromRemote(String, String)</B></A> - 
类 org.apache.hadoop.hdfs.tools.<A HREF="./org/apache/hadoop/hdfs/tools/DelegationTokenFetcher.html" title="org.apache.hadoop.hdfs.tools 中的类">DelegationTokenFetcher</A> 中的静态方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeNETStatus.html#getDuplex()"><B>getDuplex()</B></A> - 
类 org.apache.hadoop.hdfs.server.monitor.<A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeNETStatus.html" title="org.apache.hadoop.hdfs.server.monitor 中的类">ServernodeNETStatus</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FSImage.html#getEditLog()"><B>getEditLog()</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/FSImage.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FSImage</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html#getEditLogSize()"><B>getEditLogSize()</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">NameNode</A> 中的方法
<DD><B>已过时。</B>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/NamenodeProtocol.html#getEditLogSize()"><B>getEditLogSize()</B></A> - 
接口 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/NamenodeProtocol.html" title="org.apache.hadoop.hdfs.server.protocol 中的接口">NamenodeProtocol</A> 中的方法
<DD><B>已过时。</B>&nbsp;<I>See <A HREF="./org/apache/hadoop/hdfs/server/namenode/SecondaryNameNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类"><CODE>SecondaryNameNode</CODE></A></I>
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/CodingMatrix.html#getElemAt(int, int)"><B>getElemAt(int, int)</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/CodingMatrix.html" title="org.apache.hadoop.hdfs.protocol 中的类">CodingMatrix</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSUtil.ErrorSimulator.html#getErrorSimulation(int)"><B>getErrorSimulation(int)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSUtil.ErrorSimulator.html" title="org.apache.hadoop.hdfs 中的类">DFSUtil.ErrorSimulator</A> 中的静态方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#getExcessBlocks()"><B>getExcessBlocks()</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FSNamesystem</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/security/token/block/BlockTokenIdentifier.html#getExpiryDate()"><B>getExpiryDate()</B></A> - 
类 org.apache.hadoop.hdfs.security.token.block.<A HREF="./org/apache/hadoop/hdfs/security/token/block/BlockTokenIdentifier.html" title="org.apache.hadoop.hdfs.security.token.block 中的类">BlockTokenIdentifier</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/KeyUpdateCommand.html#getExportedKeys()"><B>getExportedKeys()</B></A> - 
类 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/KeyUpdateCommand.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">KeyUpdateCommand</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/LocatedBlockWithCodingFactor.html#getFactors()"><B>getFactors()</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/LocatedBlockWithCodingFactor.html" title="org.apache.hadoop.hdfs.protocol 中的类">LocatedBlockWithCodingFactor</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/Storage.html#getFields(java.util.Properties, org.apache.hadoop.hdfs.server.common.Storage.StorageDirectory)"><B>getFields(Properties, Storage.StorageDirectory)</B></A> - 
类 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/Storage.html" title="org.apache.hadoop.hdfs.server.common 中的类">Storage</A> 中的方法
<DD>Get common storage fields.
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/DataStorage.html#getFields(java.util.Properties, org.apache.hadoop.hdfs.server.common.Storage.StorageDirectory)"><B>getFields(Properties, Storage.StorageDirectory)</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/DataStorage.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">DataStorage</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FSImage.html#getFields(java.util.Properties, org.apache.hadoop.hdfs.server.common.Storage.StorageDirectory)"><B>getFields(Properties, Storage.StorageDirectory)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/FSImage.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FSImage</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/BlockMissingException.html#getFile()"><B>getFile()</B></A> - 
异常 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/BlockMissingException.html" title="org.apache.hadoop.hdfs 中的类">BlockMissingException</A> 中的方法
<DD>Returns the name of the corrupted file.
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDataset.html#getFile(org.apache.hadoop.hdfs.protocol.Block)"><B>getFile(Block)</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDataset.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">FSDataset</A> 中的方法
<DD>Turn the block identifier into a filename; ignore generation stamp!!!
<DT><A HREF="./org/apache/hadoop/fs/Hdfs.html#getFileBlockLocations(org.apache.hadoop.fs.Path, long, long)"><B>getFileBlockLocations(Path, long, long)</B></A> - 
类 org.apache.hadoop.fs.<A HREF="./org/apache/hadoop/fs/Hdfs.html" title="org.apache.hadoop.fs 中的类">Hdfs</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DistributedFileSystem.html#getFileBlockLocations(org.apache.hadoop.fs.FileStatus, long, long)"><B>getFileBlockLocations(FileStatus, long, long)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DistributedFileSystem.html" title="org.apache.hadoop.hdfs 中的类">DistributedFileSystem</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DistributedFileSystem.html#getFileBlockLocations(org.apache.hadoop.fs.Path, long, long)"><B>getFileBlockLocations(Path, long, long)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DistributedFileSystem.html" title="org.apache.hadoop.hdfs 中的类">DistributedFileSystem</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/fs/Hdfs.html#getFileChecksum(org.apache.hadoop.fs.Path)"><B>getFileChecksum(Path)</B></A> - 
类 org.apache.hadoop.fs.<A HREF="./org/apache/hadoop/fs/Hdfs.html" title="org.apache.hadoop.fs 中的类">Hdfs</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSClient.html#getFileChecksum(java.lang.String)"><B>getFileChecksum(String)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSClient.html" title="org.apache.hadoop.hdfs 中的类">DFSClient</A> 中的方法
<DD>Get the checksum of a file.
<DT><A HREF="./org/apache/hadoop/hdfs/DFSClient.html#getFileChecksum(java.lang.String, org.apache.hadoop.hdfs.protocol.ClientProtocol, javax.net.SocketFactory, int)"><B>getFileChecksum(String, ClientProtocol, SocketFactory, int)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSClient.html" title="org.apache.hadoop.hdfs 中的类">DFSClient</A> 中的静态方法
<DD>Get the checksum of a file.
<DT><A HREF="./org/apache/hadoop/hdfs/DistributedFileSystem.html#getFileChecksum(org.apache.hadoop.fs.Path)"><B>getFileChecksum(Path)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DistributedFileSystem.html" title="org.apache.hadoop.hdfs 中的类">DistributedFileSystem</A> 中的方法
<DD>
<DT><A HREF="./org/apache/hadoop/hdfs/HftpFileSystem.html#getFileChecksum(org.apache.hadoop.fs.Path)"><B>getFileChecksum(Path)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/HftpFileSystem.html" title="org.apache.hadoop.hdfs 中的类">HftpFileSystem</A> 中的方法
<DD>
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/CodingMatrix.html#getFileCutsNum()"><B>getFileCutsNum()</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/CodingMatrix.html" title="org.apache.hadoop.hdfs.protocol 中的类">CodingMatrix</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/RegeneratingCodeMatrix.html#getFileCutsNum()"><B>getFileCutsNum()</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/RegeneratingCodeMatrix.html" title="org.apache.hadoop.hdfs.protocol 中的类">RegeneratingCodeMatrix</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSClient.html#getFileInfo(java.lang.String)"><B>getFileInfo(String)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSClient.html" title="org.apache.hadoop.hdfs 中的类">DFSClient</A> 中的方法
<DD>Get the file info for a specific file or directory.
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/ClientProtocol.html#getFileInfo(java.lang.String)"><B>getFileInfo(String)</B></A> - 
接口 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/ClientProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的接口">ClientProtocol</A> 中的方法
<DD>Get the file info for a specific file or directory.
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html#getFileInfo(java.lang.String)"><B>getFileInfo(String)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">NameNode</A> 中的方法
<DD>Get the file info for a specific file.
<DT><A HREF="./org/apache/hadoop/hdfs/DFSInputStream.html#getFileLength()"><B>getFileLength()</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSInputStream.html" title="org.apache.hadoop.hdfs 中的类">DFSInputStream</A> 中的方法
<DD>Read the block length from one of the datanodes.
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/ClientProtocol.html#getFileLength(java.lang.String)"><B>getFileLength(String)</B></A> - 
接口 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/ClientProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的接口">ClientProtocol</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/LocatedBlocks.html#getFileLength()"><B>getFileLength()</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/LocatedBlocks.html" title="org.apache.hadoop.hdfs.protocol 中的类">LocatedBlocks</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html#getFileLength(java.lang.String)"><B>getFileLength(String)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">NameNode</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#getFileLengthInternal(java.lang.String)"><B>getFileLengthInternal(String)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FSNamesystem</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSClient.html#getFileLinkInfo(java.lang.String)"><B>getFileLinkInfo(String)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSClient.html" title="org.apache.hadoop.hdfs 中的类">DFSClient</A> 中的方法
<DD>Get the file info for a specific file or directory.
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/ClientProtocol.html#getFileLinkInfo(java.lang.String)"><B>getFileLinkInfo(String)</B></A> - 
接口 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/ClientProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的接口">ClientProtocol</A> 中的方法
<DD>Get the file info for a specific file or directory.
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html#getFileLinkInfo(java.lang.String)"><B>getFileLinkInfo(String)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">NameNode</A> 中的方法
<DD>Get the file info for a specific file.
<DT><A HREF="./org/apache/hadoop/fs/Hdfs.html#getFileLinkStatus(org.apache.hadoop.fs.Path)"><B>getFileLinkStatus(Path)</B></A> - 
类 org.apache.hadoop.fs.<A HREF="./org/apache/hadoop/fs/Hdfs.html" title="org.apache.hadoop.fs 中的类">Hdfs</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/BlockReader.html#getFileName(java.net.InetSocketAddress, long)"><B>getFileName(InetSocketAddress, long)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/BlockReader.html" title="org.apache.hadoop.hdfs 中的类">BlockReader</A> 中的静态方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/fs/Hdfs.html#getFileStatus(org.apache.hadoop.fs.Path)"><B>getFileStatus(Path)</B></A> - 
类 org.apache.hadoop.fs.<A HREF="./org/apache/hadoop/fs/Hdfs.html" title="org.apache.hadoop.fs 中的类">Hdfs</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DistributedFileSystem.html#getFileStatus(org.apache.hadoop.fs.Path)"><B>getFileStatus(Path)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DistributedFileSystem.html" title="org.apache.hadoop.hdfs 中的类">DistributedFileSystem</A> 中的方法
<DD>Returns the stat information about the file.
<DT><A HREF="./org/apache/hadoop/hdfs/HftpFileSystem.html#getFileStatus(org.apache.hadoop.fs.Path)"><B>getFileStatus(Path)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/HftpFileSystem.html" title="org.apache.hadoop.hdfs 中的类">HftpFileSystem</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#getFilesTotal()"><B>getFilesTotal()</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FSNamesystem</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/metrics/FSNamesystemMBean.html#getFilesTotal()"><B>getFilesTotal()</B></A> - 
接口 org.apache.hadoop.hdfs.server.namenode.metrics.<A HREF="./org/apache/hadoop/hdfs/server/namenode/metrics/FSNamesystemMBean.html" title="org.apache.hadoop.hdfs.server.namenode.metrics 中的接口">FSNamesystemMBean</A> 中的方法
<DD>Total number of files and directories
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/Storage.StorageDirectory.html#getFinalizedTmp()"><B>getFinalizedTmp()</B></A> - 
类 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/Storage.StorageDirectory.html" title="org.apache.hadoop.hdfs.server.common 中的类">Storage.StorageDirectory</A> 中的方法
<DD><code>finalized.tmp</code> is a transient directory, which holds
 the <code>previous</code> file system state while it is being removed
 in response to the finalize request.
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#getFree()"><B>getFree()</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FSNamesystem</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNodeMXBean.html#getFree()"><B>getFree()</B></A> - 
接口 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNodeMXBean.html" title="org.apache.hadoop.hdfs.server.namenode 中的接口">NameNodeMXBean</A> 中的方法
<DD>Gets total non-used raw bytes.
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/DataNode.html#getFSDataset()"><B>getFSDataset()</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/DataNode.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">DataNode</A> 中的方法
<DD>This method is used for testing.
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FSImage.html#getFsEditName()"><B>getFsEditName()</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/FSImage.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FSImage</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html#getFSImage()"><B>getFSImage()</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">NameNode</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html#getFsImageName()"><B>getFsImageName()</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">NameNode</A> 中的方法
<DD>Returns the name of the fsImage file
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html#getFsImageNameCheckpoint()"><B>getFsImageNameCheckpoint()</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">NameNode</A> 中的方法
<DD>Returns the name of the fsImage file uploaded by periodic
 checkpointing
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FSImage.html#getFSNamesystem()"><B>getFSNamesystem()</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/FSImage.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FSImage</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#getFSNamesystemMetrics()"><B>getFSNamesystemMetrics()</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FSNamesystem</A> 中的方法
<DD>get FSNamesystemMetrics
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#getFSState()"><B>getFSState()</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FSNamesystem</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/metrics/FSNamesystemMBean.html#getFSState()"><B>getFSState()</B></A> - 
接口 org.apache.hadoop.hdfs.server.namenode.metrics.<A HREF="./org/apache/hadoop/hdfs/server/namenode/metrics/FSNamesystemMBean.html" title="org.apache.hadoop.hdfs.server.namenode.metrics 中的接口">FSNamesystemMBean</A> 中的方法
<DD>The state of the file system: Safemode or Operational
<DT><A HREF="./org/apache/hadoop/fs/Hdfs.html#getFsStatus()"><B>getFsStatus()</B></A> - 
类 org.apache.hadoop.fs.<A HREF="./org/apache/hadoop/fs/Hdfs.html" title="org.apache.hadoop.fs 中的类">Hdfs</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/HdfsFileStatus.html#getFullName(java.lang.String)"><B>getFullName(String)</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/HdfsFileStatus.html" title="org.apache.hadoop.hdfs.protocol 中的类">HdfsFileStatus</A> 中的方法
<DD>Get the string representation of the full path name
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/HdfsFileStatus.html#getFullPath(org.apache.hadoop.fs.Path)"><B>getFullPath(Path)</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/HdfsFileStatus.html" title="org.apache.hadoop.hdfs.protocol 中的类">HdfsFileStatus</A> 中的方法
<DD>Get the full path
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FSInodeInfo.html#getFullPathName()"><B>getFullPathName()</B></A> - 
接口 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/FSInodeInfo.html" title="org.apache.hadoop.hdfs.server.namenode 中的接口">FSInodeInfo</A> 中的方法
<DD>a string representation of an inode
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/Block.html#getGenerationStamp(java.lang.String)"><B>getGenerationStamp(String)</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/Block.html" title="org.apache.hadoop.hdfs.protocol 中的类">Block</A> 中的静态方法
<DD>Get generation stamp from the name of the metafile name
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/Block.html#getGenerationStamp()"><B>getGenerationStamp()</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/Block.html" title="org.apache.hadoop.hdfs.protocol 中的类">Block</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/Replica.html#getGenerationStamp()"><B>getGenerationStamp()</B></A> - 
接口 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/Replica.html" title="org.apache.hadoop.hdfs.server.datanode 中的接口">Replica</A> 中的方法
<DD>Get the generation stamp
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#getGenerationStamp()"><B>getGenerationStamp()</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FSNamesystem</A> 中的方法
<DD>Gets the generation stamp for this filesystem
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/HdfsFileStatus.html#getGroup()"><B>getGroup()</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/HdfsFileStatus.html" title="org.apache.hadoop.hdfs.protocol 中的类">HdfsFileStatus</A> 中的方法
<DD>Get the group associated with the file.
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/BufferData.html#getHead()"><B>getHead()</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/BufferData.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">BufferData</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FSImage.html#getHeaderBuffer()"><B>getHeaderBuffer()</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/FSImage.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FSImage</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DistributedFileSystem.html#getHomeDirectory()"><B>getHomeDirectory()</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DistributedFileSystem.html" title="org.apache.hadoop.hdfs 中的类">DistributedFileSystem</A> 中的方法
<DD>
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeID.html#getHost()"><B>getHost()</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeID.html" title="org.apache.hadoop.hdfs.protocol 中的类">DatanodeID</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeInfo.html#getHostName()"><B>getHostName()</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeInfo.html" title="org.apache.hadoop.hdfs.protocol 中的类">DatanodeInfo</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html#getHostPortString(java.net.InetSocketAddress)"><B>getHostPortString(InetSocketAddress)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">NameNode</A> 中的静态方法
<DD>Compose a "host:port" string from the address.
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html#getHttpAddress()"><B>getHttpAddress()</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">NameNode</A> 中的方法
<DD>Returns the address of the NameNodes http server, 
 which is used to access the name-node web UI.
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/SecondaryNameNode.html#getHttpAddress(org.apache.hadoop.conf.Configuration)"><B>getHttpAddress(Configuration)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/SecondaryNameNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">SecondaryNameNode</A> 中的静态方法
<DD><B>已过时。</B>&nbsp;&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/DataNode.html#getHttpPort()"><B>getHttpPort()</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/DataNode.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">DataNode</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/DataNodeMXBean.html#getHttpPort()"><B>getHttpPort()</B></A> - 
接口 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/DataNodeMXBean.html" title="org.apache.hadoop.hdfs.server.datanode 中的接口">DataNodeMXBean</A> 中的方法
<DD>Gets the http port.
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/BackupNode.html#getHttpServerAddress(org.apache.hadoop.conf.Configuration)"><B>getHttpServerAddress(Configuration)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/BackupNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">BackupNode</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html#getHttpServerAddress(org.apache.hadoop.conf.Configuration)"><B>getHttpServerAddress(Configuration)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">NameNode</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/GetImageServlet.html" title="org.apache.hadoop.hdfs.server.namenode 中的类"><B>GetImageServlet</B></A> - <A HREF="./org/apache/hadoop/hdfs/server/namenode/package-summary.html">org.apache.hadoop.hdfs.server.namenode</A> 中的 类<DD>This class is used in Namesystem's jetty to retrieve a file.<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/GetImageServlet.html#GetImageServlet()"><B>GetImageServlet()</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/GetImageServlet.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">GetImageServlet</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/BufferData.html#getIndexFile()"><B>getIndexFile()</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/BufferData.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">BufferData</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/DataNode.html#getInfoAddr(org.apache.hadoop.conf.Configuration)"><B>getInfoAddr(Configuration)</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/DataNode.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">DataNode</A> 中的静态方法
<DD>Determine the http server's effective addr
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeID.html#getInfoPort()"><B>getInfoPort()</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeID.html" title="org.apache.hadoop.hdfs.protocol 中的类">DatanodeID</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/DataNode.html#getInfoPort()"><B>getInfoPort()</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/DataNode.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">DataNode</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html#getInfoServer(org.apache.hadoop.conf.Configuration)"><B>getInfoServer(Configuration)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">NameNode</A> 中的静态方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/LocatedBlocks.html#getInsertIndex(int)"><B>getInsertIndex(int)</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/LocatedBlocks.html" title="org.apache.hadoop.hdfs.protocol 中的类">LocatedBlocks</A> 中的静态方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/BlockPlacementPolicy.html#getInstance(org.apache.hadoop.conf.Configuration, org.apache.hadoop.hdfs.server.namenode.FSClusterStats, org.apache.hadoop.net.NetworkTopology)"><B>getInstance(Configuration, FSClusterStats, NetworkTopology)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/BlockPlacementPolicy.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">BlockPlacementPolicy</A> 中的静态方法
<DD>Get an instance of the configured Block Placement Policy based on the
 value of the configuration paramater dfs.block.replicator.classname.
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeInfo.html#getIOStatus()"><B>getIOStatus()</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeInfo.html" title="org.apache.hadoop.hdfs.protocol 中的类">DatanodeInfo</A> 中的方法
<DD>get the io status of datanode
<DT><A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeStator.html#getIOStatus()"><B>getIOStatus()</B></A> - 
类 org.apache.hadoop.hdfs.server.monitor.<A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeStator.html" title="org.apache.hadoop.hdfs.server.monitor 中的类">ServernodeStator</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeID.html#getIpcPort()"><B>getIpcPort()</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeID.html" title="org.apache.hadoop.hdfs.protocol 中的类">DatanodeID</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/CodingMatrix.html#getK()"><B>getK()</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/CodingMatrix.html" title="org.apache.hadoop.hdfs.protocol 中的类">CodingMatrix</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/RegeneratingCodeMatrix.html#getK()"><B>getK()</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/RegeneratingCodeMatrix.html" title="org.apache.hadoop.hdfs.protocol 中的类">RegeneratingCodeMatrix</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/security/token/block/BlockTokenIdentifier.html#getKeyId()"><B>getKeyId()</B></A> - 
类 org.apache.hadoop.hdfs.security.token.block.<A HREF="./org/apache/hadoop/hdfs/security/token/block/BlockTokenIdentifier.html" title="org.apache.hadoop.hdfs.security.token.block 中的类">BlockTokenIdentifier</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/security/token/block/ExportedBlockKeys.html#getKeyUpdateInterval()"><B>getKeyUpdateInterval()</B></A> - 
类 org.apache.hadoop.hdfs.security.token.block.<A HREF="./org/apache/hadoop/hdfs/security/token/block/ExportedBlockKeys.html" title="org.apache.hadoop.hdfs.security.token.block 中的类">ExportedBlockKeys</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/security/token/block/BlockTokenIdentifier.html#getKind()"><B>getKind()</B></A> - 
类 org.apache.hadoop.hdfs.security.token.block.<A HREF="./org/apache/hadoop/hdfs/security/token/block/BlockTokenIdentifier.html" title="org.apache.hadoop.hdfs.security.token.block 中的类">BlockTokenIdentifier</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/security/token/delegation/DelegationTokenIdentifier.html#getKind()"><B>getKind()</B></A> - 
类 org.apache.hadoop.hdfs.security.token.delegation.<A HREF="./org/apache/hadoop/hdfs/security/token/delegation/DelegationTokenIdentifier.html" title="org.apache.hadoop.hdfs.security.token.delegation 中的类">DelegationTokenIdentifier</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/Storage.StorageDirectory.html#getLastCheckpointTmp()"><B>getLastCheckpointTmp()</B></A> - 
类 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/Storage.StorageDirectory.html" title="org.apache.hadoop.hdfs.server.common 中的类">Storage.StorageDirectory</A> 中的方法
<DD><code>lastcheckpoint.tmp</code> is a transient directory, which holds
 current file system state while the new state is saved into the new
 <code>current</code> during regular namespace updates.
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/CodingMatrix.html#getLastID(int)"><B>getLastID(int)</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/CodingMatrix.html" title="org.apache.hadoop.hdfs.protocol 中的类">CodingMatrix</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/LocatedBlocks.html#getLastLocatedBlock()"><B>getLastLocatedBlock()</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/LocatedBlocks.html" title="org.apache.hadoop.hdfs.protocol 中的类">LocatedBlocks</A> 中的方法
<DD>Get the last located block.
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DirectoryListing.html#getLastName()"><B>getLastName()</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DirectoryListing.html" title="org.apache.hadoop.hdfs.protocol 中的类">DirectoryListing</A> 中的方法
<DD>Get the last name in this list
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeInfo.html#getLastUpdate()"><B>getLastUpdate()</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeInfo.html" title="org.apache.hadoop.hdfs.protocol 中的类">DatanodeInfo</A> 中的方法
<DD>The time when this information was accurate.
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/StorageInfo.html#getLayoutVersion()"><B>getLayoutVersion()</B></A> - 
类 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/StorageInfo.html" title="org.apache.hadoop.hdfs.server.common 中的类">StorageInfo</A> 中的方法
<DD>Layout version of the storage data.
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/LeaseManager.html#getLeaseByPath(java.lang.String)"><B>getLeaseByPath(String)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/LeaseManager.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">LeaseManager</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/HdfsFileStatus.html#getLen()"><B>getLen()</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/HdfsFileStatus.html" title="org.apache.hadoop.hdfs.protocol 中的类">HdfsFileStatus</A> 中的方法
<DD>Get the length of this file, in bytes.
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDataset.html#getLength(org.apache.hadoop.hdfs.protocol.Block)"><B>getLength(Block)</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDataset.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">FSDataset</A> 中的方法
<DD>Find the block's on-disk length
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.html#getLength(org.apache.hadoop.hdfs.protocol.Block)"><B>getLength(Block)</B></A> - 
接口 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.html" title="org.apache.hadoop.hdfs.server.datanode 中的接口">FSDatasetInterface</A> 中的方法
<DD>Returns the specified block's on-disk length (excluding metadata)
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.MetaDataInputStream.html#getLength()"><B>getLength()</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.MetaDataInputStream.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">FSDatasetInterface.MetaDataInputStream</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeInfo.html#getLevel()"><B>getLevel()</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeInfo.html" title="org.apache.hadoop.hdfs.protocol 中的类">DatanodeInfo</A> 中的方法
<DD>Return this node's level in the tree.
<DT><A HREF="./org/apache/hadoop/fs/Hdfs.html#getLinkTarget(org.apache.hadoop.fs.Path)"><B>getLinkTarget(Path)</B></A> - 
类 org.apache.hadoop.fs.<A HREF="./org/apache/hadoop/fs/Hdfs.html" title="org.apache.hadoop.fs 中的类">Hdfs</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSClient.html#getLinkTarget(java.lang.String)"><B>getLinkTarget(String)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSClient.html" title="org.apache.hadoop.hdfs 中的类">DFSClient</A> 中的方法
<DD>Resolve the *first* symlink, if any, in the path.
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/ClientProtocol.html#getLinkTarget(java.lang.String)"><B>getLinkTarget(String)</B></A> - 
接口 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/ClientProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的接口">ClientProtocol</A> 中的方法
<DD>Return the target of the given symlink.
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html#getLinkTarget(java.lang.String)"><B>getLinkTarget(String)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">NameNode</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/INodeSymlink.html#getLinkValue()"><B>getLinkValue()</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/INodeSymlink.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">INodeSymlink</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/SecureDataNodeStarter.SecureResources.html#getListener()"><B>getListener()</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/SecureDataNodeStarter.SecureResources.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">SecureDataNodeStarter.SecureResources</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/ClientProtocol.html#getListing(java.lang.String, byte[], boolean)"><B>getListing(String, byte[], boolean)</B></A> - 
接口 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/ClientProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的接口">ClientProtocol</A> 中的方法
<DD>Get a partial listing of the indicated directory
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#getListing(java.lang.String, byte[], boolean)"><B>getListing(String, byte[], boolean)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FSNamesystem</A> 中的方法
<DD>Get a partial listing of the indicated directory
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html#getListing(java.lang.String, byte[], boolean)"><B>getListing(String, byte[], boolean)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">NameNode</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#getLiveDataNodesStorageID()"><B>getLiveDataNodesStorageID()</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FSNamesystem</A> 中的方法
<DD>get the storageID of the datanodes who is/are live
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#getLiveNodes()"><B>getLiveNodes()</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FSNamesystem</A> 中的方法
<DD>Returned information is a JSON representation of map with host name as the
 key and value is a map of live node attribute keys to its values
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNodeMXBean.html#getLiveNodes()"><B>getLiveNodes()</B></A> - 
接口 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNodeMXBean.html" title="org.apache.hadoop.hdfs.server.namenode 中的接口">NameNodeMXBean</A> 中的方法
<DD>Gets the live node information of the cluster.
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/HdfsFileStatus.html#getLocalName()"><B>getLocalName()</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/HdfsFileStatus.html" title="org.apache.hadoop.hdfs.protocol 中的类">HdfsFileStatus</A> 中的方法
<DD>Get the string representation of the local name
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/HdfsFileStatus.html#getLocalNameInBytes()"><B>getLocalNameInBytes()</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/HdfsFileStatus.html" title="org.apache.hadoop.hdfs.protocol 中的类">HdfsFileStatus</A> 中的方法
<DD>Get the Java UTF8 representation of the local name
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/CumulusRecoveryCommand.html#getLocatedBlk(int)"><B>getLocatedBlk(int)</B></A> - 
类 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/CumulusRecoveryCommand.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">CumulusRecoveryCommand</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/RCRecoveryCommand.html#getLocatedBlk(int)"><B>getLocatedBlk(int)</B></A> - 
类 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/RCRecoveryCommand.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">RCRecoveryCommand</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/CumulusRecoveryCommand.html#getLocatedBlks()"><B>getLocatedBlks()</B></A> - 
类 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/CumulusRecoveryCommand.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">CumulusRecoveryCommand</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/RCRecoveryCommand.html#getLocatedBlks()"><B>getLocatedBlks()</B></A> - 
类 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/RCRecoveryCommand.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">RCRecoveryCommand</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/LocatedBlocks.html#getLocatedBlocks()"><B>getLocatedBlocks()</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/LocatedBlocks.html" title="org.apache.hadoop.hdfs.protocol 中的类">LocatedBlocks</A> 中的方法
<DD>Get located blocks.
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/LocatedBlock.html#getLocations()"><B>getLocations()</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/LocatedBlock.html" title="org.apache.hadoop.hdfs.protocol 中的类">LocatedBlock</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/CumulusRecoveryCommand.html#getLostColumn()"><B>getLostColumn()</B></A> - 
类 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/CumulusRecoveryCommand.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">CumulusRecoveryCommand</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/RCRecoveryCommand.html#getLostRow()"><B>getLostRow()</B></A> - 
类 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/RCRecoveryCommand.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">RCRecoveryCommand</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/CumulusRecoveryCommand.html#getMatrix()"><B>getMatrix()</B></A> - 
类 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/CumulusRecoveryCommand.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">CumulusRecoveryCommand</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/RCRecoveryCommand.html#getMatrix()"><B>getMatrix()</B></A> - 
类 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/RCRecoveryCommand.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">RCRecoveryCommand</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/RegeneratingCodeMatrix.html#getMatrixLog(short[][], java.lang.String)"><B>getMatrixLog(short[][], String)</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/RegeneratingCodeMatrix.html" title="org.apache.hadoop.hdfs.protocol 中的类">RegeneratingCodeMatrix</A> 中的静态方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/CodingMatrix.html#getMatrixofCertainType(byte)"><B>getMatrixofCertainType(byte)</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/CodingMatrix.html" title="org.apache.hadoop.hdfs.protocol 中的类">CodingMatrix</A> 中的静态方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeCPUStatus.html#getMaxCPURate()"><B>getMaxCPURate()</B></A> - 
类 org.apache.hadoop.hdfs.server.monitor.<A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeCPUStatus.html" title="org.apache.hadoop.hdfs.server.monitor 中的类">ServernodeCPUStatus</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeIOStatus.html#getMaxIORate()"><B>getMaxIORate()</B></A> - 
类 org.apache.hadoop.hdfs.server.monitor.<A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeIOStatus.html" title="org.apache.hadoop.hdfs.server.monitor 中的类">ServernodeIOStatus</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeMEMStatus.html#getMaxMEMRate()"><B>getMaxMEMRate()</B></A> - 
类 org.apache.hadoop.hdfs.server.monitor.<A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeMEMStatus.html" title="org.apache.hadoop.hdfs.server.monitor 中的类">ServernodeMEMStatus</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeNETStatus.html#getMaxNETRxRate()"><B>getMaxNETRxRate()</B></A> - 
类 org.apache.hadoop.hdfs.server.monitor.<A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeNETStatus.html" title="org.apache.hadoop.hdfs.server.monitor 中的类">ServernodeNETStatus</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeNETStatus.html#getMaxNETTxRate()"><B>getMaxNETTxRate()</B></A> - 
类 org.apache.hadoop.hdfs.server.monitor.<A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeNETStatus.html" title="org.apache.hadoop.hdfs.server.monitor 中的类">ServernodeNETStatus</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FSImage.html#getMaxOffset()"><B>getMaxOffset()</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/FSImage.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FSImage</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeInfo.html#getMEMStatus()"><B>getMEMStatus()</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeInfo.html" title="org.apache.hadoop.hdfs.protocol 中的类">DatanodeInfo</A> 中的方法
<DD>get the mem status of datanode
<DT><A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeStator.html#getMEMStatus()"><B>getMEMStatus()</B></A> - 
类 org.apache.hadoop.hdfs.server.monitor.<A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeStator.html" title="org.apache.hadoop.hdfs.server.monitor 中的类">ServernodeStator</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DSQuotaExceededException.html#getMessage()"><B>getMessage()</B></A> - 
异常 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DSQuotaExceededException.html" title="org.apache.hadoop.hdfs.protocol 中的类">DSQuotaExceededException</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/NSQuotaExceededException.html#getMessage()"><B>getMessage()</B></A> - 
异常 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/NSQuotaExceededException.html" title="org.apache.hadoop.hdfs.protocol 中的类">NSQuotaExceededException</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/QuotaExceededException.html#getMessage()"><B>getMessage()</B></A> - 
异常 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/QuotaExceededException.html" title="org.apache.hadoop.hdfs.protocol 中的类">QuotaExceededException</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/UnresolvedPathException.html#getMessage()"><B>getMessage()</B></A> - 
异常 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/UnresolvedPathException.html" title="org.apache.hadoop.hdfs.protocol 中的类">UnresolvedPathException</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDataset.html#getMetaDataInputStream(org.apache.hadoop.hdfs.protocol.Block)"><B>getMetaDataInputStream(Block)</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDataset.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">FSDataset</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.html#getMetaDataInputStream(org.apache.hadoop.hdfs.protocol.Block)"><B>getMetaDataInputStream(Block)</B></A> - 
接口 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.html" title="org.apache.hadoop.hdfs.server.datanode 中的接口">FSDatasetInterface</A> 中的方法
<DD>Returns metaData of block b as an input stream (and its length)
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDataset.html#getMetaDataLength(org.apache.hadoop.hdfs.protocol.Block)"><B>getMetaDataLength(Block)</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDataset.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">FSDataset</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.html#getMetaDataLength(org.apache.hadoop.hdfs.protocol.Block)"><B>getMetaDataLength(Block)</B></A> - 
接口 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.html" title="org.apache.hadoop.hdfs.server.datanode 中的接口">FSDatasetInterface</A> 中的方法
<DD>Returns the length of the metadata file of the specified block
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDataset.html#getMetaFile(org.apache.hadoop.hdfs.protocol.Block)"><B>getMetaFile(Block)</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDataset.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">FSDataset</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeCPUStatus.html#getMinCPURate()"><B>getMinCPURate()</B></A> - 
类 org.apache.hadoop.hdfs.server.monitor.<A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeCPUStatus.html" title="org.apache.hadoop.hdfs.server.monitor 中的类">ServernodeCPUStatus</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeIOStatus.html#getMinIORate()"><B>getMinIORate()</B></A> - 
类 org.apache.hadoop.hdfs.server.monitor.<A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeIOStatus.html" title="org.apache.hadoop.hdfs.server.monitor 中的类">ServernodeIOStatus</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeMEMStatus.html#getMinMEMRate()"><B>getMinMEMRate()</B></A> - 
类 org.apache.hadoop.hdfs.server.monitor.<A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeMEMStatus.html" title="org.apache.hadoop.hdfs.server.monitor 中的类">ServernodeMEMStatus</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeNETStatus.html#getMinNETRxRate()"><B>getMinNETRxRate()</B></A> - 
类 org.apache.hadoop.hdfs.server.monitor.<A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeNETStatus.html" title="org.apache.hadoop.hdfs.server.monitor 中的类">ServernodeNETStatus</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeNETStatus.html#getMinNETTxRate()"><B>getMinNETTxRate()</B></A> - 
类 org.apache.hadoop.hdfs.server.monitor.<A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeNETStatus.html" title="org.apache.hadoop.hdfs.server.monitor 中的类">ServernodeNETStatus</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSClient.html#getMissingBlocksCount()"><B>getMissingBlocksCount()</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSClient.html" title="org.apache.hadoop.hdfs 中的类">DFSClient</A> 中的方法
<DD>Returns count of blocks with no good replicas left.
<DT><A HREF="./org/apache/hadoop/hdfs/DistributedFileSystem.html#getMissingBlocksCount()"><B>getMissingBlocksCount()</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DistributedFileSystem.html" title="org.apache.hadoop.hdfs 中的类">DistributedFileSystem</A> 中的方法
<DD>Returns count of blocks with no good replicas left.
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#getMissingBlocksCount()"><B>getMissingBlocksCount()</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FSNamesystem</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/HdfsFileStatus.html#getModificationTime()"><B>getModificationTime()</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/HdfsFileStatus.html" title="org.apache.hadoop.hdfs.protocol 中的类">HdfsFileStatus</A> 中的方法
<DD>Get the modification time of the file.
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/CodingMatrix.html#getN()"><B>getN()</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/CodingMatrix.html" title="org.apache.hadoop.hdfs.protocol 中的类">CodingMatrix</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/RegeneratingCodeMatrix.html#getN()"><B>getN()</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/RegeneratingCodeMatrix.html" title="org.apache.hadoop.hdfs.protocol 中的类">RegeneratingCodeMatrix</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeID.html#getName()"><B>getName()</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeID.html" title="org.apache.hadoop.hdfs.protocol 中的类">DatanodeID</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/HdfsConstants.StartupOption.html#getName()"><B>getName()</B></A> - 
枚举 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/HdfsConstants.StartupOption.html" title="org.apache.hadoop.hdfs.server.common 中的枚举">HdfsConstants.StartupOption</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSClient.html#getNamenode()"><B>getNamenode()</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSClient.html" title="org.apache.hadoop.hdfs 中的类">DFSClient</A> 中的方法
<DD>Get the namenode associated with this DFSClient object
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/DataNode.html#getNameNodeAddr()"><B>getNameNodeAddr()</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/DataNode.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">DataNode</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/DataNode.html#getNamenodeAddress()"><B>getNamenodeAddress()</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/DataNode.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">DataNode</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/DataNodeMXBean.html#getNamenodeAddress()"><B>getNamenodeAddress()</B></A> - 
接口 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/DataNodeMXBean.html" title="org.apache.hadoop.hdfs.server.datanode 中的接口">DataNodeMXBean</A> 中的方法
<DD>Gets the namenode IP address.
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html#getNameNodeAddress()"><B>getNameNodeAddress()</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">NameNode</A> 中的方法
<DD>Returns the address on which the NameNodes is listening to.
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/DataNode.html#getNameNodeAddrForClient()"><B>getNameNodeAddrForClient()</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/DataNode.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">DataNode</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html#getNameNodeMetrics()"><B>getNameNodeMetrics()</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">NameNode</A> 中的静态方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#getNamespaceDirs(org.apache.hadoop.conf.Configuration)"><B>getNamespaceDirs(Configuration)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FSNamesystem</A> 中的静态方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#getNamespaceEditsDirs(org.apache.hadoop.conf.Configuration)"><B>getNamespaceEditsDirs(Configuration)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FSNamesystem</A> 中的静态方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/StorageInfo.html#getNamespaceID()"><B>getNamespaceID()</B></A> - 
类 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/StorageInfo.html" title="org.apache.hadoop.hdfs.server.common 中的类">StorageInfo</A> 中的方法
<DD>Namespace id of the file system.
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeInfo.html#getNETStatus()"><B>getNETStatus()</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeInfo.html" title="org.apache.hadoop.hdfs.protocol 中的类">DatanodeInfo</A> 中的方法
<DD>get the net status of datanode
<DT><A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeStator.html#getNETStatus()"><B>getNETStatus()</B></A> - 
类 org.apache.hadoop.hdfs.server.monitor.<A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeStator.html" title="org.apache.hadoop.hdfs.server.monitor 中的类">ServernodeStator</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeInfo.html#getNetworkLocation()"><B>getNetworkLocation()</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeInfo.html" title="org.apache.hadoop.hdfs.protocol 中的类">DatanodeInfo</A> 中的方法
<DD>rack name
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/BlockRecoveryCommand.RecoveringBlock.html#getNewGenerationStamp()"><B>getNewGenerationStamp()</B></A> - 
类 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/BlockRecoveryCommand.RecoveringBlock.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">BlockRecoveryCommand.RecoveringBlock</A> 中的方法
<DD>Return the new generation stamp of the block,
 which also plays role of the recovery id.
<DT><A HREF="./org/apache/hadoop/hdfs/util/LightWeightGSet.LinkedElement.html#getNext()"><B>getNext()</B></A> - 
接口 org.apache.hadoop.hdfs.util.<A HREF="./org/apache/hadoop/hdfs/util/LightWeightGSet.LinkedElement.html" title="org.apache.hadoop.hdfs.util 中的接口">LightWeightGSet.LinkedElement</A> 中的方法
<DD>Get the next element.
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeInfo.html#getNonDfsUsed()"><B>getNonDfsUsed()</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeInfo.html" title="org.apache.hadoop.hdfs.protocol 中的类">DatanodeInfo</A> 中的方法
<DD>The used space by the data node.
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#getNonDfsUsedSpace()"><B>getNonDfsUsedSpace()</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FSNamesystem</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNodeMXBean.html#getNonDfsUsedSpace()"><B>getNonDfsUsedSpace()</B></A> - 
接口 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNodeMXBean.html" title="org.apache.hadoop.hdfs.server.namenode 中的接口">NameNodeMXBean</A> 中的方法
<DD>Gets total used space by data nodes for non DFS purposes such as storing
 temporary files on the local file system
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/BlockListAsLongs.html#getNumberOfBlocks()"><B>getNumberOfBlocks()</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/BlockListAsLongs.html" title="org.apache.hadoop.hdfs.protocol 中的类">BlockListAsLongs</A> 中的方法
<DD>The number of blocks
<DT><A HREF="./org/apache/hadoop/hdfs/security/token/delegation/DelegationTokenSecretManager.html#getNumberOfKeys()"><B>getNumberOfKeys()</B></A> - 
类 org.apache.hadoop.hdfs.security.token.delegation.<A HREF="./org/apache/hadoop/hdfs/security/token/delegation/DelegationTokenSecretManager.html" title="org.apache.hadoop.hdfs.security.token.delegation 中的类">DelegationTokenSecretManager</A> 中的方法
<DD>Returns the number of delegation keys currently stored.
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/Block.html#getNumBytes()"><B>getNumBytes()</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/Block.html" title="org.apache.hadoop.hdfs.protocol 中的类">Block</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/Replica.html#getNumBytes()"><B>getNumBytes()</B></A> - 
接口 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/Replica.html" title="org.apache.hadoop.hdfs.server.datanode 中的接口">Replica</A> 中的方法
<DD>Get the number of bytes received
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#getNumDeadDataNodes()"><B>getNumDeadDataNodes()</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FSNamesystem</A> 中的方法
<DD>Number of dead data nodes
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/metrics/FSNamesystemMBean.html#getNumDeadDataNodes()"><B>getNumDeadDataNodes()</B></A> - 
接口 org.apache.hadoop.hdfs.server.namenode.metrics.<A HREF="./org/apache/hadoop/hdfs/server/namenode/metrics/FSNamesystemMBean.html" title="org.apache.hadoop.hdfs.server.namenode.metrics 中的接口">FSNamesystemMBean</A> 中的方法
<DD>Number of dead data nodes
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDataset.html#getNumFailedVolumes()"><B>getNumFailedVolumes()</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDataset.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">FSDataset</A> 中的方法
<DD>Return the number of failed volumes in the FSDataset.
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/metrics/FSDatasetMBean.html#getNumFailedVolumes()"><B>getNumFailedVolumes()</B></A> - 
接口 org.apache.hadoop.hdfs.server.datanode.metrics.<A HREF="./org/apache/hadoop/hdfs/server/datanode/metrics/FSDatasetMBean.html" title="org.apache.hadoop.hdfs.server.datanode.metrics 中的接口">FSDatasetMBean</A> 中的方法
<DD>Returns the number of failed volumes in the datanode.
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#getNumLiveDataNodes()"><B>getNumLiveDataNodes()</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FSNamesystem</A> 中的方法
<DD>Number of live data nodes
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/metrics/FSNamesystemMBean.html#getNumLiveDataNodes()"><B>getNumLiveDataNodes()</B></A> - 
接口 org.apache.hadoop.hdfs.server.namenode.metrics.<A HREF="./org/apache/hadoop/hdfs/server/namenode/metrics/FSNamesystemMBean.html" title="org.apache.hadoop.hdfs.server.namenode.metrics 中的接口">FSNamesystemMBean</A> 中的方法
<DD>Number of Live data nodes
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.PipelineAck.html#getNumOfReplies()"><B>getNumOfReplies()</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.PipelineAck.html" title="org.apache.hadoop.hdfs.protocol 中的类">DataTransferProtocol.PipelineAck</A> 中的方法
<DD>Get the number of replies
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/Storage.html#getNumStorageDirs()"><B>getNumStorageDirs()</B></A> - 
类 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/Storage.html" title="org.apache.hadoop.hdfs.server.common 中的类">Storage</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/BlockMissingException.html#getOffset()"><B>getOffset()</B></A> - 
异常 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/BlockMissingException.html" title="org.apache.hadoop.hdfs 中的类">BlockMissingException</A> 中的方法
<DD>Returns the offset at which this file is corrupted
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.PacketHeader.html#getOffsetInBlock()"><B>getOffsetInBlock()</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.PacketHeader.html" title="org.apache.hadoop.hdfs.protocol 中的类">DataTransferProtocol.PacketHeader</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/ReplicaRecoveryInfo.html#getOriginalReplicaState()"><B>getOriginalReplicaState()</B></A> - 
类 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/ReplicaRecoveryInfo.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">ReplicaRecoveryInfo</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FSEditLog.html#getOutputStreamIterator(org.apache.hadoop.hdfs.server.namenode.JournalStream.JournalType)"><B>getOutputStreamIterator(JournalStream.JournalType)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/FSEditLog.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FSEditLog</A> 中的方法
<DD>Get stream iterator for the specified type.
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/HdfsFileStatus.html#getOwner()"><B>getOwner()</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/HdfsFileStatus.html" title="org.apache.hadoop.hdfs.protocol 中的类">HdfsFileStatus</A> 中的方法
<DD>Get the owner of the file.
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.PacketHeader.html#getPacketLen()"><B>getPacketLen()</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.PacketHeader.html" title="org.apache.hadoop.hdfs.protocol 中的类">DataTransferProtocol.PacketHeader</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeInfo.html#getParent()"><B>getParent()</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeInfo.html" title="org.apache.hadoop.hdfs.protocol 中的类">DatanodeInfo</A> 中的方法
<DD>Return this node's parent
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DirectoryListing.html#getPartialListing()"><B>getPartialListing()</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DirectoryListing.html" title="org.apache.hadoop.hdfs.protocol 中的类">DirectoryListing</A> 中的方法
<DD>Get the partial listing of file status
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#getPendingDeletionBlocks()"><B>getPendingDeletionBlocks()</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FSNamesystem</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#getPendingReplicationBlocks()"><B>getPendingReplicationBlocks()</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FSNamesystem</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/metrics/FSNamesystemMBean.html#getPendingReplicationBlocks()"><B>getPendingReplicationBlocks()</B></A> - 
接口 org.apache.hadoop.hdfs.server.namenode.metrics.<A HREF="./org/apache/hadoop/hdfs/server/namenode/metrics/FSNamesystemMBean.html" title="org.apache.hadoop.hdfs.server.namenode.metrics 中的接口">FSNamesystemMBean</A> 中的方法
<DD>Blocks pending to be replicated
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#getPercentRemaining()"><B>getPercentRemaining()</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FSNamesystem</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNodeMXBean.html#getPercentRemaining()"><B>getPercentRemaining()</B></A> - 
接口 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNodeMXBean.html" title="org.apache.hadoop.hdfs.server.namenode 中的接口">NameNodeMXBean</A> 中的方法
<DD>Gets the total remaining space by data nodes as percentage of total 
 capacity
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#getPercentUsed()"><B>getPercentUsed()</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FSNamesystem</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNodeMXBean.html#getPercentUsed()"><B>getPercentUsed()</B></A> - 
接口 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNodeMXBean.html" title="org.apache.hadoop.hdfs.server.namenode 中的接口">NameNodeMXBean</A> 中的方法
<DD>Gets the total used space by data nodes as percentage of total capacity
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/HdfsFileStatus.html#getPermission()"><B>getPermission()</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/HdfsFileStatus.html" title="org.apache.hadoop.hdfs.protocol 中的类">HdfsFileStatus</A> 中的方法
<DD>Get FsPermission associated with the file.
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/CodingMatrix.html#getPerNodeBlocksNum()"><B>getPerNodeBlocksNum()</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/CodingMatrix.html" title="org.apache.hadoop.hdfs.protocol 中的类">CodingMatrix</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/RegeneratingCodeMatrix.html#getPerNodeBlocksNum()"><B>getPerNodeBlocksNum()</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/RegeneratingCodeMatrix.html" title="org.apache.hadoop.hdfs.protocol 中的类">RegeneratingCodeMatrix</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeID.html#getPort()"><B>getPort()</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeID.html" title="org.apache.hadoop.hdfs.protocol 中的类">DatanodeID</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSInputStream.html#getPos()"><B>getPos()</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSInputStream.html" title="org.apache.hadoop.hdfs 中的类">DFSInputStream</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/ClientProtocol.html#getPreferredBlockSize(java.lang.String)"><B>getPreferredBlockSize(String)</B></A> - 
接口 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/ClientProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的接口">ClientProtocol</A> 中的方法
<DD>Get the block size for the given file.
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html#getPreferredBlockSize(java.lang.String)"><B>getPreferredBlockSize(String)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">NameNode</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/Storage.StorageDirectory.html#getPreviousCheckpoint()"><B>getPreviousCheckpoint()</B></A> - 
类 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/Storage.StorageDirectory.html" title="org.apache.hadoop.hdfs.server.common 中的类">Storage.StorageDirectory</A> 中的方法
<DD><code>previous.checkpoint</code> is a directory, which holds the previous
 (before the last save) state of the storage directory.
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/Storage.StorageDirectory.html#getPreviousDir()"><B>getPreviousDir()</B></A> - 
类 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/Storage.StorageDirectory.html" title="org.apache.hadoop.hdfs.server.common 中的类">Storage.StorageDirectory</A> 中的方法
<DD>Directory <code>previous</code> contains the previous file system state,
 which the system can be rolled back to.
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/Storage.StorageDirectory.html#getPreviousTmp()"><B>getPreviousTmp()</B></A> - 
类 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/Storage.StorageDirectory.html" title="org.apache.hadoop.hdfs.server.common 中的类">Storage.StorageDirectory</A> 中的方法
<DD><code>previous.tmp</code> is a transient directory, which holds
 current file system state while the new state is saved into the new
 <code>current</code> during upgrade.
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/Storage.StorageDirectory.html#getPreviousVersionFile()"><B>getPreviousVersionFile()</B></A> - 
类 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/Storage.StorageDirectory.html" title="org.apache.hadoop.hdfs.server.common 中的类">Storage.StorageDirectory</A> 中的方法
<DD>File <code>VERSION</code> from the <code>previous</code> directory.
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/DataNode.html#getProtocolVersion(java.lang.String, long)"><B>getProtocolVersion(String, long)</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/DataNode.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">DataNode</A> 中的方法
<DD>
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html#getProtocolVersion(java.lang.String, long)"><B>getProtocolVersion(String, long)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">NameNode</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DistributedFileSystem.html#getRawCapacity()"><B>getRawCapacity()</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DistributedFileSystem.html" title="org.apache.hadoop.hdfs 中的类">DistributedFileSystem</A> 中的方法
<DD><B>已过时。</B>&nbsp;<I>Use <CODE>FileSystem.getStatus()</CODE> 
 instead</I>
<DT><A HREF="./org/apache/hadoop/hdfs/DistributedFileSystem.html#getRawUsed()"><B>getRawUsed()</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DistributedFileSystem.html" title="org.apache.hadoop.hdfs 中的类">DistributedFileSystem</A> 中的方法
<DD><B>已过时。</B>&nbsp;<I>Use <CODE>FileSystem.getStatus()</CODE> 
 instead</I>
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/BlockRecoveryCommand.html#getRecoveringBlocks()"><B>getRecoveringBlocks()</B></A> - 
类 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/BlockRecoveryCommand.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">BlockRecoveryCommand</A> 中的方法
<DD>Return the list of recovering blocks.
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/CodingMatrix.html#getRecoveryMinNodesNum()"><B>getRecoveryMinNodesNum()</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/CodingMatrix.html" title="org.apache.hadoop.hdfs.protocol 中的类">CodingMatrix</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/RegeneratingCodeMatrix.html#getRecoveryMinNodesNum()"><B>getRecoveryMinNodesNum()</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/RegeneratingCodeMatrix.html" title="org.apache.hadoop.hdfs.protocol 中的类">RegeneratingCodeMatrix</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/CodingMatrix.html#getRecoveryNodesNum()"><B>getRecoveryNodesNum()</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/CodingMatrix.html" title="org.apache.hadoop.hdfs.protocol 中的类">CodingMatrix</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/RegeneratingCodeMatrix.html#getRecoveryNodesNum()"><B>getRecoveryNodesNum()</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/RegeneratingCodeMatrix.html" title="org.apache.hadoop.hdfs.protocol 中的类">RegeneratingCodeMatrix</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.BlockConstructionStage.html#getRecoveryStage()"><B>getRecoveryStage()</B></A> - 
枚举 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.BlockConstructionStage.html" title="org.apache.hadoop.hdfs.protocol 中的枚举">DataTransferProtocol.BlockConstructionStage</A> 中的方法
<DD>get the recovery stage of this stage
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeID.html#getRegisterTime()"><B>getRegisterTime()</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeID.html" title="org.apache.hadoop.hdfs.protocol 中的类">DatanodeID</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/Storage.html#getRegistrationID(org.apache.hadoop.hdfs.server.common.StorageInfo)"><B>getRegistrationID(StorageInfo)</B></A> - 
类 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/Storage.html" title="org.apache.hadoop.hdfs.server.common 中的类">Storage</A> 中的静态方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#getRegistrationID()"><B>getRegistrationID()</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FSNamesystem</A> 中的方法
<DD>Get registrationID for datanodes based on the namespaceID.
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/DatanodeRegistration.html#getRegistrationID()"><B>getRegistrationID()</B></A> - 
类 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/DatanodeRegistration.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">DatanodeRegistration</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/NamenodeRegistration.html#getRegistrationID()"><B>getRegistrationID()</B></A> - 
类 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/NamenodeRegistration.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">NamenodeRegistration</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/NodeRegistration.html#getRegistrationID()"><B>getRegistrationID()</B></A> - 
接口 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/NodeRegistration.html" title="org.apache.hadoop.hdfs.server.protocol 中的接口">NodeRegistration</A> 中的方法
<DD>Get registration ID of the server node.
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeInfo.html#getRemaining()"><B>getRemaining()</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeInfo.html" title="org.apache.hadoop.hdfs.protocol 中的类">DatanodeInfo</A> 中的方法
<DD>The raw free space.
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDataset.html#getRemaining()"><B>getRemaining()</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDataset.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">FSDataset</A> 中的方法
<DD>Return how many bytes can still be stored in the FSDataset
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/metrics/FSDatasetMBean.html#getRemaining()"><B>getRemaining()</B></A> - 
接口 org.apache.hadoop.hdfs.server.datanode.metrics.<A HREF="./org/apache/hadoop/hdfs/server/datanode/metrics/FSDatasetMBean.html" title="org.apache.hadoop.hdfs.server.datanode.metrics 中的接口">FSDatasetMBean</A> 中的方法
<DD>Returns the amount of free storage space (in bytes)
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DirectoryListing.html#getRemainingEntries()"><B>getRemainingEntries()</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DirectoryListing.html" title="org.apache.hadoop.hdfs.protocol 中的类">DirectoryListing</A> 中的方法
<DD>Get the number of remaining entries that are left to be listed
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeInfo.html#getRemainingPercent()"><B>getRemainingPercent()</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeInfo.html" title="org.apache.hadoop.hdfs.protocol 中的类">DatanodeInfo</A> 中的方法
<DD>The remaining space as percentage of configured capacity.
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/Storage.StorageDirectory.html#getRemovedTmp()"><B>getRemovedTmp()</B></A> - 
类 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/Storage.StorageDirectory.html" title="org.apache.hadoop.hdfs.server.common 中的类">Storage.StorageDirectory</A> 中的方法
<DD><code>removed.tmp</code> is a transient directory, which holds
 current file system state while the previous state is moved into
 <code>current</code> during rollback.
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDataset.html#getReplica(long)"><B>getReplica(long)</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDataset.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">FSDataset</A> 中的方法
<DD><B>已过时。</B>&nbsp;<I>use <A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDataset.html#fetchReplicaInfo(long)"><CODE>FSDataset.fetchReplicaInfo(long)</CODE></A> instead.</I>
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.html#getReplica(long)"><B>getReplica(long)</B></A> - 
接口 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.html" title="org.apache.hadoop.hdfs.server.datanode 中的接口">FSDatasetInterface</A> 中的方法
<DD><B>已过时。</B>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/HdfsFileStatus.html#getReplication()"><B>getReplication()</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/HdfsFileStatus.html" title="org.apache.hadoop.hdfs.protocol 中的类">HdfsFileStatus</A> 中的方法
<DD>Get the replication factor of a file.
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/ClientDatanodeProtocol.html#getReplicaVisibleLength(org.apache.hadoop.hdfs.protocol.Block)"><B>getReplicaVisibleLength(Block)</B></A> - 
接口 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/ClientDatanodeProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的接口">ClientDatanodeProtocol</A> 中的方法
<DD>Return the visible length of a replica.
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/DataNode.html#getReplicaVisibleLength(org.apache.hadoop.hdfs.protocol.Block)"><B>getReplicaVisibleLength(Block)</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/DataNode.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">DataNode</A> 中的方法
<DD>Return the visible length of a replica.
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDataset.html#getReplicaVisibleLength(org.apache.hadoop.hdfs.protocol.Block)"><B>getReplicaVisibleLength(Block)</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDataset.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">FSDataset</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.html#getReplicaVisibleLength(org.apache.hadoop.hdfs.protocol.Block)"><B>getReplicaVisibleLength(Block)</B></A> - 
接口 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.html" title="org.apache.hadoop.hdfs.server.datanode 中的接口">FSDatasetInterface</A> 中的方法
<DD>Get visible length of the specified replica.
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.PipelineAck.html#getReply(int)"><B>getReply(int)</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.PipelineAck.html" title="org.apache.hadoop.hdfs.protocol 中的类">DataTransferProtocol.PipelineAck</A> 中的方法
<DD>get the ith reply
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/UnresolvedPathException.html#getResolvedPath()"><B>getResolvedPath()</B></A> - 
异常 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/UnresolvedPathException.html" title="org.apache.hadoop.hdfs.protocol 中的类">UnresolvedPathException</A> 中的方法
<DD>Return a path with the link resolved with the target.
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FSImage.html#getRestoreFailedStorage()"><B>getRestoreFailedStorage()</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/FSImage.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FSImage</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html#getRole()"><B>getRole()</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">NameNode</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/NamenodeRegistration.html#getRole()"><B>getRole()</B></A> - 
类 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/NamenodeRegistration.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">NamenodeRegistration</A> 中的方法
<DD>Get name-node role.
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/Storage.StorageDirectory.html#getRoot()"><B>getRoot()</B></A> - 
类 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/Storage.StorageDirectory.html" title="org.apache.hadoop.hdfs.server.common 中的类">Storage.StorageDirectory</A> 中的方法
<DD>Get root directory of this storage
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/CodingMatrix.html#getRow()"><B>getRow()</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/CodingMatrix.html" title="org.apache.hadoop.hdfs.protocol 中的类">CodingMatrix</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/CodingMatrix.html#getRowArray(int)"><B>getRowArray(int)</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/CodingMatrix.html" title="org.apache.hadoop.hdfs.protocol 中的类">CodingMatrix</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/DataNode.html#getRpcPort()"><B>getRpcPort()</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/DataNode.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">DataNode</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/DataNodeMXBean.html#getRpcPort()"><B>getRpcPort()</B></A> - 
接口 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/DataNodeMXBean.html" title="org.apache.hadoop.hdfs.server.datanode 中的接口">DataNodeMXBean</A> 中的方法
<DD>Gets the rpc port.
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/BackupNode.html#getRpcServerAddress(org.apache.hadoop.conf.Configuration)"><B>getRpcServerAddress(Configuration)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/BackupNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">BackupNode</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html#getRpcServerAddress(org.apache.hadoop.conf.Configuration)"><B>getRpcServerAddress(Configuration)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">NameNode</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/RSCoderProtocol.html#getRSP()"><B>getRSP()</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/RSCoderProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的类">RSCoderProtocol</A> 中的静态方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#getSafemode()"><B>getSafemode()</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FSNamesystem</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNodeMXBean.html#getSafemode()"><B>getSafemode()</B></A> - 
接口 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNodeMXBean.html" title="org.apache.hadoop.hdfs.server.namenode 中的接口">NameNodeMXBean</A> 中的方法
<DD>Gets the safemode status
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#getScheduledReplicationBlocks()"><B>getScheduledReplicationBlocks()</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FSNamesystem</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/metrics/FSNamesystemMBean.html#getScheduledReplicationBlocks()"><B>getScheduledReplicationBlocks()</B></A> - 
接口 org.apache.hadoop.hdfs.server.namenode.metrics.<A HREF="./org/apache/hadoop/hdfs/server/namenode/metrics/FSNamesystemMBean.html" title="org.apache.hadoop.hdfs.server.namenode.metrics 中的接口">FSNamesystemMBean</A> 中的方法
<DD>Blocks scheduled for replication
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/DataNode.html#getSelfAddr()"><B>getSelfAddr()</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/DataNode.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">DataNode</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.PacketHeader.html#getSeqno()"><B>getSeqno()</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.PacketHeader.html" title="org.apache.hadoop.hdfs.protocol 中的类">DataTransferProtocol.PacketHeader</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.PipelineAck.html#getSeqno()"><B>getSeqno()</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.PipelineAck.html" title="org.apache.hadoop.hdfs.protocol 中的类">DataTransferProtocol.PipelineAck</A> 中的方法
<DD>Get the sequence number
<DT><A HREF="./org/apache/hadoop/fs/Hdfs.html#getServerDefaults()"><B>getServerDefaults()</B></A> - 
类 org.apache.hadoop.fs.<A HREF="./org/apache/hadoop/fs/Hdfs.html" title="org.apache.hadoop.fs 中的类">Hdfs</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSClient.html#getServerDefaults()"><B>getServerDefaults()</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSClient.html" title="org.apache.hadoop.hdfs 中的类">DFSClient</A> 中的方法
<DD>Get server default values for a number of configuration params.
<DT><A HREF="./org/apache/hadoop/hdfs/DistributedFileSystem.html#getServerDefaults()"><B>getServerDefaults()</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DistributedFileSystem.html" title="org.apache.hadoop.hdfs 中的类">DistributedFileSystem</A> 中的方法
<DD>
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/ClientProtocol.html#getServerDefaults()"><B>getServerDefaults()</B></A> - 
接口 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/ClientProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的接口">ClientProtocol</A> 中的方法
<DD>Get server default values for a number of configuration params.
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html#getServerDefaults()"><B>getServerDefaults()</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">NameNode</A> 中的方法
<DD>Get server default values for a number of configuration params.
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html#getServernodeStator()"><B>getServernodeStator()</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">NameNode</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html#getServiceAddress(org.apache.hadoop.conf.Configuration, boolean)"><B>getServiceAddress(Configuration, boolean)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">NameNode</A> 中的静态方法
<DD>Fetches the address for services to use when connecting to namenode
 based on the value of fallback returns null if the special
 address is not specified or returns the default namenode address
 to be used by both clients and services.
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/BackupNode.html#getServiceRpcServerAddress(org.apache.hadoop.conf.Configuration)"><B>getServiceRpcServerAddress(Configuration)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/BackupNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">BackupNode</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html#getServiceRpcServerAddress(org.apache.hadoop.conf.Configuration)"><B>getServiceRpcServerAddress(Configuration)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">NameNode</A> 中的方法
<DD>Given a configuration get the address of the service rpc server
 If the service rpc is not configured returns null
<DT><A HREF="./org/apache/hadoop/hdfs/HDFSPolicyProvider.html#getServices()"><B>getServices()</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/HDFSPolicyProvider.html" title="org.apache.hadoop.hdfs 中的类">HDFSPolicyProvider</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/CheckpointCommand.html#getSignature()"><B>getSignature()</B></A> - 
类 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/CheckpointCommand.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">CheckpointCommand</A> 中的方法
<DD>Checkpoint signature is used to ensure 
 that nodes are talking about the same checkpoint.
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/CumulusRecoveryCommand.html#getSize()"><B>getSize()</B></A> - 
类 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/CumulusRecoveryCommand.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">CumulusRecoveryCommand</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/RCRecoveryCommand.html#getSize()"><B>getSize()</B></A> - 
类 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/RCRecoveryCommand.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">RCRecoveryCommand</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/GenerationStamp.html#getStamp()"><B>getStamp()</B></A> - 
类 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/GenerationStamp.html" title="org.apache.hadoop.hdfs.server.common 中的类">GenerationStamp</A> 中的方法
<DD>Returns the current generation stamp
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/LocatedBlock.html#getStartOffset()"><B>getStartOffset()</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/LocatedBlock.html" title="org.apache.hadoop.hdfs.protocol 中的类">LocatedBlock</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#getStartTime()"><B>getStartTime()</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FSNamesystem</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/HdfsConstants.ReplicaState.html#getState(int)"><B>getState(int)</B></A> - 
枚举 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/HdfsConstants.ReplicaState.html" title="org.apache.hadoop.hdfs.server.common 中的枚举">HdfsConstants.ReplicaState</A> 中的静态方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/Replica.html#getState()"><B>getState()</B></A> - 
接口 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/Replica.html" title="org.apache.hadoop.hdfs.server.datanode 中的接口">Replica</A> 中的方法
<DD>Get the replica state
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/ClientProtocol.html#getStats()"><B>getStats()</B></A> - 
接口 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/ClientProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的接口">ClientProtocol</A> 中的方法
<DD>Get a set of statistics about the filesystem.
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html#getStats()"><B>getStats()</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">NameNode</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DistributedFileSystem.html#getStatus(org.apache.hadoop.fs.Path)"><B>getStatus(Path)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DistributedFileSystem.html" title="org.apache.hadoop.hdfs 中的类">DistributedFileSystem</A> 中的方法
<DD>
<DT><A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeCPUStator.html#getStatus()"><B>getStatus()</B></A> - 
类 org.apache.hadoop.hdfs.server.monitor.<A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeCPUStator.html" title="org.apache.hadoop.hdfs.server.monitor 中的类">ServernodeCPUStator</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeIOStator.html#getStatus()"><B>getStatus()</B></A> - 
类 org.apache.hadoop.hdfs.server.monitor.<A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeIOStator.html" title="org.apache.hadoop.hdfs.server.monitor 中的类">ServernodeIOStator</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeMEMStator.html#getStatus()"><B>getStatus()</B></A> - 
类 org.apache.hadoop.hdfs.server.monitor.<A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeMEMStator.html" title="org.apache.hadoop.hdfs.server.monitor 中的类">ServernodeMEMStator</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeNETStator.html#getStatus()"><B>getStatus()</B></A> - 
类 org.apache.hadoop.hdfs.server.monitor.<A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeNETStator.html" title="org.apache.hadoop.hdfs.server.monitor 中的类">ServernodeNETStator</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/UpgradeStatusReport.html#getStatusText(boolean)"><B>getStatusText(boolean)</B></A> - 
类 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/UpgradeStatusReport.html" title="org.apache.hadoop.hdfs.server.common 中的类">UpgradeStatusReport</A> 中的方法
<DD>Get upgradeStatus data as a text for reporting.
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/Storage.html#getStorageDir(int)"><B>getStorageDir(int)</B></A> - 
类 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/Storage.html" title="org.apache.hadoop.hdfs.server.common 中的类">Storage</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#getStorageDirs(org.apache.hadoop.conf.Configuration, java.lang.String)"><B>getStorageDirs(Configuration, String)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FSNamesystem</A> 中的静态方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/Storage.StorageDirectory.html#getStorageDirType()"><B>getStorageDirType()</B></A> - 
类 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/Storage.StorageDirectory.html" title="org.apache.hadoop.hdfs.server.common 中的类">Storage.StorageDirectory</A> 中的方法
<DD>Get storage directory type
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/Storage.StorageDirType.html#getStorageDirType()"><B>getStorageDirType()</B></A> - 
接口 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/Storage.StorageDirType.html" title="org.apache.hadoop.hdfs.server.common 中的接口">Storage.StorageDirType</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeID.html#getStorageID()"><B>getStorageID()</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeID.html" title="org.apache.hadoop.hdfs.protocol 中的类">DatanodeID</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/DataStorage.html#getStorageID()"><B>getStorageID()</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/DataStorage.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">DataStorage</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDataset.html#getStorageInfo()"><B>getStorageInfo()</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDataset.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">FSDataset</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/metrics/FSDatasetMBean.html#getStorageInfo()"><B>getStorageInfo()</B></A> - 
接口 org.apache.hadoop.hdfs.server.datanode.metrics.<A HREF="./org/apache/hadoop/hdfs/server/datanode/metrics/FSDatasetMBean.html" title="org.apache.hadoop.hdfs.server.datanode.metrics 中的接口">FSDatasetMBean</A> 中的方法
<DD>Returns the storage id of the underlying storage
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDataset.html#getStoredBlock(long)"><B>getStoredBlock(long)</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDataset.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">FSDataset</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.html#getStoredBlock(long)"><B>getStoredBlock(long)</B></A> - 
接口 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.html" title="org.apache.hadoop.hdfs.server.datanode 中的接口">FSDatasetInterface</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/CodingMatrix.html#getStoreFileNodesNum()"><B>getStoreFileNodesNum()</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/CodingMatrix.html" title="org.apache.hadoop.hdfs.protocol 中的类">CodingMatrix</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/RegeneratingCodeMatrix.html#getStoreFileNodesNum()"><B>getStoreFileNodesNum()</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/RegeneratingCodeMatrix.html" title="org.apache.hadoop.hdfs.protocol 中的类">RegeneratingCodeMatrix</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/DataNode.html#getStreamingAddr(org.apache.hadoop.conf.Configuration)"><B>getStreamingAddr(Configuration)</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/DataNode.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">DataNode</A> 中的静态方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/SecureDataNodeStarter.SecureResources.html#getStreamingSocket()"><B>getStreamingSocket()</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/SecureDataNodeStarter.SecureResources.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">SecureDataNodeStarter.SecureResources</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/LayoutVersion.html#getString()"><B>getString()</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/LayoutVersion.html" title="org.apache.hadoop.hdfs.protocol 中的类">LayoutVersion</A> 中的静态方法
<DD>Gets formatted string that describes <A HREF="./org/apache/hadoop/hdfs/protocol/LayoutVersion.html" title="org.apache.hadoop.hdfs.protocol 中的类"><CODE>LayoutVersion</CODE></A> information.
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/HdfsFileStatus.html#getSymlink()"><B>getSymlink()</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/HdfsFileStatus.html" title="org.apache.hadoop.hdfs.protocol 中的类">HdfsFileStatus</A> 中的方法
<DD>Get the string representation of the symlink.
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/INodeSymlink.html#getSymlink()"><B>getSymlink()</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/INodeSymlink.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">INodeSymlink</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/BlockCommand.html#getTargets()"><B>getTargets()</B></A> - 
类 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/BlockCommand.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">BlockCommand</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#getThreads()"><B>getThreads()</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FSNamesystem</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNodeMXBean.html#getThreads()"><B>getThreads()</B></A> - 
接口 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNodeMXBean.html" title="org.apache.hadoop.hdfs.server.namenode 中的接口">NameNodeMXBean</A> 中的方法
<DD>Gets the number of threads.
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDataset.html#getTmpInputStreams(org.apache.hadoop.hdfs.protocol.Block, long, long)"><B>getTmpInputStreams(Block, long, long)</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDataset.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">FSDataset</A> 中的方法
<DD>Returns handles to the block file and its metadata file
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.html#getTmpInputStreams(org.apache.hadoop.hdfs.protocol.Block, long, long)"><B>getTmpInputStreams(Block, long, long)</B></A> - 
接口 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.html" title="org.apache.hadoop.hdfs.server.datanode 中的接口">FSDatasetInterface</A> 中的方法
<DD>Returns an input stream at specified offset of the specified block
 The block is still in the tmp directory and is not finalized
<DT><A HREF="./org/apache/hadoop/hdfs/security/token/delegation/DelegationTokenSecretManager.html#getTokenExpiryTime(org.apache.hadoop.hdfs.security.token.delegation.DelegationTokenIdentifier)"><B>getTokenExpiryTime(DelegationTokenIdentifier)</B></A> - 
类 org.apache.hadoop.hdfs.security.token.delegation.<A HREF="./org/apache/hadoop/hdfs/security/token/delegation/DelegationTokenSecretManager.html" title="org.apache.hadoop.hdfs.security.token.delegation 中的类">DelegationTokenSecretManager</A> 中的方法
<DD>Returns expiry time of a token given its identifier.
<DT><A HREF="./org/apache/hadoop/hdfs/security/token/block/ExportedBlockKeys.html#getTokenLifetime()"><B>getTokenLifetime()</B></A> - 
类 org.apache.hadoop.hdfs.security.token.block.<A HREF="./org/apache/hadoop/hdfs/security/token/block/ExportedBlockKeys.html" title="org.apache.hadoop.hdfs.security.token.block 中的类">ExportedBlockKeys</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#getTotal()"><B>getTotal()</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FSNamesystem</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNodeMXBean.html#getTotal()"><B>getTotal()</B></A> - 
接口 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNodeMXBean.html" title="org.apache.hadoop.hdfs.server.namenode 中的接口">NameNodeMXBean</A> 中的方法
<DD>Gets total raw bytes including non-dfs used space.
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#getTotalBlocks()"><B>getTotalBlocks()</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FSNamesystem</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNodeMXBean.html#getTotalBlocks()"><B>getTotalBlocks()</B></A> - 
接口 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNodeMXBean.html" title="org.apache.hadoop.hdfs.server.namenode 中的接口">NameNodeMXBean</A> 中的方法
<DD>Gets the total numbers of blocks on the cluster.
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#getTotalFiles()"><B>getTotalFiles()</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FSNamesystem</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNodeMXBean.html#getTotalFiles()"><B>getTotalFiles()</B></A> - 
接口 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNodeMXBean.html" title="org.apache.hadoop.hdfs.server.namenode 中的接口">NameNodeMXBean</A> 中的方法
<DD>Gets the total number of files on the cluster
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FSClusterStats.html#getTotalLoad()"><B>getTotalLoad()</B></A> - 
接口 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/FSClusterStats.html" title="org.apache.hadoop.hdfs.server.namenode 中的接口">FSClusterStats</A> 中的方法
<DD>an indication of the total load of the cluster.
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#getTotalLoad()"><B>getTotalLoad()</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FSNamesystem</A> 中的方法
<DD>Total number of connections.
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/metrics/FSNamesystemMBean.html#getTotalLoad()"><B>getTotalLoad()</B></A> - 
接口 org.apache.hadoop.hdfs.server.namenode.metrics.<A HREF="./org/apache/hadoop/hdfs/server/namenode/metrics/FSNamesystemMBean.html" title="org.apache.hadoop.hdfs.server.namenode.metrics 中的接口">FSNamesystemMBean</A> 中的方法
<DD>Total Load on the FSNamesystem
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/Upgradeable.html#getType()"><B>getType()</B></A> - 
接口 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/Upgradeable.html" title="org.apache.hadoop.hdfs.server.common 中的接口">Upgradeable</A> 中的方法
<DD>Get the type of the software component, which this object is upgrading.
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/UpgradeManager.html#getType()"><B>getType()</B></A> - 
类 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/UpgradeManager.html" title="org.apache.hadoop.hdfs.server.common 中的类">UpgradeManager</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/UpgradeObjectDatanode.html#getType()"><B>getType()</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/UpgradeObjectDatanode.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">UpgradeObjectDatanode</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/UpgradeObjectNamenode.html#getType()"><B>getType()</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/UpgradeObjectNamenode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">UpgradeObjectNamenode</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/JspHelper.html#getUGI(javax.servlet.http.HttpServletRequest, org.apache.hadoop.conf.Configuration)"><B>getUGI(HttpServletRequest, Configuration)</B></A> - 
类 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/JspHelper.html" title="org.apache.hadoop.hdfs.server.common 中的类">JspHelper</A> 中的静态方法
<DD>Get <CODE>UserGroupInformation</CODE> and possibly the delegation token out of
 the request.
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#getUnderReplicatedBlocks()"><B>getUnderReplicatedBlocks()</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FSNamesystem</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/metrics/FSNamesystemMBean.html#getUnderReplicatedBlocks()"><B>getUnderReplicatedBlocks()</B></A> - 
接口 org.apache.hadoop.hdfs.server.namenode.metrics.<A HREF="./org/apache/hadoop/hdfs/server/namenode/metrics/FSNamesystemMBean.html" title="org.apache.hadoop.hdfs.server.namenode.metrics 中的接口">FSNamesystemMBean</A> 中的方法
<DD>Blocks under replicated
<DT><A HREF="./org/apache/hadoop/hdfs/DFSClient.html#getUnderReplicatedBlocksCount()"><B>getUnderReplicatedBlocksCount()</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSClient.html" title="org.apache.hadoop.hdfs 中的类">DFSClient</A> 中的方法
<DD>Returns count of blocks with one of more replica missing.
<DT><A HREF="./org/apache/hadoop/hdfs/DistributedFileSystem.html#getUnderReplicatedBlocksCount()"><B>getUnderReplicatedBlocksCount()</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DistributedFileSystem.html" title="org.apache.hadoop.hdfs 中的类">DistributedFileSystem</A> 中的方法
<DD>Returns count of blocks with one of more replica missing.
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#getUpgradePermission()"><B>getUpgradePermission()</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FSNamesystem</A> 中的方法
<DD>Return the default path permission when upgrading from releases with no
 permissions (<=0.15) to releases with permissions (>=0.16)
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/UpgradeManager.html#getUpgradeState()"><B>getUpgradeState()</B></A> - 
类 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/UpgradeManager.html" title="org.apache.hadoop.hdfs.server.common 中的类">UpgradeManager</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/Upgradeable.html#getUpgradeStatus()"><B>getUpgradeStatus()</B></A> - 
接口 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/Upgradeable.html" title="org.apache.hadoop.hdfs.server.common 中的接口">Upgradeable</A> 中的方法
<DD>Upgrade status determines a percentage of the work done out of the total 
 amount required by the upgrade.
 
 100% means that the upgrade is completed.
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/UpgradeManager.html#getUpgradeStatus()"><B>getUpgradeStatus()</B></A> - 
类 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/UpgradeManager.html" title="org.apache.hadoop.hdfs.server.common 中的类">UpgradeManager</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/UpgradeObject.html#getUpgradeStatus()"><B>getUpgradeStatus()</B></A> - 
类 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/UpgradeObject.html" title="org.apache.hadoop.hdfs.server.common 中的类">UpgradeObject</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/UpgradeStatusReport.html#getUpgradeStatus()"><B>getUpgradeStatus()</B></A> - 
类 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/UpgradeStatusReport.html" title="org.apache.hadoop.hdfs.server.common 中的类">UpgradeStatusReport</A> 中的方法
<DD>Get upgrade upgradeStatus as a percentage of the total upgrade done.
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/Upgradeable.html#getUpgradeStatusReport(boolean)"><B>getUpgradeStatusReport(boolean)</B></A> - 
接口 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/Upgradeable.html" title="org.apache.hadoop.hdfs.server.common 中的接口">Upgradeable</A> 中的方法
<DD>Get status report for the upgrade.
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/UpgradeObject.html#getUpgradeStatusReport(boolean)"><B>getUpgradeStatusReport(boolean)</B></A> - 
类 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/UpgradeObject.html" title="org.apache.hadoop.hdfs.server.common 中的类">UpgradeObject</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/UpgradeManager.html#getUpgradeVersion()"><B>getUpgradeVersion()</B></A> - 
类 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/UpgradeManager.html" title="org.apache.hadoop.hdfs.server.common 中的类">UpgradeManager</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DistributedFileSystem.html#getUri()"><B>getUri()</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DistributedFileSystem.html" title="org.apache.hadoop.hdfs 中的类">DistributedFileSystem</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/HftpFileSystem.html#getUri()"><B>getUri()</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/HftpFileSystem.html" title="org.apache.hadoop.hdfs 中的类">HftpFileSystem</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/HsftpFileSystem.html#getUri()"><B>getUri()</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/HsftpFileSystem.html" title="org.apache.hadoop.hdfs 中的类">HsftpFileSystem</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html#getUri(java.net.InetSocketAddress)"><B>getUri(InetSocketAddress)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">NameNode</A> 中的静态方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/fs/Hdfs.html#getUriDefaultPort()"><B>getUriDefaultPort()</B></A> - 
类 org.apache.hadoop.fs.<A HREF="./org/apache/hadoop/fs/Hdfs.html" title="org.apache.hadoop.fs 中的类">Hdfs</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/JspHelper.html#getUrlParam(java.lang.String, java.lang.String, java.lang.String)"><B>getUrlParam(String, String, String)</B></A> - 
类 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/JspHelper.html" title="org.apache.hadoop.hdfs.server.common 中的类">JspHelper</A> 中的静态方法
<DD>Returns the url parameter for the given string, prefixed with
 paramSeparator.
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/JspHelper.html#getUrlParam(java.lang.String, java.lang.String, boolean)"><B>getUrlParam(String, String, boolean)</B></A> - 
类 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/JspHelper.html" title="org.apache.hadoop.hdfs.server.common 中的类">JspHelper</A> 中的静态方法
<DD>Returns the url parameter for the given string, prefixed with '?'
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/JspHelper.html#getUrlParam(java.lang.String, java.lang.String)"><B>getUrlParam(String, String)</B></A> - 
类 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/JspHelper.html" title="org.apache.hadoop.hdfs.server.common 中的类">JspHelper</A> 中的静态方法
<DD>Returns the url parameter for the given string, prefixed with '&'.
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#getUsed()"><B>getUsed()</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FSNamesystem</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNodeMXBean.html#getUsed()"><B>getUsed()</B></A> - 
接口 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNodeMXBean.html" title="org.apache.hadoop.hdfs.server.namenode 中的接口">NameNodeMXBean</A> 中的方法
<DD>Gets the used space by data nodes.
<DT><A HREF="./org/apache/hadoop/hdfs/security/token/block/BlockTokenIdentifier.html#getUser()"><B>getUser()</B></A> - 
类 org.apache.hadoop.hdfs.security.token.block.<A HREF="./org/apache/hadoop/hdfs/security/token/block/BlockTokenIdentifier.html" title="org.apache.hadoop.hdfs.security.token.block 中的类">BlockTokenIdentifier</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/security/token/block/BlockTokenIdentifier.html#getUserId()"><B>getUserId()</B></A> - 
类 org.apache.hadoop.hdfs.security.token.block.<A HREF="./org/apache/hadoop/hdfs/security/token/block/BlockTokenIdentifier.html" title="org.apache.hadoop.hdfs.security.token.block 中的类">BlockTokenIdentifier</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/HdfsConstants.ReplicaState.html#getValue()"><B>getValue()</B></A> - 
枚举 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/HdfsConstants.ReplicaState.html" title="org.apache.hadoop.hdfs.server.common 中的枚举">HdfsConstants.ReplicaState</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/tools/JMXGet.html#getValue(java.lang.String)"><B>getValue(String)</B></A> - 
类 org.apache.hadoop.hdfs.tools.<A HREF="./org/apache/hadoop/hdfs/tools/JMXGet.html" title="org.apache.hadoop.hdfs.tools 中的类">JMXGet</A> 中的方法
<DD>get single value by key
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/CodingMatrix.html#getVandermondeMatrix()"><B>getVandermondeMatrix()</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/CodingMatrix.html" title="org.apache.hadoop.hdfs.protocol 中的类">CodingMatrix</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/RegeneratingCodeMatrix.html#getVandermondeMatrix()"><B>getVandermondeMatrix()</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/RegeneratingCodeMatrix.html" title="org.apache.hadoop.hdfs.protocol 中的类">RegeneratingCodeMatrix</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/Upgradeable.html#getVersion()"><B>getVersion()</B></A> - 
接口 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/Upgradeable.html" title="org.apache.hadoop.hdfs.server.common 中的接口">Upgradeable</A> 中的方法
<DD>Get the layout version of the upgrade object.
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/UpgradeStatusReport.html#getVersion()"><B>getVersion()</B></A> - 
类 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/UpgradeStatusReport.html" title="org.apache.hadoop.hdfs.server.common 中的类">UpgradeStatusReport</A> 中的方法
<DD>Get the layout version of the currently running upgrade.
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/DataNode.html#getVersion()"><B>getVersion()</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/DataNode.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">DataNode</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/DataNodeMXBean.html#getVersion()"><B>getVersion()</B></A> - 
接口 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/DataNodeMXBean.html" title="org.apache.hadoop.hdfs.server.datanode 中的接口">DataNodeMXBean</A> 中的方法
<DD>Gets the version of Hadoop.
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#getVersion()"><B>getVersion()</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FSNamesystem</A> 中的方法
<DD>Class representing Namenode information for JMX interfaces
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNodeMXBean.html#getVersion()"><B>getVersion()</B></A> - 
接口 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNodeMXBean.html" title="org.apache.hadoop.hdfs.server.namenode 中的接口">NameNodeMXBean</A> 中的方法
<DD>Gets the version of Hadoop.
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/DatanodeRegistration.html#getVersion()"><B>getVersion()</B></A> - 
类 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/DatanodeRegistration.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">DatanodeRegistration</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/NamenodeRegistration.html#getVersion()"><B>getVersion()</B></A> - 
类 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/NamenodeRegistration.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">NamenodeRegistration</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/NodeRegistration.html#getVersion()"><B>getVersion()</B></A> - 
接口 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/NodeRegistration.html" title="org.apache.hadoop.hdfs.server.protocol 中的接口">NodeRegistration</A> 中的方法
<DD>Get layout version of the server node.
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/UpgradeCommand.html#getVersion()"><B>getVersion()</B></A> - 
类 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/UpgradeCommand.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">UpgradeCommand</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/Storage.StorageDirectory.html#getVersionFile()"><B>getVersionFile()</B></A> - 
类 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/Storage.StorageDirectory.html" title="org.apache.hadoop.hdfs.server.common 中的类">Storage.StorageDirectory</A> 中的方法
<DD>File <code>VERSION</code> contains the following fields:
 
 node type
 layout version
 namespaceID
 fs state creation time
 other fields specific for this node type
 
 The version file is always written last during storage directory updates.
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/JspHelper.html#getVersionTable()"><B>getVersionTable()</B></A> - 
类 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/JspHelper.html" title="org.apache.hadoop.hdfs.server.common 中的类">JspHelper</A> 中的静态方法
<DD>Return a table containing version information.
<DT><A HREF="./org/apache/hadoop/hdfs/DFSClient.DFSDataInputStream.html#getVisibleLength()"><B>getVisibleLength()</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSClient.DFSDataInputStream.html" title="org.apache.hadoop.hdfs 中的类">DFSClient.DFSDataInputStream</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/Replica.html#getVisibleLength()"><B>getVisibleLength()</B></A> - 
接口 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/Replica.html" title="org.apache.hadoop.hdfs.server.datanode 中的接口">Replica</A> 中的方法
<DD>Get the number of bytes that are visible to readers
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/DatanodeDescriptor.html#getVolumeFailures()"><B>getVolumeFailures()</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/DatanodeDescriptor.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">DatanodeDescriptor</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/DataNode.html#getVolumeInfo()"><B>getVolumeInfo()</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/DataNode.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">DataNode</A> 中的方法
<DD>Returned information is a JSON representation of a map with 
 volume name as the key and value is a map of volume attribute 
 keys to its values
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/DataNodeMXBean.html#getVolumeInfo()"><B>getVolumeInfo()</B></A> - 
接口 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/DataNodeMXBean.html" title="org.apache.hadoop.hdfs.server.datanode 中的接口">DataNodeMXBean</A> 中的方法
<DD>Gets the information of each volume on the Datanode.
<DT><A HREF="./org/apache/hadoop/hdfs/DistributedFileSystem.html#getWorkingDirectory()"><B>getWorkingDirectory()</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DistributedFileSystem.html" title="org.apache.hadoop.hdfs 中的类">DistributedFileSystem</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/HftpFileSystem.html#getWorkingDirectory()"><B>getWorkingDirectory()</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/HftpFileSystem.html" title="org.apache.hadoop.hdfs 中的类">HftpFileSystem</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeInfo.html#getXceiverCount()"><B>getXceiverCount()</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeInfo.html" title="org.apache.hadoop.hdfs.protocol 中的类">DatanodeInfo</A> 中的方法
<DD>number of active connections
<DT><A HREF="./org/apache/hadoop/hdfs/tools/offlineImageViewer/OfflineImageViewer.html#go()"><B>go()</B></A> - 
类 org.apache.hadoop.hdfs.tools.offlineImageViewer.<A HREF="./org/apache/hadoop/hdfs/tools/offlineImageViewer/OfflineImageViewer.html" title="org.apache.hadoop.hdfs.tools.offlineImageViewer 中的类">OfflineImageViewer</A> 中的方法
<DD>Process image file.
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/GenerationStamp.html#GRANDFATHER_GENERATION_STAMP"><B>GRANDFATHER_GENERATION_STAMP</B></A> - 
类 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/GenerationStamp.html" title="org.apache.hadoop.hdfs.server.common 中的类">GenerationStamp</A> 中的静态变量
<DD>Generation stamp of blocks that pre-date the introduction
 of a generation stamp.
<DT><A HREF="./org/apache/hadoop/hdfs/util/GSet.html" title="org.apache.hadoop.hdfs.util 中的接口"><B>GSet</B></A>&lt;<A HREF="./org/apache/hadoop/hdfs/util/GSet.html" title="GSet 中的类型参数">K</A>,<A HREF="./org/apache/hadoop/hdfs/util/GSet.html" title="GSet 中的类型参数">E</A> extends <A HREF="./org/apache/hadoop/hdfs/util/GSet.html" title="GSet 中的类型参数">K</A>&gt; - <A HREF="./org/apache/hadoop/hdfs/util/package-summary.html">org.apache.hadoop.hdfs.util</A> 中的 接口<DD>A <A HREF="./org/apache/hadoop/hdfs/util/GSet.html" title="org.apache.hadoop.hdfs.util 中的接口"><CODE>GSet</CODE></A> is set,
 which supports the <A HREF="./org/apache/hadoop/hdfs/util/GSet.html#get(K)"><CODE>get(Object)</CODE></A> operation.<DT><A HREF="./org/apache/hadoop/hdfs/util/GSetByHashMap.html" title="org.apache.hadoop.hdfs.util 中的类"><B>GSetByHashMap</B></A>&lt;<A HREF="./org/apache/hadoop/hdfs/util/GSetByHashMap.html" title="GSetByHashMap 中的类型参数">K</A>,<A HREF="./org/apache/hadoop/hdfs/util/GSetByHashMap.html" title="GSetByHashMap 中的类型参数">E</A> extends <A HREF="./org/apache/hadoop/hdfs/util/GSetByHashMap.html" title="GSetByHashMap 中的类型参数">K</A>&gt; - <A HREF="./org/apache/hadoop/hdfs/util/package-summary.html">org.apache.hadoop.hdfs.util</A> 中的 类<DD>A <A HREF="./org/apache/hadoop/hdfs/util/GSet.html" title="org.apache.hadoop.hdfs.util 中的接口"><CODE>GSet</CODE></A> implementation by <CODE>HashMap</CODE>.<DT><A HREF="./org/apache/hadoop/hdfs/util/GSetByHashMap.html#GSetByHashMap(int, float)"><B>GSetByHashMap(int, float)</B></A> - 
类 org.apache.hadoop.hdfs.util.<A HREF="./org/apache/hadoop/hdfs/util/GSetByHashMap.html" title="org.apache.hadoop.hdfs.util 中的类">GSetByHashMap</A> 的构造方法
<DD>&nbsp;
</DL>
<HR>
<A NAME="_H_"><!-- --></A><H2>
<B>H</B></H2>
<DL>
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDataset.html#hasEnoughResource()"><B>hasEnoughResource()</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDataset.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">FSDataset</A> 中的方法
<DD>Return true - if there are still valid volumes on the DataNode.
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.html#hasEnoughResource()"><B>hasEnoughResource()</B></A> - 
接口 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.html" title="org.apache.hadoop.hdfs.server.datanode 中的接口">FSDatasetInterface</A> 中的方法
<DD>Checks how many valid storage volumes there are in the DataNode.
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/Block.html#hashCode()"><B>hashCode()</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/Block.html" title="org.apache.hadoop.hdfs.protocol 中的类">Block</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeID.html#hashCode()"><B>hashCode()</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeID.html" title="org.apache.hadoop.hdfs.protocol 中的类">DatanodeID</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeInfo.html#hashCode()"><B>hashCode()</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeInfo.html" title="org.apache.hadoop.hdfs.protocol 中的类">DatanodeInfo</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.PacketHeader.html#hashCode()"><B>hashCode()</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.PacketHeader.html" title="org.apache.hadoop.hdfs.protocol 中的类">DataTransferProtocol.PacketHeader</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/security/token/block/BlockTokenIdentifier.html#hashCode()"><B>hashCode()</B></A> - 
类 org.apache.hadoop.hdfs.security.token.block.<A HREF="./org/apache/hadoop/hdfs/security/token/block/BlockTokenIdentifier.html" title="org.apache.hadoop.hdfs.security.token.block 中的类">BlockTokenIdentifier</A> 中的方法
<DD>
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/GenerationStamp.html#hashCode()"><B>hashCode()</B></A> - 
类 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/GenerationStamp.html" title="org.apache.hadoop.hdfs.server.common 中的类">GenerationStamp</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/UpgradeObject.html#hashCode()"><B>hashCode()</B></A> - 
类 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/UpgradeObject.html" title="org.apache.hadoop.hdfs.server.common 中的类">UpgradeObject</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/CheckpointSignature.html#hashCode()"><B>hashCode()</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/CheckpointSignature.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">CheckpointSignature</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/DatanodeDescriptor.html#hashCode()"><B>hashCode()</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/DatanodeDescriptor.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">DatanodeDescriptor</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/DatanodeRegistration.html#hashCode()"><B>hashCode()</B></A> - 
类 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/DatanodeRegistration.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">DatanodeRegistration</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/ReplicaRecoveryInfo.html#hashCode()"><B>hashCode()</B></A> - 
类 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/ReplicaRecoveryInfo.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">ReplicaRecoveryInfo</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/util/ByteArray.html#hashCode()"><B>hashCode()</B></A> - 
类 org.apache.hadoop.hdfs.util.<A HREF="./org/apache/hadoop/hdfs/util/ByteArray.html" title="org.apache.hadoop.hdfs.util 中的类">ByteArray</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DirectoryListing.html#hasMore()"><B>hasMore()</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DirectoryListing.html" title="org.apache.hadoop.hdfs.protocol 中的类">DirectoryListing</A> 中的方法
<DD>Check if there are more entries that are left to be listed
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/BlockListAsLongs.BlockReportIterator.html#hasNext()"><B>hasNext()</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/BlockListAsLongs.BlockReportIterator.html" title="org.apache.hadoop.hdfs.protocol 中的类">BlockListAsLongs.BlockReportIterator</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/BlockReader.html#hasSentStatusCode()"><B>hasSentStatusCode()</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/BlockReader.html" title="org.apache.hadoop.hdfs 中的类">BlockReader</A> 中的方法
<DD>Whether the BlockReader has reached the end of its input stream
 and successfully sent a status code back to the datanode.
<DT><A HREF="./org/apache/hadoop/fs/Hdfs.html" title="org.apache.hadoop.fs 中的类"><B>Hdfs</B></A> - <A HREF="./org/apache/hadoop/fs/package-summary.html">org.apache.hadoop.fs</A> 中的 类<DD>&nbsp;<DT><A HREF="./org/apache/hadoop/hdfs/security/token/delegation/DelegationTokenIdentifier.html#HDFS_DELEGATION_KIND"><B>HDFS_DELEGATION_KIND</B></A> - 
类 org.apache.hadoop.hdfs.security.token.delegation.<A HREF="./org/apache/hadoop/hdfs/security/token/delegation/DelegationTokenIdentifier.html" title="org.apache.hadoop.hdfs.security.token.delegation 中的类">DelegationTokenIdentifier</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/FSConstants.html#HDFS_URI_SCHEME"><B>HDFS_URI_SCHEME</B></A> - 
接口 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/FSConstants.html" title="org.apache.hadoop.hdfs.protocol 中的接口">FSConstants</A> 中的静态变量
<DD>URI Scheme for hdfs://namenode/ URIs.
<DT><A HREF="./org/apache/hadoop/hdfs/tools/HDFSConcat.html" title="org.apache.hadoop.hdfs.tools 中的类"><B>HDFSConcat</B></A> - <A HREF="./org/apache/hadoop/hdfs/tools/package-summary.html">org.apache.hadoop.hdfs.tools</A> 中的 类<DD>&nbsp;<DT><A HREF="./org/apache/hadoop/hdfs/tools/HDFSConcat.html#HDFSConcat()"><B>HDFSConcat()</B></A> - 
类 org.apache.hadoop.hdfs.tools.<A HREF="./org/apache/hadoop/hdfs/tools/HDFSConcat.html" title="org.apache.hadoop.hdfs.tools 中的类">HDFSConcat</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/HdfsConfiguration.html" title="org.apache.hadoop.hdfs 中的类"><B>HdfsConfiguration</B></A> - <A HREF="./org/apache/hadoop/hdfs/package-summary.html">org.apache.hadoop.hdfs</A> 中的 类<DD>Adds deprecated keys into the configuration.<DT><A HREF="./org/apache/hadoop/hdfs/HdfsConfiguration.html#HdfsConfiguration()"><B>HdfsConfiguration()</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/HdfsConfiguration.html" title="org.apache.hadoop.hdfs 中的类">HdfsConfiguration</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/HdfsConfiguration.html#HdfsConfiguration(boolean)"><B>HdfsConfiguration(boolean)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/HdfsConfiguration.html" title="org.apache.hadoop.hdfs 中的类">HdfsConfiguration</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/HdfsConfiguration.html#HdfsConfiguration(org.apache.hadoop.conf.Configuration)"><B>HdfsConfiguration(Configuration)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/HdfsConfiguration.html" title="org.apache.hadoop.hdfs 中的类">HdfsConfiguration</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/HdfsConstants.html" title="org.apache.hadoop.hdfs.server.common 中的接口"><B>HdfsConstants</B></A> - <A HREF="./org/apache/hadoop/hdfs/server/common/package-summary.html">org.apache.hadoop.hdfs.server.common</A> 中的 接口<DD>Some handy internal HDFS constants<DT><A HREF="./org/apache/hadoop/hdfs/server/common/HdfsConstants.BlockUCState.html" title="org.apache.hadoop.hdfs.server.common 中的枚举"><B>HdfsConstants.BlockUCState</B></A> - <A HREF="./org/apache/hadoop/hdfs/server/common/package-summary.html">org.apache.hadoop.hdfs.server.common</A> 中的 枚举<DD>States, which a block can go through while it is under construction.<DT><A HREF="./org/apache/hadoop/hdfs/server/common/HdfsConstants.NamenodeRole.html" title="org.apache.hadoop.hdfs.server.common 中的枚举"><B>HdfsConstants.NamenodeRole</B></A> - <A HREF="./org/apache/hadoop/hdfs/server/common/package-summary.html">org.apache.hadoop.hdfs.server.common</A> 中的 枚举<DD>Defines the NameNode role.<DT><A HREF="./org/apache/hadoop/hdfs/server/common/HdfsConstants.NodeType.html" title="org.apache.hadoop.hdfs.server.common 中的枚举"><B>HdfsConstants.NodeType</B></A> - <A HREF="./org/apache/hadoop/hdfs/server/common/package-summary.html">org.apache.hadoop.hdfs.server.common</A> 中的 枚举<DD>Type of the node<DT><A HREF="./org/apache/hadoop/hdfs/server/common/HdfsConstants.ReplicaState.html" title="org.apache.hadoop.hdfs.server.common 中的枚举"><B>HdfsConstants.ReplicaState</B></A> - <A HREF="./org/apache/hadoop/hdfs/server/common/package-summary.html">org.apache.hadoop.hdfs.server.common</A> 中的 枚举<DD>Block replica states, which it can go through while being constructed.<DT><A HREF="./org/apache/hadoop/hdfs/server/common/HdfsConstants.StartupOption.html" title="org.apache.hadoop.hdfs.server.common 中的枚举"><B>HdfsConstants.StartupOption</B></A> - <A HREF="./org/apache/hadoop/hdfs/server/common/package-summary.html">org.apache.hadoop.hdfs.server.common</A> 中的 枚举<DD>Startup options<DT><A HREF="./org/apache/hadoop/hdfs/protocol/HdfsFileStatus.html" title="org.apache.hadoop.hdfs.protocol 中的类"><B>HdfsFileStatus</B></A> - <A HREF="./org/apache/hadoop/hdfs/protocol/package-summary.html">org.apache.hadoop.hdfs.protocol</A> 中的 类<DD>Interface that represents the over the wire information for a file.<DT><A HREF="./org/apache/hadoop/hdfs/protocol/HdfsFileStatus.html#HdfsFileStatus()"><B>HdfsFileStatus()</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/HdfsFileStatus.html" title="org.apache.hadoop.hdfs.protocol 中的类">HdfsFileStatus</A> 的构造方法
<DD>default constructor
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/HdfsFileStatus.html#HdfsFileStatus(long, boolean, int, long, long, long, org.apache.hadoop.fs.permission.FsPermission, java.lang.String, java.lang.String, byte[], byte[])"><B>HdfsFileStatus(long, boolean, int, long, long, long, FsPermission, String, String, byte[], byte[])</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/HdfsFileStatus.html" title="org.apache.hadoop.hdfs.protocol 中的类">HdfsFileStatus</A> 的构造方法
<DD>Constructor
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/HdfsLocatedFileStatus.html" title="org.apache.hadoop.hdfs.protocol 中的类"><B>HdfsLocatedFileStatus</B></A> - <A HREF="./org/apache/hadoop/hdfs/protocol/package-summary.html">org.apache.hadoop.hdfs.protocol</A> 中的 类<DD>Interface that represents the over the wire information
 including block locations for a file.<DT><A HREF="./org/apache/hadoop/hdfs/protocol/HdfsLocatedFileStatus.html#HdfsLocatedFileStatus()"><B>HdfsLocatedFileStatus()</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/HdfsLocatedFileStatus.html" title="org.apache.hadoop.hdfs.protocol 中的类">HdfsLocatedFileStatus</A> 的构造方法
<DD>Default constructor
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/HdfsLocatedFileStatus.html#HdfsLocatedFileStatus(long, boolean, int, long, long, long, org.apache.hadoop.fs.permission.FsPermission, java.lang.String, java.lang.String, byte[], byte[], org.apache.hadoop.hdfs.protocol.LocatedBlocks)"><B>HdfsLocatedFileStatus(long, boolean, int, long, long, long, FsPermission, String, String, byte[], byte[], LocatedBlocks)</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/HdfsLocatedFileStatus.html" title="org.apache.hadoop.hdfs.protocol 中的类">HdfsLocatedFileStatus</A> 的构造方法
<DD>Constructor
<DT><A HREF="./org/apache/hadoop/hdfs/HDFSPolicyProvider.html" title="org.apache.hadoop.hdfs 中的类"><B>HDFSPolicyProvider</B></A> - <A HREF="./org/apache/hadoop/hdfs/package-summary.html">org.apache.hadoop.hdfs</A> 中的 类<DD><CODE>PolicyProvider</CODE> for HDFS protocols.<DT><A HREF="./org/apache/hadoop/hdfs/HDFSPolicyProvider.html#HDFSPolicyProvider()"><B>HDFSPolicyProvider()</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/HDFSPolicyProvider.html" title="org.apache.hadoop.hdfs 中的类">HDFSPolicyProvider</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FSImage.html#headerBuffer"><B>headerBuffer</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/FSImage.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FSImage</A> 中的变量
<DD>added by tony
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/HeaderBuffer.html" title="org.apache.hadoop.hdfs.server.namenode 中的类"><B>HeaderBuffer</B></A> - <A HREF="./org/apache/hadoop/hdfs/server/namenode/package-summary.html">org.apache.hadoop.hdfs.server.namenode</A> 中的 类<DD>&nbsp;<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NamenodeFsck.html#HEALTHY_STATUS"><B>HEALTHY_STATUS</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/NamenodeFsck.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">NamenodeFsck</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/FSConstants.html#HEARTBEAT_INTERVAL"><B>HEARTBEAT_INTERVAL</B></A> - 
接口 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/FSConstants.html" title="org.apache.hadoop.hdfs.protocol 中的接口">FSConstants</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/metrics/DataNodeMetrics.html#heartbeats"><B>heartbeats</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.metrics.<A HREF="./org/apache/hadoop/hdfs/server/datanode/metrics/DataNodeMetrics.html" title="org.apache.hadoop.hdfs.server.datanode.metrics 中的类">DataNodeMetrics</A> 中的变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/HftpFileSystem.html#HFTP_DATE_FORMAT"><B>HFTP_DATE_FORMAT</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/HftpFileSystem.html" title="org.apache.hadoop.hdfs 中的类">HftpFileSystem</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/HftpFileSystem.html#HFTP_SERVICE_NAME_KEY"><B>HFTP_SERVICE_NAME_KEY</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/HftpFileSystem.html" title="org.apache.hadoop.hdfs 中的类">HftpFileSystem</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/HftpFileSystem.html#HFTP_TIMEZONE"><B>HFTP_TIMEZONE</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/HftpFileSystem.html" title="org.apache.hadoop.hdfs 中的类">HftpFileSystem</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/HftpFileSystem.html" title="org.apache.hadoop.hdfs 中的类"><B>HftpFileSystem</B></A> - <A HREF="./org/apache/hadoop/hdfs/package-summary.html">org.apache.hadoop.hdfs</A> 中的 类<DD>An implementation of a protocol for accessing filesystems over HTTP.<DT><A HREF="./org/apache/hadoop/hdfs/HftpFileSystem.html#HftpFileSystem()"><B>HftpFileSystem()</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/HftpFileSystem.html" title="org.apache.hadoop.hdfs 中的类">HftpFileSystem</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeInfo.html#hostName"><B>hostName</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeInfo.html" title="org.apache.hadoop.hdfs.protocol 中的类">DatanodeInfo</A> 中的变量
<DD>HostName as supplied by the datanode during registration as its 
 name.
<DT><A HREF="./org/apache/hadoop/hdfs/HsftpFileSystem.html" title="org.apache.hadoop.hdfs 中的类"><B>HsftpFileSystem</B></A> - <A HREF="./org/apache/hadoop/hdfs/package-summary.html">org.apache.hadoop.hdfs</A> 中的 类<DD>An implementation of a protocol for accessing filesystems over HTTPS.<DT><A HREF="./org/apache/hadoop/hdfs/HsftpFileSystem.html#HsftpFileSystem()"><B>HsftpFileSystem()</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/HsftpFileSystem.html" title="org.apache.hadoop.hdfs 中的类">HsftpFileSystem</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/HsftpFileSystem.DummyHostnameVerifier.html" title="org.apache.hadoop.hdfs 中的类"><B>HsftpFileSystem.DummyHostnameVerifier</B></A> - <A HREF="./org/apache/hadoop/hdfs/package-summary.html">org.apache.hadoop.hdfs</A> 中的 类<DD>Dummy hostname verifier that is used to bypass hostname checking<DT><A HREF="./org/apache/hadoop/hdfs/HsftpFileSystem.DummyHostnameVerifier.html#HsftpFileSystem.DummyHostnameVerifier()"><B>HsftpFileSystem.DummyHostnameVerifier()</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/HsftpFileSystem.DummyHostnameVerifier.html" title="org.apache.hadoop.hdfs 中的类">HsftpFileSystem.DummyHostnameVerifier</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/HsftpFileSystem.DummyTrustManager.html" title="org.apache.hadoop.hdfs 中的类"><B>HsftpFileSystem.DummyTrustManager</B></A> - <A HREF="./org/apache/hadoop/hdfs/package-summary.html">org.apache.hadoop.hdfs</A> 中的 类<DD>Dummy trustmanager that is used to trust all server certificates<DT><A HREF="./org/apache/hadoop/hdfs/HsftpFileSystem.DummyTrustManager.html#HsftpFileSystem.DummyTrustManager()"><B>HsftpFileSystem.DummyTrustManager()</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/HsftpFileSystem.DummyTrustManager.html" title="org.apache.hadoop.hdfs 中的类">HsftpFileSystem.DummyTrustManager</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html#httpAddress"><B>httpAddress</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">NameNode</A> 中的变量
<DD>HTTP server address
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html#httpServer"><B>httpServer</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">NameNode</A> 中的变量
<DD>httpServer
</DL>
<HR>
<A NAME="_I_"><!-- --></A><H2>
<B>I</B></H2>
<DL>
<DT><A HREF="./org/apache/hadoop/hdfs/server/balancer/Balancer.html#ILLEGAL_ARGS"><B>ILLEGAL_ARGS</B></A> - 
类 org.apache.hadoop.hdfs.server.balancer.<A HREF="./org/apache/hadoop/hdfs/server/balancer/Balancer.html" title="org.apache.hadoop.hdfs.server.balancer 中的类">Balancer</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FSImage.html#imageDigest"><B>imageDigest</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/FSImage.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FSImage</A> 中的变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/InconsistentFSStateException.html" title="org.apache.hadoop.hdfs.server.common 中的类"><B>InconsistentFSStateException</B></A> - <A HREF="./org/apache/hadoop/hdfs/server/common/package-summary.html">org.apache.hadoop.hdfs.server.common</A> 中的 异常<DD>The exception is thrown when file system state is inconsistent 
 and is not recoverable.<DT><A HREF="./org/apache/hadoop/hdfs/server/common/InconsistentFSStateException.html#InconsistentFSStateException(java.io.File, java.lang.String)"><B>InconsistentFSStateException(File, String)</B></A> - 
异常 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/InconsistentFSStateException.html" title="org.apache.hadoop.hdfs.server.common 中的类">InconsistentFSStateException</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/InconsistentFSStateException.html#InconsistentFSStateException(java.io.File, java.lang.String, java.lang.Throwable)"><B>InconsistentFSStateException(File, String, Throwable)</B></A> - 
异常 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/InconsistentFSStateException.html" title="org.apache.hadoop.hdfs.server.common 中的类">InconsistentFSStateException</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/IncorrectVersionException.html" title="org.apache.hadoop.hdfs.server.common 中的类"><B>IncorrectVersionException</B></A> - <A HREF="./org/apache/hadoop/hdfs/server/common/package-summary.html">org.apache.hadoop.hdfs.server.common</A> 中的 异常<DD>The exception is thrown when external version does not match 
 current version of the application.<DT><A HREF="./org/apache/hadoop/hdfs/server/common/IncorrectVersionException.html#IncorrectVersionException(int, java.lang.String)"><B>IncorrectVersionException(int, String)</B></A> - 
异常 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/IncorrectVersionException.html" title="org.apache.hadoop.hdfs.server.common 中的类">IncorrectVersionException</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/IncorrectVersionException.html#IncorrectVersionException(int, java.lang.String, int)"><B>IncorrectVersionException(int, String, int)</B></A> - 
异常 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/IncorrectVersionException.html" title="org.apache.hadoop.hdfs.server.common 中的类">IncorrectVersionException</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeID.html#infoPort"><B>infoPort</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeID.html" title="org.apache.hadoop.hdfs.protocol 中的类">DatanodeID</A> 中的变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/HdfsConfiguration.html#init()"><B>init()</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/HdfsConfiguration.html" title="org.apache.hadoop.hdfs 中的类">HdfsConfiguration</A> 中的静态方法
<DD>This method is here so that when invoked, HdfsConfiguration is class-loaded if
 it hasn't already been previously loaded.
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/SecureDataNodeStarter.html#init(org.apache.commons.daemon.DaemonContext)"><B>init(DaemonContext)</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/SecureDataNodeStarter.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">SecureDataNodeStarter</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/tools/JMXGet.html#init()"><B>init()</B></A> - 
类 org.apache.hadoop.hdfs.tools.<A HREF="./org/apache/hadoop/hdfs/tools/JMXGet.html" title="org.apache.hadoop.hdfs.tools 中的类">JMXGet</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/RSCoderProtocol.html#InitialCauchyMatrix(int, int)"><B>InitialCauchyMatrix(int, int)</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/RSCoderProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的类">RSCoderProtocol</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/RSCoderProtocol.html#InitialInvertedCauchyMatrix(short[][])"><B>InitialInvertedCauchyMatrix(short[][])</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/RSCoderProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的类">RSCoderProtocol</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DistributedFileSystem.html#initialize(java.net.URI, org.apache.hadoop.conf.Configuration)"><B>initialize(URI, Configuration)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DistributedFileSystem.html" title="org.apache.hadoop.hdfs 中的类">DistributedFileSystem</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/HftpFileSystem.html#initialize(java.net.URI, org.apache.hadoop.conf.Configuration)"><B>initialize(URI, Configuration)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/HftpFileSystem.html" title="org.apache.hadoop.hdfs 中的类">HftpFileSystem</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/HsftpFileSystem.html#initialize(java.net.URI, org.apache.hadoop.conf.Configuration)"><B>initialize(URI, Configuration)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/HsftpFileSystem.html" title="org.apache.hadoop.hdfs 中的类">HsftpFileSystem</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/BackupNode.html#initialize(org.apache.hadoop.conf.Configuration)"><B>initialize(Configuration)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/BackupNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">BackupNode</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/BlockPlacementPolicy.html#initialize(org.apache.hadoop.conf.Configuration, org.apache.hadoop.hdfs.server.namenode.FSClusterStats, org.apache.hadoop.net.NetworkTopology)"><B>initialize(Configuration, FSClusterStats, NetworkTopology)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/BlockPlacementPolicy.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">BlockPlacementPolicy</A> 中的方法
<DD>Used to setup a BlockPlacementPolicy object.
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/BlockPlacementPolicyDefault.html#initialize(org.apache.hadoop.conf.Configuration, org.apache.hadoop.hdfs.server.namenode.FSClusterStats, org.apache.hadoop.net.NetworkTopology)"><B>initialize(Configuration, FSClusterStats, NetworkTopology)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/BlockPlacementPolicyDefault.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">BlockPlacementPolicyDefault</A> 中的方法
<DD>Used to setup a BlockPlacementPolicy object.
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html#initialize(org.apache.hadoop.conf.Configuration)"><B>initialize(Configuration)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">NameNode</A> 中的方法
<DD>Initialize name-node.
<DT><A HREF="./org/apache/hadoop/hdfs/DFSUtil.ErrorSimulator.html#initializeErrorSimulationEvent(int)"><B>initializeErrorSimulationEvent(int)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSUtil.ErrorSimulator.html" title="org.apache.hadoop.hdfs 中的类">DFSUtil.ErrorSimulator</A> 中的静态方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/UpgradeManager.html#initializeUpgrade()"><B>initializeUpgrade()</B></A> - 
类 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/UpgradeManager.html" title="org.apache.hadoop.hdfs.server.common 中的类">UpgradeManager</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/DataNode.html#initReplicaRecovery(org.apache.hadoop.hdfs.server.protocol.BlockRecoveryCommand.RecoveringBlock)"><B>initReplicaRecovery(BlockRecoveryCommand.RecoveringBlock)</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/DataNode.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">DataNode</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDataset.html#initReplicaRecovery(org.apache.hadoop.hdfs.server.protocol.BlockRecoveryCommand.RecoveringBlock)"><B>initReplicaRecovery(BlockRecoveryCommand.RecoveringBlock)</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDataset.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">FSDataset</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.html#initReplicaRecovery(org.apache.hadoop.hdfs.server.protocol.BlockRecoveryCommand.RecoveringBlock)"><B>initReplicaRecovery(BlockRecoveryCommand.RecoveringBlock)</B></A> - 
接口 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.html" title="org.apache.hadoop.hdfs.server.datanode 中的接口">FSDatasetInterface</A> 中的方法
<DD>Initialize a replica recovery.
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/InterDatanodeProtocol.html#initReplicaRecovery(org.apache.hadoop.hdfs.server.protocol.BlockRecoveryCommand.RecoveringBlock)"><B>initReplicaRecovery(BlockRecoveryCommand.RecoveringBlock)</B></A> - 
接口 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/InterDatanodeProtocol.html" title="org.apache.hadoop.hdfs.server.protocol 中的接口">InterDatanodeProtocol</A> 中的方法
<DD>Initialize a replica recovery.
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/INodeSymlink.html" title="org.apache.hadoop.hdfs.server.namenode 中的类"><B>INodeSymlink</B></A> - <A HREF="./org/apache/hadoop/hdfs/server/namenode/package-summary.html">org.apache.hadoop.hdfs.server.namenode</A> 中的 类<DD>An INode representing a symbolic link.<DT><A HREF="./org/apache/hadoop/hdfs/protocol/LocatedBlocks.html#insertRange(int, java.util.List)"><B>insertRange(int, List&lt;LocatedBlock&gt;)</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/LocatedBlocks.html" title="org.apache.hadoop.hdfs.protocol 中的类">LocatedBlocks</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/HeaderBuffer.html#Instance(long, java.io.File, long)"><B>Instance(long, File, long)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/HeaderBuffer.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">HeaderBuffer</A> 中的静态方法
<DD>get the Singleton Instance
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/DataNode.html#instantiateDataNode(java.lang.String[], org.apache.hadoop.conf.Configuration)"><B>instantiateDataNode(String[], Configuration)</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/DataNode.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">DataNode</A> 中的静态方法
<DD>Instantiate a single datanode object.
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/DataNode.html#instantiateDataNode(java.lang.String[], org.apache.hadoop.conf.Configuration, org.apache.hadoop.hdfs.server.datanode.SecureDataNodeStarter.SecureResources)"><B>instantiateDataNode(String[], Configuration, SecureDataNodeStarter.SecureResources)</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/DataNode.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">DataNode</A> 中的静态方法
<DD>Instantiate a single datanode object, along with its secure resources.
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/InterDatanodeProtocol.html" title="org.apache.hadoop.hdfs.server.protocol 中的接口"><B>InterDatanodeProtocol</B></A> - <A HREF="./org/apache/hadoop/hdfs/server/protocol/package-summary.html">org.apache.hadoop.hdfs.server.protocol</A> 中的 接口<DD>An inter-datanode protocol for updating generation stamp<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/DatanodeProtocol.html#INVALID_BLOCK"><B>INVALID_BLOCK</B></A> - 
接口 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/DatanodeProtocol.html" title="org.apache.hadoop.hdfs.server.protocol 中的接口">DatanodeProtocol</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDataset.html#invalidate(org.apache.hadoop.hdfs.protocol.Block[])"><B>invalidate(Block[])</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDataset.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">FSDataset</A> 中的方法
<DD>We're informed that a block is no longer valid.
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.html#invalidate(org.apache.hadoop.hdfs.protocol.Block[])"><B>invalidate(Block[])</B></A> - 
接口 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.html" title="org.apache.hadoop.hdfs.server.datanode 中的接口">FSDatasetInterface</A> 中的方法
<DD>Invalidates the specified blocks
<DT><A HREF="./org/apache/hadoop/hdfs/security/token/block/InvalidBlockTokenException.html" title="org.apache.hadoop.hdfs.security.token.block 中的类"><B>InvalidBlockTokenException</B></A> - <A HREF="./org/apache/hadoop/hdfs/security/token/block/package-summary.html">org.apache.hadoop.hdfs.security.token.block</A> 中的 异常<DD>Access token verification failed.<DT><A HREF="./org/apache/hadoop/hdfs/security/token/block/InvalidBlockTokenException.html#InvalidBlockTokenException()"><B>InvalidBlockTokenException()</B></A> - 
异常 org.apache.hadoop.hdfs.security.token.block.<A HREF="./org/apache/hadoop/hdfs/security/token/block/InvalidBlockTokenException.html" title="org.apache.hadoop.hdfs.security.token.block 中的类">InvalidBlockTokenException</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/security/token/block/InvalidBlockTokenException.html#InvalidBlockTokenException(java.lang.String)"><B>InvalidBlockTokenException(String)</B></A> - 
异常 org.apache.hadoop.hdfs.security.token.block.<A HREF="./org/apache/hadoop/hdfs/security/token/block/InvalidBlockTokenException.html" title="org.apache.hadoop.hdfs.security.token.block 中的类">InvalidBlockTokenException</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/balancer/Balancer.html#IO_EXCEPTION"><B>IO_EXCEPTION</B></A> - 
类 org.apache.hadoop.hdfs.server.balancer.<A HREF="./org/apache/hadoop/hdfs/server/balancer/Balancer.html" title="org.apache.hadoop.hdfs.server.balancer 中的类">Balancer</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeInfo.html#ioStatus"><B>ioStatus</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeInfo.html" title="org.apache.hadoop.hdfs.protocol 中的类">DatanodeInfo</A> 中的变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeID.html#ipcPort"><B>ipcPort</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeID.html" title="org.apache.hadoop.hdfs.protocol 中的类">DatanodeID</A> 中的变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/DataNode.html#ipcServer"><B>ipcServer</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/DataNode.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">DataNode</A> 中的变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/Storage.html#is203LayoutVersion(int)"><B>is203LayoutVersion(int)</B></A> - 
类 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/Storage.html" title="org.apache.hadoop.hdfs.server.common 中的类">Storage</A> 中的静态方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/DatanodeDescriptor.html#isAlive"><B>isAlive</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/DatanodeDescriptor.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">DatanodeDescriptor</A> 中的变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/Block.html#isBlockFilename(java.io.File)"><B>isBlockFilename(File)</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/Block.html" title="org.apache.hadoop.hdfs.protocol 中的类">Block</A> 中的静态方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/security/token/block/ExportedBlockKeys.html#isBlockTokenEnabled()"><B>isBlockTokenEnabled()</B></A> - 
类 org.apache.hadoop.hdfs.security.token.block.<A HREF="./org/apache/hadoop/hdfs/security/token/block/ExportedBlockKeys.html" title="org.apache.hadoop.hdfs.security.token.block 中的类">ExportedBlockKeys</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/LocatedBlock.html#isCorrupt()"><B>isCorrupt()</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/LocatedBlock.html" title="org.apache.hadoop.hdfs.protocol 中的类">LocatedBlock</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeInfo.html#isDecommissioned()"><B>isDecommissioned()</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeInfo.html" title="org.apache.hadoop.hdfs.protocol 中的类">DatanodeInfo</A> 中的方法
<DD>Returns true if the node has been decommissioned.
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeInfo.html#isDecommissionInProgress()"><B>isDecommissionInProgress()</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeInfo.html" title="org.apache.hadoop.hdfs.protocol 中的类">DatanodeInfo</A> 中的方法
<DD>Returns true if the node is in the process of being decommissioned
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/HdfsFileStatus.html#isDir()"><B>isDir()</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/HdfsFileStatus.html" title="org.apache.hadoop.hdfs.protocol 中的类">HdfsFileStatus</A> 中的方法
<DD>Is this a directory?
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/INodeSymlink.html#isDirectory()"><B>isDirectory()</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/INodeSymlink.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">INodeSymlink</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/HdfsFileStatus.html#isEmptyLocalName()"><B>isEmptyLocalName()</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/HdfsFileStatus.html" title="org.apache.hadoop.hdfs.protocol 中的类">HdfsFileStatus</A> 中的方法
<DD>Check if the local name is empty
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/UpgradeStatusReport.html#isFinalized()"><B>isFinalized()</B></A> - 
类 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/UpgradeStatusReport.html" title="org.apache.hadoop.hdfs.server.common 中的类">UpgradeStatusReport</A> 中的方法
<DD>Is current upgrade finalized.
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/CheckpointCommand.html#isImageObsolete()"><B>isImageObsolete()</B></A> - 
类 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/CheckpointCommand.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">CheckpointCommand</A> 中的方法
<DD>Indicates whether current backup image is obsolete, and therefore
 need to be discarded?
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html#isInSafeMode()"><B>isInSafeMode()</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">NameNode</A> 中的方法
<DD>Is the cluster currently in safe mode?
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/LocatedBlocks.html#isLastBlockComplete()"><B>isLastBlockComplete()</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/LocatedBlocks.html" title="org.apache.hadoop.hdfs.protocol 中的类">LocatedBlocks</A> 中的方法
<DD>Is the last block completed?
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.PacketHeader.html#isLastPacketInBlock()"><B>isLastPacketInBlock()</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.PacketHeader.html" title="org.apache.hadoop.hdfs.protocol 中的类">DataTransferProtocol.PacketHeader</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/INodeSymlink.html#isLink()"><B>isLink()</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/INodeSymlink.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">INodeSymlink</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/Storage.html#isLockSupported(int)"><B>isLockSupported(int)</B></A> - 
类 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/Storage.html" title="org.apache.hadoop.hdfs.server.common 中的类">Storage</A> 中的方法
<DD>Check whether underlying file system supports file locking.
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/Block.html#isMetaFilename(java.lang.String)"><B>isMetaFilename(String)</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/Block.html" title="org.apache.hadoop.hdfs.protocol 中的类">Block</A> 中的静态方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/Storage.StorageDirType.html#isOfType(org.apache.hadoop.hdfs.server.common.Storage.StorageDirType)"><B>isOfType(Storage.StorageDirType)</B></A> - 
接口 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/Storage.StorageDirType.html" title="org.apache.hadoop.hdfs.server.common 中的接口">Storage.StorageDirType</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/Storage.html#isPreUpgradableLayout(org.apache.hadoop.hdfs.server.common.Storage.StorageDirectory)"><B>isPreUpgradableLayout(Storage.StorageDirectory)</B></A> - 
类 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/Storage.html" title="org.apache.hadoop.hdfs.server.common 中的类">Storage</A> 中的方法
<DD>Return true if the layout of the given storage directory is from a version
 of Hadoop prior to the introduction of the "current" and "previous"
 directories which allow upgrade and rollback.
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/DataStorage.html#isPreUpgradableLayout(org.apache.hadoop.hdfs.server.common.Storage.StorageDirectory)"><B>isPreUpgradableLayout(Storage.StorageDirectory)</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/DataStorage.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">DataStorage</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/BackupStorage.html#isPreUpgradableLayout(org.apache.hadoop.hdfs.server.common.Storage.StorageDirectory)"><B>isPreUpgradableLayout(Storage.StorageDirectory)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/BackupStorage.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">BackupStorage</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FSImage.html#isPreUpgradableLayout(org.apache.hadoop.hdfs.server.common.Storage.StorageDirectory)"><B>isPreUpgradableLayout(Storage.StorageDirectory)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/FSImage.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FSImage</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/RCRecoveryCommand.html#isRCRecovery()"><B>isRCRecovery()</B></A> - 
类 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/RCRecoveryCommand.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">RCRecoveryCommand</A> 中的静态方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/RegeneratingCodeMatrix.html#isRegeneratingCodeRecovery()"><B>isRegeneratingCodeRecovery()</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/RegeneratingCodeMatrix.html" title="org.apache.hadoop.hdfs.protocol 中的类">RegeneratingCodeMatrix</A> 中的静态方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/NamenodeRegistration.html#isRole(org.apache.hadoop.hdfs.server.common.HdfsConstants.NamenodeRole)"><B>isRole(HdfsConstants.NamenodeRole)</B></A> - 
类 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/NamenodeRegistration.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">NamenodeRegistration</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.PipelineAck.html#isSuccess()"><B>isSuccess()</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.PipelineAck.html" title="org.apache.hadoop.hdfs.protocol 中的类">DataTransferProtocol.PipelineAck</A> 中的方法
<DD>Check if this ack contains error status
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/HdfsFileStatus.html#isSymlink()"><B>isSymlink()</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/HdfsFileStatus.html" title="org.apache.hadoop.hdfs.protocol 中的类">HdfsFileStatus</A> 中的方法
<DD>Is this a symbolic link?
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/LocatedBlocks.html#isUnderConstruction()"><B>isUnderConstruction()</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/LocatedBlocks.html" title="org.apache.hadoop.hdfs.protocol 中的类">LocatedBlocks</A> 中的方法
<DD>Return ture if file was under construction when 
 this LocatedBlocks was constructed, false otherwise.
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/UpgradeManager.html#isUpgradeCompleted()"><B>isUpgradeCompleted()</B></A> - 
类 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/UpgradeManager.html" title="org.apache.hadoop.hdfs.server.common 中的类">UpgradeManager</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#isUpgradeFinalized()"><B>isUpgradeFinalized()</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FSNamesystem</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNodeMXBean.html#isUpgradeFinalized()"><B>isUpgradeFinalized()</B></A> - 
接口 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNodeMXBean.html" title="org.apache.hadoop.hdfs.server.namenode 中的接口">NameNodeMXBean</A> 中的方法
<DD>Checks if upgrade is finalized.
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDataset.html#isValidBlock(org.apache.hadoop.hdfs.protocol.Block)"><B>isValidBlock(Block)</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDataset.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">FSDataset</A> 中的方法
<DD>Check whether the given block is a valid one.
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.html#isValidBlock(org.apache.hadoop.hdfs.protocol.Block)"><B>isValidBlock(Block)</B></A> - 
接口 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.html" title="org.apache.hadoop.hdfs.server.datanode 中的接口">FSDatasetInterface</A> 中的方法
<DD>Is the block valid?
<DT><A HREF="./org/apache/hadoop/hdfs/DFSUtil.html#isValidName(java.lang.String)"><B>isValidName(String)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSUtil.html" title="org.apache.hadoop.hdfs 中的类">DFSUtil</A> 中的静态方法
<DD>Whether the pathname is valid.
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/GetImageServlet.html#isValidRequestor(java.lang.String, org.apache.hadoop.conf.Configuration)"><B>isValidRequestor(String, Configuration)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/GetImageServlet.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">GetImageServlet</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/BlockListAsLongs.html#iterator()"><B>iterator()</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/BlockListAsLongs.html" title="org.apache.hadoop.hdfs.protocol 中的类">BlockListAsLongs</A> 中的方法
<DD>Returns an iterator over blocks in the block report.
<DT><A HREF="./org/apache/hadoop/hdfs/util/GSetByHashMap.html#iterator()"><B>iterator()</B></A> - 
类 org.apache.hadoop.hdfs.util.<A HREF="./org/apache/hadoop/hdfs/util/GSetByHashMap.html" title="org.apache.hadoop.hdfs.util 中的类">GSetByHashMap</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/util/LightWeightGSet.html#iterator()"><B>iterator()</B></A> - 
类 org.apache.hadoop.hdfs.util.<A HREF="./org/apache/hadoop/hdfs/util/LightWeightGSet.html" title="org.apache.hadoop.hdfs.util 中的类">LightWeightGSet</A> 中的方法
<DD>&nbsp;
</DL>
<HR>
<A NAME="_J_"><!-- --></A><H2>
<B>J</B></H2>
<DL>
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/NamenodeProtocol.html#JA_CHECKPOINT_TIME"><B>JA_CHECKPOINT_TIME</B></A> - 
接口 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/NamenodeProtocol.html" title="org.apache.hadoop.hdfs.server.protocol 中的接口">NamenodeProtocol</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/NamenodeProtocol.html#JA_IS_ALIVE"><B>JA_IS_ALIVE</B></A> - 
接口 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/NamenodeProtocol.html" title="org.apache.hadoop.hdfs.server.protocol 中的接口">NamenodeProtocol</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/NamenodeProtocol.html#JA_JOURNAL"><B>JA_JOURNAL</B></A> - 
接口 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/NamenodeProtocol.html" title="org.apache.hadoop.hdfs.server.protocol 中的接口">NamenodeProtocol</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/NamenodeProtocol.html#JA_JSPOOL_START"><B>JA_JSPOOL_START</B></A> - 
接口 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/NamenodeProtocol.html" title="org.apache.hadoop.hdfs.server.protocol 中的接口">NamenodeProtocol</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/tools/JMXGet.html" title="org.apache.hadoop.hdfs.tools 中的类"><B>JMXGet</B></A> - <A HREF="./org/apache/hadoop/hdfs/tools/package-summary.html">org.apache.hadoop.hdfs.tools</A> 中的 类<DD>tool to get data from NameNode or DataNode using MBeans currently the
 following MBeans are available (under hadoop domain):
 hadoop:service=NameNode,name=FSNamesystemState (static)
 hadoop:service=NameNode,name=NameNodeActivity (dynamic)
 hadoop:service=NameNode,name=RpcActivityForPort9000 (dynamic)
 hadoop:service=DataNode,name=RpcActivityForPort50020 (dynamic)
 hadoop:name=service=DataNode,FSDatasetState-UndefinedStorageId663800459
 (static)
 hadoop:service=DataNode,name=DataNodeActivity-UndefinedStorageId-520845215
 (dynamic)
 
 
 implementation note: all logging is sent to System.err (since it is a command
 line tool)<DT><A HREF="./org/apache/hadoop/hdfs/tools/JMXGet.html#JMXGet()"><B>JMXGet()</B></A> - 
类 org.apache.hadoop.hdfs.tools.<A HREF="./org/apache/hadoop/hdfs/tools/JMXGet.html" title="org.apache.hadoop.hdfs.tools 中的类">JMXGet</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html#join()"><B>join()</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">NameNode</A> 中的方法
<DD>Wait for service to finish.
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/BackupNode.html#journal(org.apache.hadoop.hdfs.server.protocol.NamenodeRegistration, int, int, byte[])"><B>journal(NamenodeRegistration, int, int, byte[])</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/BackupNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">BackupNode</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html#journal(org.apache.hadoop.hdfs.server.protocol.NamenodeRegistration, int, int, byte[])"><B>journal(NamenodeRegistration, int, int, byte[])</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">NameNode</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/NamenodeProtocol.html#journal(org.apache.hadoop.hdfs.server.protocol.NamenodeRegistration, int, int, byte[])"><B>journal(NamenodeRegistration, int, int, byte[])</B></A> - 
接口 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/NamenodeProtocol.html" title="org.apache.hadoop.hdfs.server.protocol 中的接口">NamenodeProtocol</A> 中的方法
<DD>Journal edit records.
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html#journalSize(org.apache.hadoop.hdfs.server.protocol.NamenodeRegistration)"><B>journalSize(NamenodeRegistration)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">NameNode</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/NamenodeProtocol.html#journalSize(org.apache.hadoop.hdfs.server.protocol.NamenodeRegistration)"><B>journalSize(NamenodeRegistration)</B></A> - 
接口 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/NamenodeProtocol.html" title="org.apache.hadoop.hdfs.server.protocol 中的接口">NamenodeProtocol</A> 中的方法
<DD>Get the size of the active name-node journal (edit log) in bytes.
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/JspHelper.html" title="org.apache.hadoop.hdfs.server.common 中的类"><B>JspHelper</B></A> - <A HREF="./org/apache/hadoop/hdfs/server/common/package-summary.html">org.apache.hadoop.hdfs.server.common</A> 中的 类<DD>&nbsp;</DL>
<HR>
<A NAME="_K_"><!-- --></A><H2>
<B>K</B></H2>
<DL>
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/KeyUpdateCommand.html" title="org.apache.hadoop.hdfs.server.protocol 中的类"><B>KeyUpdateCommand</B></A> - <A HREF="./org/apache/hadoop/hdfs/server/protocol/package-summary.html">org.apache.hadoop.hdfs.server.protocol</A> 中的 类<DD>&nbsp;<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/KeyUpdateCommand.html#KeyUpdateCommand(org.apache.hadoop.hdfs.security.token.block.ExportedBlockKeys)"><B>KeyUpdateCommand(ExportedBlockKeys)</B></A> - 
类 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/KeyUpdateCommand.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">KeyUpdateCommand</A> 的构造方法
<DD>&nbsp;
</DL>
<HR>
<A NAME="_L_"><!-- --></A><H2>
<B>L</B></H2>
<DL>
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/Storage.html#LAST_PRE_UPGRADE_LAYOUT_VERSION"><B>LAST_PRE_UPGRADE_LAYOUT_VERSION</B></A> - 
类 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/Storage.html" title="org.apache.hadoop.hdfs.server.common 中的类">Storage</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/Storage.html#LAST_UPGRADABLE_HADOOP_VERSION"><B>LAST_UPGRADABLE_HADOOP_VERSION</B></A> - 
类 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/Storage.html" title="org.apache.hadoop.hdfs.server.common 中的类">Storage</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/Storage.html#LAST_UPGRADABLE_LAYOUT_VERSION"><B>LAST_UPGRADABLE_LAYOUT_VERSION</B></A> - 
类 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/Storage.html" title="org.apache.hadoop.hdfs.server.common 中的类">Storage</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeInfo.html#lastUpdate"><B>lastUpdate</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeInfo.html" title="org.apache.hadoop.hdfs.protocol 中的类">DatanodeInfo</A> 中的变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/FSConstants.html#LAYOUT_VERSION"><B>LAYOUT_VERSION</B></A> - 
接口 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/FSConstants.html" title="org.apache.hadoop.hdfs.protocol 中的接口">FSConstants</A> 中的静态变量
<DD>Please see <A HREF="./org/apache/hadoop/hdfs/protocol/LayoutVersion.html" title="org.apache.hadoop.hdfs.protocol 中的类"><CODE>LayoutVersion</CODE></A> on adding new layout version.
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/Storage.html#LAYOUT_VERSIONS_203"><B>LAYOUT_VERSIONS_203</B></A> - 
类 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/Storage.html" title="org.apache.hadoop.hdfs.server.common 中的类">Storage</A> 中的静态变量
<DD>Layout versions of 0.20.203 release
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/LayoutVersion.html" title="org.apache.hadoop.hdfs.protocol 中的类"><B>LayoutVersion</B></A> - <A HREF="./org/apache/hadoop/hdfs/protocol/package-summary.html">org.apache.hadoop.hdfs.protocol</A> 中的 类<DD>This class tracks changes in the layout version of HDFS.<DT><A HREF="./org/apache/hadoop/hdfs/protocol/LayoutVersion.html#LayoutVersion()"><B>LayoutVersion()</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/LayoutVersion.html" title="org.apache.hadoop.hdfs.protocol 中的类">LayoutVersion</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/StorageInfo.html#layoutVersion"><B>layoutVersion</B></A> - 
类 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/StorageInfo.html" title="org.apache.hadoop.hdfs.server.common 中的类">StorageInfo</A> 中的变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/LayoutVersion.Feature.html" title="org.apache.hadoop.hdfs.protocol 中的枚举"><B>LayoutVersion.Feature</B></A> - <A HREF="./org/apache/hadoop/hdfs/protocol/package-summary.html">org.apache.hadoop.hdfs.protocol</A> 中的 枚举<DD>Enums for features that change the layout version.<DT><A HREF="./org/apache/hadoop/hdfs/protocol/FSConstants.html#LEASE_HARDLIMIT_PERIOD"><B>LEASE_HARDLIMIT_PERIOD</B></A> - 
接口 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/FSConstants.html" title="org.apache.hadoop.hdfs.protocol 中的接口">FSConstants</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/FSConstants.html#LEASE_RECOVER_PERIOD"><B>LEASE_RECOVER_PERIOD</B></A> - 
接口 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/FSConstants.html" title="org.apache.hadoop.hdfs.protocol 中的接口">FSConstants</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/FSConstants.html#LEASE_SOFTLIMIT_PERIOD"><B>LEASE_SOFTLIMIT_PERIOD</B></A> - 
接口 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/FSConstants.html" title="org.apache.hadoop.hdfs.protocol 中的接口">FSConstants</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/LeaseExpiredException.html" title="org.apache.hadoop.hdfs.server.namenode 中的类"><B>LeaseExpiredException</B></A> - <A HREF="./org/apache/hadoop/hdfs/server/namenode/package-summary.html">org.apache.hadoop.hdfs.server.namenode</A> 中的 异常<DD>The lease that was being used to create this file has expired.<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/LeaseExpiredException.html#LeaseExpiredException(java.lang.String)"><B>LeaseExpiredException(String)</B></A> - 
异常 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/LeaseExpiredException.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">LeaseExpiredException</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#leaseManager"><B>leaseManager</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FSNamesystem</A> 中的变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/LeaseManager.html" title="org.apache.hadoop.hdfs.server.namenode 中的类"><B>LeaseManager</B></A> - <A HREF="./org/apache/hadoop/hdfs/server/namenode/package-summary.html">org.apache.hadoop.hdfs.server.namenode</A> 中的 类<DD>LeaseManager does the lease housekeeping for writing on files.<DT><A HREF="./org/apache/hadoop/hdfs/util/LightWeightGSet.html" title="org.apache.hadoop.hdfs.util 中的类"><B>LightWeightGSet</B></A>&lt;<A HREF="./org/apache/hadoop/hdfs/util/LightWeightGSet.html" title="LightWeightGSet 中的类型参数">K</A>,<A HREF="./org/apache/hadoop/hdfs/util/LightWeightGSet.html" title="LightWeightGSet 中的类型参数">E</A> extends <A HREF="./org/apache/hadoop/hdfs/util/LightWeightGSet.html" title="LightWeightGSet 中的类型参数">K</A>&gt; - <A HREF="./org/apache/hadoop/hdfs/util/package-summary.html">org.apache.hadoop.hdfs.util</A> 中的 类<DD>A low memory footprint <A HREF="./org/apache/hadoop/hdfs/util/GSet.html" title="org.apache.hadoop.hdfs.util 中的接口"><CODE>GSet</CODE></A> implementation,
 which uses an array for storing the elements
 and linked lists for collision resolution.<DT><A HREF="./org/apache/hadoop/hdfs/util/LightWeightGSet.html#LightWeightGSet(int)"><B>LightWeightGSet(int)</B></A> - 
类 org.apache.hadoop.hdfs.util.<A HREF="./org/apache/hadoop/hdfs/util/LightWeightGSet.html" title="org.apache.hadoop.hdfs.util 中的类">LightWeightGSet</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/util/LightWeightGSet.LinkedElement.html" title="org.apache.hadoop.hdfs.util 中的接口"><B>LightWeightGSet.LinkedElement</B></A> - <A HREF="./org/apache/hadoop/hdfs/util/package-summary.html">org.apache.hadoop.hdfs.util</A> 中的 接口<DD>Elements of <A HREF="./org/apache/hadoop/hdfs/util/LightWeightGSet.html" title="org.apache.hadoop.hdfs.util 中的类"><CODE>LightWeightGSet</CODE></A>.<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#list"><B>list</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FSNamesystem</A> 中的变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html#listCorruptFileBlocks(java.lang.String, java.lang.String)"><B>listCorruptFileBlocks(String, String)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">NameNode</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/fs/Hdfs.html#listLocatedStatus(org.apache.hadoop.fs.Path)"><B>listLocatedStatus(Path)</B></A> - 
类 org.apache.hadoop.fs.<A HREF="./org/apache/hadoop/fs/Hdfs.html" title="org.apache.hadoop.fs 中的类">Hdfs</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DistributedFileSystem.html#listLocatedStatus(org.apache.hadoop.fs.Path, org.apache.hadoop.fs.PathFilter)"><B>listLocatedStatus(Path, PathFilter)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DistributedFileSystem.html" title="org.apache.hadoop.hdfs 中的类">DistributedFileSystem</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSClient.html#listPaths(java.lang.String, byte[])"><B>listPaths(String, byte[])</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSClient.html" title="org.apache.hadoop.hdfs 中的类">DFSClient</A> 中的方法
<DD>Get a partial listing of the indicated directory
 No block locations need to be fetched
<DT><A HREF="./org/apache/hadoop/hdfs/DFSClient.html#listPaths(java.lang.String, byte[], boolean)"><B>listPaths(String, byte[], boolean)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSClient.html" title="org.apache.hadoop.hdfs 中的类">DFSClient</A> 中的方法
<DD>Get a partial listing of the indicated directory

 Recommend to use HdfsFileStatus.EMPTY_NAME as startAfter
 if the application wants to fetch a listing starting from
 the first entry in the directory
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/ListPathsServlet.html" title="org.apache.hadoop.hdfs.server.namenode 中的类"><B>ListPathsServlet</B></A> - <A HREF="./org/apache/hadoop/hdfs/server/namenode/package-summary.html">org.apache.hadoop.hdfs.server.namenode</A> 中的 类<DD>Obtain meta-information about a filesystem.<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/ListPathsServlet.html#ListPathsServlet()"><B>ListPathsServlet()</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/ListPathsServlet.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">ListPathsServlet</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/fs/Hdfs.html#listStatus(org.apache.hadoop.fs.Path)"><B>listStatus(Path)</B></A> - 
类 org.apache.hadoop.fs.<A HREF="./org/apache/hadoop/fs/Hdfs.html" title="org.apache.hadoop.fs 中的类">Hdfs</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DistributedFileSystem.html#listStatus(org.apache.hadoop.fs.Path)"><B>listStatus(Path)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DistributedFileSystem.html" title="org.apache.hadoop.hdfs 中的类">DistributedFileSystem</A> 中的方法
<DD>List all the entries of a directory

 Note that this operation is not atomic for a large directory.
<DT><A HREF="./org/apache/hadoop/hdfs/HftpFileSystem.html#listStatus(org.apache.hadoop.fs.Path)"><B>listStatus(Path)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/HftpFileSystem.html" title="org.apache.hadoop.hdfs 中的类">HftpFileSystem</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/fs/Hdfs.html#listStatusIterator(org.apache.hadoop.fs.Path)"><B>listStatusIterator(Path)</B></A> - 
类 org.apache.hadoop.fs.<A HREF="./org/apache/hadoop/fs/Hdfs.html" title="org.apache.hadoop.fs 中的类">Hdfs</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/Storage.html#listStorageDirectories()"><B>listStorageDirectories()</B></A> - 
类 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/Storage.html" title="org.apache.hadoop.hdfs.server.common 中的类">Storage</A> 中的方法
<DD>generate storage list (debug line)
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#lmthread"><B>lmthread</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FSNamesystem</A> 中的变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/BackupNode.html#loadNamesystem(org.apache.hadoop.conf.Configuration)"><B>loadNamesystem(Configuration)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/BackupNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">BackupNode</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html#loadNamesystem(org.apache.hadoop.conf.Configuration)"><B>loadNamesystem(Configuration)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">NameNode</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/security/token/delegation/DelegationTokenSecretManager.html#loadSecretManagerState(java.io.DataInputStream)"><B>loadSecretManagerState(DataInputStream)</B></A> - 
类 org.apache.hadoop.hdfs.security.token.delegation.<A HREF="./org/apache/hadoop/hdfs/security/token/delegation/DelegationTokenSecretManager.html" title="org.apache.hadoop.hdfs.security.token.delegation 中的类">DelegationTokenSecretManager</A> 中的方法
<DD>Load SecretManager state from fsimage.
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/LocatedBlock.html" title="org.apache.hadoop.hdfs.protocol 中的类"><B>LocatedBlock</B></A> - <A HREF="./org/apache/hadoop/hdfs/protocol/package-summary.html">org.apache.hadoop.hdfs.protocol</A> 中的 类<DD>A LocatedBlock is a pair of Block, DatanodeInfo[]
 objects.<DT><A HREF="./org/apache/hadoop/hdfs/protocol/LocatedBlock.html#LocatedBlock()"><B>LocatedBlock()</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/LocatedBlock.html" title="org.apache.hadoop.hdfs.protocol 中的类">LocatedBlock</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/LocatedBlock.html#LocatedBlock(org.apache.hadoop.hdfs.protocol.Block, org.apache.hadoop.hdfs.protocol.DatanodeInfo[])"><B>LocatedBlock(Block, DatanodeInfo[])</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/LocatedBlock.html" title="org.apache.hadoop.hdfs.protocol 中的类">LocatedBlock</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/LocatedBlock.html#LocatedBlock(org.apache.hadoop.hdfs.protocol.Block, org.apache.hadoop.hdfs.protocol.DatanodeInfo[], long)"><B>LocatedBlock(Block, DatanodeInfo[], long)</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/LocatedBlock.html" title="org.apache.hadoop.hdfs.protocol 中的类">LocatedBlock</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/LocatedBlock.html#LocatedBlock(org.apache.hadoop.hdfs.protocol.Block, org.apache.hadoop.hdfs.protocol.DatanodeInfo[], long, boolean)"><B>LocatedBlock(Block, DatanodeInfo[], long, boolean)</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/LocatedBlock.html" title="org.apache.hadoop.hdfs.protocol 中的类">LocatedBlock</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/LocatedBlocks.html#locatedBlockCount()"><B>locatedBlockCount()</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/LocatedBlocks.html" title="org.apache.hadoop.hdfs.protocol 中的类">LocatedBlocks</A> 中的方法
<DD>Get number of located blocks.
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/LocatedBlocks.html" title="org.apache.hadoop.hdfs.protocol 中的类"><B>LocatedBlocks</B></A> - <A HREF="./org/apache/hadoop/hdfs/protocol/package-summary.html">org.apache.hadoop.hdfs.protocol</A> 中的 类<DD>Collection of blocks with their locations and the file length.<DT><A HREF="./org/apache/hadoop/hdfs/protocol/LocatedBlocks.html#LocatedBlocks()"><B>LocatedBlocks()</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/LocatedBlocks.html" title="org.apache.hadoop.hdfs.protocol 中的类">LocatedBlocks</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/LocatedBlocks.html#LocatedBlocks(long, boolean, java.util.List, org.apache.hadoop.hdfs.protocol.LocatedBlock, boolean)"><B>LocatedBlocks(long, boolean, List&lt;LocatedBlock&gt;, LocatedBlock, boolean)</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/LocatedBlocks.html" title="org.apache.hadoop.hdfs.protocol 中的类">LocatedBlocks</A> 的构造方法
<DD>public Constructor
<DT><A HREF="./org/apache/hadoop/hdfs/DFSUtil.html#locatedBlocks2Locations(org.apache.hadoop.hdfs.protocol.LocatedBlocks)"><B>locatedBlocks2Locations(LocatedBlocks)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSUtil.html" title="org.apache.hadoop.hdfs 中的类">DFSUtil</A> 中的静态方法
<DD>Convert a LocatedBlocks to BlockLocations[]
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/LocatedBlockWithCodingFactor.html" title="org.apache.hadoop.hdfs.protocol 中的类"><B>LocatedBlockWithCodingFactor</B></A> - <A HREF="./org/apache/hadoop/hdfs/protocol/package-summary.html">org.apache.hadoop.hdfs.protocol</A> 中的 类<DD>&nbsp;<DT><A HREF="./org/apache/hadoop/hdfs/protocol/LocatedBlockWithCodingFactor.html#LocatedBlockWithCodingFactor()"><B>LocatedBlockWithCodingFactor()</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/LocatedBlockWithCodingFactor.html" title="org.apache.hadoop.hdfs.protocol 中的类">LocatedBlockWithCodingFactor</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/LocatedBlockWithCodingFactor.html#LocatedBlockWithCodingFactor(org.apache.hadoop.hdfs.protocol.LocatedBlock, int[])"><B>LocatedBlockWithCodingFactor(LocatedBlock, int[])</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/LocatedBlockWithCodingFactor.html" title="org.apache.hadoop.hdfs.protocol 中的类">LocatedBlockWithCodingFactor</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeInfo.html#location"><B>location</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeInfo.html" title="org.apache.hadoop.hdfs.protocol 中的类">DatanodeInfo</A> 中的变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/Storage.StorageDirectory.html#lock()"><B>lock()</B></A> - 
类 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/Storage.StorageDirectory.html" title="org.apache.hadoop.hdfs.server.common 中的类">Storage.StorageDirectory</A> 中的方法
<DD>Lock storage to provide exclusive access.
<DT><A HREF="./org/apache/hadoop/hdfs/DFSClient.html#LOG"><B>LOG</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSClient.html" title="org.apache.hadoop.hdfs 中的类">DFSClient</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/ClientDatanodeProtocol.html#LOG"><B>LOG</B></A> - 
接口 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/ClientDatanodeProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的接口">ClientDatanodeProtocol</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/security/token/block/BlockTokenSecretManager.html#LOG"><B>LOG</B></A> - 
类 org.apache.hadoop.hdfs.security.token.block.<A HREF="./org/apache/hadoop/hdfs/security/token/block/BlockTokenSecretManager.html" title="org.apache.hadoop.hdfs.security.token.block 中的类">BlockTokenSecretManager</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/Storage.html#LOG"><B>LOG</B></A> - 
类 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/Storage.html" title="org.apache.hadoop.hdfs.server.common 中的类">Storage</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/DataNode.html#LOG"><B>LOG</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/DataNode.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">DataNode</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#LOG"><B>LOG</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FSNamesystem</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/LeaseManager.html#LOG"><B>LOG</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/LeaseManager.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">LeaseManager</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html#LOG"><B>LOG</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">NameNode</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NamenodeFsck.html#LOG"><B>LOG</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/NamenodeFsck.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">NamenodeFsck</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/SecondaryNameNode.html#LOG"><B>LOG</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/SecondaryNameNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">SecondaryNameNode</A> 中的静态变量
<DD><B>已过时。</B>&nbsp;&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/InterDatanodeProtocol.html#LOG"><B>LOG</B></A> - 
接口 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/InterDatanodeProtocol.html" title="org.apache.hadoop.hdfs.server.protocol 中的接口">InterDatanodeProtocol</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/util/LightWeightGSet.html#LOG"><B>LOG</B></A> - 
类 org.apache.hadoop.hdfs.util.<A HREF="./org/apache/hadoop/hdfs/util/LightWeightGSet.html" title="org.apache.hadoop.hdfs.util 中的类">LightWeightGSet</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FSEditLog.html#logCloseFile(java.lang.String, org.apache.hadoop.hdfs.server.namenode.INodeFile)"><B>logCloseFile(String, INodeFile)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/FSEditLog.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FSEditLog</A> 中的方法
<DD>modified by tony 2014/4/3
 Add close lease record to edit log.
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FSEditLog.html#logMkDir(java.lang.String, org.apache.hadoop.hdfs.server.namenode.INode)"><B>logMkDir(String, INode)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/FSEditLog.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FSEditLog</A> 中的方法
<DD>Add create directory record to edit log
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FSEditLog.html#logOpenFile(java.lang.String, org.apache.hadoop.hdfs.server.namenode.INodeFileUnderConstruction)"><B>logOpenFile(String, INodeFileUnderConstruction)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/FSEditLog.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FSEditLog</A> 中的方法
<DD>Add open lease record to edit log.
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FSEditLog.html#logSync()"><B>logSync()</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/FSEditLog.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FSEditLog</A> 中的方法
<DD>Sync all modifications done by this thread.
<DT><A HREF="./org/apache/hadoop/hdfs/security/token/delegation/DelegationTokenSecretManager.html#logUpdateMasterKey(org.apache.hadoop.security.token.delegation.DelegationKey)"><B>logUpdateMasterKey(DelegationKey)</B></A> - 
类 org.apache.hadoop.hdfs.security.token.delegation.<A HREF="./org/apache/hadoop/hdfs/security/token/delegation/DelegationTokenSecretManager.html" title="org.apache.hadoop.hdfs.security.token.delegation 中的类">DelegationTokenSecretManager</A> 中的方法
<DD>Call namesystem to update editlogs for new master key.
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#logUpdateMasterKey(org.apache.hadoop.security.token.delegation.DelegationKey)"><B>logUpdateMasterKey(DelegationKey)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FSNamesystem</A> 中的方法
<DD>Log the updateMasterKey operation to edit logs
</DL>
<HR>
<A NAME="_M_"><!-- --></A><H2>
<B>M</B></H2>
<DL>
<DT><A HREF="./org/apache/hadoop/hdfs/server/balancer/Balancer.html#main(java.lang.String[])"><B>main(String[])</B></A> - 
类 org.apache.hadoop.hdfs.server.balancer.<A HREF="./org/apache/hadoop/hdfs/server/balancer/Balancer.html" title="org.apache.hadoop.hdfs.server.balancer 中的类">Balancer</A> 中的静态方法
<DD>Run a balancer
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/DataNode.html#main(java.lang.String[])"><B>main(String[])</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/DataNode.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">DataNode</A> 中的静态方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeStator.html#main(java.lang.String[])"><B>main(String[])</B></A> - 
类 org.apache.hadoop.hdfs.server.monitor.<A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeStator.html" title="org.apache.hadoop.hdfs.server.monitor 中的类">ServernodeStator</A> 中的静态方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html#main(java.lang.String[])"><B>main(String[])</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">NameNode</A> 中的静态方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/SecondaryNameNode.html#main(java.lang.String[])"><B>main(String[])</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/SecondaryNameNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">SecondaryNameNode</A> 中的静态方法
<DD><B>已过时。</B>&nbsp;main() has some simple utility methods.
<DT><A HREF="./org/apache/hadoop/hdfs/tools/DelegationTokenFetcher.html#main(java.lang.String[])"><B>main(String[])</B></A> - 
类 org.apache.hadoop.hdfs.tools.<A HREF="./org/apache/hadoop/hdfs/tools/DelegationTokenFetcher.html" title="org.apache.hadoop.hdfs.tools 中的类">DelegationTokenFetcher</A> 中的静态方法
<DD>Command-line interface
<DT><A HREF="./org/apache/hadoop/hdfs/tools/DFSAdmin.html#main(java.lang.String[])"><B>main(String[])</B></A> - 
类 org.apache.hadoop.hdfs.tools.<A HREF="./org/apache/hadoop/hdfs/tools/DFSAdmin.html" title="org.apache.hadoop.hdfs.tools 中的类">DFSAdmin</A> 中的静态方法
<DD>main() has some simple utility methods.
<DT><A HREF="./org/apache/hadoop/hdfs/tools/DFSck.html#main(java.lang.String[])"><B>main(String[])</B></A> - 
类 org.apache.hadoop.hdfs.tools.<A HREF="./org/apache/hadoop/hdfs/tools/DFSck.html" title="org.apache.hadoop.hdfs.tools 中的类">DFSck</A> 中的静态方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/tools/HDFSConcat.html#main(java.lang.String...)"><B>main(String...)</B></A> - 
类 org.apache.hadoop.hdfs.tools.<A HREF="./org/apache/hadoop/hdfs/tools/HDFSConcat.html" title="org.apache.hadoop.hdfs.tools 中的类">HDFSConcat</A> 中的静态方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/tools/JMXGet.html#main(java.lang.String[])"><B>main(String[])</B></A> - 
类 org.apache.hadoop.hdfs.tools.<A HREF="./org/apache/hadoop/hdfs/tools/JMXGet.html" title="org.apache.hadoop.hdfs.tools 中的类">JMXGet</A> 中的静态方法
<DD>main
<DT><A HREF="./org/apache/hadoop/hdfs/tools/offlineImageViewer/OfflineImageViewer.html#main(java.lang.String[])"><B>main(String[])</B></A> - 
类 org.apache.hadoop.hdfs.tools.offlineImageViewer.<A HREF="./org/apache/hadoop/hdfs/tools/offlineImageViewer/OfflineImageViewer.html" title="org.apache.hadoop.hdfs.tools.offlineImageViewer 中的类">OfflineImageViewer</A> 中的静态方法
<DD>Entry point to command-line-driven operation.
<DT><A HREF="./org/apache/hadoop/hdfs/DistributedFileSystem.html#makeQualified(org.apache.hadoop.fs.Path)"><B>makeQualified(Path)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DistributedFileSystem.html" title="org.apache.hadoop.hdfs 中的类">DistributedFileSystem</A> 中的方法
<DD>Normalize paths that explicitly specify the default port.
<DT><A HREF="./org/apache/hadoop/hdfs/DFSInputStream.html#mark(int)"><B>mark(int)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSInputStream.html" title="org.apache.hadoop.hdfs 中的类">DFSInputStream</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#markBlockAsCorrupt(org.apache.hadoop.hdfs.protocol.Block, org.apache.hadoop.hdfs.protocol.DatanodeInfo)"><B>markBlockAsCorrupt(Block, DatanodeInfo)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FSNamesystem</A> 中的方法
<DD>Mark the block belonging to datanode as corrupt
<DT><A HREF="./org/apache/hadoop/hdfs/DFSInputStream.html#markSupported()"><B>markSupported()</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSInputStream.html" title="org.apache.hadoop.hdfs 中的类">DFSInputStream</A> 中的方法
<DD>We definitely don't support marks
<DT><A HREF="./org/apache/hadoop/hdfs/DFSClient.html#MAX_BLOCK_ACQUIRE_FAILURES"><B>MAX_BLOCK_ACQUIRE_FAILURES</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSClient.html" title="org.apache.hadoop.hdfs 中的类">DFSClient</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/balancer/Balancer.html#MAX_NUM_CONCURRENT_MOVES"><B>MAX_NUM_CONCURRENT_MOVES</B></A> - 
类 org.apache.hadoop.hdfs.server.balancer.<A HREF="./org/apache/hadoop/hdfs/server/balancer/Balancer.html" title="org.apache.hadoop.hdfs.server.balancer 中的类">Balancer</A> 中的静态变量
<DD>The maximum number of concurrent blocks moves for 
 balancing purpose at a datanode
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FSImage.html#max_offset"><B>max_offset</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/FSImage.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FSImage</A> 中的变量
<DD>added by tony
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/FSConstants.html#MAX_PATH_DEPTH"><B>MAX_PATH_DEPTH</B></A> - 
接口 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/FSConstants.html" title="org.apache.hadoop.hdfs.protocol 中的接口">FSConstants</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/FSConstants.html#MAX_PATH_LENGTH"><B>MAX_PATH_LENGTH</B></A> - 
接口 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/FSConstants.html" title="org.apache.hadoop.hdfs.protocol 中的接口">FSConstants</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeInfo.html#memStatus"><B>memStatus</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeInfo.html" title="org.apache.hadoop.hdfs.protocol 中的类">DatanodeInfo</A> 中的变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/Block.html#METADATA_EXTENSION"><B>METADATA_EXTENSION</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/Block.html" title="org.apache.hadoop.hdfs.protocol 中的类">Block</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDataset.html#METADATA_EXTENSION"><B>METADATA_EXTENSION</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDataset.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">FSDataset</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDataset.html#METADATA_VERSION"><B>METADATA_VERSION</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDataset.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">FSDataset</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDataset.html#metaFileExists(org.apache.hadoop.hdfs.protocol.Block)"><B>metaFileExists(Block)</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDataset.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">FSDataset</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.html#metaFileExists(org.apache.hadoop.hdfs.protocol.Block)"><B>metaFileExists(Block)</B></A> - 
接口 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.html" title="org.apache.hadoop.hdfs.server.datanode 中的接口">FSDatasetInterface</A> 中的方法
<DD>Does the meta file exist for this block?
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/Block.html#metaFilePattern"><B>metaFilePattern</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/Block.html" title="org.apache.hadoop.hdfs.protocol 中的类">Block</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSClient.html#metaSave(java.lang.String)"><B>metaSave(String)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSClient.html" title="org.apache.hadoop.hdfs 中的类">DFSClient</A> 中的方法
<DD>Dumps DFS data structures into specified file.
<DT><A HREF="./org/apache/hadoop/hdfs/DistributedFileSystem.html#metaSave(java.lang.String)"><B>metaSave(String)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DistributedFileSystem.html" title="org.apache.hadoop.hdfs 中的类">DistributedFileSystem</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/ClientProtocol.html#metaSave(java.lang.String)"><B>metaSave(String)</B></A> - 
接口 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/ClientProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的接口">ClientProtocol</A> 中的方法
<DD>Dumps namenode data structures into specified file.
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html#metaSave(java.lang.String)"><B>metaSave(String)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">NameNode</A> 中的方法
<DD>Dumps namenode state into specified file
<DT><A HREF="./org/apache/hadoop/hdfs/tools/DFSAdmin.html#metaSave(java.lang.String[], int)"><B>metaSave(String[], int)</B></A> - 
类 org.apache.hadoop.hdfs.tools.<A HREF="./org/apache/hadoop/hdfs/tools/DFSAdmin.html" title="org.apache.hadoop.hdfs.tools 中的类">DFSAdmin</A> 中的方法
<DD>Dumps DFS data structures into specified file.
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/FSConstants.html#MIN_BLOCKS_FOR_WRITE"><B>MIN_BLOCKS_FOR_WRITE</B></A> - 
接口 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/FSConstants.html" title="org.apache.hadoop.hdfs.protocol 中的接口">FSConstants</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/fs/Hdfs.html#mkdir(org.apache.hadoop.fs.Path, org.apache.hadoop.fs.permission.FsPermission, boolean)"><B>mkdir(Path, FsPermission, boolean)</B></A> - 
类 org.apache.hadoop.fs.<A HREF="./org/apache/hadoop/fs/Hdfs.html" title="org.apache.hadoop.fs 中的类">Hdfs</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DistributedFileSystem.html#mkdir(org.apache.hadoop.fs.Path, org.apache.hadoop.fs.permission.FsPermission)"><B>mkdir(Path, FsPermission)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DistributedFileSystem.html" title="org.apache.hadoop.hdfs 中的类">DistributedFileSystem</A> 中的方法
<DD>Create a directory with given name and permission, only when
 parent directory exists.
<DT><A HREF="./org/apache/hadoop/hdfs/DFSClient.html#mkdirs(java.lang.String)"><B>mkdirs(String)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSClient.html" title="org.apache.hadoop.hdfs 中的类">DFSClient</A> 中的方法
<DD><B>已过时。</B>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSClient.html#mkdirs(java.lang.String, org.apache.hadoop.fs.permission.FsPermission, boolean)"><B>mkdirs(String, FsPermission, boolean)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSClient.html" title="org.apache.hadoop.hdfs 中的类">DFSClient</A> 中的方法
<DD>Create a directory (or hierarchy of directories) with the given
 name and permission.
<DT><A HREF="./org/apache/hadoop/hdfs/DistributedFileSystem.html#mkdirs(org.apache.hadoop.fs.Path, org.apache.hadoop.fs.permission.FsPermission)"><B>mkdirs(Path, FsPermission)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DistributedFileSystem.html" title="org.apache.hadoop.hdfs 中的类">DistributedFileSystem</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/HftpFileSystem.html#mkdirs(org.apache.hadoop.fs.Path, org.apache.hadoop.fs.permission.FsPermission)"><B>mkdirs(Path, FsPermission)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/HftpFileSystem.html" title="org.apache.hadoop.hdfs 中的类">HftpFileSystem</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/ClientProtocol.html#mkdirs(java.lang.String, org.apache.hadoop.fs.permission.FsPermission, boolean)"><B>mkdirs(String, FsPermission, boolean)</B></A> - 
接口 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/ClientProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的接口">ClientProtocol</A> 中的方法
<DD>Create a directory (or hierarchy of directories) with the given
 name and permission.
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#mkdirs(java.lang.String, org.apache.hadoop.fs.permission.PermissionStatus, boolean)"><B>mkdirs(String, PermissionStatus, boolean)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FSNamesystem</A> 中的方法
<DD>Create all the necessary directories
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html#mkdirs(java.lang.String, org.apache.hadoop.fs.permission.FsPermission, boolean)"><B>mkdirs(String, FsPermission, boolean)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">NameNode</A> 中的方法
<DD>Create a directory (or hierarchy of directories) with the given
 name and permission.
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/MonitorServlet.html" title="org.apache.hadoop.hdfs.server.namenode 中的类"><B>MonitorServlet</B></A> - <A HREF="./org/apache/hadoop/hdfs/server/namenode/package-summary.html">org.apache.hadoop.hdfs.server.namenode</A> 中的 类<DD>&nbsp;<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/MonitorServlet.html#MonitorServlet()"><B>MonitorServlet()</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/MonitorServlet.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">MonitorServlet</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FSImage.html#moveCurrent(org.apache.hadoop.hdfs.server.common.Storage.StorageDirectory)"><B>moveCurrent(Storage.StorageDirectory)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/FSImage.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FSImage</A> 中的方法
<DD>Move <code>current</code> to <code>lastcheckpoint.tmp</code> and
 recreate empty <code>current</code>.
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FSImage.html#moveLastCheckpoint(org.apache.hadoop.hdfs.server.common.Storage.StorageDirectory)"><B>moveLastCheckpoint(Storage.StorageDirectory)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/FSImage.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FSImage</A> 中的方法
<DD>Move <code>lastcheckpoint.tmp</code> to <code>previous.checkpoint</code>
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/CodingMatrix.html#mult(byte, byte)"><B>mult(byte, byte)</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/CodingMatrix.html" title="org.apache.hadoop.hdfs.protocol 中的类">CodingMatrix</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/RegeneratingCodeMatrix.html#mult(byte, byte)"><B>mult(byte, byte)</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/RegeneratingCodeMatrix.html" title="org.apache.hadoop.hdfs.protocol 中的类">RegeneratingCodeMatrix</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/RSCoderProtocol.html#mult"><B>mult</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/RSCoderProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的类">RSCoderProtocol</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/RSCoderProtocol.html#mult(byte, byte)"><B>mult(byte, byte)</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/RSCoderProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的类">RSCoderProtocol</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/XORCoderProtocol.html#mult(byte, byte)"><B>mult(byte, byte)</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/XORCoderProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的类">XORCoderProtocol</A> 中的方法
<DD>&nbsp;
</DL>
<HR>
<A NAME="_N_"><!-- --></A><H2>
<B>N</B></H2>
<DL>
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeID.html#name"><B>name</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeID.html" title="org.apache.hadoop.hdfs.protocol 中的类">DatanodeID</A> 中的变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/tools/offlineImageViewer/NameDistributionVisitor.html" title="org.apache.hadoop.hdfs.tools.offlineImageViewer 中的类"><B>NameDistributionVisitor</B></A> - <A HREF="./org/apache/hadoop/hdfs/tools/offlineImageViewer/package-summary.html">org.apache.hadoop.hdfs.tools.offlineImageViewer</A> 中的 类<DD>File name distribution visitor.<DT><A HREF="./org/apache/hadoop/hdfs/tools/offlineImageViewer/NameDistributionVisitor.html#NameDistributionVisitor(java.lang.String, boolean)"><B>NameDistributionVisitor(String, boolean)</B></A> - 
类 org.apache.hadoop.hdfs.tools.offlineImageViewer.<A HREF="./org/apache/hadoop/hdfs/tools/offlineImageViewer/NameDistributionVisitor.html" title="org.apache.hadoop.hdfs.tools.offlineImageViewer 中的类">NameDistributionVisitor</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/DataNode.html#namenode"><B>namenode</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/DataNode.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">DataNode</A> 中的变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类"><B>NameNode</B></A> - <A HREF="./org/apache/hadoop/hdfs/server/namenode/package-summary.html">org.apache.hadoop.hdfs.server.namenode</A> 中的 类<DD>NameNode serves as both directory namespace manager and
 "inode table" for the Hadoop DFS.<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html#NameNode(org.apache.hadoop.conf.Configuration)"><B>NameNode(Configuration)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">NameNode</A> 的构造方法
<DD>Start NameNode.
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html#NameNode(org.apache.hadoop.conf.Configuration, org.apache.hadoop.hdfs.server.common.HdfsConstants.NamenodeRole)"><B>NameNode(Configuration, HdfsConstants.NamenodeRole)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">NameNode</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/metrics/NameNodeActivityMBean.html" title="org.apache.hadoop.hdfs.server.namenode.metrics 中的类"><B>NameNodeActivityMBean</B></A> - <A HREF="./org/apache/hadoop/hdfs/server/namenode/metrics/package-summary.html">org.apache.hadoop.hdfs.server.namenode.metrics</A> 中的 类<DD>This is the JMX MBean for reporting the NameNode Activity.<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/metrics/NameNodeActivityMBean.html#NameNodeActivityMBean(org.apache.hadoop.metrics.util.MetricsRegistry)"><B>NameNodeActivityMBean(MetricsRegistry)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.metrics.<A HREF="./org/apache/hadoop/hdfs/server/namenode/metrics/NameNodeActivityMBean.html" title="org.apache.hadoop.hdfs.server.namenode.metrics 中的类">NameNodeActivityMBean</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/NamenodeCommand.html" title="org.apache.hadoop.hdfs.server.protocol 中的类"><B>NamenodeCommand</B></A> - <A HREF="./org/apache/hadoop/hdfs/server/protocol/package-summary.html">org.apache.hadoop.hdfs.server.protocol</A> 中的 类<DD>Base class for name-node command.<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/NamenodeCommand.html#NamenodeCommand()"><B>NamenodeCommand()</B></A> - 
类 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/NamenodeCommand.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">NamenodeCommand</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/NamenodeCommand.html#NamenodeCommand(int)"><B>NamenodeCommand(int)</B></A> - 
类 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/NamenodeCommand.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">NamenodeCommand</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NamenodeFsck.html" title="org.apache.hadoop.hdfs.server.namenode 中的类"><B>NamenodeFsck</B></A> - <A HREF="./org/apache/hadoop/hdfs/server/namenode/package-summary.html">org.apache.hadoop.hdfs.server.namenode</A> 中的 类<DD>This class provides rudimentary checking of DFS volumes for errors and
 sub-optimal conditions.<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/metrics/NameNodeMetrics.html" title="org.apache.hadoop.hdfs.server.namenode.metrics 中的类"><B>NameNodeMetrics</B></A> - <A HREF="./org/apache/hadoop/hdfs/server/namenode/metrics/package-summary.html">org.apache.hadoop.hdfs.server.namenode.metrics</A> 中的 类<DD>This class is for maintaining  the various NameNode activity statistics
 and publishing them through the metrics interfaces.<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/metrics/NameNodeMetrics.html#NameNodeMetrics(org.apache.hadoop.conf.Configuration, org.apache.hadoop.hdfs.server.common.HdfsConstants.NamenodeRole)"><B>NameNodeMetrics(Configuration, HdfsConstants.NamenodeRole)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.metrics.<A HREF="./org/apache/hadoop/hdfs/server/namenode/metrics/NameNodeMetrics.html" title="org.apache.hadoop.hdfs.server.namenode.metrics 中的类">NameNodeMetrics</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNodeMXBean.html" title="org.apache.hadoop.hdfs.server.namenode 中的接口"><B>NameNodeMXBean</B></A> - <A HREF="./org/apache/hadoop/hdfs/server/namenode/package-summary.html">org.apache.hadoop.hdfs.server.namenode</A> 中的 接口<DD>This is the JMX management interface for namenode information<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/NamenodeProtocol.html" title="org.apache.hadoop.hdfs.server.protocol 中的接口"><B>NamenodeProtocol</B></A> - <A HREF="./org/apache/hadoop/hdfs/server/protocol/package-summary.html">org.apache.hadoop.hdfs.server.protocol</A> 中的 接口<DD>Protocol that a secondary NameNode uses to communicate with the NameNode.<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/NamenodeProtocols.html" title="org.apache.hadoop.hdfs.server.protocol 中的接口"><B>NamenodeProtocols</B></A> - <A HREF="./org/apache/hadoop/hdfs/server/protocol/package-summary.html">org.apache.hadoop.hdfs.server.protocol</A> 中的 接口<DD>The full set of RPC methods implemented by the Namenode.<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/NamenodeRegistration.html" title="org.apache.hadoop.hdfs.server.protocol 中的类"><B>NamenodeRegistration</B></A> - <A HREF="./org/apache/hadoop/hdfs/server/protocol/package-summary.html">org.apache.hadoop.hdfs.server.protocol</A> 中的 类<DD>Information sent by a subordinate name-node to the active name-node
 during the registration process.<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/NamenodeRegistration.html#NamenodeRegistration()"><B>NamenodeRegistration()</B></A> - 
类 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/NamenodeRegistration.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">NamenodeRegistration</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/NamenodeRegistration.html#NamenodeRegistration(java.lang.String, java.lang.String, org.apache.hadoop.hdfs.server.common.StorageInfo, org.apache.hadoop.hdfs.server.common.HdfsConstants.NamenodeRole, long)"><B>NamenodeRegistration(String, String, StorageInfo, HdfsConstants.NamenodeRole, long)</B></A> - 
类 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/NamenodeRegistration.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">NamenodeRegistration</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/StorageInfo.html#namespaceID"><B>namespaceID</B></A> - 
类 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/StorageInfo.html" title="org.apache.hadoop.hdfs.server.common 中的类">StorageInfo</A> 中的变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/NamespaceInfo.html" title="org.apache.hadoop.hdfs.server.protocol 中的类"><B>NamespaceInfo</B></A> - <A HREF="./org/apache/hadoop/hdfs/server/protocol/package-summary.html">org.apache.hadoop.hdfs.server.protocol</A> 中的 类<DD>NamespaceInfo is returned by the name-node in reply 
 to a data-node handshake.<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/NamespaceInfo.html#NamespaceInfo()"><B>NamespaceInfo()</B></A> - 
类 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/NamespaceInfo.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">NamespaceInfo</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/NamespaceInfo.html#NamespaceInfo(int, long, int)"><B>NamespaceInfo(int, long, int)</B></A> - 
类 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/NamespaceInfo.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">NamespaceInfo</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FSImage.html#namesystem"><B>namesystem</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/FSImage.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FSImage</A> 中的变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html#namesystem"><B>namesystem</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">NameNode</A> 中的变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/DatanodeDescriptor.html#needKeyUpdate"><B>needKeyUpdate</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/DatanodeDescriptor.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">DatanodeDescriptor</A> 中的变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/CheckpointCommand.html#needToReturnImage()"><B>needToReturnImage()</B></A> - 
类 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/CheckpointCommand.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">CheckpointCommand</A> 中的方法
<DD>Indicates whether the new checkpoint image needs to be transfered 
 back to the name-node after the checkpoint is done.
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeInfo.html#netStatus"><B>netStatus</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeInfo.html" title="org.apache.hadoop.hdfs.protocol 中的类">DatanodeInfo</A> 中的变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/HeaderBuffer.html#new_entries"><B>new_entries</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/HeaderBuffer.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">HeaderBuffer</A> 中的变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/HeaderBuffer.html#new_hash"><B>new_hash</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/HeaderBuffer.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">HeaderBuffer</A> 中的变量
<DD>new hash and entry links
<DT><A HREF="./org/apache/hadoop/hdfs/BlockReader.html#newBlockReader(java.net.Socket, java.lang.String, org.apache.hadoop.hdfs.protocol.Block, org.apache.hadoop.security.token.Token, long, long, int)"><B>newBlockReader(Socket, String, Block, Token&lt;BlockTokenIdentifier&gt;, long, long, int)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/BlockReader.html" title="org.apache.hadoop.hdfs 中的类">BlockReader</A> 中的静态方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/BlockReader.html#newBlockReader(java.net.Socket, java.lang.String, org.apache.hadoop.hdfs.protocol.Block, org.apache.hadoop.security.token.Token, long, long, int, boolean)"><B>newBlockReader(Socket, String, Block, Token&lt;BlockTokenIdentifier&gt;, long, long, int, boolean)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/BlockReader.html" title="org.apache.hadoop.hdfs 中的类">BlockReader</A> 中的静态方法
<DD>Java Doc required
<DT><A HREF="./org/apache/hadoop/hdfs/BlockReader.html#newBlockReader(java.net.Socket, java.lang.String, org.apache.hadoop.hdfs.protocol.Block, org.apache.hadoop.security.token.Token, long, long, int, boolean, java.lang.String)"><B>newBlockReader(Socket, String, Block, Token&lt;BlockTokenIdentifier&gt;, long, long, int, boolean, String)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/BlockReader.html" title="org.apache.hadoop.hdfs 中的类">BlockReader</A> 中的静态方法
<DD>Create a new BlockReader specifically to satisfy a read.
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FSImage.html#newImageDigest"><B>newImageDigest</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/FSImage.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FSImage</A> 中的变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/DataNode.html#newSocket()"><B>newSocket()</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/DataNode.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">DataNode</A> 中的方法
<DD>Creates either NIO or regular depending on socketWriteTimeout.
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/BlockListAsLongs.BlockReportIterator.html#next()"><B>next()</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/BlockListAsLongs.BlockReportIterator.html" title="org.apache.hadoop.hdfs.protocol 中的类">BlockListAsLongs.BlockReportIterator</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/GenerationStamp.html#nextStamp()"><B>nextStamp()</B></A> - 
类 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/GenerationStamp.html" title="org.apache.hadoop.hdfs.server.common 中的类">GenerationStamp</A> 中的方法
<DD>First increments the counter and then returns the stamp
<DT><A HREF="./org/apache/hadoop/hdfs/HftpFileSystem.html#nnAddr"><B>nnAddr</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/HftpFileSystem.html" title="org.apache.hadoop.hdfs 中的类">HftpFileSystem</A> 中的变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/balancer/Balancer.html#NO_MOVE_BLOCK"><B>NO_MOVE_BLOCK</B></A> - 
类 org.apache.hadoop.hdfs.server.balancer.<A HREF="./org/apache/hadoop/hdfs/server/balancer/Balancer.html" title="org.apache.hadoop.hdfs.server.balancer 中的类">Balancer</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/balancer/Balancer.html#NO_MOVE_PROGRESS"><B>NO_MOVE_PROGRESS</B></A> - 
类 org.apache.hadoop.hdfs.server.balancer.<A HREF="./org/apache/hadoop/hdfs/server/balancer/Balancer.html" title="org.apache.hadoop.hdfs.server.balancer 中的类">Balancer</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html#nodeRegistration"><B>nodeRegistration</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">NameNode</A> 中的变量
<DD>Registration information of this name-node
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/NodeRegistration.html" title="org.apache.hadoop.hdfs.server.protocol 中的接口"><B>NodeRegistration</B></A> - <A HREF="./org/apache/hadoop/hdfs/server/protocol/package-summary.html">org.apache.hadoop.hdfs.server.protocol</A> 中的 接口<DD>Generic class specifying information, which need to be sent to the name-node
 during the registration process.<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NamenodeFsck.html#NONEXISTENT_STATUS"><B>NONEXISTENT_STATUS</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/NamenodeFsck.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">NamenodeFsck</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/DatanodeProtocol.html#NOTIFY"><B>NOTIFY</B></A> - 
接口 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/DatanodeProtocol.html" title="org.apache.hadoop.hdfs.server.protocol 中的接口">DatanodeProtocol</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/NamenodeProtocol.html#NOTIFY"><B>NOTIFY</B></A> - 
接口 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/NamenodeProtocol.html" title="org.apache.hadoop.hdfs.server.protocol 中的接口">NamenodeProtocol</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/DataNode.html#notifyNamenodeReceivedBlock(org.apache.hadoop.hdfs.protocol.Block, java.lang.String)"><B>notifyNamenodeReceivedBlock(Block, String)</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/DataNode.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">DataNode</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NotReplicatedYetException.html" title="org.apache.hadoop.hdfs.server.namenode 中的类"><B>NotReplicatedYetException</B></A> - <A HREF="./org/apache/hadoop/hdfs/server/namenode/package-summary.html">org.apache.hadoop.hdfs.server.namenode</A> 中的 异常<DD>The file has not finished being written to enough datanodes yet.<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NotReplicatedYetException.html#NotReplicatedYetException(java.lang.String)"><B>NotReplicatedYetException(String)</B></A> - 
异常 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/NotReplicatedYetException.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">NotReplicatedYetException</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/Util.html#now()"><B>now()</B></A> - 
类 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/Util.html" title="org.apache.hadoop.hdfs.server.common 中的类">Util</A> 中的静态方法
<DD>Current system time.
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/NSQuotaExceededException.html" title="org.apache.hadoop.hdfs.protocol 中的类"><B>NSQuotaExceededException</B></A> - <A HREF="./org/apache/hadoop/hdfs/protocol/package-summary.html">org.apache.hadoop.hdfs.protocol</A> 中的 异常<DD>&nbsp;<DT><A HREF="./org/apache/hadoop/hdfs/protocol/NSQuotaExceededException.html#NSQuotaExceededException()"><B>NSQuotaExceededException()</B></A> - 
异常 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/NSQuotaExceededException.html" title="org.apache.hadoop.hdfs.protocol 中的类">NSQuotaExceededException</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/NSQuotaExceededException.html#NSQuotaExceededException(java.lang.String)"><B>NSQuotaExceededException(String)</B></A> - 
异常 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/NSQuotaExceededException.html" title="org.apache.hadoop.hdfs.protocol 中的类">NSQuotaExceededException</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/NSQuotaExceededException.html#NSQuotaExceededException(long, long)"><B>NSQuotaExceededException(long, long)</B></A> - 
异常 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/NSQuotaExceededException.html" title="org.apache.hadoop.hdfs.protocol 中的类">NSQuotaExceededException</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/metrics/NameNodeMetrics.html#numAddBlockOps"><B>numAddBlockOps</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.metrics.<A HREF="./org/apache/hadoop/hdfs/server/namenode/metrics/NameNodeMetrics.html" title="org.apache.hadoop.hdfs.server.namenode.metrics 中的类">NameNodeMetrics</A> 中的变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/DatanodeDescriptor.html#numBlocks()"><B>numBlocks()</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/DatanodeDescriptor.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">DatanodeDescriptor</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/metrics/NameNodeMetrics.html#numBlocksCorrupted"><B>numBlocksCorrupted</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.metrics.<A HREF="./org/apache/hadoop/hdfs/server/namenode/metrics/NameNodeMetrics.html" title="org.apache.hadoop.hdfs.server.namenode.metrics 中的类">NameNodeMetrics</A> 中的变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/CorruptReplicasMap.html#numCorruptReplicas(org.apache.hadoop.hdfs.protocol.Block)"><B>numCorruptReplicas(Block)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/CorruptReplicasMap.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">CorruptReplicasMap</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#numCorruptReplicas(org.apache.hadoop.hdfs.protocol.Block)"><B>numCorruptReplicas(Block)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FSNamesystem</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/metrics/NameNodeMetrics.html#numCreateFileOps"><B>numCreateFileOps</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.metrics.<A HREF="./org/apache/hadoop/hdfs/server/namenode/metrics/NameNodeMetrics.html" title="org.apache.hadoop.hdfs.server.namenode.metrics 中的类">NameNodeMetrics</A> 中的变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/metrics/NameNodeMetrics.html#numcreateSymlinkOps"><B>numcreateSymlinkOps</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.metrics.<A HREF="./org/apache/hadoop/hdfs/server/namenode/metrics/NameNodeMetrics.html" title="org.apache.hadoop.hdfs.server.namenode.metrics 中的类">NameNodeMetrics</A> 中的变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/metrics/NameNodeMetrics.html#numDeleteFileOps"><B>numDeleteFileOps</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.metrics.<A HREF="./org/apache/hadoop/hdfs/server/namenode/metrics/NameNodeMetrics.html" title="org.apache.hadoop.hdfs.server.namenode.metrics 中的类">NameNodeMetrics</A> 中的变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/metrics/FSNamesystemMetrics.html#numExpiredHeartbeats"><B>numExpiredHeartbeats</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.metrics.<A HREF="./org/apache/hadoop/hdfs/server/namenode/metrics/FSNamesystemMetrics.html" title="org.apache.hadoop.hdfs.server.namenode.metrics 中的类">FSNamesystemMetrics</A> 中的变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/metrics/NameNodeMetrics.html#numFileInfoOps"><B>numFileInfoOps</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.metrics.<A HREF="./org/apache/hadoop/hdfs/server/namenode/metrics/NameNodeMetrics.html" title="org.apache.hadoop.hdfs.server.namenode.metrics 中的类">NameNodeMetrics</A> 中的变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/metrics/NameNodeMetrics.html#numFilesAppended"><B>numFilesAppended</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.metrics.<A HREF="./org/apache/hadoop/hdfs/server/namenode/metrics/NameNodeMetrics.html" title="org.apache.hadoop.hdfs.server.namenode.metrics 中的类">NameNodeMetrics</A> 中的变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/metrics/NameNodeMetrics.html#numFilesCreated"><B>numFilesCreated</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.metrics.<A HREF="./org/apache/hadoop/hdfs/server/namenode/metrics/NameNodeMetrics.html" title="org.apache.hadoop.hdfs.server.namenode.metrics 中的类">NameNodeMetrics</A> 中的变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/metrics/NameNodeMetrics.html#numFilesDeleted"><B>numFilesDeleted</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.metrics.<A HREF="./org/apache/hadoop/hdfs/server/namenode/metrics/NameNodeMetrics.html" title="org.apache.hadoop.hdfs.server.namenode.metrics 中的类">NameNodeMetrics</A> 中的变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/metrics/NameNodeMetrics.html#numFilesInGetListingOps"><B>numFilesInGetListingOps</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.metrics.<A HREF="./org/apache/hadoop/hdfs/server/namenode/metrics/NameNodeMetrics.html" title="org.apache.hadoop.hdfs.server.namenode.metrics 中的类">NameNodeMetrics</A> 中的变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/metrics/NameNodeMetrics.html#numFilesRenamed"><B>numFilesRenamed</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.metrics.<A HREF="./org/apache/hadoop/hdfs/server/namenode/metrics/NameNodeMetrics.html" title="org.apache.hadoop.hdfs.server.namenode.metrics 中的类">NameNodeMetrics</A> 中的变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/metrics/NameNodeMetrics.html#numGetBlockLocations"><B>numGetBlockLocations</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.metrics.<A HREF="./org/apache/hadoop/hdfs/server/namenode/metrics/NameNodeMetrics.html" title="org.apache.hadoop.hdfs.server.namenode.metrics 中的类">NameNodeMetrics</A> 中的变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/metrics/NameNodeMetrics.html#numgetLinkTargetOps"><B>numgetLinkTargetOps</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.metrics.<A HREF="./org/apache/hadoop/hdfs/server/namenode/metrics/NameNodeMetrics.html" title="org.apache.hadoop.hdfs.server.namenode.metrics 中的类">NameNodeMetrics</A> 中的变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/metrics/NameNodeMetrics.html#numGetListingOps"><B>numGetListingOps</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.metrics.<A HREF="./org/apache/hadoop/hdfs/server/namenode/metrics/NameNodeMetrics.html" title="org.apache.hadoop.hdfs.server.namenode.metrics 中的类">NameNodeMetrics</A> 中的变量
<DD>&nbsp;
</DL>
<HR>
<A NAME="_O_"><!-- --></A><H2>
<B>O</B></H2>
<DL>
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/DataNode.html#offerService()"><B>offerService()</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/DataNode.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">DataNode</A> 中的方法
<DD>Main loop for the DataNode.
<DT><A HREF="./org/apache/hadoop/hdfs/tools/offlineImageViewer/OfflineImageViewer.html" title="org.apache.hadoop.hdfs.tools.offlineImageViewer 中的类"><B>OfflineImageViewer</B></A> - <A HREF="./org/apache/hadoop/hdfs/tools/offlineImageViewer/package-summary.html">org.apache.hadoop.hdfs.tools.offlineImageViewer</A> 中的 类<DD>OfflineImageViewer to dump the contents of an Hadoop image file to XML
 or the console.<DT><A HREF="./org/apache/hadoop/hdfs/tools/offlineImageViewer/OfflineImageViewer.html#OfflineImageViewer(java.lang.String, org.apache.hadoop.hdfs.tools.offlineImageViewer.ImageVisitor, boolean)"><B>OfflineImageViewer(String, ImageVisitor, boolean)</B></A> - 
类 org.apache.hadoop.hdfs.tools.offlineImageViewer.<A HREF="./org/apache/hadoop/hdfs/tools/offlineImageViewer/OfflineImageViewer.html" title="org.apache.hadoop.hdfs.tools.offlineImageViewer 中的类">OfflineImageViewer</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.Sender.html#op(java.io.DataOutputStream, org.apache.hadoop.hdfs.protocol.DataTransferProtocol.Op)"><B>op(DataOutputStream, DataTransferProtocol.Op)</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.Sender.html" title="org.apache.hadoop.hdfs.protocol 中的类">DataTransferProtocol.Sender</A> 中的静态方法
<DD>Initialize a operation.
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.html#OP_BLOCK_CHECKSUM"><B>OP_BLOCK_CHECKSUM</B></A> - 
接口 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的接口">DataTransferProtocol</A> 中的静态变量
<DD><B>已过时。</B>&nbsp;<I>Deprecated at 0.21.  Use Op.BLOCK_CHECKSUM instead.</I>
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.html#OP_COPY_BLOCK"><B>OP_COPY_BLOCK</B></A> - 
接口 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的接口">DataTransferProtocol</A> 中的静态变量
<DD><B>已过时。</B>&nbsp;<I>Deprecated at 0.21.  Use Op.COPY_BLOCK instead.</I>
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.html#OP_READ_BLOCK"><B>OP_READ_BLOCK</B></A> - 
接口 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的接口">DataTransferProtocol</A> 中的静态变量
<DD><B>已过时。</B>&nbsp;<I>Deprecated at 0.21.  Use Op.READ_BLOCK instead.</I>
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.html#OP_READ_METADATA"><B>OP_READ_METADATA</B></A> - 
接口 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的接口">DataTransferProtocol</A> 中的静态变量
<DD><B>已过时。</B>&nbsp;<I>As of version 15, OP_READ_METADATA is no longer supported.</I>
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.html#OP_REPLACE_BLOCK"><B>OP_REPLACE_BLOCK</B></A> - 
接口 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的接口">DataTransferProtocol</A> 中的静态变量
<DD><B>已过时。</B>&nbsp;<I>Deprecated at 0.21.  Use Op.REPLACE_BLOCK instead.</I>
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.html#OP_STATUS_CHECKSUM_OK"><B>OP_STATUS_CHECKSUM_OK</B></A> - 
接口 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的接口">DataTransferProtocol</A> 中的静态变量
<DD><B>已过时。</B>&nbsp;<I>Deprecated at 0.21.  Use Status.CHECKSUM_OK instead.</I>
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.html#OP_STATUS_ERROR"><B>OP_STATUS_ERROR</B></A> - 
接口 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的接口">DataTransferProtocol</A> 中的静态变量
<DD><B>已过时。</B>&nbsp;<I>Deprecated at 0.21.  Use Status.ERROR instead.</I>
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.html#OP_STATUS_ERROR_ACCESS_TOKEN"><B>OP_STATUS_ERROR_ACCESS_TOKEN</B></A> - 
接口 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的接口">DataTransferProtocol</A> 中的静态变量
<DD><B>已过时。</B>&nbsp;<I>Deprecated at 0.21.  Use Status.ERROR_ACCESS_TOKEN instead.</I>
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.html#OP_STATUS_ERROR_CHECKSUM"><B>OP_STATUS_ERROR_CHECKSUM</B></A> - 
接口 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的接口">DataTransferProtocol</A> 中的静态变量
<DD><B>已过时。</B>&nbsp;<I>Deprecated at 0.21.  Use Status.ERROR_CHECKSUM instead.</I>
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.html#OP_STATUS_ERROR_EXISTS"><B>OP_STATUS_ERROR_EXISTS</B></A> - 
接口 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的接口">DataTransferProtocol</A> 中的静态变量
<DD><B>已过时。</B>&nbsp;<I>Deprecated at 0.21.  Use Status.ERROR_EXISTS instead.</I>
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.html#OP_STATUS_ERROR_INVALID"><B>OP_STATUS_ERROR_INVALID</B></A> - 
接口 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的接口">DataTransferProtocol</A> 中的静态变量
<DD><B>已过时。</B>&nbsp;<I>Deprecated at 0.21.  Use Status.ERROR_INVALID instead.</I>
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.html#OP_STATUS_SUCCESS"><B>OP_STATUS_SUCCESS</B></A> - 
接口 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的接口">DataTransferProtocol</A> 中的静态变量
<DD><B>已过时。</B>&nbsp;<I>Deprecated at 0.21.  Use Status.SUCCESS instead.</I>
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.html#OP_WRITE_BLOCK"><B>OP_WRITE_BLOCK</B></A> - 
接口 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的接口">DataTransferProtocol</A> 中的静态变量
<DD><B>已过时。</B>&nbsp;<I>Deprecated at 0.21.  Use Op.WRITE_BLOCK instead.</I>
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.Receiver.html#opBlockChecksum(java.io.DataInputStream, org.apache.hadoop.hdfs.protocol.Block, org.apache.hadoop.security.token.Token)"><B>opBlockChecksum(DataInputStream, Block, Token&lt;BlockTokenIdentifier&gt;)</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.Receiver.html" title="org.apache.hadoop.hdfs.protocol 中的类">DataTransferProtocol.Receiver</A> 中的方法
<DD>Abstract OP_BLOCK_CHECKSUM method.
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.Sender.html#opBlockChecksum(java.io.DataOutputStream, org.apache.hadoop.hdfs.protocol.Block, org.apache.hadoop.security.token.Token)"><B>opBlockChecksum(DataOutputStream, Block, Token&lt;BlockTokenIdentifier&gt;)</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.Sender.html" title="org.apache.hadoop.hdfs.protocol 中的类">DataTransferProtocol.Sender</A> 中的静态方法
<DD>Send OP_BLOCK_CHECKSUM
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.Receiver.html#opCopyBlock(java.io.DataInputStream, org.apache.hadoop.hdfs.protocol.Block, org.apache.hadoop.security.token.Token)"><B>opCopyBlock(DataInputStream, Block, Token&lt;BlockTokenIdentifier&gt;)</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.Receiver.html" title="org.apache.hadoop.hdfs.protocol 中的类">DataTransferProtocol.Receiver</A> 中的方法
<DD>Abstract OP_COPY_BLOCK method.
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.Sender.html#opCopyBlock(java.io.DataOutputStream, org.apache.hadoop.hdfs.protocol.Block, org.apache.hadoop.security.token.Token)"><B>opCopyBlock(DataOutputStream, Block, Token&lt;BlockTokenIdentifier&gt;)</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.Sender.html" title="org.apache.hadoop.hdfs.protocol 中的类">DataTransferProtocol.Sender</A> 中的静态方法
<DD>Send OP_COPY_BLOCK
<DT><A HREF="./org/apache/hadoop/fs/Hdfs.html#open(org.apache.hadoop.fs.Path, int)"><B>open(Path, int)</B></A> - 
类 org.apache.hadoop.fs.<A HREF="./org/apache/hadoop/fs/Hdfs.html" title="org.apache.hadoop.fs 中的类">Hdfs</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSClient.html#open(java.lang.String)"><B>open(String)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSClient.html" title="org.apache.hadoop.hdfs 中的类">DFSClient</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSClient.html#open(java.lang.String, int, boolean, org.apache.hadoop.fs.FileSystem.Statistics)"><B>open(String, int, boolean, FileSystem.Statistics)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSClient.html" title="org.apache.hadoop.hdfs 中的类">DFSClient</A> 中的方法
<DD><B>已过时。</B>&nbsp;<I>Use <A HREF="./org/apache/hadoop/hdfs/DFSClient.html#open(java.lang.String, int, boolean)"><CODE>DFSClient.open(String, int, boolean)</CODE></A> instead.</I>
<DT><A HREF="./org/apache/hadoop/hdfs/DFSClient.html#open(java.lang.String, int, boolean)"><B>open(String, int, boolean)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSClient.html" title="org.apache.hadoop.hdfs 中的类">DFSClient</A> 中的方法
<DD>Create an input stream that obtains a nodelist from the
 namenode, and then reads from all the right places.
<DT><A HREF="./org/apache/hadoop/hdfs/DistributedFileSystem.html#open(org.apache.hadoop.fs.Path, int)"><B>open(Path, int)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DistributedFileSystem.html" title="org.apache.hadoop.hdfs 中的类">DistributedFileSystem</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/HftpFileSystem.html#open(org.apache.hadoop.fs.Path, int)"><B>open(Path, int)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/HftpFileSystem.html" title="org.apache.hadoop.hdfs 中的类">HftpFileSystem</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/HftpFileSystem.html#openConnection(java.lang.String, java.lang.String)"><B>openConnection(String, String)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/HftpFileSystem.html" title="org.apache.hadoop.hdfs 中的类">HftpFileSystem</A> 中的方法
<DD>Open an HTTP connection to the namenode to read file data and metadata.
<DT><A HREF="./org/apache/hadoop/hdfs/HsftpFileSystem.html#openConnection(java.lang.String, java.lang.String)"><B>openConnection(String, String)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/HsftpFileSystem.html" title="org.apache.hadoop.hdfs 中的类">HsftpFileSystem</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.Receiver.html#opReadBlock(java.io.DataInputStream, org.apache.hadoop.hdfs.protocol.Block, long, long, java.lang.String, org.apache.hadoop.security.token.Token)"><B>opReadBlock(DataInputStream, Block, long, long, String, Token&lt;BlockTokenIdentifier&gt;)</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.Receiver.html" title="org.apache.hadoop.hdfs.protocol 中的类">DataTransferProtocol.Receiver</A> 中的方法
<DD>Abstract OP_READ_BLOCK method.
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.Sender.html#opReadBlock(java.io.DataOutputStream, org.apache.hadoop.hdfs.protocol.Block, long, long, java.lang.String, org.apache.hadoop.security.token.Token)"><B>opReadBlock(DataOutputStream, Block, long, long, String, Token&lt;BlockTokenIdentifier&gt;)</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.Sender.html" title="org.apache.hadoop.hdfs.protocol 中的类">DataTransferProtocol.Sender</A> 中的静态方法
<DD>Send OP_READ_BLOCK
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.Receiver.html#opReplaceBlock(java.io.DataInputStream, org.apache.hadoop.hdfs.protocol.Block, java.lang.String, org.apache.hadoop.hdfs.protocol.DatanodeInfo, org.apache.hadoop.security.token.Token)"><B>opReplaceBlock(DataInputStream, Block, String, DatanodeInfo, Token&lt;BlockTokenIdentifier&gt;)</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.Receiver.html" title="org.apache.hadoop.hdfs.protocol 中的类">DataTransferProtocol.Receiver</A> 中的方法
<DD>Abstract OP_REPLACE_BLOCK method.
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.Sender.html#opReplaceBlock(java.io.DataOutputStream, org.apache.hadoop.hdfs.protocol.Block, java.lang.String, org.apache.hadoop.hdfs.protocol.DatanodeInfo, org.apache.hadoop.security.token.Token)"><B>opReplaceBlock(DataOutputStream, Block, String, DatanodeInfo, Token&lt;BlockTokenIdentifier&gt;)</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.Sender.html" title="org.apache.hadoop.hdfs.protocol 中的类">DataTransferProtocol.Sender</A> 中的静态方法
<DD>Send OP_REPLACE_BLOCK
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.Receiver.html#opWriteBlock(java.io.DataInputStream, org.apache.hadoop.hdfs.protocol.Block, int, org.apache.hadoop.hdfs.protocol.DataTransferProtocol.BlockConstructionStage, long, long, long, java.lang.String, org.apache.hadoop.hdfs.protocol.DatanodeInfo, org.apache.hadoop.hdfs.protocol.DatanodeInfo[], org.apache.hadoop.security.token.Token)"><B>opWriteBlock(DataInputStream, Block, int, DataTransferProtocol.BlockConstructionStage, long, long, long, String, DatanodeInfo, DatanodeInfo[], Token&lt;BlockTokenIdentifier&gt;)</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.Receiver.html" title="org.apache.hadoop.hdfs.protocol 中的类">DataTransferProtocol.Receiver</A> 中的方法
<DD>Abstract OP_WRITE_BLOCK method.
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.Sender.html#opWriteBlock(java.io.DataOutputStream, org.apache.hadoop.hdfs.protocol.Block, int, org.apache.hadoop.hdfs.protocol.DataTransferProtocol.BlockConstructionStage, long, long, long, java.lang.String, org.apache.hadoop.hdfs.protocol.DatanodeInfo, org.apache.hadoop.hdfs.protocol.DatanodeInfo[], org.apache.hadoop.security.token.Token)"><B>opWriteBlock(DataOutputStream, Block, int, DataTransferProtocol.BlockConstructionStage, long, long, long, String, DatanodeInfo, DatanodeInfo[], Token&lt;BlockTokenIdentifier&gt;)</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.Sender.html" title="org.apache.hadoop.hdfs.protocol 中的类">DataTransferProtocol.Sender</A> 中的静态方法
<DD>Send OP_WRITE_BLOCK
<DT><A HREF="./org/apache/hadoop/fs/package-summary.html"><B>org.apache.hadoop.fs</B></A> - 软件包 org.apache.hadoop.fs<DD>&nbsp;<DT><A HREF="./org/apache/hadoop/hdfs/package-summary.html"><B>org.apache.hadoop.hdfs</B></A> - 软件包 org.apache.hadoop.hdfs<DD>A distributed implementation of <CODE>FileSystem</CODE>.<DT><A HREF="./org/apache/hadoop/hdfs/protocol/package-summary.html"><B>org.apache.hadoop.hdfs.protocol</B></A> - 软件包 org.apache.hadoop.hdfs.protocol<DD>&nbsp;<DT><A HREF="./org/apache/hadoop/hdfs/security/token/block/package-summary.html"><B>org.apache.hadoop.hdfs.security.token.block</B></A> - 软件包 org.apache.hadoop.hdfs.security.token.block<DD>&nbsp;<DT><A HREF="./org/apache/hadoop/hdfs/security/token/delegation/package-summary.html"><B>org.apache.hadoop.hdfs.security.token.delegation</B></A> - 软件包 org.apache.hadoop.hdfs.security.token.delegation<DD>&nbsp;<DT><A HREF="./org/apache/hadoop/hdfs/server/balancer/package-summary.html"><B>org.apache.hadoop.hdfs.server.balancer</B></A> - 软件包 org.apache.hadoop.hdfs.server.balancer<DD>&nbsp;<DT><A HREF="./org/apache/hadoop/hdfs/server/common/package-summary.html"><B>org.apache.hadoop.hdfs.server.common</B></A> - 软件包 org.apache.hadoop.hdfs.server.common<DD>&nbsp;<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/package-summary.html"><B>org.apache.hadoop.hdfs.server.datanode</B></A> - 软件包 org.apache.hadoop.hdfs.server.datanode<DD>&nbsp;<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/metrics/package-summary.html"><B>org.apache.hadoop.hdfs.server.datanode.metrics</B></A> - 软件包 org.apache.hadoop.hdfs.server.datanode.metrics<DD>&nbsp;<DT><A HREF="./org/apache/hadoop/hdfs/server/monitor/package-summary.html"><B>org.apache.hadoop.hdfs.server.monitor</B></A> - 软件包 org.apache.hadoop.hdfs.server.monitor<DD>&nbsp;<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/package-summary.html"><B>org.apache.hadoop.hdfs.server.namenode</B></A> - 软件包 org.apache.hadoop.hdfs.server.namenode<DD>&nbsp;<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/metrics/package-summary.html"><B>org.apache.hadoop.hdfs.server.namenode.metrics</B></A> - 软件包 org.apache.hadoop.hdfs.server.namenode.metrics<DD>&nbsp;<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/package-summary.html"><B>org.apache.hadoop.hdfs.server.protocol</B></A> - 软件包 org.apache.hadoop.hdfs.server.protocol<DD>&nbsp;<DT><A HREF="./org/apache/hadoop/hdfs/tools/package-summary.html"><B>org.apache.hadoop.hdfs.tools</B></A> - 软件包 org.apache.hadoop.hdfs.tools<DD>&nbsp;<DT><A HREF="./org/apache/hadoop/hdfs/tools/offlineImageViewer/package-summary.html"><B>org.apache.hadoop.hdfs.tools.offlineImageViewer</B></A> - 软件包 org.apache.hadoop.hdfs.tools.offlineImageViewer<DD>&nbsp;<DT><A HREF="./org/apache/hadoop/hdfs/util/package-summary.html"><B>org.apache.hadoop.hdfs.util</B></A> - 软件包 org.apache.hadoop.hdfs.util<DD>&nbsp;</DL>
<HR>
<A NAME="_P_"><!-- --></A><H2>
<B>P</B></H2>
<DL>
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/CancelDelegationTokenServlet.html#PATH_SPEC"><B>PATH_SPEC</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/CancelDelegationTokenServlet.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">CancelDelegationTokenServlet</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/GetDelegationTokenServlet.html#PATH_SPEC"><B>PATH_SPEC</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/GetDelegationTokenServlet.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">GetDelegationTokenServlet</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/RenewDelegationTokenServlet.html#PATH_SPEC"><B>PATH_SPEC</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/RenewDelegationTokenServlet.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">RenewDelegationTokenServlet</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/QuotaExceededException.html#pathName"><B>pathName</B></A> - 
异常 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/QuotaExceededException.html" title="org.apache.hadoop.hdfs.protocol 中的类">QuotaExceededException</A> 中的变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.PacketHeader.html#PKT_HEADER_LEN"><B>PKT_HEADER_LEN</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.PacketHeader.html" title="org.apache.hadoop.hdfs.protocol 中的类">DataTransferProtocol.PacketHeader</A> 中的静态变量
<DD>Header size for a packet
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/Storage.html#PRE_GENERATIONSTAMP_LAYOUT_VERSION"><B>PRE_GENERATIONSTAMP_LAYOUT_VERSION</B></A> - 
类 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/Storage.html" title="org.apache.hadoop.hdfs.server.common 中的类">Storage</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSClient.html#primitiveCreate(java.lang.String, org.apache.hadoop.fs.permission.FsPermission, java.util.EnumSet, boolean, short, long, org.apache.hadoop.util.Progressable, int, int)"><B>primitiveCreate(String, FsPermission, EnumSet&lt;CreateFlag&gt;, boolean, short, long, Progressable, int, int)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSClient.html" title="org.apache.hadoop.hdfs 中的类">DFSClient</A> 中的方法
<DD>Same as {<A HREF="./org/apache/hadoop/hdfs/DFSClient.html#create(java.lang.String, org.apache.hadoop.fs.permission.FsPermission, java.util.EnumSet, short, long, org.apache.hadoop.util.Progressable, int)"><CODE>DFSClient.create(String, FsPermission, EnumSet, short, long,
  Progressable, int)</CODE></A> except that the permission
   is absolute (ie has already been masked with umask.
<DT><A HREF="./org/apache/hadoop/hdfs/DistributedFileSystem.html#primitiveCreate(org.apache.hadoop.fs.Path, org.apache.hadoop.fs.permission.FsPermission, java.util.EnumSet, int, short, long, org.apache.hadoop.util.Progressable, int)"><B>primitiveCreate(Path, FsPermission, EnumSet&lt;CreateFlag&gt;, int, short, long, Progressable, int)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DistributedFileSystem.html" title="org.apache.hadoop.hdfs 中的类">DistributedFileSystem</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSClient.html#primitiveMkdir(java.lang.String, org.apache.hadoop.fs.permission.FsPermission)"><B>primitiveMkdir(String, FsPermission)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSClient.html" title="org.apache.hadoop.hdfs 中的类">DFSClient</A> 中的方法
<DD>Same {<A HREF="./org/apache/hadoop/hdfs/DFSClient.html#mkdirs(java.lang.String, org.apache.hadoop.fs.permission.FsPermission, boolean)"><CODE>DFSClient.mkdirs(String, FsPermission, boolean)</CODE></A> except
 that the permissions has already been masked against umask.
<DT><A HREF="./org/apache/hadoop/hdfs/DistributedFileSystem.html#primitiveMkdir(org.apache.hadoop.fs.Path, org.apache.hadoop.fs.permission.FsPermission)"><B>primitiveMkdir(Path, FsPermission)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DistributedFileSystem.html" title="org.apache.hadoop.hdfs 中的类">DistributedFileSystem</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/tools/JMXGet.html#printAllValues()"><B>printAllValues()</B></A> - 
类 org.apache.hadoop.hdfs.tools.<A HREF="./org/apache/hadoop/hdfs/tools/JMXGet.html" title="org.apache.hadoop.hdfs.tools 中的类">JMXGet</A> 中的方法
<DD>print all attributes' values
<DT><A HREF="./org/apache/hadoop/hdfs/util/LightWeightGSet.html#printDetails(java.io.PrintStream)"><B>printDetails(PrintStream)</B></A> - 
类 org.apache.hadoop.hdfs.util.<A HREF="./org/apache/hadoop/hdfs/util/LightWeightGSet.html" title="org.apache.hadoop.hdfs.util 中的类">LightWeightGSet</A> 中的方法
<DD>Print detailed information of this object.
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/JspHelper.html#printGotoForm(javax.servlet.jsp.JspWriter, int, java.lang.String, java.lang.String)"><B>printGotoForm(JspWriter, int, String, String)</B></A> - 
类 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/JspHelper.html" title="org.apache.hadoop.hdfs.server.common 中的类">JspHelper</A> 中的静态方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/JspHelper.html#printPathWithLinks(java.lang.String, javax.servlet.jsp.JspWriter, int, java.lang.String)"><B>printPathWithLinks(String, JspWriter, int, String)</B></A> - 
类 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/JspHelper.html" title="org.apache.hadoop.hdfs.server.common 中的类">JspHelper</A> 中的静态方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/tools/DFSAdmin.html#printTopology()"><B>printTopology()</B></A> - 
类 org.apache.hadoop.hdfs.tools.<A HREF="./org/apache/hadoop/hdfs/tools/DFSAdmin.html" title="org.apache.hadoop.hdfs.tools 中的类">DFSAdmin</A> 中的方法
<DD>Display each rack and the nodes assigned to that rack, as determined
 by the NameNode, in a hierarchical manner.
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.Receiver.html#processOp(org.apache.hadoop.hdfs.protocol.DataTransferProtocol.Op, java.io.DataInputStream)"><B>processOp(DataTransferProtocol.Op, DataInputStream)</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.Receiver.html" title="org.apache.hadoop.hdfs.protocol 中的类">DataTransferProtocol.Receiver</A> 中的方法
<DD>Process op by the corresponding method.
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/BlockManager.html#processReport(org.apache.hadoop.hdfs.server.namenode.DatanodeDescriptor, org.apache.hadoop.hdfs.protocol.BlockListAsLongs)"><B>processReport(DatanodeDescriptor, BlockListAsLongs)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/BlockManager.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">BlockManager</A> 中的方法
<DD>The given node is reporting all its blocks.
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#processReport(org.apache.hadoop.hdfs.protocol.DatanodeID, org.apache.hadoop.hdfs.protocol.BlockListAsLongs)"><B>processReport(DatanodeID, BlockListAsLongs)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FSNamesystem</A> 中的方法
<DD>The given node is reporting all its blocks.
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html#processUpgradeCommand(org.apache.hadoop.hdfs.server.protocol.UpgradeCommand)"><B>processUpgradeCommand(UpgradeCommand)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">NameNode</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/UpgradeObjectNamenode.html#processUpgradeCommand(org.apache.hadoop.hdfs.server.protocol.UpgradeCommand)"><B>processUpgradeCommand(UpgradeCommand)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/UpgradeObjectNamenode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">UpgradeObjectNamenode</A> 中的方法
<DD>Process an upgrade command.
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/DatanodeProtocol.html#processUpgradeCommand(org.apache.hadoop.hdfs.server.protocol.UpgradeCommand)"><B>processUpgradeCommand(UpgradeCommand)</B></A> - 
接口 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/DatanodeProtocol.html" title="org.apache.hadoop.hdfs.server.protocol 中的接口">DatanodeProtocol</A> 中的方法
<DD>This is a very general way to send a command to the name-node during
 distributed upgrade process.
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/HeaderBuffer.html#put(org.apache.hadoop.hdfs.server.namenode.INodeFile, byte[])"><B>put(INodeFile, byte[])</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/HeaderBuffer.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">HeaderBuffer</A> 中的方法
<DD>put the BufferData(filepath,head) into the buffer.
<DT><A HREF="./org/apache/hadoop/hdfs/util/GSet.html#put(E)"><B>put(E)</B></A> - 
接口 org.apache.hadoop.hdfs.util.<A HREF="./org/apache/hadoop/hdfs/util/GSet.html" title="org.apache.hadoop.hdfs.util 中的接口">GSet</A> 中的方法
<DD>Add/replace an element.
<DT><A HREF="./org/apache/hadoop/hdfs/util/GSetByHashMap.html#put(E)"><B>put(E)</B></A> - 
类 org.apache.hadoop.hdfs.util.<A HREF="./org/apache/hadoop/hdfs/util/GSetByHashMap.html" title="org.apache.hadoop.hdfs.util 中的类">GSetByHashMap</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/util/LightWeightGSet.html#put(E)"><B>put(E)</B></A> - 
类 org.apache.hadoop.hdfs.util.<A HREF="./org/apache/hadoop/hdfs/util/LightWeightGSet.html" title="org.apache.hadoop.hdfs.util 中的类">LightWeightGSet</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.PacketHeader.html#putInBuffer(java.nio.ByteBuffer)"><B>putInBuffer(ByteBuffer)</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.PacketHeader.html" title="org.apache.hadoop.hdfs.protocol 中的类">DataTransferProtocol.PacketHeader</A> 中的方法
<DD>Write the header into the buffer.
</DL>
<HR>
<A NAME="_Q_"><!-- --></A><H2>
<B>Q</B></H2>
<DL>
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/QuotaExceededException.html#quota"><B>quota</B></A> - 
异常 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/QuotaExceededException.html" title="org.apache.hadoop.hdfs.protocol 中的类">QuotaExceededException</A> 中的变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/FSConstants.html#QUOTA_DONT_SET"><B>QUOTA_DONT_SET</B></A> - 
接口 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/FSConstants.html" title="org.apache.hadoop.hdfs.protocol 中的接口">FSConstants</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/FSConstants.html#QUOTA_RESET"><B>QUOTA_RESET</B></A> - 
接口 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/FSConstants.html" title="org.apache.hadoop.hdfs.protocol 中的接口">FSConstants</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/QuotaExceededException.html" title="org.apache.hadoop.hdfs.protocol 中的类"><B>QuotaExceededException</B></A> - <A HREF="./org/apache/hadoop/hdfs/protocol/package-summary.html">org.apache.hadoop.hdfs.protocol</A> 中的 异常<DD>This exception is thrown when modification to HDFS results in violation
 of a directory quota.<DT><A HREF="./org/apache/hadoop/hdfs/protocol/QuotaExceededException.html#QuotaExceededException()"><B>QuotaExceededException()</B></A> - 
异常 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/QuotaExceededException.html" title="org.apache.hadoop.hdfs.protocol 中的类">QuotaExceededException</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/QuotaExceededException.html#QuotaExceededException(java.lang.String)"><B>QuotaExceededException(String)</B></A> - 
异常 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/QuotaExceededException.html" title="org.apache.hadoop.hdfs.protocol 中的类">QuotaExceededException</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/QuotaExceededException.html#QuotaExceededException(long, long)"><B>QuotaExceededException(long, long)</B></A> - 
异常 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/QuotaExceededException.html" title="org.apache.hadoop.hdfs.protocol 中的类">QuotaExceededException</A> 的构造方法
<DD>&nbsp;
</DL>
<HR>
<A NAME="_R_"><!-- --></A><H2>
<B>R</B></H2>
<DL>
<DT><A HREF="./org/apache/hadoop/hdfs/HftpFileSystem.html#ran"><B>ran</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/HftpFileSystem.html" title="org.apache.hadoop.hdfs 中的类">HftpFileSystem</A> 中的变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/CodingMatrix.html#RC"><B>RC</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/CodingMatrix.html" title="org.apache.hadoop.hdfs.protocol 中的类">CodingMatrix</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/RCRecoveryCommand.html" title="org.apache.hadoop.hdfs.server.protocol 中的类"><B>RCRecoveryCommand</B></A> - <A HREF="./org/apache/hadoop/hdfs/server/protocol/package-summary.html">org.apache.hadoop.hdfs.server.protocol</A> 中的 类<DD>This is the command to guide a datanode to recover a group of blocks in RCR
 and is based on CumulusRecoveryCommand. created at 2014-4-21. modified at<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/RCRecoveryCommand.html#RCRecoveryCommand()"><B>RCRecoveryCommand()</B></A> - 
类 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/RCRecoveryCommand.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">RCRecoveryCommand</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/RCRecoveryCommand.html#RCRecoveryCommand(int, byte, byte, org.apache.hadoop.hdfs.protocol.CodingMatrix, org.apache.hadoop.hdfs.protocol.LocatedBlock[])"><B>RCRecoveryCommand(int, byte, byte, CodingMatrix, LocatedBlock[])</B></A> - 
类 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/RCRecoveryCommand.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">RCRecoveryCommand</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/BlockReader.html#read(byte[], int, int)"><B>read(byte[], int, int)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/BlockReader.html" title="org.apache.hadoop.hdfs 中的类">BlockReader</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/BlockReader.html#read()"><B>read()</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/BlockReader.html" title="org.apache.hadoop.hdfs 中的类">BlockReader</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSInputStream.html#read()"><B>read()</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSInputStream.html" title="org.apache.hadoop.hdfs 中的类">DFSInputStream</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSInputStream.html#read(byte[], int, int)"><B>read(byte[], int, int)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSInputStream.html" title="org.apache.hadoop.hdfs 中的类">DFSInputStream</A> 中的方法
<DD>Read the entire buffer.
<DT><A HREF="./org/apache/hadoop/hdfs/DFSInputStream.html#read(long, byte[], int, int)"><B>read(long, byte[], int, int)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSInputStream.html" title="org.apache.hadoop.hdfs 中的类">DFSInputStream</A> 中的方法
<DD>Read bytes starting from the specified position.
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeInfo.html#read(java.io.DataInput)"><B>read(DataInput)</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeInfo.html" title="org.apache.hadoop.hdfs.protocol 中的类">DatanodeInfo</A> 中的静态方法
<DD>Read a DatanodeInfo
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.Op.html#read(java.io.DataInput)"><B>read(DataInput)</B></A> - 
枚举 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.Op.html" title="org.apache.hadoop.hdfs.protocol 中的枚举">DataTransferProtocol.Op</A> 中的静态方法
<DD>Read from in
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.Status.html#read(java.io.DataInput)"><B>read(DataInput)</B></A> - 
枚举 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.Status.html" title="org.apache.hadoop.hdfs.protocol 中的枚举">DataTransferProtocol.Status</A> 中的静态方法
<DD>Read from in
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/LocatedBlock.html#read(java.io.DataInput)"><B>read(DataInput)</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/LocatedBlock.html" title="org.apache.hadoop.hdfs.protocol 中的类">LocatedBlock</A> 中的静态方法
<DD>Read LocatedBlock from in.
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/LocatedBlockWithCodingFactor.html#read(java.io.DataInput)"><B>read(DataInput)</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/LocatedBlockWithCodingFactor.html" title="org.apache.hadoop.hdfs.protocol 中的类">LocatedBlockWithCodingFactor</A> 中的静态方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/HdfsConstants.ReplicaState.html#read(java.io.DataInput)"><B>read(DataInput)</B></A> - 
枚举 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/HdfsConstants.ReplicaState.html" title="org.apache.hadoop.hdfs.server.common 中的枚举">HdfsConstants.ReplicaState</A> 中的静态方法
<DD>Read from in
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/Storage.StorageDirectory.html#read()"><B>read()</B></A> - 
类 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/Storage.StorageDirectory.html" title="org.apache.hadoop.hdfs.server.common 中的类">Storage.StorageDirectory</A> 中的方法
<DD>Read version file.
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/Storage.StorageDirectory.html#read(java.io.File)"><B>read(File)</B></A> - 
类 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/Storage.StorageDirectory.html" title="org.apache.hadoop.hdfs.server.common 中的类">Storage.StorageDirectory</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeCPUStatus.html#read(java.io.DataInput)"><B>read(DataInput)</B></A> - 
类 org.apache.hadoop.hdfs.server.monitor.<A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeCPUStatus.html" title="org.apache.hadoop.hdfs.server.monitor 中的类">ServernodeCPUStatus</A> 中的静态方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeIOStatus.html#read(java.io.DataInput)"><B>read(DataInput)</B></A> - 
类 org.apache.hadoop.hdfs.server.monitor.<A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeIOStatus.html" title="org.apache.hadoop.hdfs.server.monitor 中的类">ServernodeIOStatus</A> 中的静态方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeMEMStatus.html#read(java.io.DataInput)"><B>read(DataInput)</B></A> - 
类 org.apache.hadoop.hdfs.server.monitor.<A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeMEMStatus.html" title="org.apache.hadoop.hdfs.server.monitor 中的类">ServernodeMEMStatus</A> 中的静态方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeNETStatus.html#read(java.io.DataInput)"><B>read(DataInput)</B></A> - 
类 org.apache.hadoop.hdfs.server.monitor.<A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeNETStatus.html" title="org.apache.hadoop.hdfs.server.monitor 中的类">ServernodeNETStatus</A> 中的静态方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/HdfsConstants.html#READ_TIMEOUT"><B>READ_TIMEOUT</B></A> - 
接口 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/HdfsConstants.html" title="org.apache.hadoop.hdfs.server.common 中的接口">HdfsConstants</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/HdfsConstants.html#READ_TIMEOUT_EXTENSION"><B>READ_TIMEOUT_EXTENSION</B></A> - 
接口 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/HdfsConstants.html" title="org.apache.hadoop.hdfs.server.common 中的接口">HdfsConstants</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/BlockReader.html#readAll(byte[], int, int)"><B>readAll(byte[], int, int)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/BlockReader.html" title="org.apache.hadoop.hdfs 中的类">BlockReader</A> 中的方法
<DD>kind of like readFully().
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/metrics/DataNodeMetrics.html#readBlockOp"><B>readBlockOp</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.metrics.<A HREF="./org/apache/hadoop/hdfs/server/datanode/metrics/DataNodeMetrics.html" title="org.apache.hadoop.hdfs.server.datanode.metrics 中的类">DataNodeMetrics</A> 中的变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FSImageSerialization.html#readBytes(java.io.DataInputStream)"><B>readBytes(DataInputStream)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/FSImageSerialization.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FSImageSerialization</A> 中的静态方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/BlockReader.html#readChunk(long, byte[], int, int, byte[])"><B>readChunk(long, byte[], int, int, byte[])</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/BlockReader.html" title="org.apache.hadoop.hdfs 中的类">BlockReader</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DataPool.html#readedPosition"><B>readedPosition</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DataPool.html" title="org.apache.hadoop.hdfs 中的类">DataPool</A> 中的变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/Block.html#readFields(java.io.DataInput)"><B>readFields(DataInput)</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/Block.html" title="org.apache.hadoop.hdfs.protocol 中的类">Block</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/CodingMatrix.html#readFields(java.io.DataInput)"><B>readFields(DataInput)</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/CodingMatrix.html" title="org.apache.hadoop.hdfs.protocol 中的类">CodingMatrix</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeID.html#readFields(java.io.DataInput)"><B>readFields(DataInput)</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeID.html" title="org.apache.hadoop.hdfs.protocol 中的类">DatanodeID</A> 中的方法
<DD>
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeInfo.html#readFields(java.io.DataInput)"><B>readFields(DataInput)</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeInfo.html" title="org.apache.hadoop.hdfs.protocol 中的类">DatanodeInfo</A> 中的方法
<DD>
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.PacketHeader.html#readFields(java.io.DataInput)"><B>readFields(DataInput)</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.PacketHeader.html" title="org.apache.hadoop.hdfs.protocol 中的类">DataTransferProtocol.PacketHeader</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.PacketHeader.html#readFields(java.nio.ByteBuffer)"><B>readFields(ByteBuffer)</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.PacketHeader.html" title="org.apache.hadoop.hdfs.protocol 中的类">DataTransferProtocol.PacketHeader</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.PipelineAck.html#readFields(java.io.DataInput)"><B>readFields(DataInput)</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.PipelineAck.html" title="org.apache.hadoop.hdfs.protocol 中的类">DataTransferProtocol.PipelineAck</A> 中的方法
<DD>Writable interface
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DirectoryListing.html#readFields(java.io.DataInput)"><B>readFields(DataInput)</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DirectoryListing.html" title="org.apache.hadoop.hdfs.protocol 中的类">DirectoryListing</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/HdfsFileStatus.html#readFields(java.io.DataInput)"><B>readFields(DataInput)</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/HdfsFileStatus.html" title="org.apache.hadoop.hdfs.protocol 中的类">HdfsFileStatus</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/HdfsLocatedFileStatus.html#readFields(java.io.DataInput)"><B>readFields(DataInput)</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/HdfsLocatedFileStatus.html" title="org.apache.hadoop.hdfs.protocol 中的类">HdfsLocatedFileStatus</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/LocatedBlock.html#readFields(java.io.DataInput)"><B>readFields(DataInput)</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/LocatedBlock.html" title="org.apache.hadoop.hdfs.protocol 中的类">LocatedBlock</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/LocatedBlocks.html#readFields(java.io.DataInput)"><B>readFields(DataInput)</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/LocatedBlocks.html" title="org.apache.hadoop.hdfs.protocol 中的类">LocatedBlocks</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/LocatedBlockWithCodingFactor.html#readFields(java.io.DataInput)"><B>readFields(DataInput)</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/LocatedBlockWithCodingFactor.html" title="org.apache.hadoop.hdfs.protocol 中的类">LocatedBlockWithCodingFactor</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/security/token/block/BlockTokenIdentifier.html#readFields(java.io.DataInput)"><B>readFields(DataInput)</B></A> - 
类 org.apache.hadoop.hdfs.security.token.block.<A HREF="./org/apache/hadoop/hdfs/security/token/block/BlockTokenIdentifier.html" title="org.apache.hadoop.hdfs.security.token.block 中的类">BlockTokenIdentifier</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/security/token/block/ExportedBlockKeys.html#readFields(java.io.DataInput)"><B>readFields(DataInput)</B></A> - 
类 org.apache.hadoop.hdfs.security.token.block.<A HREF="./org/apache/hadoop/hdfs/security/token/block/ExportedBlockKeys.html" title="org.apache.hadoop.hdfs.security.token.block 中的类">ExportedBlockKeys</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/StorageInfo.html#readFields(java.io.DataInput)"><B>readFields(DataInput)</B></A> - 
类 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/StorageInfo.html" title="org.apache.hadoop.hdfs.server.common 中的类">StorageInfo</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/UpgradeStatusReport.html#readFields(java.io.DataInput)"><B>readFields(DataInput)</B></A> - 
类 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/UpgradeStatusReport.html" title="org.apache.hadoop.hdfs.server.common 中的类">UpgradeStatusReport</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeCPUStatus.html#readFields(java.io.DataInput)"><B>readFields(DataInput)</B></A> - 
类 org.apache.hadoop.hdfs.server.monitor.<A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeCPUStatus.html" title="org.apache.hadoop.hdfs.server.monitor 中的类">ServernodeCPUStatus</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeIOStatus.html#readFields(java.io.DataInput)"><B>readFields(DataInput)</B></A> - 
类 org.apache.hadoop.hdfs.server.monitor.<A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeIOStatus.html" title="org.apache.hadoop.hdfs.server.monitor 中的类">ServernodeIOStatus</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeMEMStatus.html#readFields(java.io.DataInput)"><B>readFields(DataInput)</B></A> - 
类 org.apache.hadoop.hdfs.server.monitor.<A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeMEMStatus.html" title="org.apache.hadoop.hdfs.server.monitor 中的类">ServernodeMEMStatus</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeNETStatus.html#readFields(java.io.DataInput)"><B>readFields(DataInput)</B></A> - 
类 org.apache.hadoop.hdfs.server.monitor.<A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeNETStatus.html" title="org.apache.hadoop.hdfs.server.monitor 中的类">ServernodeNETStatus</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/BufferData.html#readFields(java.io.RandomAccessFile)"><B>readFields(RandomAccessFile)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/BufferData.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">BufferData</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/CheckpointSignature.html#readFields(java.io.DataInput)"><B>readFields(DataInput)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/CheckpointSignature.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">CheckpointSignature</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/BlockCommand.html#readFields(java.io.DataInput)"><B>readFields(DataInput)</B></A> - 
类 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/BlockCommand.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">BlockCommand</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/BlockRecoveryCommand.html#readFields(java.io.DataInput)"><B>readFields(DataInput)</B></A> - 
类 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/BlockRecoveryCommand.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">BlockRecoveryCommand</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/BlockRecoveryCommand.RecoveringBlock.html#readFields(java.io.DataInput)"><B>readFields(DataInput)</B></A> - 
类 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/BlockRecoveryCommand.RecoveringBlock.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">BlockRecoveryCommand.RecoveringBlock</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/BlocksWithLocations.BlockWithLocations.html#readFields(java.io.DataInput)"><B>readFields(DataInput)</B></A> - 
类 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/BlocksWithLocations.BlockWithLocations.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">BlocksWithLocations.BlockWithLocations</A> 中的方法
<DD>deserialization method
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/BlocksWithLocations.html#readFields(java.io.DataInput)"><B>readFields(DataInput)</B></A> - 
类 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/BlocksWithLocations.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">BlocksWithLocations</A> 中的方法
<DD>deserialization method
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/CheckpointCommand.html#readFields(java.io.DataInput)"><B>readFields(DataInput)</B></A> - 
类 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/CheckpointCommand.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">CheckpointCommand</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/CumulusRecoveryCommand.html#readFields(java.io.DataInput)"><B>readFields(DataInput)</B></A> - 
类 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/CumulusRecoveryCommand.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">CumulusRecoveryCommand</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/DatanodeRegistration.html#readFields(java.io.DataInput)"><B>readFields(DataInput)</B></A> - 
类 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/DatanodeRegistration.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">DatanodeRegistration</A> 中的方法
<DD>
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/KeyUpdateCommand.html#readFields(java.io.DataInput)"><B>readFields(DataInput)</B></A> - 
类 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/KeyUpdateCommand.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">KeyUpdateCommand</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/NamenodeRegistration.html#readFields(java.io.DataInput)"><B>readFields(DataInput)</B></A> - 
类 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/NamenodeRegistration.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">NamenodeRegistration</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/NamespaceInfo.html#readFields(java.io.DataInput)"><B>readFields(DataInput)</B></A> - 
类 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/NamespaceInfo.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">NamespaceInfo</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/RCRecoveryCommand.html#readFields(java.io.DataInput)"><B>readFields(DataInput)</B></A> - 
类 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/RCRecoveryCommand.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">RCRecoveryCommand</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/ReplicaRecoveryInfo.html#readFields(java.io.DataInput)"><B>readFields(DataInput)</B></A> - 
类 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/ReplicaRecoveryInfo.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">ReplicaRecoveryInfo</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/ServerCommand.html#readFields(java.io.DataInput)"><B>readFields(DataInput)</B></A> - 
类 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/ServerCommand.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">ServerCommand</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/UpgradeCommand.html#readFields(java.io.DataInput)"><B>readFields(DataInput)</B></A> - 
类 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/UpgradeCommand.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">UpgradeCommand</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/Block.html#readId(java.io.DataInput)"><B>readId(DataInput)</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/Block.html" title="org.apache.hadoop.hdfs.protocol 中的类">Block</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.Receiver.html#readOp(java.io.DataInputStream)"><B>readOp(DataInputStream)</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.Receiver.html" title="org.apache.hadoop.hdfs.protocol 中的类">DataTransferProtocol.Receiver</A> 中的方法
<DD>Read an Op.
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FSImageSerialization.html#readPathComponents(java.io.DataInputStream)"><B>readPathComponents(DataInputStream)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/FSImageSerialization.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FSImageSerialization</A> 中的静态方法
<DD>Reading the path from the image and converting it to byte[][] directly
 this saves us an array copy and conversions to and from String
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/metrics/DataNodeMetrics.html#readsFromLocalClient"><B>readsFromLocalClient</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.metrics.<A HREF="./org/apache/hadoop/hdfs/server/datanode/metrics/DataNodeMetrics.html" title="org.apache.hadoop.hdfs.server.datanode.metrics 中的类">DataNodeMetrics</A> 中的变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/metrics/DataNodeMetrics.html#readsFromRemoteClient"><B>readsFromRemoteClient</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.metrics.<A HREF="./org/apache/hadoop/hdfs/server/datanode/metrics/DataNodeMetrics.html" title="org.apache.hadoop.hdfs.server.datanode.metrics 中的类">DataNodeMetrics</A> 中的变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DeprecatedUTF8.html#readString(java.io.DataInput)"><B>readString(DataInput)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DeprecatedUTF8.html" title="org.apache.hadoop.hdfs 中的类">DeprecatedUTF8</A> 中的静态方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FSImageSerialization.html#readString(java.io.DataInputStream)"><B>readString(DataInputStream)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/FSImageSerialization.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FSImageSerialization</A> 中的静态方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDataset.html#recoverAppend(org.apache.hadoop.hdfs.protocol.Block, long, long)"><B>recoverAppend(Block, long, long)</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDataset.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">FSDataset</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.html#recoverAppend(org.apache.hadoop.hdfs.protocol.Block, long, long)"><B>recoverAppend(Block, long, long)</B></A> - 
接口 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.html" title="org.apache.hadoop.hdfs.server.datanode 中的接口">FSDatasetInterface</A> 中的方法
<DD>Recover a failed append to a finalized replica
 and returns the meta info of the replica
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/DataNode.html#recoverBlocks(java.util.Collection)"><B>recoverBlocks(Collection&lt;BlockRecoveryCommand.RecoveringBlock&gt;)</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/DataNode.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">DataNode</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDataset.html#recoverClose(org.apache.hadoop.hdfs.protocol.Block, long, long)"><B>recoverClose(Block, long, long)</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDataset.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">FSDataset</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.html#recoverClose(org.apache.hadoop.hdfs.protocol.Block, long, long)"><B>recoverClose(Block, long, long)</B></A> - 
接口 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.html" title="org.apache.hadoop.hdfs.server.datanode 中的接口">FSDatasetInterface</A> 中的方法
<DD>Recover a failed pipeline close
 It bumps the replica's generation stamp and finalize it if RBW replica
<DT><A HREF="./org/apache/hadoop/hdfs/DistributedFileSystem.html#recoverLease(org.apache.hadoop.fs.Path)"><B>recoverLease(Path)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DistributedFileSystem.html" title="org.apache.hadoop.hdfs 中的类">DistributedFileSystem</A> 中的方法
<DD>Start the lease recovery of a file
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/ClientProtocol.html#recoverLease(java.lang.String, java.lang.String)"><B>recoverLease(String, String)</B></A> - 
接口 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/ClientProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的接口">ClientProtocol</A> 中的方法
<DD>Start lease recovery.
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html#recoverLease(java.lang.String, java.lang.String)"><B>recoverLease(String, String)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">NameNode</A> 中的方法
<DD>Start lease recovery.
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDataset.html#recoverRbw(org.apache.hadoop.hdfs.protocol.Block, long, long, long)"><B>recoverRbw(Block, long, long, long)</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDataset.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">FSDataset</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.html#recoverRbw(org.apache.hadoop.hdfs.protocol.Block, long, long, long)"><B>recoverRbw(Block, long, long, long)</B></A> - 
接口 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.html" title="org.apache.hadoop.hdfs.server.datanode 中的接口">FSDatasetInterface</A> 中的方法
<DD>Recovers a RBW replica and returns the meta info of the replica
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/RecoveryInProgressException.html" title="org.apache.hadoop.hdfs.protocol 中的类"><B>RecoveryInProgressException</B></A> - <A HREF="./org/apache/hadoop/hdfs/protocol/package-summary.html">org.apache.hadoop.hdfs.protocol</A> 中的 异常<DD>Exception indicating that a replica is already being recovery.<DT><A HREF="./org/apache/hadoop/hdfs/protocol/RecoveryInProgressException.html#RecoveryInProgressException(java.lang.String)"><B>RecoveryInProgressException(String)</B></A> - 
异常 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/RecoveryInProgressException.html" title="org.apache.hadoop.hdfs.protocol 中的类">RecoveryInProgressException</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSClient.html#refreshNodes()"><B>refreshNodes()</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSClient.html" title="org.apache.hadoop.hdfs 中的类">DFSClient</A> 中的方法
<DD>Refresh the hosts and exclude files.
<DT><A HREF="./org/apache/hadoop/hdfs/DistributedFileSystem.html#refreshNodes()"><B>refreshNodes()</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DistributedFileSystem.html" title="org.apache.hadoop.hdfs 中的类">DistributedFileSystem</A> 中的方法
<DD>Refreshes the list of hosts and excluded hosts from the configured 
 files.
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/ClientProtocol.html#refreshNodes()"><B>refreshNodes()</B></A> - 
接口 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/ClientProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的接口">ClientProtocol</A> 中的方法
<DD>Tells the namenode to reread the hosts and exclude files.
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#refreshNodes(org.apache.hadoop.conf.Configuration)"><B>refreshNodes(Configuration)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FSNamesystem</A> 中的方法
<DD>Rereads the config to get hosts and exclude list file names.
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html#refreshNodes()"><B>refreshNodes()</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">NameNode</A> 中的方法
<DD>Refresh the list of datanodes that the namenode should allow to  
 connect.
<DT><A HREF="./org/apache/hadoop/hdfs/tools/DFSAdmin.html#refreshNodes()"><B>refreshNodes()</B></A> - 
类 org.apache.hadoop.hdfs.tools.<A HREF="./org/apache/hadoop/hdfs/tools/DFSAdmin.html" title="org.apache.hadoop.hdfs.tools 中的类">DFSAdmin</A> 中的方法
<DD>Command to ask the namenode to reread the hosts and excluded hosts 
 file.
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html#refreshServiceAcl()"><B>refreshServiceAcl()</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">NameNode</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/tools/DFSAdmin.html#refreshServiceAcl()"><B>refreshServiceAcl()</B></A> - 
类 org.apache.hadoop.hdfs.tools.<A HREF="./org/apache/hadoop/hdfs/tools/DFSAdmin.html" title="org.apache.hadoop.hdfs.tools 中的类">DFSAdmin</A> 中的方法
<DD>Refresh the authorization policy on the <A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类"><CODE>NameNode</CODE></A>.
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html#refreshSuperUserGroupsConfiguration()"><B>refreshSuperUserGroupsConfiguration()</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">NameNode</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/tools/DFSAdmin.html#refreshSuperUserGroupsConfiguration()"><B>refreshSuperUserGroupsConfiguration()</B></A> - 
类 org.apache.hadoop.hdfs.tools.<A HREF="./org/apache/hadoop/hdfs/tools/DFSAdmin.html" title="org.apache.hadoop.hdfs.tools 中的类">DFSAdmin</A> 中的方法
<DD>refreshSuperUserGroupsConfiguration <A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类"><CODE>NameNode</CODE></A>.
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html#refreshUserToGroupsMappings()"><B>refreshUserToGroupsMappings()</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">NameNode</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/tools/DFSAdmin.html#refreshUserToGroupsMappings()"><B>refreshUserToGroupsMappings()</B></A> - 
类 org.apache.hadoop.hdfs.tools.<A HREF="./org/apache/hadoop/hdfs/tools/DFSAdmin.html" title="org.apache.hadoop.hdfs.tools 中的类">DFSAdmin</A> 中的方法
<DD>Refresh the user-to-groups mappings on the <A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类"><CODE>NameNode</CODE></A>.
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/RegeneratingCodeMatrix.html" title="org.apache.hadoop.hdfs.protocol 中的类"><B>RegeneratingCodeMatrix</B></A> - <A HREF="./org/apache/hadoop/hdfs/protocol/package-summary.html">org.apache.hadoop.hdfs.protocol</A> 中的 类<DD>This class is a copy of XORCoderPrptocol, to carry the regenerating code matrix. created at 2014-4-12. modified at
 2014-4-23<DT><A HREF="./org/apache/hadoop/hdfs/protocol/RegeneratingCodeMatrix.html#RegeneratingCodeMatrix()"><B>RegeneratingCodeMatrix()</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/RegeneratingCodeMatrix.html" title="org.apache.hadoop.hdfs.protocol 中的类">RegeneratingCodeMatrix</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/RegeneratingCodeMatrix.html#RegeneratingCodeMatrix(long)"><B>RegeneratingCodeMatrix(long)</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/RegeneratingCodeMatrix.html" title="org.apache.hadoop.hdfs.protocol 中的类">RegeneratingCodeMatrix</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/RegeneratingCodeMatrix.html#RegeneratingCodeMatrix(byte, byte)"><B>RegeneratingCodeMatrix(byte, byte)</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/RegeneratingCodeMatrix.html" title="org.apache.hadoop.hdfs.protocol 中的类">RegeneratingCodeMatrix</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/BackupNode.html#register(org.apache.hadoop.hdfs.server.protocol.NamenodeRegistration)"><B>register(NamenodeRegistration)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/BackupNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">BackupNode</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html#register(org.apache.hadoop.hdfs.server.protocol.NamenodeRegistration)"><B>register(NamenodeRegistration)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">NameNode</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/DatanodeCommand.html#REGISTER"><B>REGISTER</B></A> - 
类 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/DatanodeCommand.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">DatanodeCommand</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/NamenodeProtocol.html#register(org.apache.hadoop.hdfs.server.protocol.NamenodeRegistration)"><B>register(NamenodeRegistration)</B></A> - 
接口 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/NamenodeProtocol.html" title="org.apache.hadoop.hdfs.server.protocol 中的接口">NamenodeProtocol</A> 中的方法
<DD>Register a subordinate name-node like backup node.
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#registerDatanode(org.apache.hadoop.hdfs.server.protocol.DatanodeRegistration)"><B>registerDatanode(DatanodeRegistration)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FSNamesystem</A> 中的方法
<DD>Register Datanode.
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html#registerDatanode(org.apache.hadoop.hdfs.server.protocol.DatanodeRegistration)"><B>registerDatanode(DatanodeRegistration)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">NameNode</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/DatanodeProtocol.html#registerDatanode(org.apache.hadoop.hdfs.server.protocol.DatanodeRegistration)"><B>registerDatanode(DatanodeRegistration)</B></A> - 
接口 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/DatanodeProtocol.html" title="org.apache.hadoop.hdfs.server.protocol 中的接口">DatanodeProtocol</A> 中的方法
<DD>Register Datanode.
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeID.html#registerTime"><B>registerTime</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeID.html" title="org.apache.hadoop.hdfs.protocol 中的类">DatanodeID</A> 中的变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/metrics/DataNodeMetrics.html#registry"><B>registry</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.metrics.<A HREF="./org/apache/hadoop/hdfs/server/datanode/metrics/DataNodeMetrics.html" title="org.apache.hadoop.hdfs.server.datanode.metrics 中的类">DataNodeMetrics</A> 中的变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/metrics/NameNodeMetrics.html#registry"><B>registry</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.metrics.<A HREF="./org/apache/hadoop/hdfs/server/namenode/metrics/NameNodeMetrics.html" title="org.apache.hadoop.hdfs.server.namenode.metrics 中的类">NameNodeMetrics</A> 中的变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeInfo.html#remaining"><B>remaining</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeInfo.html" title="org.apache.hadoop.hdfs.protocol 中的类">DatanodeInfo</A> 中的变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/BlockListAsLongs.BlockReportIterator.html#remove()"><B>remove()</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/BlockListAsLongs.BlockReportIterator.html" title="org.apache.hadoop.hdfs.protocol 中的类">BlockListAsLongs.BlockReportIterator</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/HeaderBuffer.html#remove(org.apache.hadoop.hdfs.server.namenode.INodeFile)"><B>remove(INodeFile)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/HeaderBuffer.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">HeaderBuffer</A> 中的方法
<DD>remove the BufferData from the buffer
<DT><A HREF="./org/apache/hadoop/hdfs/util/GSet.html#remove(K)"><B>remove(K)</B></A> - 
接口 org.apache.hadoop.hdfs.util.<A HREF="./org/apache/hadoop/hdfs/util/GSet.html" title="org.apache.hadoop.hdfs.util 中的接口">GSet</A> 中的方法
<DD>Remove the element corresponding to the given key.
<DT><A HREF="./org/apache/hadoop/hdfs/util/GSetByHashMap.html#remove(K)"><B>remove(K)</B></A> - 
类 org.apache.hadoop.hdfs.util.<A HREF="./org/apache/hadoop/hdfs/util/GSetByHashMap.html" title="org.apache.hadoop.hdfs.util 中的类">GSetByHashMap</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/util/LightWeightGSet.html#remove(K)"><B>remove(K)</B></A> - 
类 org.apache.hadoop.hdfs.util.<A HREF="./org/apache/hadoop/hdfs/util/LightWeightGSet.html" title="org.apache.hadoop.hdfs.util 中的类">LightWeightGSet</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#removeDatanode(org.apache.hadoop.hdfs.protocol.DatanodeID)"><B>removeDatanode(DatanodeID)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FSNamesystem</A> 中的方法
<DD>Remove a datanode descriptor.
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FSImage.html#removedStorageDirs"><B>removedStorageDirs</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/FSImage.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FSImage</A> 中的变量
<DD>list of failed (and thus removed) storages
<DT><A HREF="./org/apache/hadoop/hdfs/DFSClient.html#rename(java.lang.String, java.lang.String)"><B>rename(String, String)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSClient.html" title="org.apache.hadoop.hdfs 中的类">DFSClient</A> 中的方法
<DD><B>已过时。</B>&nbsp;<I>Use <A HREF="./org/apache/hadoop/hdfs/DFSClient.html#rename(java.lang.String, java.lang.String, org.apache.hadoop.fs.Options.Rename...)"><CODE>DFSClient.rename(String, String, Options.Rename...)</CODE></A> instead.</I>
<DT><A HREF="./org/apache/hadoop/hdfs/DFSClient.html#rename(java.lang.String, java.lang.String, org.apache.hadoop.fs.Options.Rename...)"><B>rename(String, String, Options.Rename...)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSClient.html" title="org.apache.hadoop.hdfs 中的类">DFSClient</A> 中的方法
<DD>Rename file or directory.
<DT><A HREF="./org/apache/hadoop/hdfs/DistributedFileSystem.html#rename(org.apache.hadoop.fs.Path, org.apache.hadoop.fs.Path)"><B>rename(Path, Path)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DistributedFileSystem.html" title="org.apache.hadoop.hdfs 中的类">DistributedFileSystem</A> 中的方法
<DD>
<DT><A HREF="./org/apache/hadoop/hdfs/DistributedFileSystem.html#rename(org.apache.hadoop.fs.Path, org.apache.hadoop.fs.Path, org.apache.hadoop.fs.Options.Rename...)"><B>rename(Path, Path, Options.Rename...)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DistributedFileSystem.html" title="org.apache.hadoop.hdfs 中的类">DistributedFileSystem</A> 中的方法
<DD>
 This rename operation is guaranteed to be atomic.
<DT><A HREF="./org/apache/hadoop/hdfs/HftpFileSystem.html#rename(org.apache.hadoop.fs.Path, org.apache.hadoop.fs.Path)"><B>rename(Path, Path)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/HftpFileSystem.html" title="org.apache.hadoop.hdfs 中的类">HftpFileSystem</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/ClientProtocol.html#rename(java.lang.String, java.lang.String)"><B>rename(String, String)</B></A> - 
接口 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/ClientProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的接口">ClientProtocol</A> 中的方法
<DD><B>已过时。</B>&nbsp;<I>Use <A HREF="./org/apache/hadoop/hdfs/protocol/ClientProtocol.html#rename(java.lang.String, java.lang.String, org.apache.hadoop.fs.Options.Rename...)"><CODE>ClientProtocol.rename(String, String, Options.Rename...)</CODE></A> instead.</I>
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/ClientProtocol.html#rename(java.lang.String, java.lang.String, org.apache.hadoop.fs.Options.Rename...)"><B>rename(String, String, Options.Rename...)</B></A> - 
接口 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/ClientProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的接口">ClientProtocol</A> 中的方法
<DD>Rename src to dst.
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/Storage.html#rename(java.io.File, java.io.File)"><B>rename(File, File)</B></A> - 
类 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/Storage.html" title="org.apache.hadoop.hdfs.server.common 中的类">Storage</A> 中的静态方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html#rename(java.lang.String, java.lang.String)"><B>rename(String, String)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">NameNode</A> 中的方法
<DD><B>已过时。</B>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html#rename(java.lang.String, java.lang.String, org.apache.hadoop.fs.Options.Rename...)"><B>rename(String, String, Options.Rename...)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">NameNode</A> 中的方法
<DD>Rename src to dst.
<DT><A HREF="./org/apache/hadoop/fs/Hdfs.html#renameInternal(org.apache.hadoop.fs.Path, org.apache.hadoop.fs.Path)"><B>renameInternal(Path, Path)</B></A> - 
类 org.apache.hadoop.fs.<A HREF="./org/apache/hadoop/fs/Hdfs.html" title="org.apache.hadoop.fs 中的类">Hdfs</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/fs/Hdfs.html#renameInternal(org.apache.hadoop.fs.Path, org.apache.hadoop.fs.Path, boolean)"><B>renameInternal(Path, Path, boolean)</B></A> - 
类 org.apache.hadoop.fs.<A HREF="./org/apache/hadoop/fs/Hdfs.html" title="org.apache.hadoop.fs 中的类">Hdfs</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSClient.html#renewDelegationToken(org.apache.hadoop.security.token.Token)"><B>renewDelegationToken(Token&lt;DelegationTokenIdentifier&gt;)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSClient.html" title="org.apache.hadoop.hdfs 中的类">DFSClient</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DistributedFileSystem.html#renewDelegationToken(org.apache.hadoop.security.token.Token)"><B>renewDelegationToken(Token&lt;DelegationTokenIdentifier&gt;)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DistributedFileSystem.html" title="org.apache.hadoop.hdfs 中的类">DistributedFileSystem</A> 中的方法
<DD>Renew an existing delegation token.
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/ClientProtocol.html#renewDelegationToken(org.apache.hadoop.security.token.Token)"><B>renewDelegationToken(Token&lt;DelegationTokenIdentifier&gt;)</B></A> - 
接口 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/ClientProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的接口">ClientProtocol</A> 中的方法
<DD>Renew an existing delegation token.
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#renewDelegationToken(org.apache.hadoop.security.token.Token)"><B>renewDelegationToken(Token&lt;DelegationTokenIdentifier&gt;)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FSNamesystem</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html#renewDelegationToken(org.apache.hadoop.security.token.Token)"><B>renewDelegationToken(Token&lt;DelegationTokenIdentifier&gt;)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">NameNode</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/tools/DelegationTokenFetcher.html#renewDelegationToken(java.lang.String, org.apache.hadoop.security.token.Token)"><B>renewDelegationToken(String, Token&lt;DelegationTokenIdentifier&gt;)</B></A> - 
类 org.apache.hadoop.hdfs.tools.<A HREF="./org/apache/hadoop/hdfs/tools/DelegationTokenFetcher.html" title="org.apache.hadoop.hdfs.tools 中的类">DelegationTokenFetcher</A> 中的静态方法
<DD>Renew a Delegation Token.
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/RenewDelegationTokenServlet.html" title="org.apache.hadoop.hdfs.server.namenode 中的类"><B>RenewDelegationTokenServlet</B></A> - <A HREF="./org/apache/hadoop/hdfs/server/namenode/package-summary.html">org.apache.hadoop.hdfs.server.namenode</A> 中的 类<DD>Renew delegation tokens over http for use in hftp.<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/RenewDelegationTokenServlet.html#RenewDelegationTokenServlet()"><B>RenewDelegationTokenServlet()</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/RenewDelegationTokenServlet.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">RenewDelegationTokenServlet</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/GetDelegationTokenServlet.html#RENEWER"><B>RENEWER</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/GetDelegationTokenServlet.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">GetDelegationTokenServlet</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/ClientProtocol.html#renewLease(java.lang.String)"><B>renewLease(String)</B></A> - 
接口 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/ClientProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的接口">ClientProtocol</A> 中的方法
<DD>Client programs can cause stateful changes in the NameNode
 that affect other clients.
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html#renewLease(java.lang.String)"><B>renewLease(String)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">NameNode</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/metrics/DataNodeMetrics.html#replaceBlockOp"><B>replaceBlockOp</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.metrics.<A HREF="./org/apache/hadoop/hdfs/server/datanode/metrics/DataNodeMetrics.html" title="org.apache.hadoop.hdfs.server.datanode.metrics 中的类">DataNodeMetrics</A> 中的变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/Replica.html" title="org.apache.hadoop.hdfs.server.datanode 中的接口"><B>Replica</B></A> - <A HREF="./org/apache/hadoop/hdfs/server/datanode/package-summary.html">org.apache.hadoop.hdfs.server.datanode</A> 中的 接口<DD>This represents block replicas which are stored in DataNode.<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/ReplicaInfo.html" title="org.apache.hadoop.hdfs.server.datanode 中的类"><B>ReplicaInfo</B></A> - <A HREF="./org/apache/hadoop/hdfs/server/datanode/package-summary.html">org.apache.hadoop.hdfs.server.datanode</A> 中的 类<DD>This class is used by datanodes to maintain meta data of its replicas.<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/ReplicaNotFoundException.html" title="org.apache.hadoop.hdfs.server.datanode 中的类"><B>ReplicaNotFoundException</B></A> - <A HREF="./org/apache/hadoop/hdfs/server/datanode/package-summary.html">org.apache.hadoop.hdfs.server.datanode</A> 中的 异常<DD>Exception indicating that DataNode does not have a replica
 that matches the target block.<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/ReplicaNotFoundException.html#ReplicaNotFoundException()"><B>ReplicaNotFoundException()</B></A> - 
异常 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/ReplicaNotFoundException.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">ReplicaNotFoundException</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/ReplicaNotFoundException.html#ReplicaNotFoundException(java.lang.String)"><B>ReplicaNotFoundException(String)</B></A> - 
异常 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/ReplicaNotFoundException.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">ReplicaNotFoundException</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/ReplicaRecoveryInfo.html" title="org.apache.hadoop.hdfs.server.protocol 中的类"><B>ReplicaRecoveryInfo</B></A> - <A HREF="./org/apache/hadoop/hdfs/server/protocol/package-summary.html">org.apache.hadoop.hdfs.server.protocol</A> 中的 类<DD>Replica recovery information.<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/ReplicaRecoveryInfo.html#ReplicaRecoveryInfo()"><B>ReplicaRecoveryInfo()</B></A> - 
类 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/ReplicaRecoveryInfo.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">ReplicaRecoveryInfo</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/ReplicaRecoveryInfo.html#ReplicaRecoveryInfo(long, long, long, org.apache.hadoop.hdfs.server.common.HdfsConstants.ReplicaState)"><B>ReplicaRecoveryInfo(long, long, long, HdfsConstants.ReplicaState)</B></A> - 
类 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/ReplicaRecoveryInfo.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">ReplicaRecoveryInfo</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#replthread"><B>replthread</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FSNamesystem</A> 中的变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/tools/DFSAdmin.html#report()"><B>report()</B></A> - 
类 org.apache.hadoop.hdfs.tools.<A HREF="./org/apache/hadoop/hdfs/tools/DFSAdmin.html" title="org.apache.hadoop.hdfs.tools 中的类">DFSAdmin</A> 中的方法
<DD>Gives a report on how the FileSystem is doing.
<DT><A HREF="./org/apache/hadoop/hdfs/DFSClient.html#reportBadBlocks(org.apache.hadoop.hdfs.protocol.LocatedBlock[])"><B>reportBadBlocks(LocatedBlock[])</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSClient.html" title="org.apache.hadoop.hdfs 中的类">DFSClient</A> 中的方法
<DD>Report corrupt blocks that were discovered by the client.
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/ClientProtocol.html#reportBadBlocks(org.apache.hadoop.hdfs.protocol.LocatedBlock[])"><B>reportBadBlocks(LocatedBlock[])</B></A> - 
接口 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/ClientProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的接口">ClientProtocol</A> 中的方法
<DD>The client wants to report corrupted blocks (blocks with specified
 locations on datanodes).
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html#reportBadBlocks(org.apache.hadoop.hdfs.protocol.LocatedBlock[])"><B>reportBadBlocks(LocatedBlock[])</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">NameNode</A> 中的方法
<DD>The client has detected an error on the specified located blocks 
 and is reporting them to the server.
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/DatanodeProtocol.html#reportBadBlocks(org.apache.hadoop.hdfs.protocol.LocatedBlock[])"><B>reportBadBlocks(LocatedBlock[])</B></A> - 
接口 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/DatanodeProtocol.html" title="org.apache.hadoop.hdfs.server.protocol 中的接口">DatanodeProtocol</A> 中的方法
<DD>same as <A HREF="./org/apache/hadoop/hdfs/protocol/ClientProtocol.html#reportBadBlocks(org.apache.hadoop.hdfs.protocol.LocatedBlock[])"><CODE>ClientProtocol.reportBadBlocks(LocatedBlock[])</CODE></A>
 }
<DT><A HREF="./org/apache/hadoop/hdfs/DistributedFileSystem.html#reportChecksumFailure(org.apache.hadoop.fs.Path, org.apache.hadoop.fs.FSDataInputStream, long, org.apache.hadoop.fs.FSDataInputStream, long)"><B>reportChecksumFailure(Path, FSDataInputStream, long, FSDataInputStream, long)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DistributedFileSystem.html" title="org.apache.hadoop.hdfs 中的类">DistributedFileSystem</A> 中的方法
<DD>We need to find the blocks that didn't match.
<DT><A HREF="./org/apache/hadoop/hdfs/DFSInputStream.html#reset()"><B>reset()</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSInputStream.html" title="org.apache.hadoop.hdfs 中的类">DFSInputStream</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/metrics/DataNodeMetrics.html#resetAllMinMax()"><B>resetAllMinMax()</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.metrics.<A HREF="./org/apache/hadoop/hdfs/server/datanode/metrics/DataNodeMetrics.html" title="org.apache.hadoop.hdfs.server.datanode.metrics 中的类">DataNodeMetrics</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/metrics/NameNodeMetrics.html#resetAllMinMax()"><B>resetAllMinMax()</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.metrics.<A HREF="./org/apache/hadoop/hdfs/server/namenode/metrics/NameNodeMetrics.html" title="org.apache.hadoop.hdfs.server.namenode.metrics 中的类">NameNodeMetrics</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DistributedFileSystem.html#restoreFailedStorage(java.lang.String)"><B>restoreFailedStorage(String)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DistributedFileSystem.html" title="org.apache.hadoop.hdfs 中的类">DistributedFileSystem</A> 中的方法
<DD>enable/disable/check restoreFaileStorage
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/ClientProtocol.html#restoreFailedStorage(java.lang.String)"><B>restoreFailedStorage(String)</B></A> - 
接口 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/ClientProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的接口">ClientProtocol</A> 中的方法
<DD>Enable/Disable restore failed storage.
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html#restoreFailedStorage(java.lang.String)"><B>restoreFailedStorage(String)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">NameNode</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/tools/DFSAdmin.html#restoreFaileStorage(java.lang.String)"><B>restoreFaileStorage(String)</B></A> - 
类 org.apache.hadoop.hdfs.tools.<A HREF="./org/apache/hadoop/hdfs/tools/DFSAdmin.html" title="org.apache.hadoop.hdfs.tools 中的类">DFSAdmin</A> 中的方法
<DD>Command to enable/disable/check restoring of failed storage replicas in the namenode.
<DT><A HREF="./org/apache/hadoop/hdfs/security/token/block/BlockTokenSecretManager.html#retrievePassword(org.apache.hadoop.hdfs.security.token.block.BlockTokenIdentifier)"><B>retrievePassword(BlockTokenIdentifier)</B></A> - 
类 org.apache.hadoop.hdfs.security.token.block.<A HREF="./org/apache/hadoop/hdfs/security/token/block/BlockTokenSecretManager.html" title="org.apache.hadoop.hdfs.security.token.block 中的类">BlockTokenSecretManager</A> 中的方法
<DD>Look up the token password/secret for the given block token identifier.
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html#role"><B>role</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">NameNode</A> 中的变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html#rollEditLog()"><B>rollEditLog()</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">NameNode</A> 中的方法
<DD><B>已过时。</B>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/NamenodeProtocol.html#rollEditLog()"><B>rollEditLog()</B></A> - 
接口 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/NamenodeProtocol.html" title="org.apache.hadoop.hdfs.server.protocol 中的接口">NamenodeProtocol</A> 中的方法
<DD><B>已过时。</B>&nbsp;<I>See <A HREF="./org/apache/hadoop/hdfs/server/namenode/SecondaryNameNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类"><CODE>SecondaryNameNode</CODE></A></I>
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html#rollFsImage(org.apache.hadoop.hdfs.server.namenode.CheckpointSignature)"><B>rollFsImage(CheckpointSignature)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">NameNode</A> 中的方法
<DD><B>已过时。</B>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/NamenodeProtocol.html#rollFsImage(org.apache.hadoop.hdfs.server.namenode.CheckpointSignature)"><B>rollFsImage(CheckpointSignature)</B></A> - 
接口 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/NamenodeProtocol.html" title="org.apache.hadoop.hdfs.server.protocol 中的接口">NamenodeProtocol</A> 中的方法
<DD><B>已过时。</B>&nbsp;<I>See <A HREF="./org/apache/hadoop/hdfs/server/namenode/SecondaryNameNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类"><CODE>SecondaryNameNode</CODE></A></I>
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html#rpcAddress"><B>rpcAddress</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">NameNode</A> 中的变量
<DD>RPC server address
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/CodingMatrix.html#RS"><B>RS</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/CodingMatrix.html" title="org.apache.hadoop.hdfs.protocol 中的类">CodingMatrix</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/RSCoderProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的类"><B>RSCoderProtocol</B></A> - <A HREF="./org/apache/hadoop/hdfs/protocol/package-summary.html">org.apache.hadoop.hdfs.protocol</A> 中的 类<DD>&nbsp;<DT><A HREF="./org/apache/hadoop/hdfs/protocol/RSCoderProtocol.html#RSCoderProtocol(byte, byte)"><B>RSCoderProtocol(byte, byte)</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/RSCoderProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的类">RSCoderProtocol</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/balancer/Balancer.html#run(java.lang.String[])"><B>run(String[])</B></A> - 
类 org.apache.hadoop.hdfs.server.balancer.<A HREF="./org/apache/hadoop/hdfs/server/balancer/Balancer.html" title="org.apache.hadoop.hdfs.server.balancer 中的类">Balancer</A> 中的方法
<DD>main method of Balancer
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/DataNode.RCRecoveryThreadTarget.html#run()"><B>run()</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/DataNode.RCRecoveryThreadTarget.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">DataNode.RCRecoveryThreadTarget</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/DataNode.html#run()"><B>run()</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/DataNode.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">DataNode</A> 中的方法
<DD>No matter what kind of exception we get, keep retrying to offerService().
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/UpgradeObjectDatanode.html#run()"><B>run()</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/UpgradeObjectDatanode.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">UpgradeObjectDatanode</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/SecondaryNameNode.html#run()"><B>run()</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/SecondaryNameNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">SecondaryNameNode</A> 中的方法
<DD><B>已过时。</B>&nbsp;&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/tools/DFSAdmin.html#run(java.lang.String[])"><B>run(String[])</B></A> - 
类 org.apache.hadoop.hdfs.tools.<A HREF="./org/apache/hadoop/hdfs/tools/DFSAdmin.html" title="org.apache.hadoop.hdfs.tools 中的类">DFSAdmin</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/tools/DFSck.html#run(java.lang.String[])"><B>run(String[])</B></A> - 
类 org.apache.hadoop.hdfs.tools.<A HREF="./org/apache/hadoop/hdfs/tools/DFSck.html" title="org.apache.hadoop.hdfs.tools 中的类">DFSck</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/DataNode.html#runDatanodeDaemon(org.apache.hadoop.hdfs.server.datanode.DataNode)"><B>runDatanodeDaemon(DataNode)</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/DataNode.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">DataNode</A> 中的静态方法
<DD>Start a single datanode daemon and wait for it to finish.
</DL>
<HR>
<A NAME="_S_"><!-- --></A><H2>
<B>S</B></H2>
<DL>
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/SafeModeException.html" title="org.apache.hadoop.hdfs.server.namenode 中的类"><B>SafeModeException</B></A> - <A HREF="./org/apache/hadoop/hdfs/server/namenode/package-summary.html">org.apache.hadoop.hdfs.server.namenode</A> 中的 异常<DD>This exception is thrown when the name node is in safe mode.<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/SafeModeException.html#SafeModeException()"><B>SafeModeException()</B></A> - 
异常 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/SafeModeException.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">SafeModeException</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/SafeModeException.html#SafeModeException(java.lang.String, org.apache.hadoop.hdfs.server.namenode.FSNamesystem.SafeModeInfo)"><B>SafeModeException(String, FSNamesystem.SafeModeInfo)</B></A> - 
异常 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/SafeModeException.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">SafeModeException</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/metrics/NameNodeMetrics.html#safeModeTime"><B>safeModeTime</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.metrics.<A HREF="./org/apache/hadoop/hdfs/server/namenode/metrics/NameNodeMetrics.html" title="org.apache.hadoop.hdfs.server.namenode.metrics 中的类">NameNodeMetrics</A> 中的变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.PacketHeader.html#sanityCheck(long)"><B>sanityCheck(long)</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.PacketHeader.html" title="org.apache.hadoop.hdfs.protocol 中的类">DataTransferProtocol.PacketHeader</A> 中的方法
<DD>Perform a sanity check on the packet, returning true if it is sane.
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FSImage.html#saveCurrent(org.apache.hadoop.hdfs.server.common.Storage.StorageDirectory)"><B>saveCurrent(Storage.StorageDirectory)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/FSImage.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FSImage</A> 中的方法
<DD>Save current image and empty journal into <code>current</code> directory.
<DT><A HREF="./org/apache/hadoop/hdfs/DistributedFileSystem.html#saveNamespace()"><B>saveNamespace()</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DistributedFileSystem.html" title="org.apache.hadoop.hdfs 中的类">DistributedFileSystem</A> 中的方法
<DD>Save namespace image.
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/ClientProtocol.html#saveNamespace()"><B>saveNamespace()</B></A> - 
接口 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/ClientProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的接口">ClientProtocol</A> 中的方法
<DD>Save namespace image.
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html#saveNamespace()"><B>saveNamespace()</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">NameNode</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/tools/DFSAdmin.html#saveNamespace()"><B>saveNamespace()</B></A> - 
类 org.apache.hadoop.hdfs.tools.<A HREF="./org/apache/hadoop/hdfs/tools/DFSAdmin.html" title="org.apache.hadoop.hdfs.tools 中的类">DFSAdmin</A> 中的方法
<DD>Command to ask the namenode to save the namespace.
<DT><A HREF="./org/apache/hadoop/hdfs/security/token/delegation/DelegationTokenSecretManager.html#saveSecretManagerState(java.io.DataOutputStream)"><B>saveSecretManagerState(DataOutputStream)</B></A> - 
类 org.apache.hadoop.hdfs.security.token.delegation.<A HREF="./org/apache/hadoop/hdfs/security/token/delegation/DelegationTokenSecretManager.html" title="org.apache.hadoop.hdfs.security.token.delegation 中的类">DelegationTokenSecretManager</A> 中的方法
<DD>Store the current state of the SecretManager for persistence
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/DataNode.html#scheduleBlockReport(long)"><B>scheduleBlockReport(long)</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/DataNode.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">DataNode</A> 中的方法
<DD>This methods  arranges for the data node to send the block report at the next heartbeat.
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/SecondaryNameNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类"><B>SecondaryNameNode</B></A> - <A HREF="./org/apache/hadoop/hdfs/server/namenode/package-summary.html">org.apache.hadoop.hdfs.server.namenode</A> 中的 类<DD><B>已过时。</B>&nbsp;<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/SecondaryNameNode.html#SecondaryNameNode(org.apache.hadoop.conf.Configuration)"><B>SecondaryNameNode(Configuration)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/SecondaryNameNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">SecondaryNameNode</A> 的构造方法
<DD><B>已过时。</B>&nbsp;Create a connection to the primary namenode.
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/SecureDataNodeStarter.html" title="org.apache.hadoop.hdfs.server.datanode 中的类"><B>SecureDataNodeStarter</B></A> - <A HREF="./org/apache/hadoop/hdfs/server/datanode/package-summary.html">org.apache.hadoop.hdfs.server.datanode</A> 中的 类<DD>Utility class to start a datanode in a secure cluster, first obtaining 
 privileged resources before main startup and handing them to the datanode.<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/SecureDataNodeStarter.html#SecureDataNodeStarter()"><B>SecureDataNodeStarter()</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/SecureDataNodeStarter.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">SecureDataNodeStarter</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/SecureDataNodeStarter.SecureResources.html" title="org.apache.hadoop.hdfs.server.datanode 中的类"><B>SecureDataNodeStarter.SecureResources</B></A> - <A HREF="./org/apache/hadoop/hdfs/server/datanode/package-summary.html">org.apache.hadoop.hdfs.server.datanode</A> 中的 类<DD>Stash necessary resources needed for datanode operation in a secure env.<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/SecureDataNodeStarter.SecureResources.html#SecureDataNodeStarter.SecureResources(java.net.ServerSocket, org.mortbay.jetty.nio.SelectChannelConnector)"><B>SecureDataNodeStarter.SecureResources(ServerSocket, SelectChannelConnector)</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/SecureDataNodeStarter.SecureResources.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">SecureDataNodeStarter.SecureResources</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/DataNode.html#secureMain(java.lang.String[], org.apache.hadoop.hdfs.server.datanode.SecureDataNodeStarter.SecureResources)"><B>secureMain(String[], SecureDataNodeStarter.SecureResources)</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/DataNode.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">DataNode</A> 中的静态方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/BlockReader.html#seek(long)"><B>seek(long)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/BlockReader.html" title="org.apache.hadoop.hdfs 中的类">BlockReader</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSInputStream.html#seek(long)"><B>seek(long)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSInputStream.html" title="org.apache.hadoop.hdfs 中的类">DFSInputStream</A> 中的方法
<DD>Seek to a new arbitrary location
<DT><A HREF="./org/apache/hadoop/hdfs/DataPool.html#seekTo(long)"><B>seekTo(long)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DataPool.html" title="org.apache.hadoop.hdfs 中的类">DataPool</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/BlockReader.html#seekToNewSource(long)"><B>seekToNewSource(long)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/BlockReader.html" title="org.apache.hadoop.hdfs 中的类">BlockReader</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSInputStream.html#seekToNewSource(long)"><B>seekToNewSource(long)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSInputStream.html" title="org.apache.hadoop.hdfs 中的类">DFSInputStream</A> 中的方法
<DD>Seek to given position on a node other than the current node.
<DT><A HREF="./org/apache/hadoop/hdfs/security/token/block/BlockTokenSelector.html#selectToken(org.apache.hadoop.io.Text, java.util.Collection)"><B>selectToken(Text, Collection&lt;Token&lt;? extends TokenIdentifier&gt;&gt;)</B></A> - 
类 org.apache.hadoop.hdfs.security.token.block.<A HREF="./org/apache/hadoop/hdfs/security/token/block/BlockTokenSelector.html" title="org.apache.hadoop.hdfs.security.token.block 中的类">BlockTokenSelector</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html#sendHeartbeat(org.apache.hadoop.hdfs.server.protocol.DatanodeRegistration, long, long, long, org.apache.hadoop.hdfs.server.monitor.ServernodeCPUStatus, org.apache.hadoop.hdfs.server.monitor.ServernodeMEMStatus, org.apache.hadoop.hdfs.server.monitor.ServernodeNETStatus[], org.apache.hadoop.hdfs.server.monitor.ServernodeIOStatus[], int, int, int)"><B>sendHeartbeat(DatanodeRegistration, long, long, long, ServernodeCPUStatus, ServernodeMEMStatus, ServernodeNETStatus[], ServernodeIOStatus[], int, int, int)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">NameNode</A> 中的方法
<DD>Data node notify the name node that it is alive 
 Return an array of block-oriented commands for the datanode to execute.
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/DatanodeProtocol.html#sendHeartbeat(org.apache.hadoop.hdfs.server.protocol.DatanodeRegistration, long, long, long, org.apache.hadoop.hdfs.server.monitor.ServernodeCPUStatus, org.apache.hadoop.hdfs.server.monitor.ServernodeMEMStatus, org.apache.hadoop.hdfs.server.monitor.ServernodeNETStatus[], org.apache.hadoop.hdfs.server.monitor.ServernodeIOStatus[], int, int, int)"><B>sendHeartbeat(DatanodeRegistration, long, long, long, ServernodeCPUStatus, ServernodeMEMStatus, ServernodeNETStatus[], ServernodeIOStatus[], int, int, int)</B></A> - 
接口 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/DatanodeProtocol.html" title="org.apache.hadoop.hdfs.server.protocol 中的接口">DatanodeProtocol</A> 中的方法
<DD>sendHeartbeat() tells the NameNode that the DataNode is still
 alive and well.
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DSQuotaExceededException.html#serialVersionUID"><B>serialVersionUID</B></A> - 
异常 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DSQuotaExceededException.html" title="org.apache.hadoop.hdfs.protocol 中的类">DSQuotaExceededException</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/NSQuotaExceededException.html#serialVersionUID"><B>serialVersionUID</B></A> - 
异常 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/NSQuotaExceededException.html" title="org.apache.hadoop.hdfs.protocol 中的类">NSQuotaExceededException</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/QuotaExceededException.html#serialVersionUID"><B>serialVersionUID</B></A> - 
异常 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/QuotaExceededException.html" title="org.apache.hadoop.hdfs.protocol 中的类">QuotaExceededException</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSClient.html#SERVER_DEFAULTS_VALIDITY_PERIOD"><B>SERVER_DEFAULTS_VALIDITY_PERIOD</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSClient.html" title="org.apache.hadoop.hdfs 中的类">DFSClient</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/ServerCommand.html" title="org.apache.hadoop.hdfs.server.protocol 中的类"><B>ServerCommand</B></A> - <A HREF="./org/apache/hadoop/hdfs/server/protocol/package-summary.html">org.apache.hadoop.hdfs.server.protocol</A> 中的 类<DD>Base class for a server command.<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/ServerCommand.html#ServerCommand()"><B>ServerCommand()</B></A> - 
类 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/ServerCommand.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">ServerCommand</A> 的构造方法
<DD>Unknown server command constructor.
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/ServerCommand.html#ServerCommand(int)"><B>ServerCommand(int)</B></A> - 
类 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/ServerCommand.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">ServerCommand</A> 的构造方法
<DD>Create a command for the specified action.
<DT><A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeCPUStator.html" title="org.apache.hadoop.hdfs.server.monitor 中的类"><B>ServernodeCPUStator</B></A> - <A HREF="./org/apache/hadoop/hdfs/server/monitor/package-summary.html">org.apache.hadoop.hdfs.server.monitor</A> 中的 类<DD>to get the status of cpu, 
 the cpu's information is get from file '/proc/stat'.<DT><A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeCPUStator.html#ServernodeCPUStator()"><B>ServernodeCPUStator()</B></A> - 
类 org.apache.hadoop.hdfs.server.monitor.<A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeCPUStator.html" title="org.apache.hadoop.hdfs.server.monitor 中的类">ServernodeCPUStator</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeCPUStatus.html" title="org.apache.hadoop.hdfs.server.monitor 中的类"><B>ServernodeCPUStatus</B></A> - <A HREF="./org/apache/hadoop/hdfs/server/monitor/package-summary.html">org.apache.hadoop.hdfs.server.monitor</A> 中的 类<DD>ServernodeCPUStatus represents the status of cpu.<DT><A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeCPUStatus.html#ServernodeCPUStatus()"><B>ServernodeCPUStatus()</B></A> - 
类 org.apache.hadoop.hdfs.server.monitor.<A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeCPUStatus.html" title="org.apache.hadoop.hdfs.server.monitor 中的类">ServernodeCPUStatus</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeCPUStatus.html#ServernodeCPUStatus(org.apache.hadoop.hdfs.server.monitor.ServernodeCPUStatus)"><B>ServernodeCPUStatus(ServernodeCPUStatus)</B></A> - 
类 org.apache.hadoop.hdfs.server.monitor.<A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeCPUStatus.html" title="org.apache.hadoop.hdfs.server.monitor 中的类">ServernodeCPUStatus</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeIOStator.html" title="org.apache.hadoop.hdfs.server.monitor 中的类"><B>ServernodeIOStator</B></A> - <A HREF="./org/apache/hadoop/hdfs/server/monitor/package-summary.html">org.apache.hadoop.hdfs.server.monitor</A> 中的 类<DD>to get the status of io, 
 io_rate means how busy io is, that's to say, 
 how often read/write happens in a specified time slot<DT><A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeIOStator.html#ServernodeIOStator(org.apache.hadoop.conf.Configuration, org.apache.hadoop.hdfs.server.monitor.ServernodeRole)"><B>ServernodeIOStator(Configuration, ServernodeRole)</B></A> - 
类 org.apache.hadoop.hdfs.server.monitor.<A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeIOStator.html" title="org.apache.hadoop.hdfs.server.monitor 中的类">ServernodeIOStator</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeIOStatus.html" title="org.apache.hadoop.hdfs.server.monitor 中的类"><B>ServernodeIOStatus</B></A> - <A HREF="./org/apache/hadoop/hdfs/server/monitor/package-summary.html">org.apache.hadoop.hdfs.server.monitor</A> 中的 类<DD>ServernodeIOStatus represents the status of IO.<DT><A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeIOStatus.html#ServernodeIOStatus()"><B>ServernodeIOStatus()</B></A> - 
类 org.apache.hadoop.hdfs.server.monitor.<A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeIOStatus.html" title="org.apache.hadoop.hdfs.server.monitor 中的类">ServernodeIOStatus</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeIOStatus.html#ServernodeIOStatus(java.lang.String)"><B>ServernodeIOStatus(String)</B></A> - 
类 org.apache.hadoop.hdfs.server.monitor.<A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeIOStatus.html" title="org.apache.hadoop.hdfs.server.monitor 中的类">ServernodeIOStatus</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeIOStatus.html#ServernodeIOStatus(org.apache.hadoop.hdfs.server.monitor.ServernodeIOStatus)"><B>ServernodeIOStatus(ServernodeIOStatus)</B></A> - 
类 org.apache.hadoop.hdfs.server.monitor.<A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeIOStatus.html" title="org.apache.hadoop.hdfs.server.monitor 中的类">ServernodeIOStatus</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeMEMStator.html" title="org.apache.hadoop.hdfs.server.monitor 中的类"><B>ServernodeMEMStator</B></A> - <A HREF="./org/apache/hadoop/hdfs/server/monitor/package-summary.html">org.apache.hadoop.hdfs.server.monitor</A> 中的 类<DD>to get the status of mem(memory), 
 the mem's information is get from file '/proc/meminfo'.<DT><A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeMEMStator.html#ServernodeMEMStator()"><B>ServernodeMEMStator()</B></A> - 
类 org.apache.hadoop.hdfs.server.monitor.<A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeMEMStator.html" title="org.apache.hadoop.hdfs.server.monitor 中的类">ServernodeMEMStator</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeMEMStatus.html" title="org.apache.hadoop.hdfs.server.monitor 中的类"><B>ServernodeMEMStatus</B></A> - <A HREF="./org/apache/hadoop/hdfs/server/monitor/package-summary.html">org.apache.hadoop.hdfs.server.monitor</A> 中的 类<DD>ServernodeMEMStatus represents the status of memory.<DT><A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeMEMStatus.html#ServernodeMEMStatus()"><B>ServernodeMEMStatus()</B></A> - 
类 org.apache.hadoop.hdfs.server.monitor.<A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeMEMStatus.html" title="org.apache.hadoop.hdfs.server.monitor 中的类">ServernodeMEMStatus</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeMEMStatus.html#ServernodeMEMStatus(org.apache.hadoop.hdfs.server.monitor.ServernodeMEMStatus)"><B>ServernodeMEMStatus(ServernodeMEMStatus)</B></A> - 
类 org.apache.hadoop.hdfs.server.monitor.<A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeMEMStatus.html" title="org.apache.hadoop.hdfs.server.monitor 中的类">ServernodeMEMStatus</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeNETStator.html" title="org.apache.hadoop.hdfs.server.monitor 中的类"><B>ServernodeNETStator</B></A> - <A HREF="./org/apache/hadoop/hdfs/server/monitor/package-summary.html">org.apache.hadoop.hdfs.server.monitor</A> 中的 类<DD>to get the status of net(network), 
 net_rate means the network speed, in byte per second.<DT><A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeNETStator.html#ServernodeNETStator()"><B>ServernodeNETStator()</B></A> - 
类 org.apache.hadoop.hdfs.server.monitor.<A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeNETStator.html" title="org.apache.hadoop.hdfs.server.monitor 中的类">ServernodeNETStator</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeNETStatus.html" title="org.apache.hadoop.hdfs.server.monitor 中的类"><B>ServernodeNETStatus</B></A> - <A HREF="./org/apache/hadoop/hdfs/server/monitor/package-summary.html">org.apache.hadoop.hdfs.server.monitor</A> 中的 类<DD>ServernodeNETStatus represents the status of a net card.<DT><A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeNETStatus.html#ServernodeNETStatus()"><B>ServernodeNETStatus()</B></A> - 
类 org.apache.hadoop.hdfs.server.monitor.<A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeNETStatus.html" title="org.apache.hadoop.hdfs.server.monitor 中的类">ServernodeNETStatus</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeNETStatus.html#ServernodeNETStatus(java.lang.String)"><B>ServernodeNETStatus(String)</B></A> - 
类 org.apache.hadoop.hdfs.server.monitor.<A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeNETStatus.html" title="org.apache.hadoop.hdfs.server.monitor 中的类">ServernodeNETStatus</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeNETStatus.html#ServernodeNETStatus(org.apache.hadoop.hdfs.server.monitor.ServernodeNETStatus)"><B>ServernodeNETStatus(ServernodeNETStatus)</B></A> - 
类 org.apache.hadoop.hdfs.server.monitor.<A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeNETStatus.html" title="org.apache.hadoop.hdfs.server.monitor 中的类">ServernodeNETStatus</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeRole.html" title="org.apache.hadoop.hdfs.server.monitor 中的枚举"><B>ServernodeRole</B></A> - <A HREF="./org/apache/hadoop/hdfs/server/monitor/package-summary.html">org.apache.hadoop.hdfs.server.monitor</A> 中的 枚举<DD>author: xianyu
 date: 2014-04-07<DT><A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeStator.html" title="org.apache.hadoop.hdfs.server.monitor 中的类"><B>ServernodeStator</B></A> - <A HREF="./org/apache/hadoop/hdfs/server/monitor/package-summary.html">org.apache.hadoop.hdfs.server.monitor</A> 中的 类<DD>&nbsp;<DT><A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeStator.html#ServernodeStator(org.apache.hadoop.hdfs.server.monitor.ServernodeRole)"><B>ServernodeStator(ServernodeRole)</B></A> - 
类 org.apache.hadoop.hdfs.server.monitor.<A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeStator.html" title="org.apache.hadoop.hdfs.server.monitor 中的类">ServernodeStator</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeStator.html#ServernodeStator(org.apache.hadoop.conf.Configuration, org.apache.hadoop.hdfs.server.monitor.ServernodeRole)"><B>ServernodeStator(Configuration, ServernodeRole)</B></A> - 
类 org.apache.hadoop.hdfs.server.monitor.<A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeStator.html" title="org.apache.hadoop.hdfs.server.monitor 中的类">ServernodeStator</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html#serviceRPCAddress"><B>serviceRPCAddress</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">NameNode</A> 中的变量
<DD>RPC server for DN address
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html#serviceRpcServer"><B>serviceRpcServer</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">NameNode</A> 中的变量
<DD>RPC server for HDFS Services communication.
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/Block.html#set(long, long, long)"><B>set(long, long, long)</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/Block.html" title="org.apache.hadoop.hdfs.protocol 中的类">Block</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeInfo.html#setAdminState(org.apache.hadoop.hdfs.protocol.DatanodeInfo.AdminStates)"><B>setAdminState(DatanodeInfo.AdminStates)</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeInfo.html" title="org.apache.hadoop.hdfs.protocol 中的类">DatanodeInfo</A> 中的方法
<DD>Sets the admin state of this node.
<DT><A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeCPUStatus.html#setAvgCPURate(double)"><B>setAvgCPURate(double)</B></A> - 
类 org.apache.hadoop.hdfs.server.monitor.<A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeCPUStatus.html" title="org.apache.hadoop.hdfs.server.monitor 中的类">ServernodeCPUStatus</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeIOStatus.html#setAvgIORate(double)"><B>setAvgIORate(double)</B></A> - 
类 org.apache.hadoop.hdfs.server.monitor.<A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeIOStatus.html" title="org.apache.hadoop.hdfs.server.monitor 中的类">ServernodeIOStatus</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeMEMStatus.html#setAvgMEMRate(double)"><B>setAvgMEMRate(double)</B></A> - 
类 org.apache.hadoop.hdfs.server.monitor.<A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeMEMStatus.html" title="org.apache.hadoop.hdfs.server.monitor 中的类">ServernodeMEMStatus</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeNETStatus.html#setAvgNETRxRate(double)"><B>setAvgNETRxRate(double)</B></A> - 
类 org.apache.hadoop.hdfs.server.monitor.<A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeNETStatus.html" title="org.apache.hadoop.hdfs.server.monitor 中的类">ServernodeNETStatus</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeNETStatus.html#setAvgNETTxRate(double)"><B>setAvgNETTxRate(double)</B></A> - 
类 org.apache.hadoop.hdfs.server.monitor.<A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeNETStatus.html" title="org.apache.hadoop.hdfs.server.monitor 中的类">ServernodeNETStatus</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeNETStatus.html#setBandwidth(int)"><B>setBandwidth(int)</B></A> - 
类 org.apache.hadoop.hdfs.server.monitor.<A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeNETStatus.html" title="org.apache.hadoop.hdfs.server.monitor 中的类">ServernodeNETStatus</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/util/DataTransferThrottler.html#setBandwidth(long)"><B>setBandwidth(long)</B></A> - 
类 org.apache.hadoop.hdfs.util.<A HREF="./org/apache/hadoop/hdfs/util/DataTransferThrottler.html" title="org.apache.hadoop.hdfs.util 中的类">DataTransferThrottler</A> 中的方法
<DD>Sets throttle bandwidth.
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/Block.html#setBlockId(long)"><B>setBlockId(long)</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/Block.html" title="org.apache.hadoop.hdfs.protocol 中的类">Block</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/LocatedBlock.html#setBlockToken(org.apache.hadoop.security.token.Token)"><B>setBlockToken(Token&lt;BlockTokenIdentifier&gt;)</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/LocatedBlock.html" title="org.apache.hadoop.hdfs.protocol 中的类">LocatedBlock</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/CumulusRecoveryCommand.html#setBlockToken(int, org.apache.hadoop.security.token.Token)"><B>setBlockToken(int, Token&lt;BlockTokenIdentifier&gt;)</B></A> - 
类 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/CumulusRecoveryCommand.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">CumulusRecoveryCommand</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/RCRecoveryCommand.html#setBlockToken(int, org.apache.hadoop.security.token.Token)"><B>setBlockToken(int, Token&lt;BlockTokenIdentifier&gt;)</B></A> - 
类 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/RCRecoveryCommand.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">RCRecoveryCommand</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FSEditLog.html#setBufferCapacity(int)"><B>setBufferCapacity(int)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/FSEditLog.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FSEditLog</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/HeaderBuffer.html#setBufferPosition(long)"><B>setBufferPosition(long)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/HeaderBuffer.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">HeaderBuffer</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeInfo.html#setCapacity(long)"><B>setCapacity(long)</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeInfo.html" title="org.apache.hadoop.hdfs.protocol 中的类">DatanodeInfo</A> 中的方法
<DD>Sets raw capacity.
<DT><A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeNETStatus.html#setCardname(java.lang.String)"><B>setCardname(String)</B></A> - 
类 org.apache.hadoop.hdfs.server.monitor.<A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeNETStatus.html" title="org.apache.hadoop.hdfs.server.monitor 中的类">ServernodeNETStatus</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/balancer/Balancer.html#setConf(org.apache.hadoop.conf.Configuration)"><B>setConf(Configuration)</B></A> - 
类 org.apache.hadoop.hdfs.server.balancer.<A HREF="./org/apache/hadoop/hdfs/server/balancer/Balancer.html" title="org.apache.hadoop.hdfs.server.balancer 中的类">Balancer</A> 中的方法
<DD>set this balancer's configuration
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeInfo.html#setCPUStatus(org.apache.hadoop.hdfs.server.monitor.ServernodeCPUStatus)"><B>setCPUStatus(ServernodeCPUStatus)</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeInfo.html" title="org.apache.hadoop.hdfs.protocol 中的类">DatanodeInfo</A> 中的方法
<DD>set the cpu status of datanode
<DT><A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeCPUStatus.html#setCurCPURate(double)"><B>setCurCPURate(double)</B></A> - 
类 org.apache.hadoop.hdfs.server.monitor.<A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeCPUStatus.html" title="org.apache.hadoop.hdfs.server.monitor 中的类">ServernodeCPUStatus</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeIOStatus.html#setCurIORate(double)"><B>setCurIORate(double)</B></A> - 
类 org.apache.hadoop.hdfs.server.monitor.<A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeIOStatus.html" title="org.apache.hadoop.hdfs.server.monitor 中的类">ServernodeIOStatus</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeMEMStatus.html#setCurMEMRate(double)"><B>setCurMEMRate(double)</B></A> - 
类 org.apache.hadoop.hdfs.server.monitor.<A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeMEMStatus.html" title="org.apache.hadoop.hdfs.server.monitor 中的类">ServernodeMEMStatus</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeNETStatus.html#setCurNETRxRate(double)"><B>setCurNETRxRate(double)</B></A> - 
类 org.apache.hadoop.hdfs.server.monitor.<A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeNETStatus.html" title="org.apache.hadoop.hdfs.server.monitor 中的类">ServernodeNETStatus</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeNETStatus.html#setCurNETTxRate(double)"><B>setCurNETTxRate(double)</B></A> - 
类 org.apache.hadoop.hdfs.server.monitor.<A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeNETStatus.html" title="org.apache.hadoop.hdfs.server.monitor 中的类">ServernodeNETStatus</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeInfo.html#setDecommissioned()"><B>setDecommissioned()</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeInfo.html" title="org.apache.hadoop.hdfs.protocol 中的类">DatanodeInfo</A> 中的方法
<DD>Sets the admin state to indicate that decommission is complete.
<DT><A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeIOStatus.html#setDiskname(java.lang.String)"><B>setDiskname(String)</B></A> - 
类 org.apache.hadoop.hdfs.server.monitor.<A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeIOStatus.html" title="org.apache.hadoop.hdfs.server.monitor 中的类">ServernodeIOStatus</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeNETStatus.html#setDuplex(java.lang.String)"><B>setDuplex(String)</B></A> - 
类 org.apache.hadoop.hdfs.server.monitor.<A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeNETStatus.html" title="org.apache.hadoop.hdfs.server.monitor 中的类">ServernodeNETStatus</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/CodingMatrix.html#setElemAt(int, int, byte)"><B>setElemAt(int, int, byte)</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/CodingMatrix.html" title="org.apache.hadoop.hdfs.protocol 中的类">CodingMatrix</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSUtil.ErrorSimulator.html#setErrorSimulation(int)"><B>setErrorSimulation(int)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSUtil.ErrorSimulator.html" title="org.apache.hadoop.hdfs 中的类">DFSUtil.ErrorSimulator</A> 中的静态方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/security/token/block/BlockTokenIdentifier.html#setExpiryDate(long)"><B>setExpiryDate(long)</B></A> - 
类 org.apache.hadoop.hdfs.security.token.block.<A HREF="./org/apache/hadoop/hdfs/security/token/block/BlockTokenIdentifier.html" title="org.apache.hadoop.hdfs.security.token.block 中的类">BlockTokenIdentifier</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/Storage.html#setFields(java.util.Properties, org.apache.hadoop.hdfs.server.common.Storage.StorageDirectory)"><B>setFields(Properties, Storage.StorageDirectory)</B></A> - 
类 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/Storage.html" title="org.apache.hadoop.hdfs.server.common 中的类">Storage</A> 中的方法
<DD>Set common storage fields.
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/DataStorage.html#setFields(java.util.Properties, org.apache.hadoop.hdfs.server.common.Storage.StorageDirectory)"><B>setFields(Properties, Storage.StorageDirectory)</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/DataStorage.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">DataStorage</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FSImage.html#setFields(java.util.Properties, org.apache.hadoop.hdfs.server.common.Storage.StorageDirectory)"><B>setFields(Properties, Storage.StorageDirectory)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/FSImage.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FSImage</A> 中的方法
<DD>Write last checkpoint time and version file into the storage directory.
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/Block.html#setGenerationStamp(long)"><B>setGenerationStamp(long)</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/Block.html" title="org.apache.hadoop.hdfs.protocol 中的类">Block</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#setGenerationStamp(long)"><B>setGenerationStamp(long)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FSNamesystem</A> 中的方法
<DD>Sets the generation stamp for this filesystem
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/BufferData.html#setHead(byte[])"><B>setHead(byte[])</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/BufferData.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">BufferData</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeInfo.html#setHostName(java.lang.String)"><B>setHostName(String)</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeInfo.html" title="org.apache.hadoop.hdfs.protocol 中的类">DatanodeInfo</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/BackupNode.html#setHttpServerAddress(org.apache.hadoop.conf.Configuration)"><B>setHttpServerAddress(Configuration)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/BackupNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">BackupNode</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html#setHttpServerAddress(org.apache.hadoop.conf.Configuration)"><B>setHttpServerAddress(Configuration)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">NameNode</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FSImage.html#setImageDigest(org.apache.hadoop.io.MD5Hash)"><B>setImageDigest(MD5Hash)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/FSImage.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FSImage</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/BufferData.html#setIndexFile(org.apache.hadoop.hdfs.server.namenode.INodeFile)"><B>setIndexFile(INodeFile)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/BufferData.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">BufferData</A> 中的方法
<DD>new get&set for indexFile
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/DatanodeRegistration.html#setInfoPort(int)"><B>setInfoPort(int)</B></A> - 
类 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/DatanodeRegistration.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">DatanodeRegistration</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeInfo.html#setIOStatus(org.apache.hadoop.hdfs.server.monitor.ServernodeIOStatus[])"><B>setIOStatus(ServernodeIOStatus[])</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeInfo.html" title="org.apache.hadoop.hdfs.protocol 中的类">DatanodeInfo</A> 中的方法
<DD>set the io status of datanode
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/DatanodeRegistration.html#setIpcPort(int)"><B>setIpcPort(int)</B></A> - 
类 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/DatanodeRegistration.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">DatanodeRegistration</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/security/token/block/BlockTokenIdentifier.html#setKeyId(int)"><B>setKeyId(int)</B></A> - 
类 org.apache.hadoop.hdfs.security.token.block.<A HREF="./org/apache/hadoop/hdfs/security/token/block/BlockTokenIdentifier.html" title="org.apache.hadoop.hdfs.security.token.block 中的类">BlockTokenIdentifier</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/security/token/block/BlockTokenSecretManager.html#setKeys(org.apache.hadoop.hdfs.security.token.block.ExportedBlockKeys)"><B>setKeys(ExportedBlockKeys)</B></A> - 
类 org.apache.hadoop.hdfs.security.token.block.<A HREF="./org/apache/hadoop/hdfs/security/token/block/BlockTokenSecretManager.html" title="org.apache.hadoop.hdfs.security.token.block 中的类">BlockTokenSecretManager</A> 中的方法
<DD>Set block keys, only to be used in slave mode
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeInfo.html#setLastUpdate(long)"><B>setLastUpdate(long)</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeInfo.html" title="org.apache.hadoop.hdfs.protocol 中的类">DatanodeInfo</A> 中的方法
<DD>Sets time when this information was accurate.
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/LeaseManager.html#setLeasePeriod(long, long)"><B>setLeasePeriod(long, long)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/LeaseManager.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">LeaseManager</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeInfo.html#setLevel(int)"><B>setLevel(int)</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeInfo.html" title="org.apache.hadoop.hdfs.protocol 中的类">DatanodeInfo</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/tools/JMXGet.html#setLocalVMUrl(java.lang.String)"><B>setLocalVMUrl(String)</B></A> - 
类 org.apache.hadoop.hdfs.tools.<A HREF="./org/apache/hadoop/hdfs/tools/JMXGet.html" title="org.apache.hadoop.hdfs.tools 中的类">JMXGet</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeCPUStatus.html#setMaxCPURate(double)"><B>setMaxCPURate(double)</B></A> - 
类 org.apache.hadoop.hdfs.server.monitor.<A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeCPUStatus.html" title="org.apache.hadoop.hdfs.server.monitor 中的类">ServernodeCPUStatus</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeIOStatus.html#setMaxIORate(double)"><B>setMaxIORate(double)</B></A> - 
类 org.apache.hadoop.hdfs.server.monitor.<A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeIOStatus.html" title="org.apache.hadoop.hdfs.server.monitor 中的类">ServernodeIOStatus</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeMEMStatus.html#setMaxMEMRate(double)"><B>setMaxMEMRate(double)</B></A> - 
类 org.apache.hadoop.hdfs.server.monitor.<A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeMEMStatus.html" title="org.apache.hadoop.hdfs.server.monitor 中的类">ServernodeMEMStatus</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeNETStatus.html#setMaxNETRxRate(double)"><B>setMaxNETRxRate(double)</B></A> - 
类 org.apache.hadoop.hdfs.server.monitor.<A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeNETStatus.html" title="org.apache.hadoop.hdfs.server.monitor 中的类">ServernodeNETStatus</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeNETStatus.html#setMaxNETTxRate(double)"><B>setMaxNETTxRate(double)</B></A> - 
类 org.apache.hadoop.hdfs.server.monitor.<A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeNETStatus.html" title="org.apache.hadoop.hdfs.server.monitor 中的类">ServernodeNETStatus</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeInfo.html#setMEMStatus(org.apache.hadoop.hdfs.server.monitor.ServernodeMEMStatus)"><B>setMEMStatus(ServernodeMEMStatus)</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeInfo.html" title="org.apache.hadoop.hdfs.protocol 中的类">DatanodeInfo</A> 中的方法
<DD>set the mem status of datanode
<DT><A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeCPUStatus.html#setMinCPURate(double)"><B>setMinCPURate(double)</B></A> - 
类 org.apache.hadoop.hdfs.server.monitor.<A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeCPUStatus.html" title="org.apache.hadoop.hdfs.server.monitor 中的类">ServernodeCPUStatus</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeIOStatus.html#setMinIORate(double)"><B>setMinIORate(double)</B></A> - 
类 org.apache.hadoop.hdfs.server.monitor.<A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeIOStatus.html" title="org.apache.hadoop.hdfs.server.monitor 中的类">ServernodeIOStatus</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeMEMStatus.html#setMinMEMRate(double)"><B>setMinMEMRate(double)</B></A> - 
类 org.apache.hadoop.hdfs.server.monitor.<A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeMEMStatus.html" title="org.apache.hadoop.hdfs.server.monitor 中的类">ServernodeMEMStatus</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeNETStatus.html#setMinNETRxRate(double)"><B>setMinNETRxRate(double)</B></A> - 
类 org.apache.hadoop.hdfs.server.monitor.<A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeNETStatus.html" title="org.apache.hadoop.hdfs.server.monitor 中的类">ServernodeNETStatus</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeNETStatus.html#setMinNETTxRate(double)"><B>setMinNETTxRate(double)</B></A> - 
类 org.apache.hadoop.hdfs.server.monitor.<A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeNETStatus.html" title="org.apache.hadoop.hdfs.server.monitor 中的类">ServernodeNETStatus</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/DatanodeRegistration.html#setName(java.lang.String)"><B>setName(String)</B></A> - 
类 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/DatanodeRegistration.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">DatanodeRegistration</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeInfo.html#setNETStatus(org.apache.hadoop.hdfs.server.monitor.ServernodeNETStatus[])"><B>setNETStatus(ServernodeNETStatus[])</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeInfo.html" title="org.apache.hadoop.hdfs.protocol 中的类">DatanodeInfo</A> 中的方法
<DD>set the net status of datanode
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeInfo.html#setNetworkLocation(java.lang.String)"><B>setNetworkLocation(String)</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeInfo.html" title="org.apache.hadoop.hdfs.protocol 中的类">DatanodeInfo</A> 中的方法
<DD>Sets the rack name
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/DataNode.html#setNewStorageID(org.apache.hadoop.hdfs.server.protocol.DatanodeRegistration)"><B>setNewStorageID(DatanodeRegistration)</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/DataNode.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">DataNode</A> 中的静态方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/util/LightWeightGSet.LinkedElement.html#setNext(org.apache.hadoop.hdfs.util.LightWeightGSet.LinkedElement)"><B>setNext(LightWeightGSet.LinkedElement)</B></A> - 
接口 org.apache.hadoop.hdfs.util.<A HREF="./org/apache/hadoop/hdfs/util/LightWeightGSet.LinkedElement.html" title="org.apache.hadoop.hdfs.util 中的接口">LightWeightGSet.LinkedElement</A> 中的方法
<DD>Set the next element.
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#setNodeReplicationLimit(int)"><B>setNodeReplicationLimit(int)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FSNamesystem</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/Block.html#setNumBytes(long)"><B>setNumBytes(long)</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/Block.html" title="org.apache.hadoop.hdfs.protocol 中的类">Block</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/fs/Hdfs.html#setOwner(org.apache.hadoop.fs.Path, java.lang.String, java.lang.String)"><B>setOwner(Path, String, String)</B></A> - 
类 org.apache.hadoop.fs.<A HREF="./org/apache/hadoop/fs/Hdfs.html" title="org.apache.hadoop.fs 中的类">Hdfs</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSClient.html#setOwner(java.lang.String, java.lang.String, java.lang.String)"><B>setOwner(String, String, String)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSClient.html" title="org.apache.hadoop.hdfs 中的类">DFSClient</A> 中的方法
<DD>Set file or directory owner.
<DT><A HREF="./org/apache/hadoop/hdfs/DistributedFileSystem.html#setOwner(org.apache.hadoop.fs.Path, java.lang.String, java.lang.String)"><B>setOwner(Path, String, String)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DistributedFileSystem.html" title="org.apache.hadoop.hdfs 中的类">DistributedFileSystem</A> 中的方法
<DD>
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/ClientProtocol.html#setOwner(java.lang.String, java.lang.String, java.lang.String)"><B>setOwner(String, String, String)</B></A> - 
接口 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/ClientProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的接口">ClientProtocol</A> 中的方法
<DD>Set Owner of a path (i.e. a file or a directory).
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#setOwner(java.lang.String, java.lang.String, java.lang.String)"><B>setOwner(String, String, String)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FSNamesystem</A> 中的方法
<DD>Set owner for an existing file.
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html#setOwner(java.lang.String, java.lang.String, java.lang.String)"><B>setOwner(String, String, String)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">NameNode</A> 中的方法
<DD>Set Owner of a path (i.e. a file or a directory).
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeInfo.html#setParent(org.apache.hadoop.net.Node)"><B>setParent(Node)</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeInfo.html" title="org.apache.hadoop.hdfs.protocol 中的类">DatanodeInfo</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/QuotaExceededException.html#setPathName(java.lang.String)"><B>setPathName(String)</B></A> - 
异常 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/QuotaExceededException.html" title="org.apache.hadoop.hdfs.protocol 中的类">QuotaExceededException</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/fs/Hdfs.html#setPermission(org.apache.hadoop.fs.Path, org.apache.hadoop.fs.permission.FsPermission)"><B>setPermission(Path, FsPermission)</B></A> - 
类 org.apache.hadoop.fs.<A HREF="./org/apache/hadoop/fs/Hdfs.html" title="org.apache.hadoop.fs 中的类">Hdfs</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSClient.html#setPermission(java.lang.String, org.apache.hadoop.fs.permission.FsPermission)"><B>setPermission(String, FsPermission)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSClient.html" title="org.apache.hadoop.hdfs 中的类">DFSClient</A> 中的方法
<DD>Set permissions to a file or directory.
<DT><A HREF="./org/apache/hadoop/hdfs/DistributedFileSystem.html#setPermission(org.apache.hadoop.fs.Path, org.apache.hadoop.fs.permission.FsPermission)"><B>setPermission(Path, FsPermission)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DistributedFileSystem.html" title="org.apache.hadoop.hdfs 中的类">DistributedFileSystem</A> 中的方法
<DD>
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/ClientProtocol.html#setPermission(java.lang.String, org.apache.hadoop.fs.permission.FsPermission)"><B>setPermission(String, FsPermission)</B></A> - 
接口 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/ClientProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的接口">ClientProtocol</A> 中的方法
<DD>Set permissions for an existing file/directory.
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#setPermission(java.lang.String, org.apache.hadoop.fs.permission.FsPermission)"><B>setPermission(String, FsPermission)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FSNamesystem</A> 中的方法
<DD>Set permissions for an existing file.
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html#setPermission(java.lang.String, org.apache.hadoop.fs.permission.FsPermission)"><B>setPermission(String, FsPermission)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">NameNode</A> 中的方法
<DD>Set permissions for an existing file/directory.
<DT><A HREF="./org/apache/hadoop/hdfs/tools/JMXGet.html#setPort(java.lang.String)"><B>setPort(String)</B></A> - 
类 org.apache.hadoop.hdfs.tools.<A HREF="./org/apache/hadoop/hdfs/tools/JMXGet.html" title="org.apache.hadoop.hdfs.tools 中的类">JMXGet</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DistributedFileSystem.html#setQuota(org.apache.hadoop.fs.Path, long, long)"><B>setQuota(Path, long, long)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DistributedFileSystem.html" title="org.apache.hadoop.hdfs 中的类">DistributedFileSystem</A> 中的方法
<DD>Set a directory's quotas
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/ClientProtocol.html#setQuota(java.lang.String, long, long)"><B>setQuota(String, long, long)</B></A> - 
接口 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/ClientProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的接口">ClientProtocol</A> 中的方法
<DD>Set the quota for a directory.
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html#setQuota(java.lang.String, long, long)"><B>setQuota(String, long, long)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">NameNode</A> 中的方法
<DD>Set the quota for a directory.
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeInfo.html#setRemaining(long)"><B>setRemaining(long)</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeInfo.html" title="org.apache.hadoop.hdfs.protocol 中的类">DatanodeInfo</A> 中的方法
<DD>Sets raw free space.
<DT><A HREF="./org/apache/hadoop/fs/Hdfs.html#setReplication(org.apache.hadoop.fs.Path, short)"><B>setReplication(Path, short)</B></A> - 
类 org.apache.hadoop.fs.<A HREF="./org/apache/hadoop/fs/Hdfs.html" title="org.apache.hadoop.fs 中的类">Hdfs</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSClient.html#setReplication(java.lang.String, short)"><B>setReplication(String, short)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSClient.html" title="org.apache.hadoop.hdfs 中的类">DFSClient</A> 中的方法
<DD>Set replication for an existing file.
<DT><A HREF="./org/apache/hadoop/hdfs/DistributedFileSystem.html#setReplication(org.apache.hadoop.fs.Path, short)"><B>setReplication(Path, short)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DistributedFileSystem.html" title="org.apache.hadoop.hdfs 中的类">DistributedFileSystem</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/ClientProtocol.html#setReplication(java.lang.String, short)"><B>setReplication(String, short)</B></A> - 
接口 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/ClientProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的接口">ClientProtocol</A> 中的方法
<DD>Set replication for an existing file.
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#setReplication(java.lang.String, short)"><B>setReplication(String, short)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FSNamesystem</A> 中的方法
<DD>Set replication for an existing file.
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html#setReplication(java.lang.String, short)"><B>setReplication(String, short)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">NameNode</A> 中的方法
<DD>Set replication for an existing file.
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FSImage.html#setRestoreFailedStorage(boolean)"><B>setRestoreFailedStorage(boolean)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/FSImage.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FSImage</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/BackupNode.html#setRpcServerAddress(org.apache.hadoop.conf.Configuration)"><B>setRpcServerAddress(Configuration)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/BackupNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">BackupNode</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html#setRpcServerAddress(org.apache.hadoop.conf.Configuration)"><B>setRpcServerAddress(Configuration)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">NameNode</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/BackupNode.html#setRpcServiceServerAddress(org.apache.hadoop.conf.Configuration)"><B>setRpcServiceServerAddress(Configuration)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/BackupNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">BackupNode</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html#setRpcServiceServerAddress(org.apache.hadoop.conf.Configuration)"><B>setRpcServiceServerAddress(Configuration)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">NameNode</A> 中的方法
<DD>Modifies the configuration passed to contain the service rpc address setting
<DT><A HREF="./org/apache/hadoop/hdfs/DFSClient.html#setSafeMode(org.apache.hadoop.hdfs.protocol.FSConstants.SafeModeAction)"><B>setSafeMode(FSConstants.SafeModeAction)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSClient.html" title="org.apache.hadoop.hdfs 中的类">DFSClient</A> 中的方法
<DD>Enter, leave or get safe mode.
<DT><A HREF="./org/apache/hadoop/hdfs/DistributedFileSystem.html#setSafeMode(org.apache.hadoop.hdfs.protocol.FSConstants.SafeModeAction)"><B>setSafeMode(FSConstants.SafeModeAction)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DistributedFileSystem.html" title="org.apache.hadoop.hdfs 中的类">DistributedFileSystem</A> 中的方法
<DD>Enter, leave or get safe mode.
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/ClientProtocol.html#setSafeMode(org.apache.hadoop.hdfs.protocol.FSConstants.SafeModeAction)"><B>setSafeMode(FSConstants.SafeModeAction)</B></A> - 
接口 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/ClientProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的接口">ClientProtocol</A> 中的方法
<DD>Enter, leave or get safe mode.
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/BackupNode.html#setSafeMode(org.apache.hadoop.hdfs.protocol.FSConstants.SafeModeAction)"><B>setSafeMode(FSConstants.SafeModeAction)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/BackupNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">BackupNode</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html#setSafeMode(org.apache.hadoop.hdfs.protocol.FSConstants.SafeModeAction)"><B>setSafeMode(FSConstants.SafeModeAction)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">NameNode</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/tools/DFSAdmin.html#setSafeMode(java.lang.String[], int)"><B>setSafeMode(String[], int)</B></A> - 
类 org.apache.hadoop.hdfs.tools.<A HREF="./org/apache/hadoop/hdfs/tools/DFSAdmin.html" title="org.apache.hadoop.hdfs.tools 中的类">DFSAdmin</A> 中的方法
<DD>Safe mode maintenance command.
<DT><A HREF="./org/apache/hadoop/hdfs/tools/JMXGet.html#setServer(java.lang.String)"><B>setServer(String)</B></A> - 
类 org.apache.hadoop.hdfs.tools.<A HREF="./org/apache/hadoop/hdfs/tools/JMXGet.html" title="org.apache.hadoop.hdfs.tools 中的类">JMXGet</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/tools/JMXGet.html#setService(java.lang.String)"><B>setService(String)</B></A> - 
类 org.apache.hadoop.hdfs.tools.<A HREF="./org/apache/hadoop/hdfs/tools/JMXGet.html" title="org.apache.hadoop.hdfs.tools 中的类">JMXGet</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html#setServiceAddress(org.apache.hadoop.conf.Configuration, java.lang.String)"><B>setServiceAddress(Configuration, String)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">NameNode</A> 中的静态方法
<DD>Set the configuration property for the service rpc address
 to address
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/GenerationStamp.html#setStamp(long)"><B>setStamp(long)</B></A> - 
类 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/GenerationStamp.html" title="org.apache.hadoop.hdfs.server.common 中的类">GenerationStamp</A> 中的方法
<DD>Sets the current generation stamp
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeID.html#setStorageID(java.lang.String)"><B>setStorageID(String)</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeID.html" title="org.apache.hadoop.hdfs.protocol 中的类">DatanodeID</A> 中的方法
<DD>sets the data storage ID.
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/StorageInfo.html#setStorageInfo(org.apache.hadoop.hdfs.server.common.StorageInfo)"><B>setStorageInfo(StorageInfo)</B></A> - 
类 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/StorageInfo.html" title="org.apache.hadoop.hdfs.server.common 中的类">StorageInfo</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/DatanodeRegistration.html#setStorageInfo(org.apache.hadoop.hdfs.server.datanode.DataStorage)"><B>setStorageInfo(DataStorage)</B></A> - 
类 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/DatanodeRegistration.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">DatanodeRegistration</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/fs/Hdfs.html#setTimes(org.apache.hadoop.fs.Path, long, long)"><B>setTimes(Path, long, long)</B></A> - 
类 org.apache.hadoop.fs.<A HREF="./org/apache/hadoop/fs/Hdfs.html" title="org.apache.hadoop.fs 中的类">Hdfs</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSClient.html#setTimes(java.lang.String, long, long)"><B>setTimes(String, long, long)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSClient.html" title="org.apache.hadoop.hdfs 中的类">DFSClient</A> 中的方法
<DD>set the modification and access time of a file
<DT><A HREF="./org/apache/hadoop/hdfs/DistributedFileSystem.html#setTimes(org.apache.hadoop.fs.Path, long, long)"><B>setTimes(Path, long, long)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DistributedFileSystem.html" title="org.apache.hadoop.hdfs 中的类">DistributedFileSystem</A> 中的方法
<DD>
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/ClientProtocol.html#setTimes(java.lang.String, long, long)"><B>setTimes(String, long, long)</B></A> - 
接口 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/ClientProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的接口">ClientProtocol</A> 中的方法
<DD>Sets the modification and access time of the file to the specified time.
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#setTimes(java.lang.String, long, long)"><B>setTimes(String, long, long)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FSNamesystem</A> 中的方法
<DD>stores the modification and access time for this inode.
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html#setTimes(java.lang.String, long, long)"><B>setTimes(String, long, long)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">NameNode</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/security/token/block/BlockTokenSecretManager.html#setTokenLifetime(long)"><B>setTokenLifetime(long)</B></A> - 
类 org.apache.hadoop.hdfs.security.token.block.<A HREF="./org/apache/hadoop/hdfs/security/token/block/BlockTokenSecretManager.html" title="org.apache.hadoop.hdfs.security.token.block 中的类">BlockTokenSecretManager</A> 中的方法
<DD>set token lifetime.
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/UpgradeManager.html#setUpgradeState(boolean, int)"><B>setUpgradeState(boolean, int)</B></A> - 
类 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/UpgradeManager.html" title="org.apache.hadoop.hdfs.server.common 中的类">UpgradeManager</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/fs/Hdfs.html#setVerifyChecksum(boolean)"><B>setVerifyChecksum(boolean)</B></A> - 
类 org.apache.hadoop.fs.<A HREF="./org/apache/hadoop/fs/Hdfs.html" title="org.apache.hadoop.fs 中的类">Hdfs</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DistributedFileSystem.html#setVerifyChecksum(boolean)"><B>setVerifyChecksum(boolean)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DistributedFileSystem.html" title="org.apache.hadoop.hdfs 中的类">DistributedFileSystem</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DistributedFileSystem.html#setWorkingDirectory(org.apache.hadoop.fs.Path)"><B>setWorkingDirectory(Path)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DistributedFileSystem.html" title="org.apache.hadoop.hdfs 中的类">DistributedFileSystem</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/HftpFileSystem.html#setWorkingDirectory(org.apache.hadoop.fs.Path)"><B>setWorkingDirectory(Path)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/HftpFileSystem.html" title="org.apache.hadoop.hdfs 中的类">HftpFileSystem</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeInfo.html#setXceiverCount(int)"><B>setXceiverCount(int)</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeInfo.html" title="org.apache.hadoop.hdfs.protocol 中的类">DatanodeInfo</A> 中的方法
<DD>Sets number of active connections
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/DataNode.html#shutdown()"><B>shutdown()</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/DataNode.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">DataNode</A> 中的方法
<DD>Shut down this instance of the datanode.
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDataset.html#shutdown()"><B>shutdown()</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDataset.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">FSDataset</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.html#shutdown()"><B>shutdown()</B></A> - 
接口 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.html" title="org.apache.hadoop.hdfs.server.datanode 中的接口">FSDatasetInterface</A> 中的方法
<DD>Shutdown the FSDataset
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/metrics/DataNodeActivityMBean.html#shutdown()"><B>shutdown()</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.metrics.<A HREF="./org/apache/hadoop/hdfs/server/datanode/metrics/DataNodeActivityMBean.html" title="org.apache.hadoop.hdfs.server.datanode.metrics 中的类">DataNodeActivityMBean</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/metrics/DataNodeMetrics.html#shutdown()"><B>shutdown()</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.metrics.<A HREF="./org/apache/hadoop/hdfs/server/datanode/metrics/DataNodeMetrics.html" title="org.apache.hadoop.hdfs.server.datanode.metrics 中的类">DataNodeMetrics</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#shutdown()"><B>shutdown()</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FSNamesystem</A> 中的方法
<DD>shutdown FSNamesystem
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/metrics/NameNodeActivityMBean.html#shutdown()"><B>shutdown()</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.metrics.<A HREF="./org/apache/hadoop/hdfs/server/namenode/metrics/NameNodeActivityMBean.html" title="org.apache.hadoop.hdfs.server.namenode.metrics 中的类">NameNodeActivityMBean</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/metrics/NameNodeMetrics.html#shutdown()"><B>shutdown()</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.metrics.<A HREF="./org/apache/hadoop/hdfs/server/namenode/metrics/NameNodeMetrics.html" title="org.apache.hadoop.hdfs.server.namenode.metrics 中的类">NameNodeMetrics</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/SecondaryNameNode.html#shutdown()"><B>shutdown()</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/SecondaryNameNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">SecondaryNameNode</A> 中的方法
<DD><B>已过时。</B>&nbsp;Shut down this instance of the datanode.
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/CorruptReplicasMap.html#size()"><B>size()</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/CorruptReplicasMap.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">CorruptReplicasMap</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/util/GSet.html#size()"><B>size()</B></A> - 
接口 org.apache.hadoop.hdfs.util.<A HREF="./org/apache/hadoop/hdfs/util/GSet.html" title="org.apache.hadoop.hdfs.util 中的接口">GSet</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/util/GSetByHashMap.html#size()"><B>size()</B></A> - 
类 org.apache.hadoop.hdfs.util.<A HREF="./org/apache/hadoop/hdfs/util/GSetByHashMap.html" title="org.apache.hadoop.hdfs.util 中的类">GSetByHashMap</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/util/LightWeightGSet.html#size()"><B>size()</B></A> - 
类 org.apache.hadoop.hdfs.util.<A HREF="./org/apache/hadoop/hdfs/util/LightWeightGSet.html" title="org.apache.hadoop.hdfs.util 中的类">LightWeightGSet</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/FSConstants.html#SIZE_OF_INTEGER"><B>SIZE_OF_INTEGER</B></A> - 
接口 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/FSConstants.html" title="org.apache.hadoop.hdfs.protocol 中的接口">FSConstants</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/BlockReader.html#skip(long)"><B>skip(long)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/BlockReader.html" title="org.apache.hadoop.hdfs 中的类">BlockReader</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/FSConstants.html#SMALL_BUFFER_SIZE"><B>SMALL_BUFFER_SIZE</B></A> - 
接口 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/FSConstants.html" title="org.apache.hadoop.hdfs.protocol 中的接口">FSConstants</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/JspHelper.html#sortNodeList(java.util.ArrayList, java.lang.String, java.lang.String)"><B>sortNodeList(ArrayList&lt;DatanodeDescriptor&gt;, String, String)</B></A> - 
类 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/JspHelper.html" title="org.apache.hadoop.hdfs.server.common 中的类">JspHelper</A> 中的静态方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/SecureDataNodeStarter.html#start()"><B>start()</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/SecureDataNodeStarter.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">SecureDataNodeStarter</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/BackupNode.html#startCheckpoint(org.apache.hadoop.hdfs.server.protocol.NamenodeRegistration)"><B>startCheckpoint(NamenodeRegistration)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/BackupNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">BackupNode</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html#startCheckpoint(org.apache.hadoop.hdfs.server.protocol.NamenodeRegistration)"><B>startCheckpoint(NamenodeRegistration)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">NameNode</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/NamenodeProtocol.html#startCheckpoint(org.apache.hadoop.hdfs.server.protocol.NamenodeRegistration)"><B>startCheckpoint(NamenodeRegistration)</B></A> - 
接口 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/NamenodeProtocol.html" title="org.apache.hadoop.hdfs.server.protocol 中的接口">NamenodeProtocol</A> 中的方法
<DD>A request to the active name-node to start a checkpoint.
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeInfo.html#startDecommission()"><B>startDecommission()</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeInfo.html" title="org.apache.hadoop.hdfs.protocol 中的类">DatanodeInfo</A> 中的方法
<DD>Start decommissioning a node.
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/Upgradeable.html#startUpgrade()"><B>startUpgrade()</B></A> - 
接口 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/Upgradeable.html" title="org.apache.hadoop.hdfs.server.common 中的接口">Upgradeable</A> 中的方法
<DD>Prepare for the upgrade.
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/UpgradeManager.html#startUpgrade()"><B>startUpgrade()</B></A> - 
类 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/UpgradeManager.html" title="org.apache.hadoop.hdfs.server.common 中的类">UpgradeManager</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/UpgradeObjectNamenode.html#startUpgrade()"><B>startUpgrade()</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/UpgradeObjectNamenode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">UpgradeObjectNamenode</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html#stateChangeLog"><B>stateChangeLog</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">NameNode</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/UpgradeObject.html#status"><B>status</B></A> - 
类 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/UpgradeObject.html" title="org.apache.hadoop.hdfs.server.common 中的类">UpgradeObject</A> 中的变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/SecureDataNodeStarter.html#stop()"><B>stop()</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/SecureDataNodeStarter.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">SecureDataNodeStarter</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/BackupNode.html#stop()"><B>stop()</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/BackupNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">BackupNode</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html#stop()"><B>stop()</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">NameNode</A> 中的方法
<DD>Stop all NameNode threads and wait for all to finish.
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeInfo.html#stopDecommission()"><B>stopDecommission()</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeInfo.html" title="org.apache.hadoop.hdfs.protocol 中的类">DatanodeInfo</A> 中的方法
<DD>Stop decommissioning a node.
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html#stopDecommission(org.apache.hadoop.hdfs.server.namenode.DatanodeDescriptor)"><B>stopDecommission(DatanodeDescriptor)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/FSNamesystem.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">FSNamesystem</A> 中的方法
<DD>Stop decommissioning the specified datanodes.
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html#stopRequested"><B>stopRequested</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">NameNode</A> 中的变量
<DD>only used for testing purposes
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/Storage.html" title="org.apache.hadoop.hdfs.server.common 中的类"><B>Storage</B></A> - <A HREF="./org/apache/hadoop/hdfs/server/common/package-summary.html">org.apache.hadoop.hdfs.server.common</A> 中的 类<DD>Storage information file.<DT><A HREF="./org/apache/hadoop/hdfs/server/common/Storage.html#Storage(org.apache.hadoop.hdfs.server.common.HdfsConstants.NodeType)"><B>Storage(HdfsConstants.NodeType)</B></A> - 
类 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/Storage.html" title="org.apache.hadoop.hdfs.server.common 中的类">Storage</A> 的构造方法
<DD>Create empty storage info of the specified type
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/Storage.html#Storage(org.apache.hadoop.hdfs.server.common.HdfsConstants.NodeType, int, long)"><B>Storage(HdfsConstants.NodeType, int, long)</B></A> - 
类 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/Storage.html" title="org.apache.hadoop.hdfs.server.common 中的类">Storage</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/Storage.html#Storage(org.apache.hadoop.hdfs.server.common.HdfsConstants.NodeType, org.apache.hadoop.hdfs.server.common.StorageInfo)"><B>Storage(HdfsConstants.NodeType, StorageInfo)</B></A> - 
类 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/Storage.html" title="org.apache.hadoop.hdfs.server.common 中的类">Storage</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/Storage.StorageDirectory.html" title="org.apache.hadoop.hdfs.server.common 中的类"><B>Storage.StorageDirectory</B></A> - <A HREF="./org/apache/hadoop/hdfs/server/common/package-summary.html">org.apache.hadoop.hdfs.server.common</A> 中的 类<DD>One of the storage directories.<DT><A HREF="./org/apache/hadoop/hdfs/server/common/Storage.StorageDirectory.html#Storage.StorageDirectory(java.io.File)"><B>Storage.StorageDirectory(File)</B></A> - 
类 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/Storage.StorageDirectory.html" title="org.apache.hadoop.hdfs.server.common 中的类">Storage.StorageDirectory</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/Storage.StorageDirectory.html#Storage.StorageDirectory(java.io.File, org.apache.hadoop.hdfs.server.common.Storage.StorageDirType)"><B>Storage.StorageDirectory(File, Storage.StorageDirType)</B></A> - 
类 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/Storage.StorageDirectory.html" title="org.apache.hadoop.hdfs.server.common 中的类">Storage.StorageDirectory</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/Storage.StorageDirType.html" title="org.apache.hadoop.hdfs.server.common 中的接口"><B>Storage.StorageDirType</B></A> - <A HREF="./org/apache/hadoop/hdfs/server/common/package-summary.html">org.apache.hadoop.hdfs.server.common</A> 中的 接口<DD>An interface to denote storage directory type
 Implementations can define a type for storage directory by implementing
 this interface.<DT><A HREF="./org/apache/hadoop/hdfs/server/common/Storage.StorageState.html" title="org.apache.hadoop.hdfs.server.common 中的枚举"><B>Storage.StorageState</B></A> - <A HREF="./org/apache/hadoop/hdfs/server/common/package-summary.html">org.apache.hadoop.hdfs.server.common</A> 中的 枚举<DD>&nbsp;<DT><A HREF="./org/apache/hadoop/hdfs/server/common/Storage.html#STORAGE_DIR_CURRENT"><B>STORAGE_DIR_CURRENT</B></A> - 
类 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/Storage.html" title="org.apache.hadoop.hdfs.server.common 中的类">Storage</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/Storage.html#STORAGE_FILE_VERSION"><B>STORAGE_FILE_VERSION</B></A> - 
类 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/Storage.html" title="org.apache.hadoop.hdfs.server.common 中的类">Storage</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/Storage.html#storageDirs"><B>storageDirs</B></A> - 
类 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/Storage.html" title="org.apache.hadoop.hdfs.server.common 中的类">Storage</A> 中的变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeID.html#storageID"><B>storageID</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeID.html" title="org.apache.hadoop.hdfs.protocol 中的类">DatanodeID</A> 中的变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/StorageInfo.html" title="org.apache.hadoop.hdfs.server.common 中的类"><B>StorageInfo</B></A> - <A HREF="./org/apache/hadoop/hdfs/server/common/package-summary.html">org.apache.hadoop.hdfs.server.common</A> 中的 类<DD>Common class for storage information.<DT><A HREF="./org/apache/hadoop/hdfs/server/common/StorageInfo.html#StorageInfo()"><B>StorageInfo()</B></A> - 
类 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/StorageInfo.html" title="org.apache.hadoop.hdfs.server.common 中的类">StorageInfo</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/StorageInfo.html#StorageInfo(int, int, long)"><B>StorageInfo(int, int, long)</B></A> - 
类 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/StorageInfo.html" title="org.apache.hadoop.hdfs.server.common 中的类">StorageInfo</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/StorageInfo.html#StorageInfo(org.apache.hadoop.hdfs.server.common.StorageInfo)"><B>StorageInfo(StorageInfo)</B></A> - 
类 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/StorageInfo.html" title="org.apache.hadoop.hdfs.server.common 中的类">StorageInfo</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/DatanodeRegistration.html#storageInfo"><B>storageInfo</B></A> - 
类 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/DatanodeRegistration.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">DatanodeRegistration</A> 中的变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/JspHelper.html#streamBlockInAscii(java.net.InetSocketAddress, long, org.apache.hadoop.security.token.Token, long, long, long, long, javax.servlet.jsp.JspWriter, org.apache.hadoop.conf.Configuration)"><B>streamBlockInAscii(InetSocketAddress, long, Token&lt;BlockTokenIdentifier&gt;, long, long, long, long, JspWriter, Configuration)</B></A> - 
类 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/JspHelper.html" title="org.apache.hadoop.hdfs.server.common 中的类">JspHelper</A> 中的静态方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/StreamFile.html" title="org.apache.hadoop.hdfs.server.namenode 中的类"><B>StreamFile</B></A> - <A HREF="./org/apache/hadoop/hdfs/server/namenode/package-summary.html">org.apache.hadoop.hdfs.server.namenode</A> 中的 类<DD>&nbsp;<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/StreamFile.html#StreamFile()"><B>StreamFile()</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/StreamFile.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">StreamFile</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSUtil.html#string2Bytes(java.lang.String)"><B>string2Bytes(String)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSUtil.html" title="org.apache.hadoop.hdfs 中的类">DFSUtil</A> 中的静态方法
<DD>Converts a string to a byte array using UTF8 encoding.
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/JspHelper.html#string2ChunkSizeToView(java.lang.String, int)"><B>string2ChunkSizeToView(String, int)</B></A> - 
类 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/JspHelper.html" title="org.apache.hadoop.hdfs.server.common 中的类">JspHelper</A> 中的静态方法
<DD>Convert a String to chunk-size-to-view.
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/Util.html#stringAsURI(java.lang.String)"><B>stringAsURI(String)</B></A> - 
类 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/Util.html" title="org.apache.hadoop.hdfs.server.common 中的类">Util</A> 中的静态方法
<DD>Interprets the passed string as a URI.
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/Util.html#stringCollectionAsURIs(java.util.Collection)"><B>stringCollectionAsURIs(Collection&lt;String&gt;)</B></A> - 
类 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/Util.html" title="org.apache.hadoop.hdfs.server.common 中的类">Util</A> 中的静态方法
<DD>Converts a collection of strings into a collection of URIs.
<DT><A HREF="./org/apache/hadoop/hdfs/DFSClient.html#stringifyToken(org.apache.hadoop.security.token.Token)"><B>stringifyToken(Token&lt;DelegationTokenIdentifier&gt;)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSClient.html" title="org.apache.hadoop.hdfs 中的类">DFSClient</A> 中的静态方法
<DD>A test method for printing out tokens
<DT><A HREF="./org/apache/hadoop/hdfs/server/balancer/Balancer.html#SUCCESS"><B>SUCCESS</B></A> - 
类 org.apache.hadoop.hdfs.server.balancer.<A HREF="./org/apache/hadoop/hdfs/server/balancer/Balancer.html" title="org.apache.hadoop.hdfs.server.balancer 中的类">Balancer</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/LayoutVersion.html#supports(org.apache.hadoop.hdfs.protocol.LayoutVersion.Feature, int)"><B>supports(LayoutVersion.Feature, int)</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/LayoutVersion.html" title="org.apache.hadoop.hdfs.protocol 中的类">LayoutVersion</A> 中的静态方法
<DD>Returns true if a given feature is supported in the given layout version
<DT><A HREF="./org/apache/hadoop/fs/Hdfs.html#supportsSymlinks()"><B>supportsSymlinks()</B></A> - 
类 org.apache.hadoop.fs.<A HREF="./org/apache/hadoop/fs/Hdfs.html" title="org.apache.hadoop.fs 中的类">Hdfs</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/metrics/NameNodeMetrics.html#syncs"><B>syncs</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.metrics.<A HREF="./org/apache/hadoop/hdfs/server/namenode/metrics/NameNodeMetrics.html" title="org.apache.hadoop.hdfs.server.namenode.metrics 中的类">NameNodeMetrics</A> 中的变量
<DD>&nbsp;
</DL>
<HR>
<A NAME="_T_"><!-- --></A><H2>
<B>T</B></H2>
<DL>
<DT><A HREF="./org/apache/hadoop/hdfs/BlockReader.html#takeSocket()"><B>takeSocket()</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/BlockReader.html" title="org.apache.hadoop.hdfs 中的类">BlockReader</A> 中的方法
<DD>Take the socket used to talk to the DN.
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/DatanodeDescriptor.BlockTargetPair.html#targets"><B>targets</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/DatanodeDescriptor.BlockTargetPair.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">DatanodeDescriptor.BlockTargetPair</A> 中的变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/util/DataTransferThrottler.html#throttle(long)"><B>throttle(long)</B></A> - 
类 org.apache.hadoop.hdfs.util.<A HREF="./org/apache/hadoop/hdfs/util/DataTransferThrottler.html" title="org.apache.hadoop.hdfs.util 中的类">DataTransferThrottler</A> 中的方法
<DD>Given the numOfBytes sent/received since last time throttle was called,
 make the current thread sleep if I/O rate is too fast
 compared to the given bandwidth.
<DT><A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeCPUStatus.html#toDump()"><B>toDump()</B></A> - 
类 org.apache.hadoop.hdfs.server.monitor.<A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeCPUStatus.html" title="org.apache.hadoop.hdfs.server.monitor 中的类">ServernodeCPUStatus</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeIOStatus.html#toDump()"><B>toDump()</B></A> - 
类 org.apache.hadoop.hdfs.server.monitor.<A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeIOStatus.html" title="org.apache.hadoop.hdfs.server.monitor 中的类">ServernodeIOStatus</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeMEMStatus.html#toDump()"><B>toDump()</B></A> - 
类 org.apache.hadoop.hdfs.server.monitor.<A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeMEMStatus.html" title="org.apache.hadoop.hdfs.server.monitor 中的类">ServernodeMEMStatus</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeNETStatus.html#toDump()"><B>toDump()</B></A> - 
类 org.apache.hadoop.hdfs.server.monitor.<A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeNETStatus.html" title="org.apache.hadoop.hdfs.server.monitor 中的类">ServernodeNETStatus</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/CancelDelegationTokenServlet.html#TOKEN"><B>TOKEN</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/CancelDelegationTokenServlet.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">CancelDelegationTokenServlet</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/RenewDelegationTokenServlet.html#TOKEN"><B>TOKEN</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/RenewDelegationTokenServlet.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">RenewDelegationTokenServlet</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/HdfsConstants.StartupOption.html#toNodeRole()"><B>toNodeRole()</B></A> - 
枚举 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/HdfsConstants.StartupOption.html" title="org.apache.hadoop.hdfs.server.common 中的枚举">HdfsConstants.StartupOption</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DFSClient.html#toString()"><B>toString()</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DFSClient.html" title="org.apache.hadoop.hdfs 中的类">DFSClient</A> 中的方法
<DD>
<DT><A HREF="./org/apache/hadoop/hdfs/DistributedFileSystem.html#toString()"><B>toString()</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DistributedFileSystem.html" title="org.apache.hadoop.hdfs 中的类">DistributedFileSystem</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/Block.html#toString()"><B>toString()</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/Block.html" title="org.apache.hadoop.hdfs.protocol 中的类">Block</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/CodingMatrix.html#toString()"><B>toString()</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/CodingMatrix.html" title="org.apache.hadoop.hdfs.protocol 中的类">CodingMatrix</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeID.html#toString()"><B>toString()</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeID.html" title="org.apache.hadoop.hdfs.protocol 中的类">DatanodeID</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.PacketHeader.html#toString()"><B>toString()</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.PacketHeader.html" title="org.apache.hadoop.hdfs.protocol 中的类">DataTransferProtocol.PacketHeader</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.PipelineAck.html#toString()"><B>toString()</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.PipelineAck.html" title="org.apache.hadoop.hdfs.protocol 中的类">DataTransferProtocol.PipelineAck</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/LocatedBlock.html#toString()"><B>toString()</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/LocatedBlock.html" title="org.apache.hadoop.hdfs.protocol 中的类">LocatedBlock</A> 中的方法
<DD>
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/LocatedBlocks.html#toString()"><B>toString()</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/LocatedBlocks.html" title="org.apache.hadoop.hdfs.protocol 中的类">LocatedBlocks</A> 中的方法
<DD>
<DT><A HREF="./org/apache/hadoop/hdfs/security/token/block/BlockTokenIdentifier.html#toString()"><B>toString()</B></A> - 
类 org.apache.hadoop.hdfs.security.token.block.<A HREF="./org/apache/hadoop/hdfs/security/token/block/BlockTokenIdentifier.html" title="org.apache.hadoop.hdfs.security.token.block 中的类">BlockTokenIdentifier</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/HdfsConstants.NamenodeRole.html#toString()"><B>toString()</B></A> - 
枚举 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/HdfsConstants.NamenodeRole.html" title="org.apache.hadoop.hdfs.server.common 中的枚举">HdfsConstants.NamenodeRole</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/UpgradeStatusReport.html#toString()"><B>toString()</B></A> - 
类 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/UpgradeStatusReport.html" title="org.apache.hadoop.hdfs.server.common 中的类">UpgradeStatusReport</A> 中的方法
<DD>Print basic upgradeStatus details.
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/DataNode.html#toString()"><B>toString()</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/DataNode.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">DataNode</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDataset.html#toString()"><B>toString()</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDataset.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">FSDataset</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.html#toString()"><B>toString()</B></A> - 
接口 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.html" title="org.apache.hadoop.hdfs.server.datanode 中的接口">FSDatasetInterface</A> 中的方法
<DD>Stringifies the name of the storage
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/ReplicaInfo.html#toString()"><B>toString()</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/ReplicaInfo.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">ReplicaInfo</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeCPUStatus.html#toString()"><B>toString()</B></A> - 
类 org.apache.hadoop.hdfs.server.monitor.<A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeCPUStatus.html" title="org.apache.hadoop.hdfs.server.monitor 中的类">ServernodeCPUStatus</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeIOStatus.html#toString()"><B>toString()</B></A> - 
类 org.apache.hadoop.hdfs.server.monitor.<A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeIOStatus.html" title="org.apache.hadoop.hdfs.server.monitor 中的类">ServernodeIOStatus</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeMEMStatus.html#toString()"><B>toString()</B></A> - 
类 org.apache.hadoop.hdfs.server.monitor.<A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeMEMStatus.html" title="org.apache.hadoop.hdfs.server.monitor 中的类">ServernodeMEMStatus</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeNETStatus.html#toString()"><B>toString()</B></A> - 
类 org.apache.hadoop.hdfs.server.monitor.<A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeNETStatus.html" title="org.apache.hadoop.hdfs.server.monitor 中的类">ServernodeNETStatus</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeRole.html#toString()"><B>toString()</B></A> - 
枚举 org.apache.hadoop.hdfs.server.monitor.<A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeRole.html" title="org.apache.hadoop.hdfs.server.monitor 中的枚举">ServernodeRole</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/BufferData.html#toString()"><B>toString()</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/BufferData.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">BufferData</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/CheckpointSignature.html#toString()"><B>toString()</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/CheckpointSignature.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">CheckpointSignature</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/LeaseManager.html#toString()"><B>toString()</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/LeaseManager.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">LeaseManager</A> 中的方法
<DD>
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/SecondaryNameNode.html#toString()"><B>toString()</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/SecondaryNameNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">SecondaryNameNode</A> 中的方法
<DD><B>已过时。</B>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/DatanodeRegistration.html#toString()"><B>toString()</B></A> - 
类 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/DatanodeRegistration.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">DatanodeRegistration</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/NamenodeRegistration.html#toString()"><B>toString()</B></A> - 
类 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/NamenodeRegistration.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">NamenodeRegistration</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/NodeRegistration.html#toString()"><B>toString()</B></A> - 
接口 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/NodeRegistration.html" title="org.apache.hadoop.hdfs.server.protocol 中的接口">NodeRegistration</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/util/LightWeightGSet.html#toString()"><B>toString()</B></A> - 
类 org.apache.hadoop.hdfs.util.<A HREF="./org/apache/hadoop/hdfs/util/LightWeightGSet.html" title="org.apache.hadoop.hdfs.util 中的类">LightWeightGSet</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/metrics/NameNodeMetrics.html#transactions"><B>transactions</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.metrics.<A HREF="./org/apache/hadoop/hdfs/server/namenode/metrics/NameNodeMetrics.html" title="org.apache.hadoop.hdfs.server.namenode.metrics 中的类">NameNodeMetrics</A> 中的变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/metrics/NameNodeMetrics.html#transactionsBatchedInSync"><B>transactionsBatchedInSync</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.metrics.<A HREF="./org/apache/hadoop/hdfs/server/namenode/metrics/NameNodeMetrics.html" title="org.apache.hadoop.hdfs.server.namenode.metrics 中的类">NameNodeMetrics</A> 中的变量
<DD>&nbsp;
</DL>
<HR>
<A NAME="_U_"><!-- --></A><H2>
<B>U</B></H2>
<DL>
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/UpgradeCommand.html#UC_ACTION_REPORT_STATUS"><B>UC_ACTION_REPORT_STATUS</B></A> - 
类 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/UpgradeCommand.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">UpgradeCommand</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/UpgradeCommand.html#UC_ACTION_START_UPGRADE"><B>UC_ACTION_START_UPGRADE</B></A> - 
类 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/UpgradeCommand.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">UpgradeCommand</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/HftpFileSystem.html#ugi"><B>ugi</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/HftpFileSystem.html" title="org.apache.hadoop.hdfs 中的类">HftpFileSystem</A> 中的变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDataset.html#unfinalizeBlock(org.apache.hadoop.hdfs.protocol.Block)"><B>unfinalizeBlock(Block)</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDataset.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">FSDataset</A> 中的方法
<DD>Remove the temporary block file (if any)
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.html#unfinalizeBlock(org.apache.hadoop.hdfs.protocol.Block)"><B>unfinalizeBlock(Block)</B></A> - 
接口 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.html" title="org.apache.hadoop.hdfs.server.datanode 中的接口">FSDatasetInterface</A> 中的方法
<DD>Unfinalizes the block previously opened for writing using writeToBlock.
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.PipelineAck.html#UNKOWN_SEQNO"><B>UNKOWN_SEQNO</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.PipelineAck.html" title="org.apache.hadoop.hdfs.protocol 中的类">DataTransferProtocol.PipelineAck</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDataset.html#unlinkBlock(org.apache.hadoop.hdfs.protocol.Block, int)"><B>unlinkBlock(Block, int)</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDataset.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">FSDataset</A> 中的方法
<DD>Make a copy of the block if this block is linked to an existing
 snapshot.
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/Storage.StorageDirectory.html#unlock()"><B>unlock()</B></A> - 
类 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/Storage.StorageDirectory.html" title="org.apache.hadoop.hdfs.server.common 中的类">Storage.StorageDirectory</A> 中的方法
<DD>Unlock storage.
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/Storage.html#unlockAll()"><B>unlockAll()</B></A> - 
类 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/Storage.html" title="org.apache.hadoop.hdfs.server.common 中的类">Storage</A> 中的方法
<DD>Unlock all storage directories.
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/UnregisteredNodeException.html" title="org.apache.hadoop.hdfs.protocol 中的类"><B>UnregisteredNodeException</B></A> - <A HREF="./org/apache/hadoop/hdfs/protocol/package-summary.html">org.apache.hadoop.hdfs.protocol</A> 中的 异常<DD>This exception is thrown when a node that has not previously 
 registered is trying to access the name node.<DT><A HREF="./org/apache/hadoop/hdfs/protocol/UnregisteredNodeException.html#UnregisteredNodeException(org.apache.hadoop.hdfs.server.protocol.NodeRegistration)"><B>UnregisteredNodeException(NodeRegistration)</B></A> - 
异常 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/UnregisteredNodeException.html" title="org.apache.hadoop.hdfs.protocol 中的类">UnregisteredNodeException</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/UnregisteredNodeException.html#UnregisteredNodeException(org.apache.hadoop.hdfs.protocol.DatanodeID, org.apache.hadoop.hdfs.protocol.DatanodeInfo)"><B>UnregisteredNodeException(DatanodeID, DatanodeInfo)</B></A> - 
异常 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/UnregisteredNodeException.html" title="org.apache.hadoop.hdfs.protocol 中的类">UnregisteredNodeException</A> 的构造方法
<DD>The exception is thrown if a different data-node claims the same
 storage id as the existing one.
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/UnresolvedPathException.html" title="org.apache.hadoop.hdfs.protocol 中的类"><B>UnresolvedPathException</B></A> - <A HREF="./org/apache/hadoop/hdfs/protocol/package-summary.html">org.apache.hadoop.hdfs.protocol</A> 中的 异常<DD>Thrown when a symbolic link is encountered in a path.<DT><A HREF="./org/apache/hadoop/hdfs/protocol/UnresolvedPathException.html#UnresolvedPathException(java.lang.String)"><B>UnresolvedPathException(String)</B></A> - 
异常 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/UnresolvedPathException.html" title="org.apache.hadoop.hdfs.protocol 中的类">UnresolvedPathException</A> 的构造方法
<DD>Used by RemoteException to instantiate an UnresolvedPathException.
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/UnresolvedPathException.html#UnresolvedPathException(java.lang.String, java.lang.String, java.lang.String, java.lang.String)"><B>UnresolvedPathException(String, String, String, String)</B></A> - 
异常 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/UnresolvedPathException.html" title="org.apache.hadoop.hdfs.protocol 中的类">UnresolvedPathException</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/UnsupportedActionException.html" title="org.apache.hadoop.hdfs.server.namenode 中的类"><B>UnsupportedActionException</B></A> - <A HREF="./org/apache/hadoop/hdfs/server/namenode/package-summary.html">org.apache.hadoop.hdfs.server.namenode</A> 中的 异常<DD>This exception is thrown when an operation is not supported.<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/UnsupportedActionException.html#UnsupportedActionException(java.lang.String)"><B>UnsupportedActionException(String)</B></A> - 
异常 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/UnsupportedActionException.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">UnsupportedActionException</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/ClientProtocol.html#updateBlockForPipeline(org.apache.hadoop.hdfs.protocol.Block, java.lang.String)"><B>updateBlockForPipeline(Block, String)</B></A> - 
接口 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/ClientProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的接口">ClientProtocol</A> 中的方法
<DD>Get a new generation stamp together with an access token for 
 a block under construction
 
 This method is called only when a client needs to recover a failed
 pipeline or set up a pipeline for appending to a block.
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html#updateBlockForPipeline(org.apache.hadoop.hdfs.protocol.Block, java.lang.String)"><B>updateBlockForPipeline(Block, String)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">NameNode</A> 中的方法
<DD>Get a new generation stamp together with an access token for 
 a block under construction
 
 This method is called only when a client needs to recover a failed
 pipeline or set up a pipeline for appending to a block.
<DT><A HREF="./org/apache/hadoop/hdfs/security/token/block/BlockTokenSecretManager.html#updateKeys()"><B>updateKeys()</B></A> - 
类 org.apache.hadoop.hdfs.security.token.block.<A HREF="./org/apache/hadoop/hdfs/security/token/block/BlockTokenSecretManager.html" title="org.apache.hadoop.hdfs.security.token.block 中的类">BlockTokenSecretManager</A> 中的方法
<DD>Update block keys, only to be used in master mode
<DT><A HREF="./org/apache/hadoop/hdfs/security/token/delegation/DelegationTokenSecretManager.html#updatePersistedMasterKey(org.apache.hadoop.security.token.delegation.DelegationKey)"><B>updatePersistedMasterKey(DelegationKey)</B></A> - 
类 org.apache.hadoop.hdfs.security.token.delegation.<A HREF="./org/apache/hadoop/hdfs/security/token/delegation/DelegationTokenSecretManager.html" title="org.apache.hadoop.hdfs.security.token.delegation 中的类">DelegationTokenSecretManager</A> 中的方法
<DD>Add a MasterKey to the list of keys.
<DT><A HREF="./org/apache/hadoop/hdfs/security/token/delegation/DelegationTokenSecretManager.html#updatePersistedTokenCancellation(org.apache.hadoop.hdfs.security.token.delegation.DelegationTokenIdentifier)"><B>updatePersistedTokenCancellation(DelegationTokenIdentifier)</B></A> - 
类 org.apache.hadoop.hdfs.security.token.delegation.<A HREF="./org/apache/hadoop/hdfs/security/token/delegation/DelegationTokenSecretManager.html" title="org.apache.hadoop.hdfs.security.token.delegation 中的类">DelegationTokenSecretManager</A> 中的方法
<DD>Update the token cache with the cancel record in edit logs
<DT><A HREF="./org/apache/hadoop/hdfs/security/token/delegation/DelegationTokenSecretManager.html#updatePersistedTokenRenewal(org.apache.hadoop.hdfs.security.token.delegation.DelegationTokenIdentifier, long)"><B>updatePersistedTokenRenewal(DelegationTokenIdentifier, long)</B></A> - 
类 org.apache.hadoop.hdfs.security.token.delegation.<A HREF="./org/apache/hadoop/hdfs/security/token/delegation/DelegationTokenSecretManager.html" title="org.apache.hadoop.hdfs.security.token.delegation 中的类">DelegationTokenSecretManager</A> 中的方法
<DD>Update the token cache with renewal record in edit logs.
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/ClientProtocol.html#updatePipeline(java.lang.String, org.apache.hadoop.hdfs.protocol.Block, org.apache.hadoop.hdfs.protocol.Block, org.apache.hadoop.hdfs.protocol.DatanodeID[])"><B>updatePipeline(String, Block, Block, DatanodeID[])</B></A> - 
接口 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/ClientProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的接口">ClientProtocol</A> 中的方法
<DD>Update a pipeline for a block under construction
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html#updatePipeline(java.lang.String, org.apache.hadoop.hdfs.protocol.Block, org.apache.hadoop.hdfs.protocol.Block, org.apache.hadoop.hdfs.protocol.DatanodeID[])"><B>updatePipeline(String, Block, Block, DatanodeID[])</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">NameNode</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/HftpFileSystem.html#updateQuery(java.lang.String)"><B>updateQuery(String)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/HftpFileSystem.html" title="org.apache.hadoop.hdfs 中的类">HftpFileSystem</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeID.html#updateRegInfo(org.apache.hadoop.hdfs.protocol.DatanodeID)"><B>updateRegInfo(DatanodeID)</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeID.html" title="org.apache.hadoop.hdfs.protocol 中的类">DatanodeID</A> 中的方法
<DD>Update fields when a new registration request comes in.
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/DatanodeDescriptor.html#updateRegInfo(org.apache.hadoop.hdfs.protocol.DatanodeID)"><B>updateRegInfo(DatanodeID)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/DatanodeDescriptor.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">DatanodeDescriptor</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/DataNode.html#updateReplicaUnderRecovery(org.apache.hadoop.hdfs.protocol.Block, long, long)"><B>updateReplicaUnderRecovery(Block, long, long)</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/DataNode.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">DataNode</A> 中的方法
<DD>Update replica with the new generation stamp and length.
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDataset.html#updateReplicaUnderRecovery(org.apache.hadoop.hdfs.protocol.Block, long, long)"><B>updateReplicaUnderRecovery(Block, long, long)</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDataset.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">FSDataset</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.html#updateReplicaUnderRecovery(org.apache.hadoop.hdfs.protocol.Block, long, long)"><B>updateReplicaUnderRecovery(Block, long, long)</B></A> - 
接口 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/FSDatasetInterface.html" title="org.apache.hadoop.hdfs.server.datanode 中的接口">FSDatasetInterface</A> 中的方法
<DD>Update replica's generation stamp and length and finalize it.
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/InterDatanodeProtocol.html#updateReplicaUnderRecovery(org.apache.hadoop.hdfs.protocol.Block, long, long)"><B>updateReplicaUnderRecovery(Block, long, long)</B></A> - 
接口 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/InterDatanodeProtocol.html" title="org.apache.hadoop.hdfs.server.protocol 中的接口">InterDatanodeProtocol</A> 中的方法
<DD>Update replica with the new generation stamp and length.
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/Upgradeable.html" title="org.apache.hadoop.hdfs.server.common 中的接口"><B>Upgradeable</B></A> - <A HREF="./org/apache/hadoop/hdfs/server/common/package-summary.html">org.apache.hadoop.hdfs.server.common</A> 中的 接口<DD>Common interface for distributed upgrade objects.<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/UpgradeCommand.html" title="org.apache.hadoop.hdfs.server.protocol 中的类"><B>UpgradeCommand</B></A> - <A HREF="./org/apache/hadoop/hdfs/server/protocol/package-summary.html">org.apache.hadoop.hdfs.server.protocol</A> 中的 类<DD>This as a generic distributed upgrade command.<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/UpgradeCommand.html#UpgradeCommand()"><B>UpgradeCommand()</B></A> - 
类 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/UpgradeCommand.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">UpgradeCommand</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/UpgradeCommand.html#UpgradeCommand(int, int, short)"><B>UpgradeCommand(int, int, short)</B></A> - 
类 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/UpgradeCommand.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">UpgradeCommand</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/UpgradeManager.html" title="org.apache.hadoop.hdfs.server.common 中的类"><B>UpgradeManager</B></A> - <A HREF="./org/apache/hadoop/hdfs/server/common/package-summary.html">org.apache.hadoop.hdfs.server.common</A> 中的 类<DD>Generic upgrade manager.<DT><A HREF="./org/apache/hadoop/hdfs/server/common/UpgradeManager.html#UpgradeManager()"><B>UpgradeManager()</B></A> - 
类 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/UpgradeManager.html" title="org.apache.hadoop.hdfs.server.common 中的类">UpgradeManager</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/UpgradeObject.html" title="org.apache.hadoop.hdfs.server.common 中的类"><B>UpgradeObject</B></A> - <A HREF="./org/apache/hadoop/hdfs/server/common/package-summary.html">org.apache.hadoop.hdfs.server.common</A> 中的 类<DD>Abstract upgrade object.<DT><A HREF="./org/apache/hadoop/hdfs/server/common/UpgradeObject.html#UpgradeObject()"><B>UpgradeObject()</B></A> - 
类 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/UpgradeObject.html" title="org.apache.hadoop.hdfs.server.common 中的类">UpgradeObject</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/UpgradeObjectCollection.html" title="org.apache.hadoop.hdfs.server.common 中的类"><B>UpgradeObjectCollection</B></A> - <A HREF="./org/apache/hadoop/hdfs/server/common/package-summary.html">org.apache.hadoop.hdfs.server.common</A> 中的 类<DD>Collection of upgrade objects.<DT><A HREF="./org/apache/hadoop/hdfs/server/common/UpgradeObjectCollection.html#UpgradeObjectCollection()"><B>UpgradeObjectCollection()</B></A> - 
类 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/UpgradeObjectCollection.html" title="org.apache.hadoop.hdfs.server.common 中的类">UpgradeObjectCollection</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/UpgradeObjectDatanode.html" title="org.apache.hadoop.hdfs.server.datanode 中的类"><B>UpgradeObjectDatanode</B></A> - <A HREF="./org/apache/hadoop/hdfs/server/datanode/package-summary.html">org.apache.hadoop.hdfs.server.datanode</A> 中的 类<DD>Base class for data-node upgrade objects.<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/UpgradeObjectDatanode.html#UpgradeObjectDatanode()"><B>UpgradeObjectDatanode()</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.<A HREF="./org/apache/hadoop/hdfs/server/datanode/UpgradeObjectDatanode.html" title="org.apache.hadoop.hdfs.server.datanode 中的类">UpgradeObjectDatanode</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/UpgradeObjectNamenode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类"><B>UpgradeObjectNamenode</B></A> - <A HREF="./org/apache/hadoop/hdfs/server/namenode/package-summary.html">org.apache.hadoop.hdfs.server.namenode</A> 中的 类<DD>Base class for name-node upgrade objects.<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/UpgradeObjectNamenode.html#UpgradeObjectNamenode()"><B>UpgradeObjectNamenode()</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/UpgradeObjectNamenode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">UpgradeObjectNamenode</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/tools/DFSAdmin.html#upgradeProgress(java.lang.String[], int)"><B>upgradeProgress(String[], int)</B></A> - 
类 org.apache.hadoop.hdfs.tools.<A HREF="./org/apache/hadoop/hdfs/tools/DFSAdmin.html" title="org.apache.hadoop.hdfs.tools 中的类">DFSAdmin</A> 中的方法
<DD>Command to request current distributed upgrade status, 
 a detailed status, or to force the upgrade to proceed.
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/UpgradeManager.html#upgradeState"><B>upgradeState</B></A> - 
类 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/UpgradeManager.html" title="org.apache.hadoop.hdfs.server.common 中的类">UpgradeManager</A> 中的变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/UpgradeStatusReport.html#upgradeStatus"><B>upgradeStatus</B></A> - 
类 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/UpgradeStatusReport.html" title="org.apache.hadoop.hdfs.server.common 中的类">UpgradeStatusReport</A> 中的变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/UpgradeStatusReport.html" title="org.apache.hadoop.hdfs.server.common 中的类"><B>UpgradeStatusReport</B></A> - <A HREF="./org/apache/hadoop/hdfs/server/common/package-summary.html">org.apache.hadoop.hdfs.server.common</A> 中的 类<DD>Base upgrade upgradeStatus class.<DT><A HREF="./org/apache/hadoop/hdfs/server/common/UpgradeStatusReport.html#UpgradeStatusReport()"><B>UpgradeStatusReport()</B></A> - 
类 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/UpgradeStatusReport.html" title="org.apache.hadoop.hdfs.server.common 中的类">UpgradeStatusReport</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/UpgradeStatusReport.html#UpgradeStatusReport(int, short, boolean)"><B>UpgradeStatusReport(int, short, boolean)</B></A> - 
类 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/UpgradeStatusReport.html" title="org.apache.hadoop.hdfs.server.common 中的类">UpgradeStatusReport</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/UpgradeManager.html#upgradeVersion"><B>upgradeVersion</B></A> - 
类 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/UpgradeManager.html" title="org.apache.hadoop.hdfs.server.common 中的类">UpgradeManager</A> 中的变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/Util.html" title="org.apache.hadoop.hdfs.server.common 中的类"><B>Util</B></A> - <A HREF="./org/apache/hadoop/hdfs/server/common/package-summary.html">org.apache.hadoop.hdfs.server.common</A> 中的 类<DD>&nbsp;<DT><A HREF="./org/apache/hadoop/hdfs/server/common/Util.html#Util()"><B>Util()</B></A> - 
类 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/Util.html" title="org.apache.hadoop.hdfs.server.common 中的类">Util</A> 的构造方法
<DD>&nbsp;
</DL>
<HR>
<A NAME="_V_"><!-- --></A><H2>
<B>V</B></H2>
<DL>
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/JspHelper.html#validateLong(java.lang.String)"><B>validateLong(String)</B></A> - 
类 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/JspHelper.html" title="org.apache.hadoop.hdfs.server.common 中的类">JspHelper</A> 中的静态方法
<DD>Validate a long value.
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/JspHelper.html#validatePath(java.lang.String)"><B>validatePath(String)</B></A> - 
类 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/JspHelper.html" title="org.apache.hadoop.hdfs.server.common 中的类">JspHelper</A> 中的静态方法
<DD>Validate filename.
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/JspHelper.html#validateURL(java.lang.String)"><B>validateURL(String)</B></A> - 
类 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/JspHelper.html" title="org.apache.hadoop.hdfs.server.common 中的类">JspHelper</A> 中的静态方法
<DD>Validate a URL.
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeInfo.AdminStates.html#valueOf(java.lang.String)"><B>valueOf(String)</B></A> - 
枚举 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeInfo.AdminStates.html" title="org.apache.hadoop.hdfs.protocol 中的枚举">DatanodeInfo.AdminStates</A> 中的静态方法
<DD>返回带有指定名称的该类型的枚举常量。
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.BlockConstructionStage.html#valueOf(java.lang.String)"><B>valueOf(String)</B></A> - 
枚举 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.BlockConstructionStage.html" title="org.apache.hadoop.hdfs.protocol 中的枚举">DataTransferProtocol.BlockConstructionStage</A> 中的静态方法
<DD>返回带有指定名称的该类型的枚举常量。
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.Op.html#valueOf(java.lang.String)"><B>valueOf(String)</B></A> - 
枚举 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.Op.html" title="org.apache.hadoop.hdfs.protocol 中的枚举">DataTransferProtocol.Op</A> 中的静态方法
<DD>返回带有指定名称的该类型的枚举常量。
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.Status.html#valueOf(java.lang.String)"><B>valueOf(String)</B></A> - 
枚举 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.Status.html" title="org.apache.hadoop.hdfs.protocol 中的枚举">DataTransferProtocol.Status</A> 中的静态方法
<DD>返回带有指定名称的该类型的枚举常量。
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/FSConstants.DatanodeReportType.html#valueOf(java.lang.String)"><B>valueOf(String)</B></A> - 
枚举 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/FSConstants.DatanodeReportType.html" title="org.apache.hadoop.hdfs.protocol 中的枚举">FSConstants.DatanodeReportType</A> 中的静态方法
<DD>返回带有指定名称的该类型的枚举常量。
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/FSConstants.SafeModeAction.html#valueOf(java.lang.String)"><B>valueOf(String)</B></A> - 
枚举 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/FSConstants.SafeModeAction.html" title="org.apache.hadoop.hdfs.protocol 中的枚举">FSConstants.SafeModeAction</A> 中的静态方法
<DD>返回带有指定名称的该类型的枚举常量。
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/FSConstants.UpgradeAction.html#valueOf(java.lang.String)"><B>valueOf(String)</B></A> - 
枚举 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/FSConstants.UpgradeAction.html" title="org.apache.hadoop.hdfs.protocol 中的枚举">FSConstants.UpgradeAction</A> 中的静态方法
<DD>返回带有指定名称的该类型的枚举常量。
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/LayoutVersion.Feature.html#valueOf(java.lang.String)"><B>valueOf(String)</B></A> - 
枚举 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/LayoutVersion.Feature.html" title="org.apache.hadoop.hdfs.protocol 中的枚举">LayoutVersion.Feature</A> 中的静态方法
<DD>返回带有指定名称的该类型的枚举常量。
<DT><A HREF="./org/apache/hadoop/hdfs/security/token/block/BlockTokenSecretManager.AccessMode.html#valueOf(java.lang.String)"><B>valueOf(String)</B></A> - 
枚举 org.apache.hadoop.hdfs.security.token.block.<A HREF="./org/apache/hadoop/hdfs/security/token/block/BlockTokenSecretManager.AccessMode.html" title="org.apache.hadoop.hdfs.security.token.block 中的枚举">BlockTokenSecretManager.AccessMode</A> 中的静态方法
<DD>返回带有指定名称的该类型的枚举常量。
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/HdfsConstants.BlockUCState.html#valueOf(java.lang.String)"><B>valueOf(String)</B></A> - 
枚举 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/HdfsConstants.BlockUCState.html" title="org.apache.hadoop.hdfs.server.common 中的枚举">HdfsConstants.BlockUCState</A> 中的静态方法
<DD>返回带有指定名称的该类型的枚举常量。
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/HdfsConstants.NamenodeRole.html#valueOf(java.lang.String)"><B>valueOf(String)</B></A> - 
枚举 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/HdfsConstants.NamenodeRole.html" title="org.apache.hadoop.hdfs.server.common 中的枚举">HdfsConstants.NamenodeRole</A> 中的静态方法
<DD>返回带有指定名称的该类型的枚举常量。
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/HdfsConstants.NodeType.html#valueOf(java.lang.String)"><B>valueOf(String)</B></A> - 
枚举 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/HdfsConstants.NodeType.html" title="org.apache.hadoop.hdfs.server.common 中的枚举">HdfsConstants.NodeType</A> 中的静态方法
<DD>返回带有指定名称的该类型的枚举常量。
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/HdfsConstants.ReplicaState.html#valueOf(java.lang.String)"><B>valueOf(String)</B></A> - 
枚举 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/HdfsConstants.ReplicaState.html" title="org.apache.hadoop.hdfs.server.common 中的枚举">HdfsConstants.ReplicaState</A> 中的静态方法
<DD>返回带有指定名称的该类型的枚举常量。
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/HdfsConstants.StartupOption.html#valueOf(java.lang.String)"><B>valueOf(String)</B></A> - 
枚举 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/HdfsConstants.StartupOption.html" title="org.apache.hadoop.hdfs.server.common 中的枚举">HdfsConstants.StartupOption</A> 中的静态方法
<DD>返回带有指定名称的该类型的枚举常量。
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/Storage.StorageState.html#valueOf(java.lang.String)"><B>valueOf(String)</B></A> - 
枚举 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/Storage.StorageState.html" title="org.apache.hadoop.hdfs.server.common 中的枚举">Storage.StorageState</A> 中的静态方法
<DD>返回带有指定名称的该类型的枚举常量。
<DT><A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeRole.html#valueOf(java.lang.String)"><B>valueOf(String)</B></A> - 
枚举 org.apache.hadoop.hdfs.server.monitor.<A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeRole.html" title="org.apache.hadoop.hdfs.server.monitor 中的枚举">ServernodeRole</A> 中的静态方法
<DD>返回带有指定名称的该类型的枚举常量。
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeInfo.AdminStates.html#values()"><B>values()</B></A> - 
枚举 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeInfo.AdminStates.html" title="org.apache.hadoop.hdfs.protocol 中的枚举">DatanodeInfo.AdminStates</A> 中的静态方法
<DD>按照声明该枚举类型的常量的顺序，返回
包含这些常量的数组。
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.BlockConstructionStage.html#values()"><B>values()</B></A> - 
枚举 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.BlockConstructionStage.html" title="org.apache.hadoop.hdfs.protocol 中的枚举">DataTransferProtocol.BlockConstructionStage</A> 中的静态方法
<DD>按照声明该枚举类型的常量的顺序，返回
包含这些常量的数组。
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.Op.html#values()"><B>values()</B></A> - 
枚举 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.Op.html" title="org.apache.hadoop.hdfs.protocol 中的枚举">DataTransferProtocol.Op</A> 中的静态方法
<DD>按照声明该枚举类型的常量的顺序，返回
包含这些常量的数组。
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.Status.html#values()"><B>values()</B></A> - 
枚举 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.Status.html" title="org.apache.hadoop.hdfs.protocol 中的枚举">DataTransferProtocol.Status</A> 中的静态方法
<DD>按照声明该枚举类型的常量的顺序，返回
包含这些常量的数组。
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/FSConstants.DatanodeReportType.html#values()"><B>values()</B></A> - 
枚举 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/FSConstants.DatanodeReportType.html" title="org.apache.hadoop.hdfs.protocol 中的枚举">FSConstants.DatanodeReportType</A> 中的静态方法
<DD>按照声明该枚举类型的常量的顺序，返回
包含这些常量的数组。
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/FSConstants.SafeModeAction.html#values()"><B>values()</B></A> - 
枚举 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/FSConstants.SafeModeAction.html" title="org.apache.hadoop.hdfs.protocol 中的枚举">FSConstants.SafeModeAction</A> 中的静态方法
<DD>按照声明该枚举类型的常量的顺序，返回
包含这些常量的数组。
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/FSConstants.UpgradeAction.html#values()"><B>values()</B></A> - 
枚举 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/FSConstants.UpgradeAction.html" title="org.apache.hadoop.hdfs.protocol 中的枚举">FSConstants.UpgradeAction</A> 中的静态方法
<DD>按照声明该枚举类型的常量的顺序，返回
包含这些常量的数组。
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/LayoutVersion.Feature.html#values()"><B>values()</B></A> - 
枚举 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/LayoutVersion.Feature.html" title="org.apache.hadoop.hdfs.protocol 中的枚举">LayoutVersion.Feature</A> 中的静态方法
<DD>按照声明该枚举类型的常量的顺序，返回
包含这些常量的数组。
<DT><A HREF="./org/apache/hadoop/hdfs/security/token/block/BlockTokenSecretManager.AccessMode.html#values()"><B>values()</B></A> - 
枚举 org.apache.hadoop.hdfs.security.token.block.<A HREF="./org/apache/hadoop/hdfs/security/token/block/BlockTokenSecretManager.AccessMode.html" title="org.apache.hadoop.hdfs.security.token.block 中的枚举">BlockTokenSecretManager.AccessMode</A> 中的静态方法
<DD>按照声明该枚举类型的常量的顺序，返回
包含这些常量的数组。
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/HdfsConstants.BlockUCState.html#values()"><B>values()</B></A> - 
枚举 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/HdfsConstants.BlockUCState.html" title="org.apache.hadoop.hdfs.server.common 中的枚举">HdfsConstants.BlockUCState</A> 中的静态方法
<DD>按照声明该枚举类型的常量的顺序，返回
包含这些常量的数组。
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/HdfsConstants.NamenodeRole.html#values()"><B>values()</B></A> - 
枚举 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/HdfsConstants.NamenodeRole.html" title="org.apache.hadoop.hdfs.server.common 中的枚举">HdfsConstants.NamenodeRole</A> 中的静态方法
<DD>按照声明该枚举类型的常量的顺序，返回
包含这些常量的数组。
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/HdfsConstants.NodeType.html#values()"><B>values()</B></A> - 
枚举 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/HdfsConstants.NodeType.html" title="org.apache.hadoop.hdfs.server.common 中的枚举">HdfsConstants.NodeType</A> 中的静态方法
<DD>按照声明该枚举类型的常量的顺序，返回
包含这些常量的数组。
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/HdfsConstants.ReplicaState.html#values()"><B>values()</B></A> - 
枚举 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/HdfsConstants.ReplicaState.html" title="org.apache.hadoop.hdfs.server.common 中的枚举">HdfsConstants.ReplicaState</A> 中的静态方法
<DD>按照声明该枚举类型的常量的顺序，返回
包含这些常量的数组。
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/HdfsConstants.StartupOption.html#values()"><B>values()</B></A> - 
枚举 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/HdfsConstants.StartupOption.html" title="org.apache.hadoop.hdfs.server.common 中的枚举">HdfsConstants.StartupOption</A> 中的静态方法
<DD>按照声明该枚举类型的常量的顺序，返回
包含这些常量的数组。
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/Storage.StorageState.html#values()"><B>values()</B></A> - 
枚举 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/Storage.StorageState.html" title="org.apache.hadoop.hdfs.server.common 中的枚举">Storage.StorageState</A> 中的静态方法
<DD>按照声明该枚举类型的常量的顺序，返回
包含这些常量的数组。
<DT><A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeRole.html#values()"><B>values()</B></A> - 
枚举 org.apache.hadoop.hdfs.server.monitor.<A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeRole.html" title="org.apache.hadoop.hdfs.server.monitor 中的枚举">ServernodeRole</A> 中的静态方法
<DD>按照声明该枚举类型的常量的顺序，返回
包含这些常量的数组。
<DT><A HREF="./org/apache/hadoop/hdfs/HsftpFileSystem.DummyHostnameVerifier.html#verify(java.lang.String, javax.net.ssl.SSLSession)"><B>verify(String, SSLSession)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/HsftpFileSystem.DummyHostnameVerifier.html" title="org.apache.hadoop.hdfs 中的类">HsftpFileSystem.DummyHostnameVerifier</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/BlockPlacementPolicy.html#verifyBlockPlacement(java.lang.String, org.apache.hadoop.hdfs.protocol.LocatedBlock, int)"><B>verifyBlockPlacement(String, LocatedBlock, int)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/BlockPlacementPolicy.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">BlockPlacementPolicy</A> 中的方法
<DD>Verify that the block is replicated on at least minRacks different racks
 if there is more than minRacks rack in the system.
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/BlockPlacementPolicyDefault.html#verifyBlockPlacement(java.lang.String, org.apache.hadoop.hdfs.protocol.LocatedBlock, int)"><B>verifyBlockPlacement(String, LocatedBlock, int)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/BlockPlacementPolicyDefault.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">BlockPlacementPolicyDefault</A> 中的方法
<DD>Verify that the block is replicated on at least minRacks different racks
 if there is more than minRacks rack in the system.
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html#verifyRequest(org.apache.hadoop.hdfs.server.protocol.NodeRegistration)"><B>verifyRequest(NodeRegistration)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">NameNode</A> 中的方法
<DD>Verify request.
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html#verifyVersion(int)"><B>verifyVersion(int)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">NameNode</A> 中的方法
<DD>Verify version.
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/UpgradeStatusReport.html#version"><B>version</B></A> - 
类 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/UpgradeStatusReport.html" title="org.apache.hadoop.hdfs.server.common 中的类">UpgradeStatusReport</A> 中的变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/ClientDatanodeProtocol.html#versionID"><B>versionID</B></A> - 
接口 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/ClientDatanodeProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的接口">ClientDatanodeProtocol</A> 中的静态变量
<DD>6: recoverBlock() removed.
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/ClientProtocol.html#versionID"><B>versionID</B></A> - 
接口 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/ClientProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的接口">ClientProtocol</A> 中的静态变量
<DD>Compared to the previous version the following changes have been introduced:
 (Only the latest change is reflected.
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/DatanodeProtocol.html#versionID"><B>versionID</B></A> - 
接口 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/DatanodeProtocol.html" title="org.apache.hadoop.hdfs.server.protocol 中的接口">DatanodeProtocol</A> 中的静态变量
<DD>26: remove getBlockLocations optimization
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/InterDatanodeProtocol.html#versionID"><B>versionID</B></A> - 
接口 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/InterDatanodeProtocol.html" title="org.apache.hadoop.hdfs.server.protocol 中的接口">InterDatanodeProtocol</A> 中的静态变量
<DD>5: getBlockMetaDataInfo(), updateBlock() removed.
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/NamenodeProtocol.html#versionID"><B>versionID</B></A> - 
接口 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/NamenodeProtocol.html" title="org.apache.hadoop.hdfs.server.protocol 中的接口">NamenodeProtocol</A> 中的静态变量
<DD>Compared to the previous version the following changes have been introduced:
 (Only the latest change is reflected.
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html#versionRequest()"><B>versionRequest()</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/NameNode.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">NameNode</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/DatanodeProtocol.html#versionRequest()"><B>versionRequest()</B></A> - 
接口 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/DatanodeProtocol.html" title="org.apache.hadoop.hdfs.server.protocol 中的接口">DatanodeProtocol</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/NamenodeProtocol.html#versionRequest()"><B>versionRequest()</B></A> - 
接口 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/NamenodeProtocol.html" title="org.apache.hadoop.hdfs.server.protocol 中的接口">NamenodeProtocol</A> 中的方法
<DD>Request name-node version and storage information.
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/metrics/DataNodeMetrics.html#volumeFailures"><B>volumeFailures</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.metrics.<A HREF="./org/apache/hadoop/hdfs/server/datanode/metrics/DataNodeMetrics.html" title="org.apache.hadoop.hdfs.server.datanode.metrics 中的类">DataNodeMetrics</A> 中的变量
<DD>&nbsp;
</DL>
<HR>
<A NAME="_W_"><!-- --></A><H2>
<B>W</B></H2>
<DL>
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/JspHelper.html#WEB_UGI_PROPERTY_NAME"><B>WEB_UGI_PROPERTY_NAME</B></A> - 
类 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/JspHelper.html" title="org.apache.hadoop.hdfs.server.common 中的类">JspHelper</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/Block.html#write(java.io.DataOutput)"><B>write(DataOutput)</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/Block.html" title="org.apache.hadoop.hdfs.protocol 中的类">Block</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/CodingMatrix.html#write(java.io.DataOutput)"><B>write(DataOutput)</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/CodingMatrix.html" title="org.apache.hadoop.hdfs.protocol 中的类">CodingMatrix</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeID.html#write(java.io.DataOutput)"><B>write(DataOutput)</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeID.html" title="org.apache.hadoop.hdfs.protocol 中的类">DatanodeID</A> 中的方法
<DD>
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeInfo.html#write(java.io.DataOutput)"><B>write(DataOutput)</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeInfo.html" title="org.apache.hadoop.hdfs.protocol 中的类">DatanodeInfo</A> 中的方法
<DD>
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.Op.html#write(java.io.DataOutput)"><B>write(DataOutput)</B></A> - 
枚举 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.Op.html" title="org.apache.hadoop.hdfs.protocol 中的枚举">DataTransferProtocol.Op</A> 中的方法
<DD>Write to out
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.PacketHeader.html#write(java.io.DataOutput)"><B>write(DataOutput)</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.PacketHeader.html" title="org.apache.hadoop.hdfs.protocol 中的类">DataTransferProtocol.PacketHeader</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.PipelineAck.html#write(java.io.DataOutput)"><B>write(DataOutput)</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.PipelineAck.html" title="org.apache.hadoop.hdfs.protocol 中的类">DataTransferProtocol.PipelineAck</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.Status.html#write(java.io.DataOutput)"><B>write(DataOutput)</B></A> - 
枚举 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.Status.html" title="org.apache.hadoop.hdfs.protocol 中的枚举">DataTransferProtocol.Status</A> 中的方法
<DD>Write to out
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DirectoryListing.html#write(java.io.DataOutput)"><B>write(DataOutput)</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DirectoryListing.html" title="org.apache.hadoop.hdfs.protocol 中的类">DirectoryListing</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/HdfsFileStatus.html#write(java.io.DataOutput)"><B>write(DataOutput)</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/HdfsFileStatus.html" title="org.apache.hadoop.hdfs.protocol 中的类">HdfsFileStatus</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/HdfsLocatedFileStatus.html#write(java.io.DataOutput)"><B>write(DataOutput)</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/HdfsLocatedFileStatus.html" title="org.apache.hadoop.hdfs.protocol 中的类">HdfsLocatedFileStatus</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/LocatedBlock.html#write(java.io.DataOutput)"><B>write(DataOutput)</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/LocatedBlock.html" title="org.apache.hadoop.hdfs.protocol 中的类">LocatedBlock</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/LocatedBlocks.html#write(java.io.DataOutput)"><B>write(DataOutput)</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/LocatedBlocks.html" title="org.apache.hadoop.hdfs.protocol 中的类">LocatedBlocks</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/LocatedBlockWithCodingFactor.html#write(java.io.DataOutput)"><B>write(DataOutput)</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/LocatedBlockWithCodingFactor.html" title="org.apache.hadoop.hdfs.protocol 中的类">LocatedBlockWithCodingFactor</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/security/token/block/BlockTokenIdentifier.html#write(java.io.DataOutput)"><B>write(DataOutput)</B></A> - 
类 org.apache.hadoop.hdfs.security.token.block.<A HREF="./org/apache/hadoop/hdfs/security/token/block/BlockTokenIdentifier.html" title="org.apache.hadoop.hdfs.security.token.block 中的类">BlockTokenIdentifier</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/security/token/block/ExportedBlockKeys.html#write(java.io.DataOutput)"><B>write(DataOutput)</B></A> - 
类 org.apache.hadoop.hdfs.security.token.block.<A HREF="./org/apache/hadoop/hdfs/security/token/block/ExportedBlockKeys.html" title="org.apache.hadoop.hdfs.security.token.block 中的类">ExportedBlockKeys</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/HdfsConstants.ReplicaState.html#write(java.io.DataOutput)"><B>write(DataOutput)</B></A> - 
枚举 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/HdfsConstants.ReplicaState.html" title="org.apache.hadoop.hdfs.server.common 中的枚举">HdfsConstants.ReplicaState</A> 中的方法
<DD>Write to out
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/Storage.StorageDirectory.html#write()"><B>write()</B></A> - 
类 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/Storage.StorageDirectory.html" title="org.apache.hadoop.hdfs.server.common 中的类">Storage.StorageDirectory</A> 中的方法
<DD>Write version file.
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/Storage.StorageDirectory.html#write(java.io.File)"><B>write(File)</B></A> - 
类 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/Storage.StorageDirectory.html" title="org.apache.hadoop.hdfs.server.common 中的类">Storage.StorageDirectory</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/StorageInfo.html#write(java.io.DataOutput)"><B>write(DataOutput)</B></A> - 
类 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/StorageInfo.html" title="org.apache.hadoop.hdfs.server.common 中的类">StorageInfo</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/UpgradeStatusReport.html#write(java.io.DataOutput)"><B>write(DataOutput)</B></A> - 
类 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/UpgradeStatusReport.html" title="org.apache.hadoop.hdfs.server.common 中的类">UpgradeStatusReport</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeCPUStatus.html#write(java.io.DataOutput)"><B>write(DataOutput)</B></A> - 
类 org.apache.hadoop.hdfs.server.monitor.<A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeCPUStatus.html" title="org.apache.hadoop.hdfs.server.monitor 中的类">ServernodeCPUStatus</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeIOStatus.html#write(java.io.DataOutput)"><B>write(DataOutput)</B></A> - 
类 org.apache.hadoop.hdfs.server.monitor.<A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeIOStatus.html" title="org.apache.hadoop.hdfs.server.monitor 中的类">ServernodeIOStatus</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeMEMStatus.html#write(java.io.DataOutput)"><B>write(DataOutput)</B></A> - 
类 org.apache.hadoop.hdfs.server.monitor.<A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeMEMStatus.html" title="org.apache.hadoop.hdfs.server.monitor 中的类">ServernodeMEMStatus</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeNETStatus.html#write(java.io.DataOutput)"><B>write(DataOutput)</B></A> - 
类 org.apache.hadoop.hdfs.server.monitor.<A HREF="./org/apache/hadoop/hdfs/server/monitor/ServernodeNETStatus.html" title="org.apache.hadoop.hdfs.server.monitor 中的类">ServernodeNETStatus</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/BufferData.html#write(java.io.RandomAccessFile)"><B>write(RandomAccessFile)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/BufferData.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">BufferData</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/CheckpointSignature.html#write(java.io.DataOutput)"><B>write(DataOutput)</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/CheckpointSignature.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">CheckpointSignature</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/BlockCommand.html#write(java.io.DataOutput)"><B>write(DataOutput)</B></A> - 
类 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/BlockCommand.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">BlockCommand</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/BlockRecoveryCommand.RecoveringBlock.html#write(java.io.DataOutput)"><B>write(DataOutput)</B></A> - 
类 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/BlockRecoveryCommand.RecoveringBlock.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">BlockRecoveryCommand.RecoveringBlock</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/BlockRecoveryCommand.html#write(java.io.DataOutput)"><B>write(DataOutput)</B></A> - 
类 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/BlockRecoveryCommand.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">BlockRecoveryCommand</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/BlocksWithLocations.BlockWithLocations.html#write(java.io.DataOutput)"><B>write(DataOutput)</B></A> - 
类 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/BlocksWithLocations.BlockWithLocations.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">BlocksWithLocations.BlockWithLocations</A> 中的方法
<DD>serialization method
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/BlocksWithLocations.html#write(java.io.DataOutput)"><B>write(DataOutput)</B></A> - 
类 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/BlocksWithLocations.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">BlocksWithLocations</A> 中的方法
<DD>serialization method
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/CheckpointCommand.html#write(java.io.DataOutput)"><B>write(DataOutput)</B></A> - 
类 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/CheckpointCommand.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">CheckpointCommand</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/CumulusRecoveryCommand.html#write(java.io.DataOutput)"><B>write(DataOutput)</B></A> - 
类 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/CumulusRecoveryCommand.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">CumulusRecoveryCommand</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/DatanodeRegistration.html#write(java.io.DataOutput)"><B>write(DataOutput)</B></A> - 
类 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/DatanodeRegistration.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">DatanodeRegistration</A> 中的方法
<DD>
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/KeyUpdateCommand.html#write(java.io.DataOutput)"><B>write(DataOutput)</B></A> - 
类 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/KeyUpdateCommand.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">KeyUpdateCommand</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/NamenodeRegistration.html#write(java.io.DataOutput)"><B>write(DataOutput)</B></A> - 
类 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/NamenodeRegistration.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">NamenodeRegistration</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/NamespaceInfo.html#write(java.io.DataOutput)"><B>write(DataOutput)</B></A> - 
类 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/NamespaceInfo.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">NamespaceInfo</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/RCRecoveryCommand.html#write(java.io.DataOutput)"><B>write(DataOutput)</B></A> - 
类 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/RCRecoveryCommand.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">RCRecoveryCommand</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/ReplicaRecoveryInfo.html#write(java.io.DataOutput)"><B>write(DataOutput)</B></A> - 
类 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/ReplicaRecoveryInfo.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">ReplicaRecoveryInfo</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/ServerCommand.html#write(java.io.DataOutput)"><B>write(DataOutput)</B></A> - 
类 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/ServerCommand.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">ServerCommand</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/protocol/UpgradeCommand.html#write(java.io.DataOutput)"><B>write(DataOutput)</B></A> - 
类 org.apache.hadoop.hdfs.server.protocol.<A HREF="./org/apache/hadoop/hdfs/server/protocol/UpgradeCommand.html" title="org.apache.hadoop.hdfs.server.protocol 中的类">UpgradeCommand</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/HdfsConstants.html#WRITE_TIMEOUT"><B>WRITE_TIMEOUT</B></A> - 
接口 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/HdfsConstants.html" title="org.apache.hadoop.hdfs.server.common 中的接口">HdfsConstants</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/HdfsConstants.html#WRITE_TIMEOUT_EXTENSION"><B>WRITE_TIMEOUT_EXTENSION</B></A> - 
接口 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/HdfsConstants.html" title="org.apache.hadoop.hdfs.server.common 中的接口">HdfsConstants</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/common/Storage.html#writeAll()"><B>writeAll()</B></A> - 
类 org.apache.hadoop.hdfs.server.common.<A HREF="./org/apache/hadoop/hdfs/server/common/Storage.html" title="org.apache.hadoop.hdfs.server.common 中的类">Storage</A> 中的方法
<DD>Write all data storage files.
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/metrics/DataNodeMetrics.html#writeBlockOp"><B>writeBlockOp</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.metrics.<A HREF="./org/apache/hadoop/hdfs/server/datanode/metrics/DataNodeMetrics.html" title="org.apache.hadoop.hdfs.server.datanode.metrics 中的类">DataNodeMetrics</A> 中的变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/Block.html#writeId(java.io.DataOutput)"><B>writeId(DataOutput)</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/Block.html" title="org.apache.hadoop.hdfs.protocol 中的类">Block</A> 中的方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.Status.html#writeOutputStream(java.io.OutputStream)"><B>writeOutputStream(OutputStream)</B></A> - 
枚举 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DataTransferProtocol.Status.html" title="org.apache.hadoop.hdfs.protocol 中的枚举">DataTransferProtocol.Status</A> 中的方法
<DD>Write to out
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/metrics/DataNodeMetrics.html#writesFromLocalClient"><B>writesFromLocalClient</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.metrics.<A HREF="./org/apache/hadoop/hdfs/server/datanode/metrics/DataNodeMetrics.html" title="org.apache.hadoop.hdfs.server.datanode.metrics 中的类">DataNodeMetrics</A> 中的变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/server/datanode/metrics/DataNodeMetrics.html#writesFromRemoteClient"><B>writesFromRemoteClient</B></A> - 
类 org.apache.hadoop.hdfs.server.datanode.metrics.<A HREF="./org/apache/hadoop/hdfs/server/datanode/metrics/DataNodeMetrics.html" title="org.apache.hadoop.hdfs.server.datanode.metrics 中的类">DataNodeMetrics</A> 中的变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/DeprecatedUTF8.html#writeString(java.io.DataOutput, java.lang.String)"><B>writeString(DataOutput, String)</B></A> - 
类 org.apache.hadoop.hdfs.<A HREF="./org/apache/hadoop/hdfs/DeprecatedUTF8.html" title="org.apache.hadoop.hdfs 中的类">DeprecatedUTF8</A> 中的静态方法
<DD>&nbsp;
</DL>
<HR>
<A NAME="_X_"><!-- --></A><H2>
<B>X</B></H2>
<DL>
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeInfo.html#xceiverCount"><B>xceiverCount</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/DatanodeInfo.html" title="org.apache.hadoop.hdfs.protocol 中的类">DatanodeInfo</A> 中的变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/CodingMatrix.html#XOR"><B>XOR</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/CodingMatrix.html" title="org.apache.hadoop.hdfs.protocol 中的类">CodingMatrix</A> 中的静态变量
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/XORCoderProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的类"><B>XORCoderProtocol</B></A> - <A HREF="./org/apache/hadoop/hdfs/protocol/package-summary.html">org.apache.hadoop.hdfs.protocol</A> 中的 类<DD>&nbsp;<DT><A HREF="./org/apache/hadoop/hdfs/protocol/XORCoderProtocol.html#XORCoderProtocol(long)"><B>XORCoderProtocol(long)</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/XORCoderProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的类">XORCoderProtocol</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/XORCoderProtocol.html#XORCoderProtocol(byte, byte)"><B>XORCoderProtocol(byte, byte)</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/XORCoderProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的类">XORCoderProtocol</A> 的构造方法
<DD>&nbsp;
<DT><A HREF="./org/apache/hadoop/hdfs/protocol/XORCoderProtocol.html#XORCoderProtocol()"><B>XORCoderProtocol()</B></A> - 
类 org.apache.hadoop.hdfs.protocol.<A HREF="./org/apache/hadoop/hdfs/protocol/XORCoderProtocol.html" title="org.apache.hadoop.hdfs.protocol 中的类">XORCoderProtocol</A> 的构造方法
<DD>&nbsp;
</DL>
<HR>
<A NAME="___"><!-- --></A><H2>
<B>_</B></H2>
<DL>
<DT><A HREF="./org/apache/hadoop/hdfs/server/namenode/HeaderBuffer.html#_instance"><B>_instance</B></A> - 
类 org.apache.hadoop.hdfs.server.namenode.<A HREF="./org/apache/hadoop/hdfs/server/namenode/HeaderBuffer.html" title="org.apache.hadoop.hdfs.server.namenode 中的类">HeaderBuffer</A> 中的静态变量
<DD>&nbsp;
</DL>
<HR>
<A HREF="#_A_">A</A> <A HREF="#_B_">B</A> <A HREF="#_C_">C</A> <A HREF="#_D_">D</A> <A HREF="#_E_">E</A> <A HREF="#_F_">F</A> <A HREF="#_G_">G</A> <A HREF="#_H_">H</A> <A HREF="#_I_">I</A> <A HREF="#_J_">J</A> <A HREF="#_K_">K</A> <A HREF="#_L_">L</A> <A HREF="#_M_">M</A> <A HREF="#_N_">N</A> <A HREF="#_O_">O</A> <A HREF="#_P_">P</A> <A HREF="#_Q_">Q</A> <A HREF="#_R_">R</A> <A HREF="#_S_">S</A> <A HREF="#_T_">T</A> <A HREF="#_U_">U</A> <A HREF="#_V_">V</A> <A HREF="#_W_">W</A> <A HREF="#_X_">X</A> <A HREF="#___">_</A> 

<!-- ======= START OF BOTTOM NAVBAR ====== -->
<A NAME="navbar_bottom"><!-- --></A>
<A HREF="#skip-navbar_bottom" title="跳过导航链接"></A>
<TABLE BORDER="0" WIDTH="100%" CELLPADDING="1" CELLSPACING="0" SUMMARY="">
<TR>
<TD COLSPAN=2 BGCOLOR="#EEEEFF" CLASS="NavBarCell1">
<A NAME="navbar_bottom_firstrow"><!-- --></A>
<TABLE BORDER="0" CELLPADDING="0" CELLSPACING="3" SUMMARY="">
  <TR ALIGN="center" VALIGN="top">
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="./overview-summary.html"><FONT CLASS="NavBarFont1"><B>概述</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <FONT CLASS="NavBarFont1">软件包</FONT>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <FONT CLASS="NavBarFont1">类</FONT>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <FONT CLASS="NavBarFont1">使用</FONT>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="./overview-tree.html"><FONT CLASS="NavBarFont1"><B>树</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="./deprecated-list.html"><FONT CLASS="NavBarFont1"><B>已过时</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#FFFFFF" CLASS="NavBarCell1Rev"> &nbsp;<FONT CLASS="NavBarFont1Rev"><B>索引</B></FONT>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="./help-doc.html"><FONT CLASS="NavBarFont1"><B>帮助</B></FONT></A>&nbsp;</TD>
  </TR>
</TABLE>
</TD>
<TD ALIGN="right" VALIGN="top" ROWSPAN=3><EM>
</EM>
</TD>
</TR>

<TR>
<TD BGCOLOR="white" CLASS="NavBarCell2"><FONT SIZE="-2">
&nbsp;上一个&nbsp;
&nbsp;下一个</FONT></TD>
<TD BGCOLOR="white" CLASS="NavBarCell2"><FONT SIZE="-2">
  <A HREF="./index.html?index-all.html" target="_top"><B>框架</B></A>  &nbsp;
&nbsp;<A HREF="index-all.html" target="_top"><B>无框架</B></A>  &nbsp;
&nbsp;<SCRIPT type="text/javascript">
  <!--
  if(window==top) {
    document.writeln('<A HREF="./allclasses-noframe.html"><B>所有类</B></A>');
  }
  //-->
</SCRIPT>
<NOSCRIPT>
  <A HREF="./allclasses-noframe.html"><B>所有类</B></A>
</NOSCRIPT>


</FONT></TD>
</TR>
</TABLE>
<A NAME="skip-navbar_bottom"></A>
<!-- ======== END OF BOTTOM NAVBAR ======= -->

<HR>
Copyright &copy; 2009 The Apache Software Foundation
</BODY>
</HTML>
